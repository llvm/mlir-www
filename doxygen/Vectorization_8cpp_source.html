<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MLIR: lib/Dialect/Linalg/Transforms/Vectorization.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MLIR
   &#160;<span id="projectnumber">22.0.0git</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_97aefd0d527b934f1d99a682da8fe6a9.html">lib</a></li><li class="navelem"><a class="el" href="dir_1a25ec519b6c1121408b67cc33ce3f15.html">Dialect</a></li><li class="navelem"><a class="el" href="dir_8edb792440615361a0811a7329611599.html">Linalg</a></li><li class="navelem"><a class="el" href="dir_7e2f808e77498894ca0efbd745da2201.html">Transforms</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Vectorization.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="Vectorization_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">//===- Vectorization.cpp - Implementation of linalg Vectorization ---------===//</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.</span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment">// This file implements the linalg dialect Vectorization transformations.</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Dialect_2Affine_2Utils_8h.html">mlir/Dialect/Affine/Utils.h</a>&quot;</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160; </div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="SliceAnalysis_8h.html">mlir/Analysis/SliceAnalysis.h</a>&quot;</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="AffineOps_8h.html">mlir/Dialect/Affine/IR/AffineOps.h</a>&quot;</span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2Arith_2IR_2Arith_8h.html">mlir/Dialect/Arith/IR/Arith.h</a>&quot;</span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="FuncOps_8h.html">mlir/Dialect/Func/IR/FuncOps.h</a>&quot;</span></div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2Linalg_2IR_2Linalg_8h.html">mlir/Dialect/Linalg/IR/Linalg.h</a>&quot;</span></div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2Linalg_2Transforms_2Transforms_8h.html">mlir/Dialect/Linalg/Transforms/Transforms.h</a>&quot;</span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Dialect_2Linalg_2Utils_2Utils_8h.html">mlir/Dialect/Linalg/Utils/Utils.h</a>&quot;</span></div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2Tensor_2IR_2Tensor_8h.html">mlir/Dialect/Tensor/IR/Tensor.h</a>&quot;</span></div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="IndexingUtils_8h.html">mlir/Dialect/Utils/IndexingUtils.h</a>&quot;</span></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="StructuredOpsUtils_8h.html">mlir/Dialect/Utils/StructuredOpsUtils.h</a>&quot;</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="VectorOps_8h.html">mlir/Dialect/Vector/IR/VectorOps.h</a>&quot;</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="MaskableOpInterface_8h.html">mlir/Dialect/Vector/Interfaces/MaskableOpInterface.h</a>&quot;</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="VectorUtils_8h.html">mlir/Dialect/Vector/Utils/VectorUtils.h</a>&quot;</span></div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2IR_2AffineExpr_8h.html">mlir/IR/AffineExpr.h</a>&quot;</span></div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2IR_2AffineMap_8h.html">mlir/IR/AffineMap.h</a>&quot;</span></div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Builders_8h.html">mlir/IR/Builders.h</a>&quot;</span></div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="BuiltinTypeInterfaces_8h.html">mlir/IR/BuiltinTypeInterfaces.h</a>&quot;</span></div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2IR_2BuiltinTypes_8h.html">mlir/IR/BuiltinTypes.h</a>&quot;</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="OpDefinition_8h.html">mlir/IR/OpDefinition.h</a>&quot;</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="PatternMatch_8h.html">mlir/IR/PatternMatch.h</a>&quot;</span></div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Value_8h.html">mlir/IR/Value.h</a>&quot;</span></div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2Support_2LLVM_8h.html">mlir/Support/LLVM.h</a>&quot;</span></div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="RegionUtils_8h.html">mlir/Transforms/RegionUtils.h</a>&quot;</span></div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="preprocessor">#include &quot;llvm/ADT/STLExtras.h&quot;</span></div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="preprocessor">#include &quot;llvm/ADT/Sequence.h&quot;</span></div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="preprocessor">#include &quot;llvm/ADT/SmallVector.h&quot;</span></div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="preprocessor">#include &quot;llvm/ADT/TypeSwitch.h&quot;</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="preprocessor">#include &quot;llvm/Support/DebugLog.h&quot;</span></div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="preprocessor">#include &quot;llvm/Support/InterleavedRange.h&quot;</span></div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="preprocessor">#include &quot;llvm/Support/MathExtras.h&quot;</span></div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="preprocessor">#include &quot;llvm/Support/raw_ostream.h&quot;</span></div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="preprocessor">#include &lt;optional&gt;</span></div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160; </div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="keyword">using namespace </span><a class="code" href="namespacemlir.html">mlir</a>;</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="keyword">using namespace </span><a class="code" href="namespacemlir_1_1linalg.html">mlir::linalg</a>;</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160; </div>
<div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ad78e062f62e0d6e453941fb4ca843e4d">   50</a></span>&#160;<span class="preprocessor">#define DEBUG_TYPE &quot;linalg-vectorization&quot;</span></div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="comment">/// Try to vectorize `convOp` as a convolution.</span></div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="comment"></span><span class="keyword">static</span> FailureOr&lt;Operation *&gt;</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<a class="code" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, LinalgOp convOp,</div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;                     <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVecSizes = {},</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;                     <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputVecScalableFlags = {},</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;                     <span class="keywordtype">bool</span> flatten1DDepthwiseConv = <span class="keyword">false</span>);</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="comment">/// Vectorize tensor::InsertSliceOp with:</span></div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="comment">///   * vector::TransferReadOp + vector::TransferWriteOp</span></div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment">/// The vector sizes are either:</span></div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment">///   * user-provided in `inputVectorSizes`, or</span></div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment">///   * inferred from the static dims in the input and output tensors.</span></div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">/// Bails out if:</span></div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment">///   * vector sizes are not user-provided, and</span></div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="comment">///   * at least one dim is dynamic (in both the input and output tensors).</span></div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment">/// Before:</span></div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="comment">///     !t_in_type = tensor&lt;1x2x3xf32&gt;</span></div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="comment">///     !t_out_type = tensor&lt;9x8x7x1x2x3xf32&gt;</span></div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;<span class="comment">///     !v_type = vector&lt;1x2x3xf32&gt;</span></div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="comment">///     %inserted_slice = tensor.insert_slice %src into %dest ... : !t_in_type</span></div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment">///     into !t_out_type</span></div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment">/// After:</span></div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;<span class="comment">///     %read = vector.transfer_read %src[...], %pad ... : !t_in_type, !v_type</span></div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;<span class="comment">///     %write = vector.transfer_write %read, %dest ... : !v_type, !t_out_type</span></div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="comment"></span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<a class="code" href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926">vectorizeAsInsertSliceOp</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, tensor::InsertSliceOp sliceOp,</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;                         <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;                         <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults);</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="comment">/// Returns the effective Pad value for the input op, provided it&#39;s a scalar.</span></div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="comment">/// Many Ops exhibit pad-like behaviour, but this isn&#39;t always explicit. If</span></div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;<span class="comment">/// this Op performs padding, retrieve the padding value provided that it&#39;s</span></div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;<span class="comment">/// a scalar and static/fixed for all the padded values. Returns an empty value</span></div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;<span class="comment">/// otherwise.</span></div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classmlir_1_1Value.html">Value</a> <a class="code" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op);</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;<span class="comment">/// Return the unique instance of OpType in `block` if it is indeed unique.</span></div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;<span class="comment">/// Return null if none or more than 1 instances exist.</span></div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="comment"></span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> OpType&gt;</div>
<div class="line"><a name="l00093"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ab37ae3178304b744d6b0249a60a6e7a3">   93</a></span>&#160;<span class="keyword">static</span> OpType <a class="code" href="Vectorization_8cpp.html#ab37ae3178304b744d6b0249a60a6e7a3">getSingleOpOfType</a>(<a class="code" href="classmlir_1_1Block.html">Block</a> &amp;block) {</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;  OpType res;</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;  block.<a class="code" href="classmlir_1_1Block.html#a790af2827870ed217e85447b8ed8559c">walk</a>([&amp;](OpType op) {</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;    <span class="keywordflow">if</span> (res) {</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;      res = <span class="keyword">nullptr</span>;</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1WalkResult.html#abab80dca5987e18f9abf08162cd3faaa">WalkResult::interrupt</a>();</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;    }</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    res = op;</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1WalkResult.html#a97a7015a793bb5d2a97f08e358f42797">WalkResult::advance</a>();</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;  });</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;  <span class="keywordflow">return</span> res;</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;}</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;<span class="comment">/// Helper function to extract the input slices after filter is unrolled along</span></div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;<span class="comment">/// kw.</span></div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a></div>
<div class="line"><a name="l00109"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a41a2f2306467feacee5865c5be9c0401">  109</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a41a2f2306467feacee5865c5be9c0401">extractConvInputSlices</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Location.html">Location</a> loc, <a class="code" href="classmlir_1_1Value.html">Value</a> input,</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;                       int64_t nSize, int64_t wSize, int64_t cSize,</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;                       int64_t kwSize, <span class="keywordtype">int</span> strideW, <span class="keywordtype">int</span> dilationW,</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;                       int64_t wSizeStep, <span class="keywordtype">bool</span> isSingleChanneled) {</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> result;</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;  <span class="keywordflow">if</span> (isSingleChanneled) {</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;    <span class="comment">// Extract input slice of size {wSizeStep} @ [w + kw] for non-channeled</span></div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    <span class="comment">// convolution.</span></div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> sizes = {wSizeStep};</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1};</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;      <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;        result.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;            rewriter, loc, input, <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{w + kw}, sizes,</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;            strides));</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;      }</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;    }</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;  } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;    <span class="comment">// Extract lhs slice of size {n, wSizeStep, c} @ [0, sw * w + dw * kw, 0]</span></div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;    <span class="comment">// for channeled convolution.</span></div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> sizes = {nSize, wSizeStep, cSize};</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1, 1, 1};</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;      <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;        result.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;            rewriter, loc, input,</div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;            <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{0, w * strideW + kw * dilationW, 0},</div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;            sizes, strides));</div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;      }</div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;    }</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;  }</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;  <span class="keywordflow">return</span> result;</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;}</div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;<span class="comment">/// Helper function to extract the filter slices after filter is unrolled along</span></div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;<span class="comment">/// kw.</span></div>
<div class="line"><a name="l00145"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a313dd728e35dcd639ff665bcc97d81ad">  145</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> <a class="code" href="Vectorization_8cpp.html#a313dd728e35dcd639ff665bcc97d81ad">extractConvFilterSlices</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;                                                  <a class="code" href="classmlir_1_1Location.html">Location</a> loc, <a class="code" href="classmlir_1_1Value.html">Value</a> filter,</div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;                                                  int64_t kwSize) {</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> result;</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;  <span class="comment">// Extract rhs slice of size [{c, f} for channeled convolutions and {1} for</span></div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;  <span class="comment">// non-chanelled convolution] @ [kw].</span></div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;  <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;    result.push_back(vector::ExtractOp::create(</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;        rewriter, loc, filter, <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{kw}));</div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;  }</div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;  <span class="keywordflow">return</span> result;</div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;}</div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment">/// Helper function to extract the result slices after filter is unrolled along</span></div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="comment">/// kw.</span></div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a></div>
<div class="line"><a name="l00161"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#abe4a6208d725462b6ab07ee8310da2f1">  161</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#abe4a6208d725462b6ab07ee8310da2f1">extractConvResultSlices</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Location.html">Location</a> loc, <a class="code" href="classmlir_1_1Value.html">Value</a> res,</div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;                        int64_t nSize, int64_t wSize, int64_t fSize,</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;                        int64_t wSizeStep, <span class="keywordtype">bool</span> isSingleChanneled) {</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> result;</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;  <span class="keywordflow">if</span> (isSingleChanneled) {</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;    <span class="comment">// Extract res slice: {wSizeStep} @ [w] for non-channeled convolution.</span></div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> sizes = {wSizeStep};</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1};</div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;    <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;      result.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;          rewriter, loc, res, <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{w}, sizes,</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;          strides));</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;    }</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;  } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;    <span class="comment">// Extract res slice: {n, wSizeStep, f} @ [0, w, 0] for channeled</span></div>
<div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;    <span class="comment">// convolution.</span></div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> sizes = {nSize, wSizeStep, fSize};</div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1, 1, 1};</div>
<div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;    <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;      result.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;          rewriter, loc, res, <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{0, w, 0}, sizes,</div>
<div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;          strides));</div>
<div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;    }</div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;  }</div>
<div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;  <span class="keywordflow">return</span> result;</div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;}</div>
<div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;<span class="comment">/// Helper function to insert the computed result slices.</span></div>
<div class="line"><a name="l00189"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a110d1ed6891097419f0358bd63e974c8">  189</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classmlir_1_1Value.html">Value</a> <a class="code" href="Vectorization_8cpp.html#a110d1ed6891097419f0358bd63e974c8">insertConvResultSlices</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Location.html">Location</a> loc,</div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;                                    <a class="code" href="classmlir_1_1Value.html">Value</a> res, int64_t wSize, int64_t wSizeStep,</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;                                    <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;resVals,</div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;                                    <span class="keywordtype">bool</span> isSingleChanneled) {</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160; </div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;  <span class="keywordflow">if</span> (isSingleChanneled) {</div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;    <span class="comment">// Write back res slice: {wSizeStep} @ [w] for non-channeled convolution.</span></div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;    <span class="comment">// This does not depend on kw.</span></div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1};</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;    <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;      res = vector::InsertStridedSliceOp::create(</div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;          rewriter, loc, resVals[w], res, <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{w},</div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;          strides);</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;    }</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;  } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;    <span class="comment">// Write back res slice: {n, wSizeStep, f} @ [0, w, 0] for channeled</span></div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;    <span class="comment">// convolution. This does not depend on kw.</span></div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1, 1, 1};</div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;    <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;      res = vector::InsertStridedSliceOp::create(</div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;          rewriter, loc, resVals[w], res,</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;          <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{0, w, 0}, strides);</div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;    }</div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;  }</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;  <span class="keywordflow">return</span> res;</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;}</div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;<span class="comment">/// Contains the vectorization state and related methods used across the</span></div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;<span class="comment">/// vectorization process of a given operation.</span></div>
<div class="line"><a name="l00218"></a><span class="lineno"><a class="line" href="structVectorizationState.html">  218</a></span>&#160;<span class="comment"></span><span class="keyword">struct </span><a class="code" href="structVectorizationState.html">VectorizationState</a> {</div>
<div class="line"><a name="l00219"></a><span class="lineno"><a class="line" href="structVectorizationState.html#ac46e33dfa27baf34825d041264c2fd9c">  219</a></span>&#160;  <a class="code" href="structVectorizationState.html#ac46e33dfa27baf34825d041264c2fd9c">VectorizationState</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter) : rewriterGuard(rewriter) {}</div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;<span class="comment">  /// Initializes the vectorization state, including the computation of the</span></div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;<span class="comment">  /// canonical vector shape for vectorization.</span></div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;<span class="comment"></span>  LogicalResult initState(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, LinalgOp linalgOp,</div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;                          <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;                          <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputScalableVecDims,</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;                          <span class="keywordtype">bool</span> assumeDynamicDimsMatchVecSizes = <span class="keyword">false</span>);</div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;<span class="comment">  /// Returns the canonical vector shape used to vectorize the iteration space.</span></div>
<div class="line"><a name="l00229"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a62f8a62afd86fa2984ca7c4ad23904b4">  229</a></span>&#160;<span class="comment"></span>  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> <a class="code" href="structVectorizationState.html#a62f8a62afd86fa2984ca7c4ad23904b4">getCanonicalVecShape</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> canonicalVecShape; }</div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;<span class="comment">  /// Returns the vector dimensions that are scalable in the canonical vector</span></div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;<span class="comment">  /// shape.</span></div>
<div class="line"><a name="l00233"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a0ac270c1aef44b0633eb6a4f3e2aa071">  233</a></span>&#160;<span class="comment"></span>  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> <a class="code" href="structVectorizationState.html#a0ac270c1aef44b0633eb6a4f3e2aa071">getScalableVecDims</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> scalableVecDims; }</div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;<span class="comment">  /// Returns a vector type of the provided `elementType` with the canonical</span></div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;<span class="comment">  /// vector shape and the corresponding fixed/scalable dimensions bit. If</span></div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="comment">  /// `dimPermutation` is provided, the canonical vector dimensions are permuted</span></div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;<span class="comment">  /// accordingly.</span></div>
<div class="line"><a name="l00239"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a5b0655951fd32179a5cfbd895109fd7a">  239</a></span>&#160;<span class="comment"></span>  VectorType <a class="code" href="structVectorizationState.html#a5b0655951fd32179a5cfbd895109fd7a">getCanonicalVecType</a>(</div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;      <a class="code" href="classmlir_1_1Type.html">Type</a> elementType,</div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;      std::optional&lt;AffineMap&gt; dimPermutation = std::nullopt)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> <a class="code" href="PolynomialApproximation_8cpp.html#a42d8a93cefd0d3e87b43de975bfd31bc">vectorShape</a>;</div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> scalableDims;</div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;    <span class="keywordflow">if</span> (dimPermutation.has_value()) {</div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;      <a class="code" href="PolynomialApproximation_8cpp.html#a42d8a93cefd0d3e87b43de975bfd31bc">vectorShape</a> =</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;          applyPermutationMap&lt;int64_t&gt;(*dimPermutation, canonicalVecShape);</div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;      scalableDims =</div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;          applyPermutationMap&lt;bool&gt;(*dimPermutation, scalableVecDims);</div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;    } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;      <a class="code" href="PolynomialApproximation_8cpp.html#a42d8a93cefd0d3e87b43de975bfd31bc">vectorShape</a>.append(canonicalVecShape.begin(), canonicalVecShape.end());</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;      scalableDims.append(scalableVecDims.begin(), scalableVecDims.end());</div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;    }</div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160; </div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(<a class="code" href="PolynomialApproximation_8cpp.html#a42d8a93cefd0d3e87b43de975bfd31bc">vectorShape</a>, elementType, scalableDims);</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;  }</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;<span class="comment">  /// Masks an operation with the canonical vector mask if the operation needs</span></div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;<span class="comment">  /// masking. Returns the masked operation or the original operation if masking</span></div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;<span class="comment">  /// is not needed. If provided, the canonical mask for this operation is</span></div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;<span class="comment">  /// permuted using `maybeIndexingMap`.</span></div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;  <a class="code" href="namespacemlir_1_1vector.html#a4f68d86708480673ecc59b2714973a65">maskOperation</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *opToMask, LinalgOp linalgOp,</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;                std::optional&lt;AffineMap&gt; maybeIndexingMap = std::nullopt);</div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160; </div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;<span class="keyword">private</span>:<span class="comment"></span></div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;<span class="comment">  /// Initializes the iteration space static sizes using the Linalg op</span></div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;<span class="comment">  /// information. This may become more complicated in the future.</span></div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;<span class="comment"></span>  <span class="keywordtype">void</span> initIterSpaceStaticSizes(LinalgOp linalgOp) {</div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;    iterSpaceStaticSizes.append(linalgOp.getStaticLoopRanges());</div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;  }</div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;<span class="comment">  /// Generates &#39;arith.constant&#39; and &#39;tensor/memref.dim&#39; operations for</span></div>
<div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;<span class="comment">  /// all the static and dynamic dimensions of the iteration space to be</span></div>
<div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;<span class="comment">  /// vectorized and store them in `iterSpaceValueSizes`.</span></div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;<span class="comment"></span>  LogicalResult precomputeIterSpaceValueSizes(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;                                              LinalgOp linalgOp);</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;<span class="comment">  /// Create or retrieve an existing mask value to mask `opToMask` in the</span></div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;<span class="comment">  /// canonical vector iteration space. If `maybeMaskingMap` the mask is</span></div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;<span class="comment">  /// permuted using that permutation map. If a new mask is created, it will be</span></div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;<span class="comment">  /// cached for future users.</span></div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1Value.html">Value</a> getOrCreateMaskFor(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *opToMask,</div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;                           LinalgOp linalgOp,</div>
<div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;                           std::optional&lt;AffineMap&gt; maybeMaskingMap);</div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;<span class="comment">  /// Check whether this permutation map can be used for masking. At the</span></div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;<span class="comment">  /// moment we only make sure that there are no broadcast dimensions, but this</span></div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;<span class="comment">  /// might change if indexing maps evolve.</span></div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> isValidMaskingMap(<a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> maskingMap) {</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;    <span class="keywordflow">return</span> maskingMap.<a class="code" href="classmlir_1_1AffineMap.html#acf141c61521d9a40ba68c0b350a31836">getBroadcastDims</a>().size() == 0;</div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;  }</div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;<span class="comment">  /// Turn the input indexing map into a valid masking map.</span></div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;<span class="comment">  ///</span></div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;<span class="comment">  /// The input indexing map may contain &quot;zero&quot; results, e.g.:</span></div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;<span class="comment">  ///    (d0, d1, d2, d3) -&gt; (d2, d1, d0, 0)</span></div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;<span class="comment">  /// Applying such maps to canonical vector shapes like this one:</span></div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;<span class="comment">  ///    (1, 16, 16, 4)</span></div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;<span class="comment">  /// would yield an invalid vector shape like this:</span></div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;<span class="comment">  ///    (16, 16, 1, 0)</span></div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;<span class="comment">  /// Instead, drop the broadcasting dims that make no sense for masking perm.</span></div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;<span class="comment">  /// maps:</span></div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;<span class="comment">  ///    (d0, d1, d2, d3) -&gt; (d2, d1, d0)</span></div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;<span class="comment">  /// This way, the corresponding vector/mask type will be:</span></div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;<span class="comment">  ///    vector&lt;16x16x1xty&gt;</span></div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;<span class="comment">  /// rather than this invalid Vector type:</span></div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;<span class="comment">  ///    vector&lt;16x16x1x0xty&gt;</span></div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> getMaskingMapFromIndexingMap(<a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> &amp;indexingMap) {</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;    <span class="keywordflow">return</span> indexingMap.<a class="code" href="classmlir_1_1AffineMap.html#ac8532830efc67348905fd1e414beaebb">dropZeroResults</a>();</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;  }</div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160; </div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;  <span class="comment">// Holds the compile-time static sizes of the iteration space to vectorize.</span></div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;  <span class="comment">// Dynamic dimensions are represented using ShapedType::kDynamic.</span></div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> iterSpaceStaticSizes;</div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;<span class="comment">  /// Holds the value sizes of the iteration space to vectorize. Static</span></div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;<span class="comment">  /// dimensions are represented by &#39;arith.constant&#39; and dynamic</span></div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;<span class="comment">  /// dimensions by &#39;tensor/memref.dim&#39;.</span></div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;<span class="comment"></span>  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> iterSpaceValueSizes;</div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;<span class="comment">  /// Holds the canonical vector shape used to vectorize the iteration space.</span></div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;<span class="comment"></span>  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> canonicalVecShape;</div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;<span class="comment">  /// Holds the vector dimensions that are scalable in the canonical vector</span></div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;<span class="comment">  /// shape.</span></div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;<span class="comment"></span>  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> scalableVecDims;</div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;<span class="comment">  /// Holds the active masks for permutations of the canonical vector iteration</span></div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;<span class="comment">  /// space.</span></div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;<span class="comment"></span>  <a class="code" href="classllvm_1_1DenseMap.html">DenseMap&lt;AffineMap, Value&gt;</a> activeMaskCache;</div>
<div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;<span class="comment">  /// Global vectorization guard for the incoming rewriter. It&#39;s initialized</span></div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;<span class="comment">  /// when the vectorization state is initialized.</span></div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1OpBuilder_1_1InsertionGuard.html">OpBuilder::InsertionGuard</a> rewriterGuard;</div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;<span class="comment">  /// Do all dynamic dims match the corresponding vector sizes?</span></div>
<div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;<span class="comment">  ///</span></div>
<div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;<span class="comment">  /// When a dynamic tensor/memref dimension matches the corresponding vector</span></div>
<div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;<span class="comment">  /// dimension, masking can be safely skipped, despite the presence of dynamic</span></div>
<div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;<span class="comment">  /// shapes. Use this flag with care and only for cases where you are</span></div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;<span class="comment">  /// confident the assumption holds.</span></div>
<div class="line"><a name="l00342"></a><span class="lineno"><a class="line" href="structVectorizationHookResult.html#a325ec6cd37d3dcf718897f5e68a37b91">  342</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> assumeDynamicDimsMatchVecSizes = <span class="keyword">false</span>;</div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;};</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160; </div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;LogicalResult</div>
<div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;VectorizationState::precomputeIterSpaceValueSizes(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;                                                  LinalgOp linalgOp) {</div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;  <span class="comment">// TODO: Support 0-d vectors.</span></div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> vecDim = 0, end = canonicalVecShape.size(); vecDim &lt; end; ++vecDim) {</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;    <span class="keywordflow">if</span> (ShapedType::isStatic(iterSpaceStaticSizes[vecDim])) {</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;      <span class="comment">// Create constant index op for static dimensions.</span></div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;      iterSpaceValueSizes.push_back(<a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;          rewriter, linalgOp.getLoc(), iterSpaceStaticSizes[vecDim]));</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;      <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;    }</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160; </div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;    <span class="comment">// Find an operand defined on this dimension of the iteration space to</span></div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;    <span class="comment">// extract the runtime dimension size.</span></div>
<div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> operand;</div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;    <span class="keywordtype">unsigned</span> operandDimPos;</div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;    <span class="keywordflow">if</span> (failed(linalgOp.mapIterationSpaceDimToOperandDim(vecDim, operand,</div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;                                                         operandDimPos)))</div>
<div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160; </div>
<div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> dynamicDim =</div>
<div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;        linalgOp.hasPureTensorSemantics()</div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;            ? (<a class="code" href="classmlir_1_1Value.html">Value</a>)tensor::DimOp::create(rewriter, linalgOp.getLoc(), operand,</div>
<div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;                                           operandDimPos)</div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;            : (<a class="code" href="classmlir_1_1Value.html">Value</a>)memref::DimOp::create(rewriter, linalgOp.getLoc(), operand,</div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;                                           operandDimPos);</div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;    iterSpaceValueSizes.push_back(dynamicDim);</div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;  }</div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160; </div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;}</div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;<span class="comment">/// Initializes the vectorization state, including the computation of the</span></div>
<div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;<span class="comment">/// canonical vector shape for vectorization.</span></div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;<span class="comment"></span><span class="comment">// TODO: Move this to the constructor when we can remove the failure cases.</span></div>
<div class="line"><a name="l00380"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a18a5831810f1beae1d2f37fb9f711b18">  380</a></span>&#160;LogicalResult <a class="code" href="structVectorizationState.html#a18a5831810f1beae1d2f37fb9f711b18">VectorizationState::initState</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;                                            LinalgOp linalgOp,</div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;                                            <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;                                            <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputScalableVecDims,</div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;                                            <span class="keywordtype">bool</span> assumeDimsMatchVec) {</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;  assumeDynamicDimsMatchVecSizes = assumeDimsMatchVec;</div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;  <span class="comment">// Initialize the insertion point.</span></div>
<div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;  rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(linalgOp);</div>
<div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160; </div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;  <span class="keywordflow">if</span> (!inputVectorSizes.empty()) {</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;    <span class="comment">// Get the canonical vector shape from the input vector sizes provided. This</span></div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;    <span class="comment">// path should be taken to vectorize code with dynamic shapes and when using</span></div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;    <span class="comment">// vector sizes greater than the iteration space sizes.</span></div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;    canonicalVecShape.append(inputVectorSizes.begin(), inputVectorSizes.end());</div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;    scalableVecDims.append(inputScalableVecDims.begin(),</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;                           inputScalableVecDims.end());</div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;  } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;    <span class="comment">// Compute the canonical vector shape from the operation shape. If there are</span></div>
<div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;    <span class="comment">// dynamic shapes, the operation won&#39;t be vectorized. We assume all the</span></div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;    <span class="comment">// vector dimensions are fixed.</span></div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;    canonicalVecShape = linalgOp.getStaticLoopRanges();</div>
<div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;    scalableVecDims.append(linalgOp.getNumLoops(), <span class="keyword">false</span>);</div>
<div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;  }</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160; </div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Canonical vector shape: &quot;</span> &lt;&lt; llvm::interleaved(canonicalVecShape);</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Scalable vector dims: &quot;</span> &lt;&lt; llvm::interleaved(scalableVecDims);</div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160; </div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;  <span class="keywordflow">if</span> (ShapedType::isDynamicShape(canonicalVecShape))</div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160; </div>
<div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;  <span class="comment">// Initialize iteration space static sizes.</span></div>
<div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;  initIterSpaceStaticSizes(linalgOp);</div>
<div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160; </div>
<div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;  <span class="comment">// Generate &#39;arith.constant&#39; and &#39;tensor/memref.dim&#39; operations for</span></div>
<div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;  <span class="comment">// all the static and dynamic dimensions of the iteration space, needed to</span></div>
<div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;  <span class="comment">// compute a mask during vectorization.</span></div>
<div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;  <span class="keywordflow">if</span> (failed(precomputeIterSpaceValueSizes(rewriter, linalgOp)))</div>
<div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160; </div>
<div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;}</div>
<div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;<span class="comment">/// Create or retrieve an existing mask value to mask `opToMask` in the</span></div>
<div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;<span class="comment">/// canonical vector iteration space. If `maybeMaskingMap` the mask is permuted</span></div>
<div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;<span class="comment">/// using that permutation map. If a new mask is created, it will be cached for</span></div>
<div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;<span class="comment">/// future users.</span></div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="comment"></span><a class="code" href="classmlir_1_1Value.html">Value</a> VectorizationState::getOrCreateMaskFor(</div>
<div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;    <a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *opToMask, LinalgOp linalgOp,</div>
<div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;    std::optional&lt;AffineMap&gt; maybeMaskingMap) {</div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160; </div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;  assert((!maybeMaskingMap || isValidMaskingMap(*maybeMaskingMap)) &amp;&amp;</div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;         <span class="stringliteral">&quot;Ill-formed masking map.&quot;</span>);</div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160; </div>
<div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;  <span class="comment">// No mask is needed if the operation is not maskable.</span></div>
<div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;  <span class="keyword">auto</span> maskableOp = dyn_cast&lt;vector::MaskableOpInterface&gt;(opToMask);</div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;  <span class="keywordflow">if</span> (!maskableOp)</div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1Value.html">Value</a>();</div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160; </div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;  assert(!maskableOp.isMasked() &amp;&amp;</div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;         <span class="stringliteral">&quot;Masking an operation that is already masked&quot;</span>);</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160; </div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;  <span class="comment">// If no masking map was provided, use an identity map with the loop dims.</span></div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;  assert((!maybeMaskingMap || *maybeMaskingMap) &amp;&amp;</div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;         <span class="stringliteral">&quot;Unexpected null mask permutation map&quot;</span>);</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;  <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> maskingMap =</div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;      maybeMaskingMap ? *maybeMaskingMap</div>
<div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;                      : <a class="code" href="classmlir_1_1AffineMap.html#a39ed2c2a4c743450a4a999fa6db1bf84">AffineMap::getMultiDimIdentityMap</a>(</div>
<div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;                            linalgOp.getNumLoops(), rewriter.<a class="code" href="classmlir_1_1Builder.html#aa6d1e114c8047cad1b014b504688a868">getContext</a>());</div>
<div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160; </div>
<div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Masking map: &quot;</span> &lt;&lt; maskingMap;</div>
<div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160; </div>
<div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;  <span class="comment">// Return the active mask for the masking map of this operation if it was</span></div>
<div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;  <span class="comment">// already created.</span></div>
<div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;  <span class="keyword">auto</span> activeMaskIt = activeMaskCache.find(maskingMap);</div>
<div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;  <span class="keywordflow">if</span> (activeMaskIt != activeMaskCache.end()) {</div>
<div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> mask = activeMaskIt-&gt;second;</div>
<div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Reusing mask: &quot;</span> &lt;&lt; mask;</div>
<div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;    <span class="keywordflow">return</span> mask;</div>
<div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;  }</div>
<div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160; </div>
<div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;  <span class="comment">// Compute permuted projection of the iteration space to be masked and the</span></div>
<div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;  <span class="comment">// corresponding mask shape. If the resulting iteration space dimensions are</span></div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;  <span class="comment">// static and identical to the mask shape, masking is not needed for this</span></div>
<div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;  <span class="comment">// operation.</span></div>
<div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;  <span class="comment">// TODO: Improve this check. Only projected permutation indexing maps are</span></div>
<div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;  <span class="comment">// supported.</span></div>
<div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> permutedStaticSizes =</div>
<div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;      applyPermutationMap&lt;int64_t&gt;(maskingMap, iterSpaceStaticSizes);</div>
<div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;  <span class="keyword">auto</span> maskType = getCanonicalVecType(rewriter.<a class="code" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>(), maskingMap);</div>
<div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;  <span class="keyword">auto</span> maskShape = maskType.getShape();</div>
<div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160; </div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Mask shape: &quot;</span> &lt;&lt; llvm::interleaved(maskShape);</div>
<div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160; </div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;  <span class="keywordflow">if</span> (permutedStaticSizes == maskShape) {</div>
<div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Masking is not needed for masking map: &quot;</span> &lt;&lt; maskingMap;</div>
<div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;    activeMaskCache[maskingMap] = <a class="code" href="classmlir_1_1Value.html">Value</a>();</div>
<div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1Value.html">Value</a>();</div>
<div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;  }</div>
<div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160; </div>
<div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;  <span class="keywordflow">if</span> (assumeDynamicDimsMatchVecSizes) {</div>
<div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;    <span class="comment">// While for _dynamic_ dim sizes we can _assume_ that the corresponding</span></div>
<div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;    <span class="comment">// vector sizes match, we still need to check the _static_ dim sizes. Only</span></div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;    <span class="comment">// then we can be 100% sure that masking is not required.</span></div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;    <span class="keywordflow">if</span> (llvm::all_of(llvm::zip(permutedStaticSizes, maskType.getShape()),</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;                     [](<span class="keyword">auto</span> it) {</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;                       return std::get&lt;0&gt;(it) == ShapedType::kDynamic</div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;                                  ? true</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;                                  : std::get&lt;0&gt;(it) == std::get&lt;1&gt;(it);</div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;                     })) {</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;      LDBG()</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;          &lt;&lt; <span class="stringliteral">&quot;Dynamic + static dimensions match vector sizes, masking is not &quot;</span></div>
<div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;             <span class="stringliteral">&quot;required.&quot;</span>;</div>
<div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;      activeMaskCache[maskingMap] = <a class="code" href="classmlir_1_1Value.html">Value</a>();</div>
<div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1Value.html">Value</a>();</div>
<div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;    }</div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;  }</div>
<div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160; </div>
<div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;  <span class="comment">// Permute the iteration space value sizes to compute the mask upper bounds.</span></div>
<div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> upperBounds =</div>
<div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;      <a class="code" href="namespacemlir.html#a2b76f177cd65bd4fd394f9dc65d20be2">applyPermutationMap</a>(maskingMap, <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;Value&gt;</a>(iterSpaceValueSizes));</div>
<div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;  assert(!maskShape.empty() &amp;&amp; !upperBounds.empty() &amp;&amp;</div>
<div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;         <span class="stringliteral">&quot;Masked 0-d vectors are not supported yet&quot;</span>);</div>
<div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160; </div>
<div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;  <span class="comment">// Create the mask based on the dimension values.</span></div>
<div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> mask = vector::CreateMaskOp::create(rewriter, linalgOp.getLoc(),</div>
<div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;                                            maskType, upperBounds);</div>
<div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Creating new mask: &quot;</span> &lt;&lt; mask;</div>
<div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;  activeMaskCache[maskingMap] = mask;</div>
<div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;  <span class="keywordflow">return</span> mask;</div>
<div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;}</div>
<div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160; </div>
<div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;<a class="code" href="classmlir_1_1Operation.html">Operation</a> *</div>
<div class="line"><a name="l00512"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a37816d928cc471a94c6ec113f60969a2">  512</a></span>&#160;<a class="code" href="namespacemlir_1_1vector.html#a4f68d86708480673ecc59b2714973a65">VectorizationState::maskOperation</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *opToMask,</div>
<div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;                                  LinalgOp linalgOp,</div>
<div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;                                  std::optional&lt;AffineMap&gt; maybeIndexingMap) {</div>
<div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Trying to mask: &quot;</span> &lt;&lt; *opToMask;</div>
<div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160; </div>
<div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;  std::optional&lt;AffineMap&gt; maybeMaskingMap = std::nullopt;</div>
<div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;  <span class="keywordflow">if</span> (maybeIndexingMap)</div>
<div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;    maybeMaskingMap = getMaskingMapFromIndexingMap(*maybeIndexingMap);</div>
<div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160; </div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;  <span class="comment">// Create or retrieve mask for this operation.</span></div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> mask =</div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;      getOrCreateMaskFor(rewriter, opToMask, linalgOp, maybeMaskingMap);</div>
<div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160; </div>
<div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;  <span class="keywordflow">if</span> (!mask) {</div>
<div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;No mask required&quot;</span>;</div>
<div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;    <span class="keywordflow">return</span> opToMask;</div>
<div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;  }</div>
<div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160; </div>
<div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;  <span class="comment">// Wrap the operation with a new `vector.mask` and update D-U chain.</span></div>
<div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;  assert(opToMask &amp;&amp; <span class="stringliteral">&quot;Expected a valid operation to mask&quot;</span>);</div>
<div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;  <span class="keyword">auto</span> maskOp = cast&lt;vector::MaskOp&gt;(</div>
<div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;      <a class="code" href="namespacemlir_1_1vector.html#a4f68d86708480673ecc59b2714973a65">mlir::vector::maskOperation</a>(rewriter, opToMask, mask));</div>
<div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *maskOpTerminator = &amp;maskOp.getMaskRegion().front().back();</div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160; </div>
<div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [resIdx, resVal] : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">llvm::enumerate</a>(opToMask-&gt;<a class="code" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>()))</div>
<div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a9bc0bf42591d2bf716733ed23bb8b6e6">replaceAllUsesExcept</a>(resVal, maskOp.getResult(resIdx),</div>
<div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;                                  maskOpTerminator);</div>
<div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160; </div>
<div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Masked operation: &quot;</span> &lt;&lt; *maskOp;</div>
<div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;  <span class="keywordflow">return</span> maskOp;</div>
<div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;}</div>
<div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;<span class="comment">/// Given an indexing `map` coming from a LinalgOp indexing, restricted to a</span></div>
<div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;<span class="comment">/// projectedPermutation, compress the unused dimensions to serve as a</span></div>
<div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;<span class="comment">/// permutation_map for a vector transfer operation.</span></div>
<div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;<span class="comment">/// For example, given a linalg op such as:</span></div>
<div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;<span class="comment">///   %0 = linalg.generic {</span></div>
<div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;<span class="comment">///        indexing_maps = affine_map&lt;(d0, d1, d2, d3, d4) -&gt; (d4, d0, d2)&gt;,</span></div>
<div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;<span class="comment">///        indexing_maps = affine_map&lt;(d0, d1, d2, d3, d4) -&gt; (d1, d3)&gt;</span></div>
<div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;<span class="comment">///      }</span></div>
<div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;<span class="comment">///     ins(%0 : tensor&lt;2x3x4xf32&gt;)</span></div>
<div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;<span class="comment">///    outs(%1 : tensor&lt;5x6xf32&gt;)</span></div>
<div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;<span class="comment">/// the iteration domain size of the linalg op is 3x5x4x6x2. The first affine</span></div>
<div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;<span class="comment">/// map is reindexed to `affine_map&lt;(d0, d1, d2) -&gt; (d2, d0, d1)&gt;`, the second</span></div>
<div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;<span class="comment">/// affine map is reindexed to `affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;`.</span></div>
<div class="line"><a name="l00561"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">  561</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> <a class="code" href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">reindexIndexingMap</a>(<a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> map) {</div>
<div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;  assert(map.<a class="code" href="classmlir_1_1AffineMap.html#a457a8530ceb03d15e3b171ea3a9fc4a6">isProjectedPermutation</a>(<span class="comment">/*allowZeroInResults=*/</span><span class="keyword">true</span>) &amp;&amp;</div>
<div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;         <span class="stringliteral">&quot;expected projected permutation&quot;</span>);</div>
<div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;  <span class="keyword">auto</span> res = <a class="code" href="namespacemlir.html#a99f84d2ce14eec6c85a20251582e5cc1">compressUnusedDims</a>(map);</div>
<div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;  assert(res.getNumDims() ==</div>
<div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;             (res.getNumResults() - res.getNumOfZeroResults()) &amp;&amp;</div>
<div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;         <span class="stringliteral">&quot;expected reindexed map with same number of dims and results&quot;</span>);</div>
<div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;  <span class="keywordflow">return</span> res;</div>
<div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;}</div>
<div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;<span class="comment">/// Helper enum to represent conv1d input traversal order.</span></div>
<div class="line"><a name="l00572"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fec">  572</a></span>&#160;<span class="comment"></span><span class="keyword">enum class</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fec">Conv1DOpOrder</a> {</div>
<div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;  <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">W</a>,   <span class="comment">// Corresponds to non-channeled 1D convolution operation.</span></div>
<div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;  <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Ncw</a>, <span class="comment">// Corresponds to operation that traverses the input in (n, c, w) order.</span></div>
<div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;  <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Nwc</a>  <span class="comment">// Corresponds to operation that traverses the input in (n, w, c) order.</span></div>
<div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;};</div>
<div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;<span class="comment">/// Helper data structure to represent the result of vectorization for a single</span></div>
<div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;<span class="comment">/// operation. In certain specific cases, like terminators, we do not want to</span></div>
<div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;<span class="comment">/// propagate.</span></div>
<div class="line"><a name="l00581"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550a">  581</a></span>&#160;<span class="comment"></span><span class="keyword">enum</span> <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550a">VectorizationHookStatus</a> {<span class="comment"></span></div>
<div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;<span class="comment">  /// Op failed to vectorize.</span></div>
<div class="line"><a name="l00583"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">  583</a></span>&#160;<span class="comment"></span>  <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">Failure</a> = 0,<span class="comment"></span></div>
<div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;<span class="comment">  /// Op vectorized and custom function took care of replacement logic</span></div>
<div class="line"><a name="l00585"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f">  585</a></span>&#160;<span class="comment"></span>  <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f">NoReplace</a>,<span class="comment"></span></div>
<div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;<span class="comment">  /// Op vectorized into a new Op whose results will replace original Op&#39;s</span></div>
<div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;<span class="comment">  /// results.</span></div>
<div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;<span class="comment"></span>  <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">NewOp</a></div>
<div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;  <span class="comment">// TODO: support values if Op vectorized to Many-Ops whose results we need to</span></div>
<div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;  <span class="comment">// aggregate for replacement.</span></div>
<div class="line"><a name="l00591"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">  591</a></span>&#160;};<span class="comment"></span></div>
<div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;<span class="comment">/// VectorizationHookResult contains the vectorized op returned from a</span></div>
<div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;<span class="comment">/// CustomVectorizationHook. This is an internal implementation detail of</span></div>
<div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;<span class="comment">/// linalg vectorization, not to be confused with VectorizationResult.</span></div>
<div class="line"><a name="l00595"></a><span class="lineno"><a class="line" href="structVectorizationHookResult.html">  595</a></span>&#160;<span class="comment"></span><span class="keyword">struct </span><a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a> {<span class="comment"></span></div>
<div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;<span class="comment">  /// Return status from vectorizing the current op.</span></div>
<div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;<span class="comment"></span>  <span class="keyword">enum</span> <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550a">VectorizationHookStatus</a> status = <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>;<span class="comment"></span></div>
<div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;<span class="comment">  /// New vectorized operation to replace the current op.</span></div>
<div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;<span class="comment">  /// Replacement behavior is specified by `status`.</span></div>
<div class="line"><a name="l00600"></a><span class="lineno"><a class="line" href="structVectorizationHookResult.html#ab9025f3486cb1c8f0c6461db368c1a50">  600</a></span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *<a class="code" href="structVectorizationHookResult.html#ab9025f3486cb1c8f0c6461db368c1a50">newOp</a>;</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;};</div>
<div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160; </div>
<div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;std::optional&lt;vector::CombiningKind&gt;</div>
<div class="line"><a name="l00604"></a><span class="lineno"><a class="line" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">  604</a></span>&#160;<a class="code" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">mlir::linalg::getCombinerOpKind</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *combinerOp) {</div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;  using ::mlir::vector::CombiningKind;</div>
<div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160; </div>
<div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;  <span class="keywordflow">if</span> (!combinerOp)</div>
<div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;    <span class="keywordflow">return</span> std::nullopt;</div>
<div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classllvm_1_1TypeSwitch.html">llvm::TypeSwitch&lt;Operation *, std::optional&lt;CombiningKind&gt;</a>&gt;(combinerOp)</div>
<div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;      .Case&lt;arith::AddIOp, arith::AddFOp&gt;(</div>
<div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;          [&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::ADD; })</div>
<div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;      .Case&lt;arith::AndIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::AND; })</div>
<div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;      .Case&lt;arith::MaxSIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MAXSI; })</div>
<div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;      .Case&lt;arith::MaxUIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MAXUI; })</div>
<div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;      .Case&lt;arith::MaximumFOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MAXIMUMF; })</div>
<div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;      .Case&lt;arith::MaxNumFOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MAXNUMF; })</div>
<div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;      .Case&lt;arith::MinSIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MINSI; })</div>
<div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;      .Case&lt;arith::MinUIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> <a class="code" href="SparseTensorIterator_8cpp.html#ace3cf96892ab9fd15d9e7b6b35044b43">CombiningKind::MINUI</a>; })</div>
<div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;      .Case&lt;arith::MinimumFOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MINIMUMF; })</div>
<div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;      .Case&lt;arith::MinNumFOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MINNUMF; })</div>
<div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;      .Case&lt;arith::MulIOp, arith::MulFOp&gt;(</div>
<div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;          [&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MUL; })</div>
<div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;      .Case&lt;arith::OrIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::OR; })</div>
<div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;      .Case&lt;arith::XOrIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::XOR; })</div>
<div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;      .Default([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> std::nullopt; });</div>
<div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;}</div>
<div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;<span class="comment">/// Check whether `outputOperand` is a reduction with a single combiner</span></div>
<div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;<span class="comment">/// operation. Return the combiner operation of the reduction. Return</span></div>
<div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;<span class="comment">/// nullptr otherwise. Multiple reduction operations would impose an</span></div>
<div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;<span class="comment">/// ordering between reduction dimensions and is currently unsupported in</span></div>
<div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;<span class="comment">/// Linalg. This limitation is motivated by the fact that e.g. min(max(X)) !=</span></div>
<div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;<span class="comment">/// max(min(X))</span></div>
<div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160;<span class="comment"></span><span class="comment">// TODO: use in LinalgOp verification, there is a circular dependency atm.</span></div>
<div class="line"><a name="l00635"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a69cbb7a1a1669d28a2e2f4b221a2132f">  635</a></span>&#160;<span class="keyword">static</span> <a class="code" href="classmlir_1_1Operation.html">Operation</a> *<a class="code" href="Vectorization_8cpp.html#a69cbb7a1a1669d28a2e2f4b221a2132f">matchLinalgReduction</a>(<a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> *outputOperand) {</div>
<div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;  <span class="keyword">auto</span> linalgOp = cast&lt;LinalgOp&gt;(outputOperand-&gt;<a class="code" href="classmlir_1_1detail_1_1IROperandBase.html#ac5a818295c7c908f8015c93181239769">getOwner</a>());</div>
<div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;  <span class="keywordtype">unsigned</span> outputPos =</div>
<div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;      outputOperand-&gt;<a class="code" href="classmlir_1_1OpOperand.html#a097f9026defd8afd19ab06b21aa11bdf">getOperandNumber</a>() - linalgOp.getNumDpsInputs();</div>
<div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;  <span class="comment">// Only single combiner operations are supported for now.</span></div>
<div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Operation *, 4&gt;</a> combinerOps;</div>
<div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;  <span class="keywordflow">if</span> (!<a class="code" href="namespacemlir.html#a6bc751bc8f30d71ad4cb771c0fcc788b">matchReduction</a>(linalgOp.getRegionOutputArgs(), outputPos, combinerOps) ||</div>
<div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;      combinerOps.size() != 1)</div>
<div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">nullptr</span>;</div>
<div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160; </div>
<div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;  <span class="comment">// Return the combiner operation.</span></div>
<div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;  <span class="keywordflow">return</span> combinerOps[0];</div>
<div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;}</div>
<div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;<span class="comment">/// Broadcast `value` to a vector of `shape` if possible. Return value</span></div>
<div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;<span class="comment">/// otherwise.</span></div>
<div class="line"><a name="l00651"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">  651</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classmlir_1_1Value.html">Value</a> <a class="code" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(<a class="code" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;b, <a class="code" href="classmlir_1_1Value.html">Value</a> value, <a class="code" href="classmlir_1_1Type.html">Type</a> dstType) {</div>
<div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;  <span class="keyword">auto</span> dstVecType = dyn_cast&lt;VectorType&gt;(dstType);</div>
<div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;  <span class="comment">// If no shape to broadcast to, just return `value`.</span></div>
<div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;  <span class="keywordflow">if</span> (dstVecType.getRank() == 0)</div>
<div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;    <span class="keywordflow">return</span> value;</div>
<div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="namespacemlir_1_1vector.html#a5150a3f7aa4857a1863bd10fb551442a">vector::isBroadcastableTo</a>(value.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>(), dstVecType) !=</div>
<div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;      <a class="code" href="namespacemlir_1_1vector.html#acfee45e655b185bd625e2f7994dc2c50a505a83f220c02df2f85c3810cd9ceb38">vector::BroadcastableToResult::Success</a>)</div>
<div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;    <span class="keywordflow">return</span> value;</div>
<div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;  <a class="code" href="classmlir_1_1Location.html">Location</a> loc = b.<a class="code" href="classmlir_1_1OpBuilder.html#a10fe4674bc755659cb9d09131c713ebc">getInsertionPoint</a>()-&gt;getLoc();</div>
<div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;  <span class="keywordflow">return</span> b.<a class="code" href="classmlir_1_1OpBuilder.html#a9bfa9ca1c08777d5eba6276c24c0cf9a">createOrFold</a>&lt;vector::BroadcastOp&gt;(loc, dstVecType, value);</div>
<div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;}</div>
<div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;<span class="comment">/// Create MultiDimReductionOp to compute the reduction for `reductionOp`. This</span></div>
<div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;<span class="comment">/// assumes that `reductionOp` has two operands and one of them is the reduction</span></div>
<div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;<span class="comment">/// initial value.buildMultiDimReduce</span></div>
<div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;<span class="comment"></span><span class="comment">// Note: this is a true builder that notifies the OpBuilder listener.</span></div>
<div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;<span class="comment">// TODO: Consider moving as a static helper on the ReduceOp.</span></div>
<div class="line"><a name="l00668"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a786634b3fadeefcfe74e0c22f18312f1">  668</a></span>&#160;<span class="keyword">static</span> <a class="code" href="classmlir_1_1Operation.html">Operation</a> *<a class="code" href="Vectorization_8cpp.html#a786634b3fadeefcfe74e0c22f18312f1">buildMultiDimReduce</a>(<a class="code" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;b, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *reduceOp,</div>
<div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;                                      <a class="code" href="classmlir_1_1Value.html">Value</a> valueToReduce, <a class="code" href="classmlir_1_1Value.html">Value</a> acc,</div>
<div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;                                      <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> dimsToMask) {</div>
<div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;  <span class="keyword">auto</span> maybeKind = <a class="code" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp);</div>
<div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;  assert(maybeKind &amp;&amp; <span class="stringliteral">&quot;Failed precondition: could not get reduction kind&quot;</span>);</div>
<div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;  <span class="keywordflow">return</span> vector::MultiDimReductionOp::create(</div>
<div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;      b, reduceOp-&gt;<a class="code" href="classmlir_1_1Operation.html#a6c0b8ce5ff714a34f0192f3aa60dc7ea">getLoc</a>(), valueToReduce, acc, dimsToMask, *maybeKind);</div>
<div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;}</div>
<div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160; </div>
<div class="line"><a name="l00677"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ae26a024dfac331ddb29bc4a78271b9d0">  677</a></span>&#160;<span class="keyword">static</span> <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> <a class="code" href="Vectorization_8cpp.html#ae26a024dfac331ddb29bc4a78271b9d0">getDimsToReduce</a>(LinalgOp linalgOp) {</div>
<div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;  <span class="keywordflow">return</span> llvm::to_vector(</div>
<div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;      llvm::map_range(linalgOp.getIteratorTypesArray(), <a class="code" href="namespacemlir_1_1linalg.html#a5377722f56e02541897c157260bd1eee">isReductionIterator</a>));</div>
<div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;}</div>
<div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;<span class="comment">/// Check if `op` is a linalg.reduce or a linalg.generic that has at least one</span></div>
<div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;<span class="comment">/// reduction iterator.</span></div>
<div class="line"><a name="l00684"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">  684</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code" href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">hasReductionIterator</a>(LinalgOp &amp;op) {</div>
<div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;  <span class="keywordflow">return</span> isa&lt;linalg::ReduceOp&gt;(op) ||</div>
<div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;         (isa&lt;linalg::GenericOp&gt;(op) &amp;&amp;</div>
<div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;          llvm::any_of(op.getIteratorTypesArray(), <a class="code" href="namespacemlir_1_1linalg.html#a5377722f56e02541897c157260bd1eee">isReductionIterator</a>));</div>
<div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;}</div>
<div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;<span class="comment">/// Build a vector.transfer_write of `value` into `outputOperand` at indices set</span></div>
<div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;<span class="comment">/// to all `0`; where `outputOperand` is an output operand of the LinalgOp</span></div>
<div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;<span class="comment">/// currently being vectorized. If `dest` has null rank, build an memref.store.</span></div>
<div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;<span class="comment">/// Return the produced value or null if no value is produced.</span></div>
<div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;<span class="comment"></span><span class="comment">// Note: this is a true builder that notifies the OpBuilder listener.</span></div>
<div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;<span class="comment">// TODO: Consider moving as a static helper on the ReduceOp.</span></div>
<div class="line"><a name="l00696"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a4ffeefd6b3cba67afe11ecdc2b48fcef">  696</a></span>&#160;<span class="keyword">static</span> <a class="code" href="classmlir_1_1Value.html">Value</a> <a class="code" href="Vectorization_8cpp.html#a4ffeefd6b3cba67afe11ecdc2b48fcef">buildVectorWrite</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Value.html">Value</a> value,</div>
<div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;                              <a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> *outputOperand,</div>
<div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;                              <a class="code" href="structVectorizationState.html">VectorizationState</a> &amp;state) {</div>
<div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;  <a class="code" href="classmlir_1_1Location.html">Location</a> loc = value.<a class="code" href="classmlir_1_1Value.html#ae9df8c75072dbaab98cd4b7cd82b6ebc">getLoc</a>();</div>
<div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;  <span class="keyword">auto</span> linalgOp = cast&lt;LinalgOp&gt;(outputOperand-&gt;<a class="code" href="classmlir_1_1detail_1_1IROperandBase.html#ac5a818295c7c908f8015c93181239769">getOwner</a>());</div>
<div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;  <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> opOperandMap = linalgOp.getMatchingIndexingMap(outputOperand);</div>
<div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160; </div>
<div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;  <span class="comment">// Compute the vector type of the value to store. This type should be an</span></div>
<div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;  <span class="comment">// identity or projection of the canonical vector type without any permutation</span></div>
<div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;  <span class="comment">// applied, given that any permutation in a transfer write happens as part of</span></div>
<div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;  <span class="comment">// the write itself.</span></div>
<div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;  <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> vectorTypeMap = <a class="code" href="classmlir_1_1AffineMap.html#ac64464574634cca5ffcd023227260414">AffineMap::getFilteredIdentityMap</a>(</div>
<div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;      opOperandMap.<a class="code" href="classmlir_1_1AffineMap.html#a07ce6ee55edc21c008a3bf8d10a2d726">getContext</a>(), opOperandMap.<a class="code" href="classmlir_1_1AffineMap.html#aa821f07143bcad97d6df532c232129a3">getNumInputs</a>(),</div>
<div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;      [&amp;](<a class="code" href="classmlir_1_1AffineDimExpr.html">AffineDimExpr</a> dimExpr) -&gt; <span class="keywordtype">bool</span> {</div>
<div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;        return llvm::is_contained(opOperandMap.getResults(), dimExpr);</div>
<div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;      });</div>
<div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;  <span class="keyword">auto</span> vectorType = state.getCanonicalVecType(</div>
<div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;      <a class="code" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(outputOperand-&gt;<a class="code" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>().<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()), vectorTypeMap);</div>
<div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160; </div>
<div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *write;</div>
<div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;  <span class="keywordflow">if</span> (vectorType.getRank() &gt; 0) {</div>
<div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;    <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> writeMap = <a class="code" href="namespacemlir.html#a52b322818d83a2256d4e4391acbf78a2">inversePermutation</a>(<a class="code" href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">reindexIndexingMap</a>(opOperandMap));</div>
<div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> indices(</div>
<div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;        linalgOp.getRank(outputOperand),</div>
<div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;        <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0));</div>
<div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;    value = <a class="code" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(rewriter, value, vectorType);</div>
<div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;    assert(value.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>() == vectorType &amp;&amp; <span class="stringliteral">&quot;Incorrect type&quot;</span>);</div>
<div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160;    write = vector::TransferWriteOp::create(</div>
<div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;        rewriter, loc, value, outputOperand-&gt;<a class="code" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>(), indices, writeMap);</div>
<div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160;  } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;    <span class="comment">// 0-d case is still special: do not invert the reindexing writeMap.</span></div>
<div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;    <span class="keywordflow">if</span> (!isa&lt;VectorType&gt;(value.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()))</div>
<div class="line"><a name="l00728"></a><span class="lineno">  728</span>&#160;      value = vector::BroadcastOp::create(rewriter, loc, vectorType, value);</div>
<div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;    assert(value.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>() == vectorType &amp;&amp; <span class="stringliteral">&quot;Incorrect type&quot;</span>);</div>
<div class="line"><a name="l00730"></a><span class="lineno">  730</span>&#160;    write = vector::TransferWriteOp::create(rewriter, loc, value,</div>
<div class="line"><a name="l00731"></a><span class="lineno">  731</span>&#160;                                            outputOperand-&gt;<a class="code" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>(), <a class="code" href="classmlir_1_1ValueRange.html">ValueRange</a>{});</div>
<div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160;  }</div>
<div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160; </div>
<div class="line"><a name="l00734"></a><span class="lineno">  734</span>&#160;  write = state.maskOperation(rewriter, write, linalgOp, opOperandMap);</div>
<div class="line"><a name="l00735"></a><span class="lineno">  735</span>&#160; </div>
<div class="line"><a name="l00736"></a><span class="lineno">  736</span>&#160;  <span class="comment">// If masked, set in-bounds to true. Masking guarantees that the access will</span></div>
<div class="line"><a name="l00737"></a><span class="lineno">  737</span>&#160;  <span class="comment">// be in-bounds.</span></div>
<div class="line"><a name="l00738"></a><span class="lineno">  738</span>&#160;  <span class="keywordflow">if</span> (<span class="keyword">auto</span> maskOp = dyn_cast&lt;vector::MaskingOpInterface&gt;(write)) {</div>
<div class="line"><a name="l00739"></a><span class="lineno">  739</span>&#160;    <span class="keyword">auto</span> maskedWriteOp = cast&lt;vector::TransferWriteOp&gt;(maskOp.getMaskableOp());</div>
<div class="line"><a name="l00740"></a><span class="lineno">  740</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(maskedWriteOp.getVectorType().getRank(), <span class="keyword">true</span>);</div>
<div class="line"><a name="l00741"></a><span class="lineno">  741</span>&#160;    maskedWriteOp.setInBoundsAttr(rewriter.<a class="code" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;  }</div>
<div class="line"><a name="l00743"></a><span class="lineno">  743</span>&#160; </div>
<div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;vectorized op: &quot;</span> &lt;&lt; *write;</div>
<div class="line"><a name="l00745"></a><span class="lineno">  745</span>&#160;  <span class="keywordflow">if</span> (!write-&gt;<a class="code" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>().empty())</div>
<div class="line"><a name="l00746"></a><span class="lineno">  746</span>&#160;    <span class="keywordflow">return</span> write-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0);</div>
<div class="line"><a name="l00747"></a><span class="lineno">  747</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1Value.html">Value</a>();</div>
<div class="line"><a name="l00748"></a><span class="lineno">  748</span>&#160;}</div>
<div class="line"><a name="l00749"></a><span class="lineno">  749</span>&#160; </div>
<div class="line"><a name="l00750"></a><span class="lineno">  750</span>&#160;<span class="comment">// Custom vectorization precondition function type. This is intented to be used</span></div>
<div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;<span class="comment">// with CustomVectorizationHook. Returns success if the corresponding custom</span></div>
<div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160;<span class="comment">// hook can vectorize the op.</span></div>
<div class="line"><a name="l00753"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a9b7d2592a2bad4ef2be89bf0d7efd19a">  753</a></span>&#160;<span class="keyword">using</span> <a class="code" href="Vectorization_8cpp.html#a9b7d2592a2bad4ef2be89bf0d7efd19a">CustomVectorizationPrecondition</a> =</div>
<div class="line"><a name="l00754"></a><span class="lineno">  754</span>&#160;    std::function&lt;LogicalResult(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *, <span class="keywordtype">bool</span>)&gt;;</div>
<div class="line"><a name="l00755"></a><span class="lineno">  755</span>&#160; </div>
<div class="line"><a name="l00756"></a><span class="lineno">  756</span>&#160;<span class="comment">// Custom vectorization function type. Produce a vector form of Operation*</span></div>
<div class="line"><a name="l00757"></a><span class="lineno">  757</span>&#160;<span class="comment">// assuming all its vectorized operands are already in the IRMapping.</span></div>
<div class="line"><a name="l00758"></a><span class="lineno">  758</span>&#160;<span class="comment">// Return nullptr if the Operation cannot be vectorized.</span></div>
<div class="line"><a name="l00759"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a8a252028bd6c5a6051cc0e8a48c72afb">  759</a></span>&#160;<span class="keyword">using</span> <a class="code" href="Vectorization_8cpp.html#a8a252028bd6c5a6051cc0e8a48c72afb">CustomVectorizationHook</a> =</div>
<div class="line"><a name="l00760"></a><span class="lineno">  760</span>&#160;    std::function&lt;<a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *, <span class="keyword">const</span> <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;)&gt;;</div>
<div class="line"><a name="l00761"></a><span class="lineno">  761</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00762"></a><span class="lineno">  762</span>&#160;<span class="comment">/// Helper function to vectorize the terminator of a `linalgOp`. New result</span></div>
<div class="line"><a name="l00763"></a><span class="lineno">  763</span>&#160;<span class="comment">/// vector values are appended to `newResults`. Return</span></div>
<div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;<span class="comment">/// VectorizationHookStatus::NoReplace to signal the vectorization algorithm</span></div>
<div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;<span class="comment">/// that it should not try to map produced operations and instead return the</span></div>
<div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;<span class="comment">/// results using the `newResults` vector making them available to the</span></div>
<div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;<span class="comment">/// vectorization algorithm for RAUW. This function is meant to be used as a</span></div>
<div class="line"><a name="l00768"></a><span class="lineno">  768</span>&#160;<span class="comment">/// CustomVectorizationHook.</span></div>
<div class="line"><a name="l00769"></a><span class="lineno">  769</span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a></div>
<div class="line"><a name="l00770"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#af85a26f7c1860388d0e83d22745a27aa">  770</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#af85a26f7c1860388d0e83d22745a27aa">vectorizeLinalgYield</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *op,</div>
<div class="line"><a name="l00771"></a><span class="lineno">  771</span>&#160;                     <span class="keyword">const</span> <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm, <a class="code" href="structVectorizationState.html">VectorizationState</a> &amp;state,</div>
<div class="line"><a name="l00772"></a><span class="lineno">  772</span>&#160;                     LinalgOp linalgOp, <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults) {</div>
<div class="line"><a name="l00773"></a><span class="lineno">  773</span>&#160;  <span class="keyword">auto</span> yieldOp = dyn_cast&lt;linalg::YieldOp&gt;(op);</div>
<div class="line"><a name="l00774"></a><span class="lineno">  774</span>&#160;  <span class="keywordflow">if</span> (!yieldOp)</div>
<div class="line"><a name="l00775"></a><span class="lineno">  775</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a name="l00776"></a><span class="lineno">  776</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;output : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">llvm::enumerate</a>(yieldOp.getValues())) {</div>
<div class="line"><a name="l00777"></a><span class="lineno">  777</span>&#160;    <span class="comment">// TODO: Scan for an opportunity for reuse.</span></div>
<div class="line"><a name="l00778"></a><span class="lineno">  778</span>&#160;    <span class="comment">// TODO: use a map.</span></div>
<div class="line"><a name="l00779"></a><span class="lineno">  779</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> vectorValue = bvm.<a class="code" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(output.value());</div>
<div class="line"><a name="l00780"></a><span class="lineno">  780</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> newResult =</div>
<div class="line"><a name="l00781"></a><span class="lineno">  781</span>&#160;        <a class="code" href="Vectorization_8cpp.html#a4ffeefd6b3cba67afe11ecdc2b48fcef">buildVectorWrite</a>(rewriter, vectorValue,</div>
<div class="line"><a name="l00782"></a><span class="lineno">  782</span>&#160;                         linalgOp.getDpsInitOperand(output.index()), state);</div>
<div class="line"><a name="l00783"></a><span class="lineno">  783</span>&#160;    <span class="keywordflow">if</span> (newResult)</div>
<div class="line"><a name="l00784"></a><span class="lineno">  784</span>&#160;      newResults.push_back(newResult);</div>
<div class="line"><a name="l00785"></a><span class="lineno">  785</span>&#160;  }</div>
<div class="line"><a name="l00786"></a><span class="lineno">  786</span>&#160; </div>
<div class="line"><a name="l00787"></a><span class="lineno">  787</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f">VectorizationHookStatus::NoReplace</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a name="l00788"></a><span class="lineno">  788</span>&#160;}</div>
<div class="line"><a name="l00789"></a><span class="lineno">  789</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00790"></a><span class="lineno">  790</span>&#160;<span class="comment">/// Helper function to vectorize the index operations of a `linalgOp`. Return</span></div>
<div class="line"><a name="l00791"></a><span class="lineno">  791</span>&#160;<span class="comment">/// VectorizationHookStatus::NewOp to signal the vectorization algorithm that it</span></div>
<div class="line"><a name="l00792"></a><span class="lineno">  792</span>&#160;<span class="comment">/// should map the produced operations. This function is meant to be used as a</span></div>
<div class="line"><a name="l00793"></a><span class="lineno">  793</span>&#160;<span class="comment">/// CustomVectorizationHook.</span></div>
<div class="line"><a name="l00794"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a280bd1ab81d418cd32713eeb0a2dfffd">  794</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a> <a class="code" href="Vectorization_8cpp.html#a280bd1ab81d418cd32713eeb0a2dfffd">vectorizeLinalgIndex</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a name="l00795"></a><span class="lineno">  795</span>&#160;                                                    <a class="code" href="structVectorizationState.html">VectorizationState</a> &amp;state,</div>
<div class="line"><a name="l00796"></a><span class="lineno">  796</span>&#160;                                                    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *op,</div>
<div class="line"><a name="l00797"></a><span class="lineno">  797</span>&#160;                                                    LinalgOp linalgOp) {</div>
<div class="line"><a name="l00798"></a><span class="lineno">  798</span>&#160;  IndexOp indexOp = dyn_cast&lt;linalg::IndexOp&gt;(op);</div>
<div class="line"><a name="l00799"></a><span class="lineno">  799</span>&#160;  <span class="keywordflow">if</span> (!indexOp)</div>
<div class="line"><a name="l00800"></a><span class="lineno">  800</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a name="l00801"></a><span class="lineno">  801</span>&#160;  <span class="keyword">auto</span> loc = indexOp.getLoc();</div>
<div class="line"><a name="l00802"></a><span class="lineno">  802</span>&#160;  <span class="comment">// Compute the static loop sizes of the index op.</span></div>
<div class="line"><a name="l00803"></a><span class="lineno">  803</span>&#160;  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> targetShape = state.getCanonicalVecShape();</div>
<div class="line"><a name="l00804"></a><span class="lineno">  804</span>&#160;  <span class="keyword">auto</span> dim = indexOp.getDim();</div>
<div class="line"><a name="l00805"></a><span class="lineno">  805</span>&#160;  <span class="comment">// Compute a one-dimensional index vector for the index op dimension.</span></div>
<div class="line"><a name="l00806"></a><span class="lineno">  806</span>&#160;  <span class="keyword">auto</span> indexVectorType =</div>
<div class="line"><a name="l00807"></a><span class="lineno">  807</span>&#160;      <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>({targetShape[dim]}, rewriter.<a class="code" href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">getIndexType</a>(),</div>
<div class="line"><a name="l00808"></a><span class="lineno">  808</span>&#160;                      state.getScalableVecDims()[dim]);</div>
<div class="line"><a name="l00809"></a><span class="lineno">  809</span>&#160;  <span class="keyword">auto</span> indexSteps = vector::StepOp::create(rewriter, loc, indexVectorType);</div>
<div class="line"><a name="l00810"></a><span class="lineno">  810</span>&#160;  <span class="comment">// Return the one-dimensional index vector if it lives in the trailing</span></div>
<div class="line"><a name="l00811"></a><span class="lineno">  811</span>&#160;  <span class="comment">// dimension of the iteration space since the vectorization algorithm in this</span></div>
<div class="line"><a name="l00812"></a><span class="lineno">  812</span>&#160;  <span class="comment">// case can handle the broadcast.</span></div>
<div class="line"><a name="l00813"></a><span class="lineno">  813</span>&#160;  <span class="keywordflow">if</span> (dim == targetShape.size() - 1)</div>
<div class="line"><a name="l00814"></a><span class="lineno">  814</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>, indexSteps};</div>
<div class="line"><a name="l00815"></a><span class="lineno">  815</span>&#160;  <span class="comment">// Otherwise permute the targetShape to move the index dimension last,</span></div>
<div class="line"><a name="l00816"></a><span class="lineno">  816</span>&#160;  <span class="comment">// broadcast the one-dimensional index vector to the permuted shape, and</span></div>
<div class="line"><a name="l00817"></a><span class="lineno">  817</span>&#160;  <span class="comment">// finally transpose the broadcasted index vector to undo the permutation.</span></div>
<div class="line"><a name="l00818"></a><span class="lineno">  818</span>&#160;  <span class="keyword">auto</span> permPattern =</div>
<div class="line"><a name="l00819"></a><span class="lineno">  819</span>&#160;      llvm::to_vector(llvm::seq&lt;unsigned&gt;(0, targetShape.size()));</div>
<div class="line"><a name="l00820"></a><span class="lineno">  820</span>&#160;  std::swap(permPattern[dim], permPattern.back());</div>
<div class="line"><a name="l00821"></a><span class="lineno">  821</span>&#160;  <span class="keyword">auto</span> permMap =</div>
<div class="line"><a name="l00822"></a><span class="lineno">  822</span>&#160;      <a class="code" href="classmlir_1_1AffineMap.html#acd08312b1039c20f008d2f6785c47816">AffineMap::getPermutationMap</a>(permPattern, linalgOp.getContext());</div>
<div class="line"><a name="l00823"></a><span class="lineno">  823</span>&#160; </div>
<div class="line"><a name="l00824"></a><span class="lineno">  824</span>&#160;  <span class="keyword">auto</span> broadCastOp = vector::BroadcastOp::create(</div>
<div class="line"><a name="l00825"></a><span class="lineno">  825</span>&#160;      rewriter, loc,</div>
<div class="line"><a name="l00826"></a><span class="lineno">  826</span>&#160;      state.getCanonicalVecType(rewriter.<a class="code" href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">getIndexType</a>(), permMap), indexSteps);</div>
<div class="line"><a name="l00827"></a><span class="lineno">  827</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> transposition =</div>
<div class="line"><a name="l00828"></a><span class="lineno">  828</span>&#160;      llvm::to_vector&lt;16&gt;(llvm::seq&lt;int64_t&gt;(0, linalgOp.getNumLoops()));</div>
<div class="line"><a name="l00829"></a><span class="lineno">  829</span>&#160;  std::swap(transposition.back(), transposition[dim]);</div>
<div class="line"><a name="l00830"></a><span class="lineno">  830</span>&#160;  <span class="keyword">auto</span> transposeOp =</div>
<div class="line"><a name="l00831"></a><span class="lineno">  831</span>&#160;      vector::TransposeOp::create(rewriter, loc, broadCastOp, transposition);</div>
<div class="line"><a name="l00832"></a><span class="lineno">  832</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>, transposeOp};</div>
<div class="line"><a name="l00833"></a><span class="lineno">  833</span>&#160;}</div>
<div class="line"><a name="l00834"></a><span class="lineno">  834</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00835"></a><span class="lineno">  835</span>&#160;<span class="comment">/// Helper function to check if the tensor.extract can be vectorized by the</span></div>
<div class="line"><a name="l00836"></a><span class="lineno">  836</span>&#160;<span class="comment">/// custom hook vectorizeTensorExtract.</span></div>
<div class="line"><a name="l00837"></a><span class="lineno">  837</span>&#160;<span class="comment"></span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l00838"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ad09df73d48432e3de8291c7076164ba7">  838</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#ad09df73d48432e3de8291c7076164ba7">tensorExtractVectorizationPrecondition</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keywordtype">bool</span> vectorizeNDExtract) {</div>
<div class="line"><a name="l00839"></a><span class="lineno">  839</span>&#160;  tensor::ExtractOp extractOp = dyn_cast&lt;tensor::ExtractOp&gt;(op);</div>
<div class="line"><a name="l00840"></a><span class="lineno">  840</span>&#160;  <span class="keywordflow">if</span> (!extractOp)</div>
<div class="line"><a name="l00841"></a><span class="lineno">  841</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00842"></a><span class="lineno">  842</span>&#160; </div>
<div class="line"><a name="l00843"></a><span class="lineno">  843</span>&#160;  <span class="keywordflow">if</span> (extractOp.getIndices().size() != 1 &amp;&amp; !vectorizeNDExtract)</div>
<div class="line"><a name="l00844"></a><span class="lineno">  844</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00845"></a><span class="lineno">  845</span>&#160; </div>
<div class="line"><a name="l00846"></a><span class="lineno">  846</span>&#160;  <span class="comment">// Check the index type, but only for non 0-d tensors (for which we do need</span></div>
<div class="line"><a name="l00847"></a><span class="lineno">  847</span>&#160;  <span class="comment">// access indices).</span></div>
<div class="line"><a name="l00848"></a><span class="lineno">  848</span>&#160;  <span class="keywordflow">if</span> (not extractOp.getIndices().empty()) {</div>
<div class="line"><a name="l00849"></a><span class="lineno">  849</span>&#160;    <span class="keywordflow">if</span> (!VectorType::isValidElementType(extractOp.getIndices()[0].getType()))</div>
<div class="line"><a name="l00850"></a><span class="lineno">  850</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00851"></a><span class="lineno">  851</span>&#160;  }</div>
<div class="line"><a name="l00852"></a><span class="lineno">  852</span>&#160; </div>
<div class="line"><a name="l00853"></a><span class="lineno">  853</span>&#160;  <span class="keywordflow">if</span> (!llvm::all_of(extractOp-&gt;getResultTypes(),</div>
<div class="line"><a name="l00854"></a><span class="lineno">  854</span>&#160;                    VectorType::isValidElementType)) {</div>
<div class="line"><a name="l00855"></a><span class="lineno">  855</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00856"></a><span class="lineno">  856</span>&#160;  }</div>
<div class="line"><a name="l00857"></a><span class="lineno">  857</span>&#160; </div>
<div class="line"><a name="l00858"></a><span class="lineno">  858</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00859"></a><span class="lineno">  859</span>&#160;}</div>
<div class="line"><a name="l00860"></a><span class="lineno">  860</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00861"></a><span class="lineno">  861</span>&#160;<span class="comment">/// Calculates the offsets (`$index_vec`) for `vector.gather` operations</span></div>
<div class="line"><a name="l00862"></a><span class="lineno">  862</span>&#160;<span class="comment">/// generated from `tensor.extract`. The offset is calculated as follows</span></div>
<div class="line"><a name="l00863"></a><span class="lineno">  863</span>&#160;<span class="comment">/// (example using scalar values):</span></div>
<div class="line"><a name="l00864"></a><span class="lineno">  864</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00865"></a><span class="lineno">  865</span>&#160;<span class="comment">///    offset = extractOp.indices[0]</span></div>
<div class="line"><a name="l00866"></a><span class="lineno">  866</span>&#160;<span class="comment">///    for (i = 1; i &lt; numIndices; i++)</span></div>
<div class="line"><a name="l00867"></a><span class="lineno">  867</span>&#160;<span class="comment">///      offset = extractOp.dimSize[i] * offset + extractOp.indices[i];</span></div>
<div class="line"><a name="l00868"></a><span class="lineno">  868</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00869"></a><span class="lineno">  869</span>&#160;<span class="comment">/// For tensor&lt;45 x 80 x 15 x f32&gt; and index [1, 2, 3], this leads to:</span></div>
<div class="line"><a name="l00870"></a><span class="lineno">  870</span>&#160;<span class="comment">///  offset = ( ( 1 ) * 80 +  2 ) * 15  + 3</span></div>
<div class="line"><a name="l00871"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ae4411a5d89520c86474035493a7da7c1">  871</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classmlir_1_1Value.html">Value</a> <a class="code" href="Vectorization_8cpp.html#ae4411a5d89520c86474035493a7da7c1">calculateGatherOffset</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a name="l00872"></a><span class="lineno">  872</span>&#160;                                   <a class="code" href="structVectorizationState.html">VectorizationState</a> &amp;state,</div>
<div class="line"><a name="l00873"></a><span class="lineno">  873</span>&#160;                                   tensor::ExtractOp extractOp,</div>
<div class="line"><a name="l00874"></a><span class="lineno">  874</span>&#160;                                   <span class="keyword">const</span> <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) {</div>
<div class="line"><a name="l00875"></a><span class="lineno">  875</span>&#160;  <span class="comment">// The vector of indices for GatherOp should be shaped as the output vector.</span></div>
<div class="line"><a name="l00876"></a><span class="lineno">  876</span>&#160;  <span class="keyword">auto</span> indexVecType = state.getCanonicalVecType(rewriter.<a class="code" href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">getIndexType</a>());</div>
<div class="line"><a name="l00877"></a><span class="lineno">  877</span>&#160;  <span class="keyword">auto</span> loc = extractOp.getLoc();</div>
<div class="line"><a name="l00878"></a><span class="lineno">  878</span>&#160; </div>
<div class="line"><a name="l00879"></a><span class="lineno">  879</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> offset = <a class="code" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(</div>
<div class="line"><a name="l00880"></a><span class="lineno">  880</span>&#160;      rewriter, bvm.<a class="code" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(extractOp.getIndices()[0]), indexVecType);</div>
<div class="line"><a name="l00881"></a><span class="lineno">  881</span>&#160; </div>
<div class="line"><a name="l00882"></a><span class="lineno">  882</span>&#160;  <span class="keyword">const</span> <span class="keywordtype">size_t</span> numIndices = extractOp.getIndices().size();</div>
<div class="line"><a name="l00883"></a><span class="lineno">  883</span>&#160;  <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 1; i &lt; numIndices; i++) {</div>
<div class="line"><a name="l00884"></a><span class="lineno">  884</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> dimIdx = <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, i);</div>
<div class="line"><a name="l00885"></a><span class="lineno">  885</span>&#160; </div>
<div class="line"><a name="l00886"></a><span class="lineno">  886</span>&#160;    <span class="keyword">auto</span> dimSize = <a class="code" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(</div>
<div class="line"><a name="l00887"></a><span class="lineno">  887</span>&#160;        rewriter,</div>
<div class="line"><a name="l00888"></a><span class="lineno">  888</span>&#160;        tensor::DimOp::create(rewriter, loc, extractOp.getTensor(), dimIdx),</div>
<div class="line"><a name="l00889"></a><span class="lineno">  889</span>&#160;        indexVecType);</div>
<div class="line"><a name="l00890"></a><span class="lineno">  890</span>&#160; </div>
<div class="line"><a name="l00891"></a><span class="lineno">  891</span>&#160;    offset = arith::MulIOp::create(rewriter, loc, offset, dimSize);</div>
<div class="line"><a name="l00892"></a><span class="lineno">  892</span>&#160; </div>
<div class="line"><a name="l00893"></a><span class="lineno">  893</span>&#160;    <span class="keyword">auto</span> extractOpIndex = <a class="code" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(</div>
<div class="line"><a name="l00894"></a><span class="lineno">  894</span>&#160;        rewriter, bvm.<a class="code" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(extractOp.getIndices()[i]), indexVecType);</div>
<div class="line"><a name="l00895"></a><span class="lineno">  895</span>&#160; </div>
<div class="line"><a name="l00896"></a><span class="lineno">  896</span>&#160;    offset = arith::AddIOp::create(rewriter, loc, extractOpIndex, offset);</div>
<div class="line"><a name="l00897"></a><span class="lineno">  897</span>&#160;  }</div>
<div class="line"><a name="l00898"></a><span class="lineno">  898</span>&#160; </div>
<div class="line"><a name="l00899"></a><span class="lineno">  899</span>&#160;  <span class="keywordflow">return</span> offset;</div>
<div class="line"><a name="l00900"></a><span class="lineno">  900</span>&#160;}</div>
<div class="line"><a name="l00901"></a><span class="lineno">  901</span>&#160; </div>
<div class="line"><a name="l00902"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea">  902</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcc">VectorMemoryAccessKind</a> { <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">ScalarBroadcast</a>, <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea">Contiguous</a>, <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">Gather</a> };</div>
<div class="line"><a name="l00903"></a><span class="lineno">  903</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00904"></a><span class="lineno">  904</span>&#160;<span class="comment">/// Find the index of the trailing non-unit dim in linalgOp. This hook is used</span></div>
<div class="line"><a name="l00905"></a><span class="lineno">  905</span>&#160;<span class="comment">/// when checking whether `tensor.extract` Op (within a `linalg.generic` Op)</span></div>
<div class="line"><a name="l00906"></a><span class="lineno">  906</span>&#160;<span class="comment">/// represents a contiguous load operation.</span></div>
<div class="line"><a name="l00907"></a><span class="lineno">  907</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00908"></a><span class="lineno">  908</span>&#160;<span class="comment">/// Note that when calling this hook, it is assumed that the output vector is</span></div>
<div class="line"><a name="l00909"></a><span class="lineno">  909</span>&#160;<span class="comment">/// effectively 1D. Other cases (i.e. reading n-D vectors) should&#39;ve been</span></div>
<div class="line"><a name="l00910"></a><span class="lineno">  910</span>&#160;<span class="comment">/// labelled as a gather load before entering this method.</span></div>
<div class="line"><a name="l00911"></a><span class="lineno">  911</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00912"></a><span class="lineno">  912</span>&#160;<span class="comment">/// Following on from the above, it is assumed that:</span></div>
<div class="line"><a name="l00913"></a><span class="lineno">  913</span>&#160;<span class="comment">///   * for statically shaped loops, when no masks are used, only one dim is !=</span></div>
<div class="line"><a name="l00914"></a><span class="lineno">  914</span>&#160;<span class="comment">///   1 (that&#39;s what the shape of the output vector is based on).</span></div>
<div class="line"><a name="l00915"></a><span class="lineno">  915</span>&#160;<span class="comment">///   * for dynamically shaped loops, there might be more non-unit dims</span></div>
<div class="line"><a name="l00916"></a><span class="lineno">  916</span>&#160;<span class="comment">///   as the output vector type is user-specified.</span></div>
<div class="line"><a name="l00917"></a><span class="lineno">  917</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00918"></a><span class="lineno">  918</span>&#160;<span class="comment">/// TODO: Statically shaped loops + vector masking</span></div>
<div class="line"><a name="l00919"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a7e9ce28bca426dd4de93ad09392b4ec1">  919</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> uint64_t <a class="code" href="Vectorization_8cpp.html#a7e9ce28bca426dd4de93ad09392b4ec1">getTrailingNonUnitLoopDimIdx</a>(LinalgOp linalgOp) {</div>
<div class="line"><a name="l00920"></a><span class="lineno">  920</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> loopRanges = linalgOp.getStaticLoopRanges();</div>
<div class="line"><a name="l00921"></a><span class="lineno">  921</span>&#160;  assert(</div>
<div class="line"><a name="l00922"></a><span class="lineno">  922</span>&#160;      (linalgOp.hasDynamicShape() ||</div>
<div class="line"><a name="l00923"></a><span class="lineno">  923</span>&#160;       llvm::count_if(loopRanges, [](int64_t dim) { return dim != 1; }) == 1) &amp;&amp;</div>
<div class="line"><a name="l00924"></a><span class="lineno">  924</span>&#160;      <span class="stringliteral">&quot;For statically shaped Linalg Ops, only one &quot;</span></div>
<div class="line"><a name="l00925"></a><span class="lineno">  925</span>&#160;      <span class="stringliteral">&quot;non-unit loop dim is expected&quot;</span>);</div>
<div class="line"><a name="l00926"></a><span class="lineno">  926</span>&#160;  assert(loopRanges.size() != 0 &amp;&amp; <span class="stringliteral">&quot;Empty loops, nothing to analyse.&quot;</span>);</div>
<div class="line"><a name="l00927"></a><span class="lineno">  927</span>&#160; </div>
<div class="line"><a name="l00928"></a><span class="lineno">  928</span>&#160;  <span class="keywordtype">size_t</span> idx = loopRanges.size() - 1;</div>
<div class="line"><a name="l00929"></a><span class="lineno">  929</span>&#160;  <span class="keywordflow">for</span> (; idx != 0; idx--)</div>
<div class="line"><a name="l00930"></a><span class="lineno">  930</span>&#160;    <span class="keywordflow">if</span> (loopRanges[idx] != 1)</div>
<div class="line"><a name="l00931"></a><span class="lineno">  931</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l00932"></a><span class="lineno">  932</span>&#160; </div>
<div class="line"><a name="l00933"></a><span class="lineno">  933</span>&#160;  <span class="keywordflow">return</span> idx;</div>
<div class="line"><a name="l00934"></a><span class="lineno">  934</span>&#160;}</div>
<div class="line"><a name="l00935"></a><span class="lineno">  935</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00936"></a><span class="lineno">  936</span>&#160;<span class="comment">/// Checks whether `val` can be used for calculating a loop invariant index.</span></div>
<div class="line"><a name="l00937"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">  937</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a>(LinalgOp &amp;linalgOp, <a class="code" href="classmlir_1_1Value.html">Value</a> &amp;val,</div>
<div class="line"><a name="l00938"></a><span class="lineno">  938</span>&#160;                               VectorType resType) {</div>
<div class="line"><a name="l00939"></a><span class="lineno">  939</span>&#160; </div>
<div class="line"><a name="l00940"></a><span class="lineno">  940</span>&#160;  assert(((llvm::count_if(resType.getShape(),</div>
<div class="line"><a name="l00941"></a><span class="lineno">  941</span>&#160;                          [](int64_t dimSize) { return dimSize &gt; 1; }) == 1)) &amp;&amp;</div>
<div class="line"><a name="l00942"></a><span class="lineno">  942</span>&#160;         <span class="stringliteral">&quot;n-D vectors are not yet supported&quot;</span>);</div>
<div class="line"><a name="l00943"></a><span class="lineno">  943</span>&#160; </div>
<div class="line"><a name="l00944"></a><span class="lineno">  944</span>&#160;  <span class="comment">// Blocks outside _this_ linalg.generic are effectively loop invariant.</span></div>
<div class="line"><a name="l00945"></a><span class="lineno">  945</span>&#160;  <span class="comment">// However, analysing block arguments for _this_ linalg.generic Op is a bit</span></div>
<div class="line"><a name="l00946"></a><span class="lineno">  946</span>&#160;  <span class="comment">// tricky. Just bail out in the latter case.</span></div>
<div class="line"><a name="l00947"></a><span class="lineno">  947</span>&#160;  <span class="comment">// TODO: We could try analysing the corresponding affine map here.</span></div>
<div class="line"><a name="l00948"></a><span class="lineno">  948</span>&#160;  <span class="keyword">auto</span> *block = linalgOp.getBlock();</div>
<div class="line"><a name="l00949"></a><span class="lineno">  949</span>&#160;  <span class="keywordflow">if</span> (isa&lt;BlockArgument&gt;(val))</div>
<div class="line"><a name="l00950"></a><span class="lineno">  950</span>&#160;    <span class="keywordflow">return</span> !llvm::is_contained(block-&gt;getArguments(), val);</div>
<div class="line"><a name="l00951"></a><span class="lineno">  951</span>&#160; </div>
<div class="line"><a name="l00952"></a><span class="lineno">  952</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *defOp = val.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>();</div>
<div class="line"><a name="l00953"></a><span class="lineno">  953</span>&#160;  assert(defOp &amp;&amp; <span class="stringliteral">&quot;This is neither a block argument nor an operation result&quot;</span>);</div>
<div class="line"><a name="l00954"></a><span class="lineno">  954</span>&#160; </div>
<div class="line"><a name="l00955"></a><span class="lineno">  955</span>&#160;  <span class="comment">// IndexOp is loop invariant as long as its result remains constant across</span></div>
<div class="line"><a name="l00956"></a><span class="lineno">  956</span>&#160;  <span class="comment">// iterations. Note that for dynamic shapes, the corresponding dim will also</span></div>
<div class="line"><a name="l00957"></a><span class="lineno">  957</span>&#160;  <span class="comment">// be conservatively treated as != 1.</span></div>
<div class="line"><a name="l00958"></a><span class="lineno">  958</span>&#160;  <span class="keywordflow">if</span> (<span class="keyword">auto</span> indexOp = dyn_cast&lt;linalg::IndexOp&gt;(defOp)) {</div>
<div class="line"><a name="l00959"></a><span class="lineno">  959</span>&#160;    <span class="keywordflow">return</span> linalgOp.getStaticLoopRanges()[indexOp.getDim()] == 1;</div>
<div class="line"><a name="l00960"></a><span class="lineno">  960</span>&#160;  }</div>
<div class="line"><a name="l00961"></a><span class="lineno">  961</span>&#160; </div>
<div class="line"><a name="l00962"></a><span class="lineno">  962</span>&#160;  <span class="keyword">auto</span> *ancestor = block-&gt;findAncestorOpInBlock(*defOp);</div>
<div class="line"><a name="l00963"></a><span class="lineno">  963</span>&#160; </div>
<div class="line"><a name="l00964"></a><span class="lineno">  964</span>&#160;  <span class="comment">// Values define outside `linalgOp` are loop invariant.</span></div>
<div class="line"><a name="l00965"></a><span class="lineno">  965</span>&#160;  <span class="keywordflow">if</span> (!ancestor)</div>
<div class="line"><a name="l00966"></a><span class="lineno">  966</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l00967"></a><span class="lineno">  967</span>&#160; </div>
<div class="line"><a name="l00968"></a><span class="lineno">  968</span>&#160;  <span class="comment">// Values defined inside `linalgOp`, which are constant, are loop invariant.</span></div>
<div class="line"><a name="l00969"></a><span class="lineno">  969</span>&#160;  <span class="keywordflow">if</span> (isa&lt;arith::ConstantOp&gt;(ancestor))</div>
<div class="line"><a name="l00970"></a><span class="lineno">  970</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l00971"></a><span class="lineno">  971</span>&#160; </div>
<div class="line"><a name="l00972"></a><span class="lineno">  972</span>&#160;  <span class="keywordtype">bool</span> result = <span class="keyword">true</span>;</div>
<div class="line"><a name="l00973"></a><span class="lineno">  973</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> op : ancestor-&gt;getOperands())</div>
<div class="line"><a name="l00974"></a><span class="lineno">  974</span>&#160;    result &amp;= <a class="code" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a>(linalgOp, op, resType);</div>
<div class="line"><a name="l00975"></a><span class="lineno">  975</span>&#160; </div>
<div class="line"><a name="l00976"></a><span class="lineno">  976</span>&#160;  <span class="keywordflow">return</span> result;</div>
<div class="line"><a name="l00977"></a><span class="lineno">  977</span>&#160;}</div>
<div class="line"><a name="l00978"></a><span class="lineno">  978</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00979"></a><span class="lineno">  979</span>&#160;<span class="comment">/// Check whether `val` could be used for calculating the trailing index for a</span></div>
<div class="line"><a name="l00980"></a><span class="lineno">  980</span>&#160;<span class="comment">/// contiguous load operation.</span></div>
<div class="line"><a name="l00981"></a><span class="lineno">  981</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00982"></a><span class="lineno">  982</span>&#160;<span class="comment">/// There are currently 3 types of values that are allowed here:</span></div>
<div class="line"><a name="l00983"></a><span class="lineno">  983</span>&#160;<span class="comment">///   1. loop-invariant values,</span></div>
<div class="line"><a name="l00984"></a><span class="lineno">  984</span>&#160;<span class="comment">///   2. values that increment by 1 with every loop iteration,</span></div>
<div class="line"><a name="l00985"></a><span class="lineno">  985</span>&#160;<span class="comment">///   3. results of basic arithmetic operations (linear and continuous)</span></div>
<div class="line"><a name="l00986"></a><span class="lineno">  986</span>&#160;<span class="comment">///      involving 1., 2. and 3.</span></div>
<div class="line"><a name="l00987"></a><span class="lineno">  987</span>&#160;<span class="comment">/// This method returns True if indeed only such values are used in calculating</span></div>
<div class="line"><a name="l00988"></a><span class="lineno">  988</span>&#160;<span class="comment">/// `val.`</span></div>
<div class="line"><a name="l00989"></a><span class="lineno">  989</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00990"></a><span class="lineno">  990</span>&#160;<span class="comment">/// Additionally, the trailing index for a contiguous load operation should</span></div>
<div class="line"><a name="l00991"></a><span class="lineno">  991</span>&#160;<span class="comment">/// increment by 1 with every loop iteration, i.e. be based on:</span></div>
<div class="line"><a name="l00992"></a><span class="lineno">  992</span>&#160;<span class="comment">///   * `linalg.index &lt;dim&gt;` ,</span></div>
<div class="line"><a name="l00993"></a><span class="lineno">  993</span>&#160;<span class="comment">/// where &lt;dim&gt; is the trailing non-unit dim of the iteration space (this way,</span></div>
<div class="line"><a name="l00994"></a><span class="lineno">  994</span>&#160;<span class="comment">/// `linalg.index &lt;dim&gt;` increments by 1 with every loop iteration).</span></div>
<div class="line"><a name="l00995"></a><span class="lineno">  995</span>&#160;<span class="comment">/// `foundIndexOp` is updated to `true` when such Op is found.</span></div>
<div class="line"><a name="l00996"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3">  996</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code" href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3">isContiguousLoadIdx</a>(LinalgOp &amp;linalgOp, <a class="code" href="classmlir_1_1Value.html">Value</a> &amp;val,</div>
<div class="line"><a name="l00997"></a><span class="lineno">  997</span>&#160;                                <span class="keywordtype">bool</span> &amp;foundIndexOp, VectorType resType) {</div>
<div class="line"><a name="l00998"></a><span class="lineno">  998</span>&#160; </div>
<div class="line"><a name="l00999"></a><span class="lineno">  999</span>&#160;  assert(((llvm::count_if(resType.getShape(),</div>
<div class="line"><a name="l01000"></a><span class="lineno"> 1000</span>&#160;                          [](int64_t dimSize) { return dimSize &gt; 1; }) == 1)) &amp;&amp;</div>
<div class="line"><a name="l01001"></a><span class="lineno"> 1001</span>&#160;         <span class="stringliteral">&quot;n-D vectors are not yet supported&quot;</span>);</div>
<div class="line"><a name="l01002"></a><span class="lineno"> 1002</span>&#160; </div>
<div class="line"><a name="l01003"></a><span class="lineno"> 1003</span>&#160;  <span class="comment">// Blocks outside _this_ linalg.generic are effectively loop invariant.</span></div>
<div class="line"><a name="l01004"></a><span class="lineno"> 1004</span>&#160;  <span class="comment">// However, analysing block arguments for _this_ linalg.generic Op is a bit</span></div>
<div class="line"><a name="l01005"></a><span class="lineno"> 1005</span>&#160;  <span class="comment">// tricky. Just bail out in the latter case.</span></div>
<div class="line"><a name="l01006"></a><span class="lineno"> 1006</span>&#160;  <span class="comment">// TODO: We could try analysing the corresponding affine map here.</span></div>
<div class="line"><a name="l01007"></a><span class="lineno"> 1007</span>&#160;  <span class="keyword">auto</span> *block = linalgOp.getBlock();</div>
<div class="line"><a name="l01008"></a><span class="lineno"> 1008</span>&#160;  <span class="keywordflow">if</span> (isa&lt;BlockArgument&gt;(val))</div>
<div class="line"><a name="l01009"></a><span class="lineno"> 1009</span>&#160;    <span class="keywordflow">return</span> !llvm::is_contained(block-&gt;getArguments(), val);</div>
<div class="line"><a name="l01010"></a><span class="lineno"> 1010</span>&#160; </div>
<div class="line"><a name="l01011"></a><span class="lineno"> 1011</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *defOp = val.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>();</div>
<div class="line"><a name="l01012"></a><span class="lineno"> 1012</span>&#160;  assert(defOp &amp;&amp; <span class="stringliteral">&quot;This is neither a block argument nor an operation result&quot;</span>);</div>
<div class="line"><a name="l01013"></a><span class="lineno"> 1013</span>&#160; </div>
<div class="line"><a name="l01014"></a><span class="lineno"> 1014</span>&#160;  <span class="keywordflow">if</span> (<span class="keyword">auto</span> indexOp = dyn_cast&lt;linalg::IndexOp&gt;(defOp)) {</div>
<div class="line"><a name="l01015"></a><span class="lineno"> 1015</span>&#160;    <span class="keyword">auto</span> loopDimThatIncrementsByOne = <a class="code" href="Vectorization_8cpp.html#a7e9ce28bca426dd4de93ad09392b4ec1">getTrailingNonUnitLoopDimIdx</a>(linalgOp);</div>
<div class="line"><a name="l01016"></a><span class="lineno"> 1016</span>&#160; </div>
<div class="line"><a name="l01017"></a><span class="lineno"> 1017</span>&#160;    foundIndexOp = (indexOp.getDim() == loopDimThatIncrementsByOne);</div>
<div class="line"><a name="l01018"></a><span class="lineno"> 1018</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l01019"></a><span class="lineno"> 1019</span>&#160;  }</div>
<div class="line"><a name="l01020"></a><span class="lineno"> 1020</span>&#160; </div>
<div class="line"><a name="l01021"></a><span class="lineno"> 1021</span>&#160;  <span class="keyword">auto</span> *ancestor = block-&gt;findAncestorOpInBlock(*defOp);</div>
<div class="line"><a name="l01022"></a><span class="lineno"> 1022</span>&#160; </div>
<div class="line"><a name="l01023"></a><span class="lineno"> 1023</span>&#160;  <span class="keywordflow">if</span> (!ancestor)</div>
<div class="line"><a name="l01024"></a><span class="lineno"> 1024</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l01025"></a><span class="lineno"> 1025</span>&#160; </div>
<div class="line"><a name="l01026"></a><span class="lineno"> 1026</span>&#160;  <span class="comment">// Conservatively reject Ops that could lead to indices with stride other</span></div>
<div class="line"><a name="l01027"></a><span class="lineno"> 1027</span>&#160;  <span class="comment">// than 1.</span></div>
<div class="line"><a name="l01028"></a><span class="lineno"> 1028</span>&#160;  <span class="keywordflow">if</span> (!isa&lt;arith::AddIOp, arith::ConstantOp, linalg::IndexOp&gt;(ancestor))</div>
<div class="line"><a name="l01029"></a><span class="lineno"> 1029</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l01030"></a><span class="lineno"> 1030</span>&#160; </div>
<div class="line"><a name="l01031"></a><span class="lineno"> 1031</span>&#160;  <span class="keywordtype">bool</span> result = <span class="keyword">false</span>;</div>
<div class="line"><a name="l01032"></a><span class="lineno"> 1032</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> op : ancestor-&gt;getOperands())</div>
<div class="line"><a name="l01033"></a><span class="lineno"> 1033</span>&#160;    result |= <a class="code" href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3">isContiguousLoadIdx</a>(linalgOp, op, foundIndexOp, resType);</div>
<div class="line"><a name="l01034"></a><span class="lineno"> 1034</span>&#160; </div>
<div class="line"><a name="l01035"></a><span class="lineno"> 1035</span>&#160;  <span class="keywordflow">return</span> result;</div>
<div class="line"><a name="l01036"></a><span class="lineno"> 1036</span>&#160;}</div>
<div class="line"><a name="l01037"></a><span class="lineno"> 1037</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01038"></a><span class="lineno"> 1038</span>&#160;<span class="comment">/// Infer the memory access pattern for the input ExtractOp</span></div>
<div class="line"><a name="l01039"></a><span class="lineno"> 1039</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01040"></a><span class="lineno"> 1040</span>&#160;<span class="comment">/// Based on the ExtratOp result shape and the access indices, decides whether</span></div>
<div class="line"><a name="l01041"></a><span class="lineno"> 1041</span>&#160;<span class="comment">/// this Op corresponds to a contiguous load (including a broadcast of a scalar)</span></div>
<div class="line"><a name="l01042"></a><span class="lineno"> 1042</span>&#160;<span class="comment">/// or a gather load. When analysing the ExtractOp indices (to identify</span></div>
<div class="line"><a name="l01043"></a><span class="lineno"> 1043</span>&#160;<span class="comment">/// contiguous laods), this method looks for &quot;loop&quot; invariant indices (e.g.</span></div>
<div class="line"><a name="l01044"></a><span class="lineno"> 1044</span>&#160;<span class="comment">/// block arguments) and indices that change linearly (e.g. via `linalg.index`</span></div>
<div class="line"><a name="l01045"></a><span class="lineno"> 1045</span>&#160;<span class="comment">/// Op).</span></div>
<div class="line"><a name="l01046"></a><span class="lineno"> 1046</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01047"></a><span class="lineno"> 1047</span>&#160;<span class="comment">/// Note that it is always safe to use gather load operations for contiguous</span></div>
<div class="line"><a name="l01048"></a><span class="lineno"> 1048</span>&#160;<span class="comment">/// loads (albeit slow), but not vice-versa. When in doubt, bail out and assume</span></div>
<div class="line"><a name="l01049"></a><span class="lineno"> 1049</span>&#160;<span class="comment">/// that `extractOp` is a gather load.</span></div>
<div class="line"><a name="l01050"></a><span class="lineno"> 1050</span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcc">VectorMemoryAccessKind</a></div>
<div class="line"><a name="l01051"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a172594be3a7384cb03a833aed99dc03c"> 1051</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a172594be3a7384cb03a833aed99dc03c">getTensorExtractMemoryAccessPattern</a>(tensor::ExtractOp extractOp,</div>
<div class="line"><a name="l01052"></a><span class="lineno"> 1052</span>&#160;                                    LinalgOp &amp;linalgOp, VectorType resType) {</div>
<div class="line"><a name="l01053"></a><span class="lineno"> 1053</span>&#160; </div>
<div class="line"><a name="l01054"></a><span class="lineno"> 1054</span>&#160;  <span class="keyword">auto</span> inputShape = cast&lt;ShapedType&gt;(extractOp.getTensor().getType());</div>
<div class="line"><a name="l01055"></a><span class="lineno"> 1055</span>&#160; </div>
<div class="line"><a name="l01056"></a><span class="lineno"> 1056</span>&#160;  <span class="comment">// 0. Is this a 0-D vector? If yes then this is a scalar broadcast.</span></div>
<div class="line"><a name="l01057"></a><span class="lineno"> 1057</span>&#160;  <span class="keywordflow">if</span> (inputShape.getShape().empty())</div>
<div class="line"><a name="l01058"></a><span class="lineno"> 1058</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">VectorMemoryAccessKind::ScalarBroadcast</a>;</div>
<div class="line"><a name="l01059"></a><span class="lineno"> 1059</span>&#160; </div>
<div class="line"><a name="l01060"></a><span class="lineno"> 1060</span>&#160;  <span class="comment">// True for vectors that are effectively 1D, e.g. `vector&lt;1x4x1xi32&gt;`, false</span></div>
<div class="line"><a name="l01061"></a><span class="lineno"> 1061</span>&#160;  <span class="comment">// otherwise.</span></div>
<div class="line"><a name="l01062"></a><span class="lineno"> 1062</span>&#160;  <span class="keywordtype">bool</span> isOutput1DVector =</div>
<div class="line"><a name="l01063"></a><span class="lineno"> 1063</span>&#160;      (llvm::count_if(resType.getShape(),</div>
<div class="line"><a name="l01064"></a><span class="lineno"> 1064</span>&#160;                      [](int64_t dimSize) { return dimSize &gt; 1; }) == 1);</div>
<div class="line"><a name="l01065"></a><span class="lineno"> 1065</span>&#160;  <span class="comment">// 1. Assume that it&#39;s a gather load when reading non-1D vector.</span></div>
<div class="line"><a name="l01066"></a><span class="lineno"> 1066</span>&#160;  <span class="keywordflow">if</span> (!isOutput1DVector)</div>
<div class="line"><a name="l01067"></a><span class="lineno"> 1067</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">VectorMemoryAccessKind::Gather</a>;</div>
<div class="line"><a name="l01068"></a><span class="lineno"> 1068</span>&#160; </div>
<div class="line"><a name="l01069"></a><span class="lineno"> 1069</span>&#160;  <span class="keywordtype">bool</span> leadingIdxsLoopInvariant = <span class="keyword">true</span>;</div>
<div class="line"><a name="l01070"></a><span class="lineno"> 1070</span>&#160; </div>
<div class="line"><a name="l01071"></a><span class="lineno"> 1071</span>&#160;  <span class="comment">// 2. Analyze the leading indices of `extractOp`.</span></div>
<div class="line"><a name="l01072"></a><span class="lineno"> 1072</span>&#160;  <span class="comment">// Look at the way each index is calculated and decide whether it is suitable</span></div>
<div class="line"><a name="l01073"></a><span class="lineno"> 1073</span>&#160;  <span class="comment">// for a contiguous load, i.e. whether it&#39;s loop invariant. If not, it&#39;s a</span></div>
<div class="line"><a name="l01074"></a><span class="lineno"> 1074</span>&#160;  <span class="comment">// gather load.</span></div>
<div class="line"><a name="l01075"></a><span class="lineno"> 1075</span>&#160;  <span class="keyword">auto</span> indices = extractOp.getIndices();</div>
<div class="line"><a name="l01076"></a><span class="lineno"> 1076</span>&#160;  <span class="keyword">auto</span> leadIndices = indices.drop_back(1);</div>
<div class="line"><a name="l01077"></a><span class="lineno"> 1077</span>&#160; </div>
<div class="line"><a name="l01078"></a><span class="lineno"> 1078</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, indexVal] : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">llvm::enumerate</a>(leadIndices)) {</div>
<div class="line"><a name="l01079"></a><span class="lineno"> 1079</span>&#160;    <span class="keywordflow">if</span> (inputShape.getShape()[i] == 1)</div>
<div class="line"><a name="l01080"></a><span class="lineno"> 1080</span>&#160;      <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l01081"></a><span class="lineno"> 1081</span>&#160; </div>
<div class="line"><a name="l01082"></a><span class="lineno"> 1082</span>&#160;    leadingIdxsLoopInvariant &amp;= <a class="code" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a>(linalgOp, indexVal, resType);</div>
<div class="line"><a name="l01083"></a><span class="lineno"> 1083</span>&#160;  }</div>
<div class="line"><a name="l01084"></a><span class="lineno"> 1084</span>&#160; </div>
<div class="line"><a name="l01085"></a><span class="lineno"> 1085</span>&#160;  <span class="keywordflow">if</span> (!leadingIdxsLoopInvariant) {</div>
<div class="line"><a name="l01086"></a><span class="lineno"> 1086</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Found gather load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a name="l01087"></a><span class="lineno"> 1087</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">VectorMemoryAccessKind::Gather</a>;</div>
<div class="line"><a name="l01088"></a><span class="lineno"> 1088</span>&#160;  }</div>
<div class="line"><a name="l01089"></a><span class="lineno"> 1089</span>&#160; </div>
<div class="line"><a name="l01090"></a><span class="lineno"> 1090</span>&#160;  <span class="comment">// 3. Analyze the trailing index for `extractOp`.</span></div>
<div class="line"><a name="l01091"></a><span class="lineno"> 1091</span>&#160;  <span class="comment">// At this point we know that the leading indices are loop invariant. This</span></div>
<div class="line"><a name="l01092"></a><span class="lineno"> 1092</span>&#160;  <span class="comment">// means that is potentially a scalar or a contiguous load. We can decide</span></div>
<div class="line"><a name="l01093"></a><span class="lineno"> 1093</span>&#160;  <span class="comment">// based on the trailing idx.</span></div>
<div class="line"><a name="l01094"></a><span class="lineno"> 1094</span>&#160;  <span class="keyword">auto</span> extractOpTrailingIdx = indices.back();</div>
<div class="line"><a name="l01095"></a><span class="lineno"> 1095</span>&#160; </div>
<div class="line"><a name="l01096"></a><span class="lineno"> 1096</span>&#160;  <span class="comment">// 3a. Scalar broadcast load</span></div>
<div class="line"><a name="l01097"></a><span class="lineno"> 1097</span>&#160;  <span class="comment">// If the trailing index is loop invariant then this is a scalar load.</span></div>
<div class="line"><a name="l01098"></a><span class="lineno"> 1098</span>&#160;  <span class="keywordflow">if</span> (leadingIdxsLoopInvariant &amp;&amp;</div>
<div class="line"><a name="l01099"></a><span class="lineno"> 1099</span>&#160;      <a class="code" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a>(linalgOp, extractOpTrailingIdx, resType)) {</div>
<div class="line"><a name="l01100"></a><span class="lineno"> 1100</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Found scalar broadcast load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a name="l01101"></a><span class="lineno"> 1101</span>&#160; </div>
<div class="line"><a name="l01102"></a><span class="lineno"> 1102</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">VectorMemoryAccessKind::ScalarBroadcast</a>;</div>
<div class="line"><a name="l01103"></a><span class="lineno"> 1103</span>&#160;  }</div>
<div class="line"><a name="l01104"></a><span class="lineno"> 1104</span>&#160; </div>
<div class="line"><a name="l01105"></a><span class="lineno"> 1105</span>&#160;  <span class="comment">// 3b. Contiguous loads</span></div>
<div class="line"><a name="l01106"></a><span class="lineno"> 1106</span>&#160;  <span class="comment">// The trailing `extractOp` index should increment with every loop iteration.</span></div>
<div class="line"><a name="l01107"></a><span class="lineno"> 1107</span>&#160;  <span class="comment">// This effectively means that it must be based on the trailing loop index.</span></div>
<div class="line"><a name="l01108"></a><span class="lineno"> 1108</span>&#160;  <span class="comment">// This is what the following bool captures.</span></div>
<div class="line"><a name="l01109"></a><span class="lineno"> 1109</span>&#160;  <span class="keywordtype">bool</span> foundIndexOp = <span class="keyword">false</span>;</div>
<div class="line"><a name="l01110"></a><span class="lineno"> 1110</span>&#160;  <span class="keywordtype">bool</span> isContiguousLoad = <a class="code" href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3">isContiguousLoadIdx</a>(linalgOp, extractOpTrailingIdx,</div>
<div class="line"><a name="l01111"></a><span class="lineno"> 1111</span>&#160;                                              foundIndexOp, resType);</div>
<div class="line"><a name="l01112"></a><span class="lineno"> 1112</span>&#160;  <span class="comment">// TODO: Support generating contiguous loads for column vectors - that will</span></div>
<div class="line"><a name="l01113"></a><span class="lineno"> 1113</span>&#160;  <span class="comment">// require adding a permutation map to tranfer_read Ops.</span></div>
<div class="line"><a name="l01114"></a><span class="lineno"> 1114</span>&#160;  <span class="keywordtype">bool</span> isRowVector = resType.getShape().back() != 1;</div>
<div class="line"><a name="l01115"></a><span class="lineno"> 1115</span>&#160;  isContiguousLoad &amp;= (foundIndexOp &amp;&amp; isRowVector);</div>
<div class="line"><a name="l01116"></a><span class="lineno"> 1116</span>&#160; </div>
<div class="line"><a name="l01117"></a><span class="lineno"> 1117</span>&#160;  <span class="keywordflow">if</span> (isContiguousLoad) {</div>
<div class="line"><a name="l01118"></a><span class="lineno"> 1118</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Found contigous load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a name="l01119"></a><span class="lineno"> 1119</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea">VectorMemoryAccessKind::Contiguous</a>;</div>
<div class="line"><a name="l01120"></a><span class="lineno"> 1120</span>&#160;  }</div>
<div class="line"><a name="l01121"></a><span class="lineno"> 1121</span>&#160; </div>
<div class="line"><a name="l01122"></a><span class="lineno"> 1122</span>&#160;  <span class="comment">// 4. Fallback case - gather load.</span></div>
<div class="line"><a name="l01123"></a><span class="lineno"> 1123</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Found gather load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a name="l01124"></a><span class="lineno"> 1124</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">VectorMemoryAccessKind::Gather</a>;</div>
<div class="line"><a name="l01125"></a><span class="lineno"> 1125</span>&#160;}</div>
<div class="line"><a name="l01126"></a><span class="lineno"> 1126</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01127"></a><span class="lineno"> 1127</span>&#160;<span class="comment">/// Helper function to vectorize the tensor.extract operations. Returns</span></div>
<div class="line"><a name="l01128"></a><span class="lineno"> 1128</span>&#160;<span class="comment">/// VectorizationHookStatus::NewOp to signal the vectorization algorithm that it</span></div>
<div class="line"><a name="l01129"></a><span class="lineno"> 1129</span>&#160;<span class="comment">/// should map the produced operations. This function is meant to be used as a</span></div>
<div class="line"><a name="l01130"></a><span class="lineno"> 1130</span>&#160;<span class="comment">/// CustomVectorizationHook.</span></div>
<div class="line"><a name="l01131"></a><span class="lineno"> 1131</span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a></div>
<div class="line"><a name="l01132"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a26cb5e24425fdce30baaba6f7c0f5c84"> 1132</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a26cb5e24425fdce30baaba6f7c0f5c84">vectorizeTensorExtract</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="structVectorizationState.html">VectorizationState</a> &amp;state,</div>
<div class="line"><a name="l01133"></a><span class="lineno"> 1133</span>&#160;                       <a class="code" href="classmlir_1_1Operation.html">Operation</a> *op, LinalgOp linalgOp, <span class="keyword">const</span> <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) {</div>
<div class="line"><a name="l01134"></a><span class="lineno"> 1134</span>&#160;  tensor::ExtractOp extractOp = dyn_cast&lt;tensor::ExtractOp&gt;(op);</div>
<div class="line"><a name="l01135"></a><span class="lineno"> 1135</span>&#160;  <span class="keywordflow">if</span> (!extractOp)</div>
<div class="line"><a name="l01136"></a><span class="lineno"> 1136</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a name="l01137"></a><span class="lineno"> 1137</span>&#160;  <span class="keyword">auto</span> loc = extractOp.getLoc();</div>
<div class="line"><a name="l01138"></a><span class="lineno"> 1138</span>&#160; </div>
<div class="line"><a name="l01139"></a><span class="lineno"> 1139</span>&#160;  <span class="comment">// Compute the static loop sizes of the extract op.</span></div>
<div class="line"><a name="l01140"></a><span class="lineno"> 1140</span>&#160;  <span class="keyword">auto</span> resultType = state.getCanonicalVecType(extractOp.getResult().getType());</div>
<div class="line"><a name="l01141"></a><span class="lineno"> 1141</span>&#160;  <span class="keyword">auto</span> maskConstantOp = arith::ConstantOp::create(</div>
<div class="line"><a name="l01142"></a><span class="lineno"> 1142</span>&#160;      rewriter, loc,</div>
<div class="line"><a name="l01143"></a><span class="lineno"> 1143</span>&#160;      <a class="code" href="classmlir_1_1DenseIntElementsAttr.html#a9db4e0b61c851fb050659e8a3cd4f4a0">DenseIntElementsAttr::get</a>(state.getCanonicalVecType(rewriter.<a class="code" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>()),</div>
<div class="line"><a name="l01144"></a><span class="lineno"> 1144</span>&#160;                                <span class="comment">/*value=*/</span><span class="keyword">true</span>));</div>
<div class="line"><a name="l01145"></a><span class="lineno"> 1145</span>&#160;  <span class="keyword">auto</span> passThruConstantOp = arith::ConstantOp::create(</div>
<div class="line"><a name="l01146"></a><span class="lineno"> 1146</span>&#160;      rewriter, loc, rewriter.<a class="code" href="classmlir_1_1Builder.html#a8e943986e58a8b0c88fcd51b0f0afafb">getZeroAttr</a>(resultType));</div>
<div class="line"><a name="l01147"></a><span class="lineno"> 1147</span>&#160; </div>
<div class="line"><a name="l01148"></a><span class="lineno"> 1148</span>&#160;  <span class="comment">// Base indices are currently set to 0. We will need to re-visit if more</span></div>
<div class="line"><a name="l01149"></a><span class="lineno"> 1149</span>&#160;  <span class="comment">// generic scenarios are to be supported.</span></div>
<div class="line"><a name="l01150"></a><span class="lineno"> 1150</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> baseIndices(</div>
<div class="line"><a name="l01151"></a><span class="lineno"> 1151</span>&#160;      extractOp.getIndices().size(),</div>
<div class="line"><a name="l01152"></a><span class="lineno"> 1152</span>&#160;      <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0));</div>
<div class="line"><a name="l01153"></a><span class="lineno"> 1153</span>&#160; </div>
<div class="line"><a name="l01154"></a><span class="lineno"> 1154</span>&#160;  <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcc">VectorMemoryAccessKind</a> memAccessKind =</div>
<div class="line"><a name="l01155"></a><span class="lineno"> 1155</span>&#160;      <a class="code" href="Vectorization_8cpp.html#a172594be3a7384cb03a833aed99dc03c">getTensorExtractMemoryAccessPattern</a>(extractOp, linalgOp, resultType);</div>
<div class="line"><a name="l01156"></a><span class="lineno"> 1156</span>&#160; </div>
<div class="line"><a name="l01157"></a><span class="lineno"> 1157</span>&#160;  <span class="comment">// 1. Handle gather access</span></div>
<div class="line"><a name="l01158"></a><span class="lineno"> 1158</span>&#160;  <span class="keywordflow">if</span> (memAccessKind == <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">VectorMemoryAccessKind::Gather</a>) {</div>
<div class="line"><a name="l01159"></a><span class="lineno"> 1159</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> offset = <a class="code" href="Vectorization_8cpp.html#ae4411a5d89520c86474035493a7da7c1">calculateGatherOffset</a>(rewriter, state, extractOp, bvm);</div>
<div class="line"><a name="l01160"></a><span class="lineno"> 1160</span>&#160; </div>
<div class="line"><a name="l01161"></a><span class="lineno"> 1161</span>&#160;    <span class="comment">// Generate the gather load</span></div>
<div class="line"><a name="l01162"></a><span class="lineno"> 1162</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *gatherOp = vector::GatherOp::create(</div>
<div class="line"><a name="l01163"></a><span class="lineno"> 1163</span>&#160;        rewriter, loc, resultType, extractOp.getTensor(), baseIndices, offset,</div>
<div class="line"><a name="l01164"></a><span class="lineno"> 1164</span>&#160;        maskConstantOp, passThruConstantOp);</div>
<div class="line"><a name="l01165"></a><span class="lineno"> 1165</span>&#160;    gatherOp = state.maskOperation(rewriter, gatherOp, linalgOp);</div>
<div class="line"><a name="l01166"></a><span class="lineno"> 1166</span>&#160; </div>
<div class="line"><a name="l01167"></a><span class="lineno"> 1167</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorised as gather load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a name="l01168"></a><span class="lineno"> 1168</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>, gatherOp};</div>
<div class="line"><a name="l01169"></a><span class="lineno"> 1169</span>&#160;  }</div>
<div class="line"><a name="l01170"></a><span class="lineno"> 1170</span>&#160; </div>
<div class="line"><a name="l01171"></a><span class="lineno"> 1171</span>&#160;  <span class="comment">// 2. Handle:</span></div>
<div class="line"><a name="l01172"></a><span class="lineno"> 1172</span>&#160;  <span class="comment">//  a. scalar loads + broadcast,</span></div>
<div class="line"><a name="l01173"></a><span class="lineno"> 1173</span>&#160;  <span class="comment">//  b. contiguous loads.</span></div>
<div class="line"><a name="l01174"></a><span class="lineno"> 1174</span>&#160;  <span class="comment">// Both cases use vector.transfer_read.</span></div>
<div class="line"><a name="l01175"></a><span class="lineno"> 1175</span>&#160; </div>
<div class="line"><a name="l01176"></a><span class="lineno"> 1176</span>&#160;  <span class="comment">// Collect indices for `vector.transfer_read`. At this point, the indices will</span></div>
<div class="line"><a name="l01177"></a><span class="lineno"> 1177</span>&#160;  <span class="comment">// either be scalars or would have been broadcast to vectors matching the</span></div>
<div class="line"><a name="l01178"></a><span class="lineno"> 1178</span>&#160;  <span class="comment">// result type. For indices that are vectors, there are two options:</span></div>
<div class="line"><a name="l01179"></a><span class="lineno"> 1179</span>&#160;  <span class="comment">//    * for non-trailing indices, all elements are identical (contiguous</span></div>
<div class="line"><a name="l01180"></a><span class="lineno"> 1180</span>&#160;  <span class="comment">//      loads are identified by looking for non-trailing indices that are</span></div>
<div class="line"><a name="l01181"></a><span class="lineno"> 1181</span>&#160;  <span class="comment">//      invariant with respect to the corresponding linalg.generic), or</span></div>
<div class="line"><a name="l01182"></a><span class="lineno"> 1182</span>&#160;  <span class="comment">//    * for trailing indices, the index vector will contain values with stride</span></div>
<div class="line"><a name="l01183"></a><span class="lineno"> 1183</span>&#160;  <span class="comment">//      one, but for `vector.transfer_read` only the first (i.e. 0th) index is</span></div>
<div class="line"><a name="l01184"></a><span class="lineno"> 1184</span>&#160;  <span class="comment">//      needed.</span></div>
<div class="line"><a name="l01185"></a><span class="lineno"> 1185</span>&#160;  <span class="comment">// This means that</span></div>
<div class="line"><a name="l01186"></a><span class="lineno"> 1186</span>&#160;  <span class="comment">//   * for scalar indices - just re-use it,</span></div>
<div class="line"><a name="l01187"></a><span class="lineno"> 1187</span>&#160;  <span class="comment">//   * for vector indices (e.g. `vector&lt;1x1x4xindex&gt;`) - extract the bottom</span></div>
<div class="line"><a name="l01188"></a><span class="lineno"> 1188</span>&#160;  <span class="comment">//    (0th) element and use that.</span></div>
<div class="line"><a name="l01189"></a><span class="lineno"> 1189</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> transferReadIdxs;</div>
<div class="line"><a name="l01190"></a><span class="lineno"> 1190</span>&#160;  <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; extractOp.getIndices().size(); i++) {</div>
<div class="line"><a name="l01191"></a><span class="lineno"> 1191</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> idx = bvm.<a class="code" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(extractOp.getIndices()[i]);</div>
<div class="line"><a name="l01192"></a><span class="lineno"> 1192</span>&#160;    <span class="keywordflow">if</span> (idx.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>().<a class="code" href="classmlir_1_1Type.html#a5d5d5335ce4fc906636a2690155a7d72">isIndex</a>()) {</div>
<div class="line"><a name="l01193"></a><span class="lineno"> 1193</span>&#160;      transferReadIdxs.push_back(idx);</div>
<div class="line"><a name="l01194"></a><span class="lineno"> 1194</span>&#160;      <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l01195"></a><span class="lineno"> 1195</span>&#160;    }</div>
<div class="line"><a name="l01196"></a><span class="lineno"> 1196</span>&#160; </div>
<div class="line"><a name="l01197"></a><span class="lineno"> 1197</span>&#160;    <span class="keyword">auto</span> indexAs1dVector = vector::ShapeCastOp::create(</div>
<div class="line"><a name="l01198"></a><span class="lineno"> 1198</span>&#160;        rewriter, loc,</div>
<div class="line"><a name="l01199"></a><span class="lineno"> 1199</span>&#160;        <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(resultType.getShape().back(), rewriter.<a class="code" href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">getIndexType</a>(),</div>
<div class="line"><a name="l01200"></a><span class="lineno"> 1200</span>&#160;                        resultType.getScalableDims().back()),</div>
<div class="line"><a name="l01201"></a><span class="lineno"> 1201</span>&#160;        idx);</div>
<div class="line"><a name="l01202"></a><span class="lineno"> 1202</span>&#160;    transferReadIdxs.push_back(</div>
<div class="line"><a name="l01203"></a><span class="lineno"> 1203</span>&#160;        vector::ExtractOp::create(rewriter, loc, indexAs1dVector, 0));</div>
<div class="line"><a name="l01204"></a><span class="lineno"> 1204</span>&#160;  }</div>
<div class="line"><a name="l01205"></a><span class="lineno"> 1205</span>&#160; </div>
<div class="line"><a name="l01206"></a><span class="lineno"> 1206</span>&#160;  <span class="comment">// `tensor.extract_element` is always in-bounds, hence the following holds.</span></div>
<div class="line"><a name="l01207"></a><span class="lineno"> 1207</span>&#160;  <span class="keyword">auto</span> dstRank = resultType.getRank();</div>
<div class="line"><a name="l01208"></a><span class="lineno"> 1208</span>&#160;  <span class="keyword">auto</span> srcRank = extractOp.getTensor().getType().getRank();</div>
<div class="line"><a name="l01209"></a><span class="lineno"> 1209</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(dstRank, <span class="keyword">true</span>);</div>
<div class="line"><a name="l01210"></a><span class="lineno"> 1210</span>&#160; </div>
<div class="line"><a name="l01211"></a><span class="lineno"> 1211</span>&#160;  <span class="comment">// 2a. Handle scalar broadcast access.</span></div>
<div class="line"><a name="l01212"></a><span class="lineno"> 1212</span>&#160;  <span class="keywordflow">if</span> (memAccessKind == <a class="code" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">VectorMemoryAccessKind::ScalarBroadcast</a>) {</div>
<div class="line"><a name="l01213"></a><span class="lineno"> 1213</span>&#160;    <a class="code" href="classmlir_1_1MLIRContext.html">MLIRContext</a> *ctx = rewriter.<a class="code" href="classmlir_1_1Builder.html#aa6d1e114c8047cad1b014b504688a868">getContext</a>();</div>
<div class="line"><a name="l01214"></a><span class="lineno"> 1214</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;AffineExpr&gt;</a> exprs(dstRank, <a class="code" href="namespacemlir.html#ab26cdced424aa629fde4150cc8674d50">getAffineConstantExpr</a>(0, ctx));</div>
<div class="line"><a name="l01215"></a><span class="lineno"> 1215</span>&#160;    <span class="keyword">auto</span> permutationMap = <a class="code" href="classmlir_1_1AffineMap.html#a3cfca2eb29fddf3c4bda714cccaa53f9">AffineMap::get</a>(srcRank, 0, exprs, ctx);</div>
<div class="line"><a name="l01216"></a><span class="lineno"> 1216</span>&#160; </div>
<div class="line"><a name="l01217"></a><span class="lineno"> 1217</span>&#160;    <span class="keyword">auto</span> transferReadOp = vector::TransferReadOp::create(</div>
<div class="line"><a name="l01218"></a><span class="lineno"> 1218</span>&#160;        rewriter, loc, resultType, extractOp.getTensor(), transferReadIdxs,</div>
<div class="line"><a name="l01219"></a><span class="lineno"> 1219</span>&#160;        <span class="comment">/*padding=*/</span>std::nullopt, permutationMap, inBounds);</div>
<div class="line"><a name="l01220"></a><span class="lineno"> 1220</span>&#160; </div>
<div class="line"><a name="l01221"></a><span class="lineno"> 1221</span>&#160;    <span class="comment">// Mask this broadcasting xfer_read here rather than relying on the generic</span></div>
<div class="line"><a name="l01222"></a><span class="lineno"> 1222</span>&#160;    <span class="comment">// path (the generic path assumes identity masking map, which wouldn&#39;t be</span></div>
<div class="line"><a name="l01223"></a><span class="lineno"> 1223</span>&#160;    <span class="comment">// valid here).</span></div>
<div class="line"><a name="l01224"></a><span class="lineno"> 1224</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> readMaskShape = {1};</div>
<div class="line"><a name="l01225"></a><span class="lineno"> 1225</span>&#160;    <span class="keyword">auto</span> readMaskType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(readMaskShape, rewriter.<a class="code" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>());</div>
<div class="line"><a name="l01226"></a><span class="lineno"> 1226</span>&#160;    <span class="keyword">auto</span> allTrue = vector::ConstantMaskOp::create(</div>
<div class="line"><a name="l01227"></a><span class="lineno"> 1227</span>&#160;        rewriter, loc, readMaskType, <a class="code" href="namespacemlir_1_1vector.html#a4ba6d4a825dbd36205be5322733056efa822b19813c2556c566eec6864da1319f">vector::ConstantMaskKind::AllTrue</a>);</div>
<div class="line"><a name="l01228"></a><span class="lineno"> 1228</span>&#160;    <span class="keyword">auto</span> *maskedReadOp =</div>
<div class="line"><a name="l01229"></a><span class="lineno"> 1229</span>&#160;        <a class="code" href="namespacemlir_1_1vector.html#a4f68d86708480673ecc59b2714973a65">mlir::vector::maskOperation</a>(rewriter, transferReadOp, allTrue);</div>
<div class="line"><a name="l01230"></a><span class="lineno"> 1230</span>&#160; </div>
<div class="line"><a name="l01231"></a><span class="lineno"> 1231</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorised as scalar broadcast load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a name="l01232"></a><span class="lineno"> 1232</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>,</div>
<div class="line"><a name="l01233"></a><span class="lineno"> 1233</span>&#160;                                   maskedReadOp};</div>
<div class="line"><a name="l01234"></a><span class="lineno"> 1234</span>&#160;  }</div>
<div class="line"><a name="l01235"></a><span class="lineno"> 1235</span>&#160; </div>
<div class="line"><a name="l01236"></a><span class="lineno"> 1236</span>&#160;  <span class="comment">// 2b. Handle contiguous access.</span></div>
<div class="line"><a name="l01237"></a><span class="lineno"> 1237</span>&#160;  <span class="keyword">auto</span> permutationMap = <a class="code" href="classmlir_1_1AffineMap.html#a035fc7c93286e3aa0354f522f2cd885a">AffineMap::getMinorIdentityMap</a>(</div>
<div class="line"><a name="l01238"></a><span class="lineno"> 1238</span>&#160;      srcRank, <a class="code" href="PolynomialApproximation_8cpp.html#af7cb11d1121f694b53c0981dc5e8ba9a">std::min</a>(dstRank, srcRank), rewriter.<a class="code" href="classmlir_1_1Builder.html#aa6d1e114c8047cad1b014b504688a868">getContext</a>());</div>
<div class="line"><a name="l01239"></a><span class="lineno"> 1239</span>&#160; </div>
<div class="line"><a name="l01240"></a><span class="lineno"> 1240</span>&#160;  int32_t rankDiff = dstRank - srcRank;</div>
<div class="line"><a name="l01241"></a><span class="lineno"> 1241</span>&#160;  <span class="comment">// When dstRank &gt; srcRank, broadcast the source tensor to the unitary leading</span></div>
<div class="line"><a name="l01242"></a><span class="lineno"> 1242</span>&#160;  <span class="comment">// dims so that the ranks match. This is done by extending the map with 0s.</span></div>
<div class="line"><a name="l01243"></a><span class="lineno"> 1243</span>&#160;  <span class="comment">// For example, for dstRank = 3, srcRank = 2, the following map created</span></div>
<div class="line"><a name="l01244"></a><span class="lineno"> 1244</span>&#160;  <span class="comment">// above:</span></div>
<div class="line"><a name="l01245"></a><span class="lineno"> 1245</span>&#160;  <span class="comment">//    (d0, d1) --&gt; (d0, d1)</span></div>
<div class="line"><a name="l01246"></a><span class="lineno"> 1246</span>&#160;  <span class="comment">// is extended as:</span></div>
<div class="line"><a name="l01247"></a><span class="lineno"> 1247</span>&#160;  <span class="comment">//    (d0, d1) --&gt; (0, d0, d1)</span></div>
<div class="line"><a name="l01248"></a><span class="lineno"> 1248</span>&#160;  <span class="keywordflow">while</span> (rankDiff &gt; 0) {</div>
<div class="line"><a name="l01249"></a><span class="lineno"> 1249</span>&#160;    permutationMap = permutationMap.insertResult(</div>
<div class="line"><a name="l01250"></a><span class="lineno"> 1250</span>&#160;        <a class="code" href="namespacemlir.html#ab26cdced424aa629fde4150cc8674d50">mlir::getAffineConstantExpr</a>(0, rewriter.<a class="code" href="classmlir_1_1Builder.html#aa6d1e114c8047cad1b014b504688a868">getContext</a>()), 0);</div>
<div class="line"><a name="l01251"></a><span class="lineno"> 1251</span>&#160;    rankDiff--;</div>
<div class="line"><a name="l01252"></a><span class="lineno"> 1252</span>&#160;  }</div>
<div class="line"><a name="l01253"></a><span class="lineno"> 1253</span>&#160; </div>
<div class="line"><a name="l01254"></a><span class="lineno"> 1254</span>&#160;  <span class="keyword">auto</span> transferReadOp = vector::TransferReadOp::create(</div>
<div class="line"><a name="l01255"></a><span class="lineno"> 1255</span>&#160;      rewriter, loc, resultType, extractOp.getTensor(), transferReadIdxs,</div>
<div class="line"><a name="l01256"></a><span class="lineno"> 1256</span>&#160;      <span class="comment">/*padding=*/</span>std::nullopt, permutationMap, inBounds);</div>
<div class="line"><a name="l01257"></a><span class="lineno"> 1257</span>&#160; </div>
<div class="line"><a name="l01258"></a><span class="lineno"> 1258</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorised as contiguous load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a name="l01259"></a><span class="lineno"> 1259</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>,</div>
<div class="line"><a name="l01260"></a><span class="lineno"> 1260</span>&#160;                                 transferReadOp};</div>
<div class="line"><a name="l01261"></a><span class="lineno"> 1261</span>&#160;}</div>
<div class="line"><a name="l01262"></a><span class="lineno"> 1262</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01263"></a><span class="lineno"> 1263</span>&#160;<span class="comment">/// Emit reduction operations if the shapes of the value to reduce is different</span></div>
<div class="line"><a name="l01264"></a><span class="lineno"> 1264</span>&#160;<span class="comment">/// that the result shape.</span></div>
<div class="line"><a name="l01265"></a><span class="lineno"> 1265</span>&#160;<span class="comment"></span><span class="comment">// Note: this is a true builder that notifies the OpBuilder listener.</span></div>
<div class="line"><a name="l01266"></a><span class="lineno"> 1266</span>&#160;<span class="comment">// TODO: Consider moving as a static helper on the ReduceOp.</span></div>
<div class="line"><a name="l01267"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a53b9b71ed8f443a028671c1eb661054d"> 1267</a></span>&#160;<span class="keyword">static</span> <a class="code" href="classmlir_1_1Operation.html">Operation</a> *<a class="code" href="Vectorization_8cpp.html#a53b9b71ed8f443a028671c1eb661054d">reduceIfNeeded</a>(<a class="code" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;b, LinalgOp linalgOp, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *op,</div>
<div class="line"><a name="l01268"></a><span class="lineno"> 1268</span>&#160;                                 <a class="code" href="classmlir_1_1Value.html">Value</a> reduceValue, <a class="code" href="classmlir_1_1Value.html">Value</a> initialValue,</div>
<div class="line"><a name="l01269"></a><span class="lineno"> 1269</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) {</div>
<div class="line"><a name="l01270"></a><span class="lineno"> 1270</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> reduceVec = bvm.<a class="code" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(reduceValue);</div>
<div class="line"><a name="l01271"></a><span class="lineno"> 1271</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> outputVec = bvm.<a class="code" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(initialValue);</div>
<div class="line"><a name="l01272"></a><span class="lineno"> 1272</span>&#160;  <span class="keyword">auto</span> reduceType = dyn_cast&lt;VectorType&gt;(reduceVec.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l01273"></a><span class="lineno"> 1273</span>&#160;  <span class="keyword">auto</span> outputType = dyn_cast&lt;VectorType&gt;(outputVec.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l01274"></a><span class="lineno"> 1274</span>&#160;  <span class="comment">// Reduce only if needed as the value may already have been reduce for</span></div>
<div class="line"><a name="l01275"></a><span class="lineno"> 1275</span>&#160;  <span class="comment">// contraction vectorization.</span></div>
<div class="line"><a name="l01276"></a><span class="lineno"> 1276</span>&#160;  <span class="keywordflow">if</span> (!reduceType ||</div>
<div class="line"><a name="l01277"></a><span class="lineno"> 1277</span>&#160;      (outputType &amp;&amp; reduceType.getShape() == outputType.getShape()))</div>
<div class="line"><a name="l01278"></a><span class="lineno"> 1278</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">nullptr</span>;</div>
<div class="line"><a name="l01279"></a><span class="lineno"> 1279</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> dimsToMask = <a class="code" href="Vectorization_8cpp.html#ae26a024dfac331ddb29bc4a78271b9d0">getDimsToReduce</a>(linalgOp);</div>
<div class="line"><a name="l01280"></a><span class="lineno"> 1280</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a786634b3fadeefcfe74e0c22f18312f1">buildMultiDimReduce</a>(b, op, reduceVec, outputVec, dimsToMask);</div>
<div class="line"><a name="l01281"></a><span class="lineno"> 1281</span>&#160;}</div>
<div class="line"><a name="l01282"></a><span class="lineno"> 1282</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01283"></a><span class="lineno"> 1283</span>&#160;<span class="comment">/// Generic vectorization for a single operation `op`, given already vectorized</span></div>
<div class="line"><a name="l01284"></a><span class="lineno"> 1284</span>&#160;<span class="comment">/// operands carried by `bvm`. Vectorization occurs as follows:</span></div>
<div class="line"><a name="l01285"></a><span class="lineno"> 1285</span>&#160;<span class="comment">///   1. Try to apply any of the `customVectorizationHooks` and return its</span></div>
<div class="line"><a name="l01286"></a><span class="lineno"> 1286</span>&#160;<span class="comment">///   result on success.</span></div>
<div class="line"><a name="l01287"></a><span class="lineno"> 1287</span>&#160;<span class="comment">///   2. Clone any constant in the current scope without vectorization: each</span></div>
<div class="line"><a name="l01288"></a><span class="lineno"> 1288</span>&#160;<span class="comment">///   consumer of the constant will later determine the shape to which the</span></div>
<div class="line"><a name="l01289"></a><span class="lineno"> 1289</span>&#160;<span class="comment">///   constant needs to be broadcast to.</span></div>
<div class="line"><a name="l01290"></a><span class="lineno"> 1290</span>&#160;<span class="comment">///   3. Fail on any remaining non `ElementwiseMappable` op. It is the purpose</span></div>
<div class="line"><a name="l01291"></a><span class="lineno"> 1291</span>&#160;<span class="comment">///   of the `customVectorizationHooks` to cover such cases.</span></div>
<div class="line"><a name="l01292"></a><span class="lineno"> 1292</span>&#160;<span class="comment">///   4. Clone `op` in vector form to a vector of shape prescribed by the first</span></div>
<div class="line"><a name="l01293"></a><span class="lineno"> 1293</span>&#160;<span class="comment">///   operand of maximal rank. Other operands have smaller rank and are</span></div>
<div class="line"><a name="l01294"></a><span class="lineno"> 1294</span>&#160;<span class="comment">///   broadcast accordingly. It is assumed this broadcast is always legal,</span></div>
<div class="line"><a name="l01295"></a><span class="lineno"> 1295</span>&#160;<span class="comment">///   otherwise, it means one of the `customVectorizationHooks` is incorrect.</span></div>
<div class="line"><a name="l01296"></a><span class="lineno"> 1296</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01297"></a><span class="lineno"> 1297</span>&#160;<span class="comment">/// This function assumes all operands of `op` have been vectorized and are in</span></div>
<div class="line"><a name="l01298"></a><span class="lineno"> 1298</span>&#160;<span class="comment">/// the `bvm` mapping. As a consequence, this function is meant to be called  on</span></div>
<div class="line"><a name="l01299"></a><span class="lineno"> 1299</span>&#160;<span class="comment">/// a topologically-sorted list of ops.</span></div>
<div class="line"><a name="l01300"></a><span class="lineno"> 1300</span>&#160;<span class="comment">/// This function does not update `bvm` but returns a VectorizationHookStatus</span></div>
<div class="line"><a name="l01301"></a><span class="lineno"> 1301</span>&#160;<span class="comment">/// that instructs the caller what `bvm` update needs to occur.</span></div>
<div class="line"><a name="l01302"></a><span class="lineno"> 1302</span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a></div>
<div class="line"><a name="l01303"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a455f83de6534e53da06be057973f7e38"> 1303</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a455f83de6534e53da06be057973f7e38">vectorizeOneOp</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="structVectorizationState.html">VectorizationState</a> &amp;state,</div>
<div class="line"><a name="l01304"></a><span class="lineno"> 1304</span>&#160;               LinalgOp linalgOp, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keyword">const</span> <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm,</div>
<div class="line"><a name="l01305"></a><span class="lineno"> 1305</span>&#160;               <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;CustomVectorizationHook&gt;</a> customVectorizationHooks) {</div>
<div class="line"><a name="l01306"></a><span class="lineno"> 1306</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;vectorize op &quot;</span> &lt;&lt; *op;</div>
<div class="line"><a name="l01307"></a><span class="lineno"> 1307</span>&#160; </div>
<div class="line"><a name="l01308"></a><span class="lineno"> 1308</span>&#160;  <span class="comment">// 1. Try to apply any CustomVectorizationHook.</span></div>
<div class="line"><a name="l01309"></a><span class="lineno"> 1309</span>&#160;  <span class="keywordflow">if</span> (!customVectorizationHooks.empty()) {</div>
<div class="line"><a name="l01310"></a><span class="lineno"> 1310</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;customFunc : customVectorizationHooks) {</div>
<div class="line"><a name="l01311"></a><span class="lineno"> 1311</span>&#160;      <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a> result = customFunc(op, bvm);</div>
<div class="line"><a name="l01312"></a><span class="lineno"> 1312</span>&#160;      <span class="keywordflow">if</span> (result.<a class="code" href="structVectorizationHookResult.html#a325ec6cd37d3dcf718897f5e68a37b91">status</a> == <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>)</div>
<div class="line"><a name="l01313"></a><span class="lineno"> 1313</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l01314"></a><span class="lineno"> 1314</span>&#160;      <span class="keywordflow">return</span> result;</div>
<div class="line"><a name="l01315"></a><span class="lineno"> 1315</span>&#160;    }</div>
<div class="line"><a name="l01316"></a><span class="lineno"> 1316</span>&#160;  }</div>
<div class="line"><a name="l01317"></a><span class="lineno"> 1317</span>&#160; </div>
<div class="line"><a name="l01318"></a><span class="lineno"> 1318</span>&#160;  <span class="comment">// 2. Constant ops don&#39;t get vectorized but rather broadcasted at their users.</span></div>
<div class="line"><a name="l01319"></a><span class="lineno"> 1319</span>&#160;  <span class="comment">// Clone so that the constant is not confined to the linalgOp block .</span></div>
<div class="line"><a name="l01320"></a><span class="lineno"> 1320</span>&#160;  <span class="keywordflow">if</span> (isa&lt;arith::ConstantOp, func::ConstantOp&gt;(op))</div>
<div class="line"><a name="l01321"></a><span class="lineno"> 1321</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>,</div>
<div class="line"><a name="l01322"></a><span class="lineno"> 1322</span>&#160;                                   rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a394cad81296b42a24e1c37b045e15359">clone</a>(*op)};</div>
<div class="line"><a name="l01323"></a><span class="lineno"> 1323</span>&#160; </div>
<div class="line"><a name="l01324"></a><span class="lineno"> 1324</span>&#160;  <span class="comment">// 3. Only ElementwiseMappable are allowed in the generic vectorization.</span></div>
<div class="line"><a name="l01325"></a><span class="lineno"> 1325</span>&#160;  <span class="keywordflow">if</span> (!<a class="code" href="namespacemlir_1_1OpTrait.html#a0c5480822c4898f287f588dfe98d1c85">OpTrait::hasElementwiseMappableTraits</a>(op))</div>
<div class="line"><a name="l01326"></a><span class="lineno"> 1326</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a name="l01327"></a><span class="lineno"> 1327</span>&#160; </div>
<div class="line"><a name="l01328"></a><span class="lineno"> 1328</span>&#160;  <span class="comment">// 4 . Check if the operation is a reduction.</span></div>
<div class="line"><a name="l01329"></a><span class="lineno"> 1329</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;std::pair&lt;Value, Value&gt;</a>&gt; reductionOperands;</div>
<div class="line"><a name="l01330"></a><span class="lineno"> 1330</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1Value.html">Value</a> operand : op-&gt;<a class="code" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>()) {</div>
<div class="line"><a name="l01331"></a><span class="lineno"> 1331</span>&#160;    <span class="keyword">auto</span> blockArg = dyn_cast&lt;BlockArgument&gt;(operand);</div>
<div class="line"><a name="l01332"></a><span class="lineno"> 1332</span>&#160;    <span class="keywordflow">if</span> (!blockArg || blockArg.getOwner() != linalgOp.getBlock() ||</div>
<div class="line"><a name="l01333"></a><span class="lineno"> 1333</span>&#160;        blockArg.getArgNumber() &lt; linalgOp.getNumDpsInputs())</div>
<div class="line"><a name="l01334"></a><span class="lineno"> 1334</span>&#160;      <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l01335"></a><span class="lineno"> 1335</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Operation *&gt;</a> reductionOps;</div>
<div class="line"><a name="l01336"></a><span class="lineno"> 1336</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> reduceValue = <a class="code" href="namespacemlir.html#a6bc751bc8f30d71ad4cb771c0fcc788b">matchReduction</a>(</div>
<div class="line"><a name="l01337"></a><span class="lineno"> 1337</span>&#160;        linalgOp.getRegionOutputArgs(),</div>
<div class="line"><a name="l01338"></a><span class="lineno"> 1338</span>&#160;        blockArg.getArgNumber() - linalgOp.getNumDpsInputs(), reductionOps);</div>
<div class="line"><a name="l01339"></a><span class="lineno"> 1339</span>&#160;    <span class="keywordflow">if</span> (!reduceValue)</div>
<div class="line"><a name="l01340"></a><span class="lineno"> 1340</span>&#160;      <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l01341"></a><span class="lineno"> 1341</span>&#160;    reductionOperands.push_back(std::make_pair(reduceValue, operand));</div>
<div class="line"><a name="l01342"></a><span class="lineno"> 1342</span>&#160;  }</div>
<div class="line"><a name="l01343"></a><span class="lineno"> 1343</span>&#160;  <span class="keywordflow">if</span> (!reductionOperands.empty()) {</div>
<div class="line"><a name="l01344"></a><span class="lineno"> 1344</span>&#160;    assert(reductionOperands.size() == 1);</div>
<div class="line"><a name="l01345"></a><span class="lineno"> 1345</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *reduceOp =</div>
<div class="line"><a name="l01346"></a><span class="lineno"> 1346</span>&#160;        <a class="code" href="Vectorization_8cpp.html#a53b9b71ed8f443a028671c1eb661054d">reduceIfNeeded</a>(rewriter, linalgOp, op, reductionOperands[0].first,</div>
<div class="line"><a name="l01347"></a><span class="lineno"> 1347</span>&#160;                       reductionOperands[0].second, bvm);</div>
<div class="line"><a name="l01348"></a><span class="lineno"> 1348</span>&#160;    <span class="keywordflow">if</span> (reduceOp)</div>
<div class="line"><a name="l01349"></a><span class="lineno"> 1349</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>, reduceOp};</div>
<div class="line"><a name="l01350"></a><span class="lineno"> 1350</span>&#160;  }</div>
<div class="line"><a name="l01351"></a><span class="lineno"> 1351</span>&#160; </div>
<div class="line"><a name="l01352"></a><span class="lineno"> 1352</span>&#160;  <span class="comment">// 5. Generic vectorization path for ElementwiseMappable ops.</span></div>
<div class="line"><a name="l01353"></a><span class="lineno"> 1353</span>&#160;  <span class="comment">//   a. Get the first max ranked shape.</span></div>
<div class="line"><a name="l01354"></a><span class="lineno"> 1354</span>&#160;  VectorType firstMaxRankedType;</div>
<div class="line"><a name="l01355"></a><span class="lineno"> 1355</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1Value.html">Value</a> operand : op-&gt;<a class="code" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>()) {</div>
<div class="line"><a name="l01356"></a><span class="lineno"> 1356</span>&#160;    <span class="keyword">auto</span> vecOperand = bvm.<a class="code" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(operand);</div>
<div class="line"><a name="l01357"></a><span class="lineno"> 1357</span>&#160;    assert(vecOperand &amp;&amp; <span class="stringliteral">&quot;Vector operand couldn&#39;t be found&quot;</span>);</div>
<div class="line"><a name="l01358"></a><span class="lineno"> 1358</span>&#160; </div>
<div class="line"><a name="l01359"></a><span class="lineno"> 1359</span>&#160;    <span class="keyword">auto</span> vecType = dyn_cast&lt;VectorType&gt;(vecOperand.getType());</div>
<div class="line"><a name="l01360"></a><span class="lineno"> 1360</span>&#160;    <span class="keywordflow">if</span> (vecType &amp;&amp; (!firstMaxRankedType ||</div>
<div class="line"><a name="l01361"></a><span class="lineno"> 1361</span>&#160;                    firstMaxRankedType.getRank() &lt; vecType.getRank()))</div>
<div class="line"><a name="l01362"></a><span class="lineno"> 1362</span>&#160;      firstMaxRankedType = vecType;</div>
<div class="line"><a name="l01363"></a><span class="lineno"> 1363</span>&#160;  }</div>
<div class="line"><a name="l01364"></a><span class="lineno"> 1364</span>&#160;  <span class="comment">//   b. Broadcast each op if needed.</span></div>
<div class="line"><a name="l01365"></a><span class="lineno"> 1365</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> vecOperands;</div>
<div class="line"><a name="l01366"></a><span class="lineno"> 1366</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1Value.html">Value</a> scalarOperand : op-&gt;<a class="code" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>()) {</div>
<div class="line"><a name="l01367"></a><span class="lineno"> 1367</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> vecOperand = bvm.<a class="code" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(scalarOperand);</div>
<div class="line"><a name="l01368"></a><span class="lineno"> 1368</span>&#160;    assert(vecOperand &amp;&amp; <span class="stringliteral">&quot;Vector operand couldn&#39;t be found&quot;</span>);</div>
<div class="line"><a name="l01369"></a><span class="lineno"> 1369</span>&#160; </div>
<div class="line"><a name="l01370"></a><span class="lineno"> 1370</span>&#160;    <span class="keywordflow">if</span> (firstMaxRankedType) {</div>
<div class="line"><a name="l01371"></a><span class="lineno"> 1371</span>&#160;      <span class="keyword">auto</span> vecType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(firstMaxRankedType.getShape(),</div>
<div class="line"><a name="l01372"></a><span class="lineno"> 1372</span>&#160;                                     <a class="code" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(vecOperand.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()),</div>
<div class="line"><a name="l01373"></a><span class="lineno"> 1373</span>&#160;                                     firstMaxRankedType.getScalableDims());</div>
<div class="line"><a name="l01374"></a><span class="lineno"> 1374</span>&#160;      vecOperands.push_back(<a class="code" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(rewriter, vecOperand, vecType));</div>
<div class="line"><a name="l01375"></a><span class="lineno"> 1375</span>&#160;    } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l01376"></a><span class="lineno"> 1376</span>&#160;      vecOperands.push_back(vecOperand);</div>
<div class="line"><a name="l01377"></a><span class="lineno"> 1377</span>&#160;    }</div>
<div class="line"><a name="l01378"></a><span class="lineno"> 1378</span>&#160;  }</div>
<div class="line"><a name="l01379"></a><span class="lineno"> 1379</span>&#160;  <span class="comment">//   c. for elementwise, the result is the vector with the firstMaxRankedShape</span></div>
<div class="line"><a name="l01380"></a><span class="lineno"> 1380</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Type&gt;</a> resultTypes;</div>
<div class="line"><a name="l01381"></a><span class="lineno"> 1381</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1Type.html">Type</a> resultType : op-&gt;<a class="code" href="classmlir_1_1Operation.html#ac3095b4b7756a4974ba1c21b0e8ed762">getResultTypes</a>()) {</div>
<div class="line"><a name="l01382"></a><span class="lineno"> 1382</span>&#160;    resultTypes.push_back(</div>
<div class="line"><a name="l01383"></a><span class="lineno"> 1383</span>&#160;        firstMaxRankedType</div>
<div class="line"><a name="l01384"></a><span class="lineno"> 1384</span>&#160;            ? <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(firstMaxRankedType.getShape(), resultType,</div>
<div class="line"><a name="l01385"></a><span class="lineno"> 1385</span>&#160;                              firstMaxRankedType.getScalableDims())</div>
<div class="line"><a name="l01386"></a><span class="lineno"> 1386</span>&#160;            : resultType);</div>
<div class="line"><a name="l01387"></a><span class="lineno"> 1387</span>&#160;  }</div>
<div class="line"><a name="l01388"></a><span class="lineno"> 1388</span>&#160;  <span class="comment">//   d. Build and return the new op.</span></div>
<div class="line"><a name="l01389"></a><span class="lineno"> 1389</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a>{</div>
<div class="line"><a name="l01390"></a><span class="lineno"> 1390</span>&#160;      <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>,</div>
<div class="line"><a name="l01391"></a><span class="lineno"> 1391</span>&#160;      rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#ac6a6edadd39800db410864ef06a004b2">create</a>(op-&gt;<a class="code" href="classmlir_1_1Operation.html#a6c0b8ce5ff714a34f0192f3aa60dc7ea">getLoc</a>(), op-&gt;<a class="code" href="classmlir_1_1Operation.html#ab2e11ba83ff765eb7595554f97aaaa75">getName</a>().<a class="code" href="classmlir_1_1OperationName.html#a2c83cffa9a4c4fb68436d9ee3497c226">getIdentifier</a>(), vecOperands,</div>
<div class="line"><a name="l01392"></a><span class="lineno"> 1392</span>&#160;                      resultTypes, op-&gt;<a class="code" href="classmlir_1_1Operation.html#a8ec626dafc87ed8fb20d8323017dec72">getAttrs</a>())};</div>
<div class="line"><a name="l01393"></a><span class="lineno"> 1393</span>&#160;}</div>
<div class="line"><a name="l01394"></a><span class="lineno"> 1394</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01395"></a><span class="lineno"> 1395</span>&#160;<span class="comment">/// Generic vectorization function that rewrites the body of a `linalgOp` into</span></div>
<div class="line"><a name="l01396"></a><span class="lineno"> 1396</span>&#160;<span class="comment">/// vector form. Generic vectorization proceeds as follows:</span></div>
<div class="line"><a name="l01397"></a><span class="lineno"> 1397</span>&#160;<span class="comment">///   1. Verify the `linalgOp` has one non-empty region.</span></div>
<div class="line"><a name="l01398"></a><span class="lineno"> 1398</span>&#160;<span class="comment">///   2. Values defined above the region are mapped to themselves and will be</span></div>
<div class="line"><a name="l01399"></a><span class="lineno"> 1399</span>&#160;<span class="comment">///   broadcasted on a per-need basis by their consumers.</span></div>
<div class="line"><a name="l01400"></a><span class="lineno"> 1400</span>&#160;<span class="comment">///   3. Each region argument is vectorized into a vector.transfer_read (or 0-d</span></div>
<div class="line"><a name="l01401"></a><span class="lineno"> 1401</span>&#160;<span class="comment">///   load).</span></div>
<div class="line"><a name="l01402"></a><span class="lineno"> 1402</span>&#160;<span class="comment">///   TODO: Reuse opportunities for RAR dependencies.</span></div>
<div class="line"><a name="l01403"></a><span class="lineno"> 1403</span>&#160;<span class="comment">///   4a. Register CustomVectorizationHook for YieldOp to capture the results.</span></div>
<div class="line"><a name="l01404"></a><span class="lineno"> 1404</span>&#160;<span class="comment">///   4rewriter. Register CustomVectorizationHook for IndexOp to access the</span></div>
<div class="line"><a name="l01405"></a><span class="lineno"> 1405</span>&#160;<span class="comment">///   iteration indices.</span></div>
<div class="line"><a name="l01406"></a><span class="lineno"> 1406</span>&#160;<span class="comment">///   5. Iteratively call vectorizeOneOp on the region operations.</span></div>
<div class="line"><a name="l01407"></a><span class="lineno"> 1407</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01408"></a><span class="lineno"> 1408</span>&#160;<span class="comment">/// When `broadcastToMaximalCommonShape` is set to true, eager broadcasting is</span></div>
<div class="line"><a name="l01409"></a><span class="lineno"> 1409</span>&#160;<span class="comment">/// performed to the maximal common vector size implied by the `linalgOp`</span></div>
<div class="line"><a name="l01410"></a><span class="lineno"> 1410</span>&#160;<span class="comment">/// iteration space. This eager broadcasting is introduced in the</span></div>
<div class="line"><a name="l01411"></a><span class="lineno"> 1411</span>&#160;<span class="comment">/// permutation_map of the vector.transfer_read operations. The eager</span></div>
<div class="line"><a name="l01412"></a><span class="lineno"> 1412</span>&#160;<span class="comment">/// broadcasting makes it trivial to determine where broadcast, transposes and</span></div>
<div class="line"><a name="l01413"></a><span class="lineno"> 1413</span>&#160;<span class="comment">/// reductions should occur, without any bookkeeping. The tradeoff is that, in</span></div>
<div class="line"><a name="l01414"></a><span class="lineno"> 1414</span>&#160;<span class="comment">/// the absence of good canonicalizations, the amount of work increases.</span></div>
<div class="line"><a name="l01415"></a><span class="lineno"> 1415</span>&#160;<span class="comment">/// This is not deemed a problem as we expect canonicalizations and foldings to</span></div>
<div class="line"><a name="l01416"></a><span class="lineno"> 1416</span>&#160;<span class="comment">/// aggressively clean up the useless work.</span></div>
<div class="line"><a name="l01417"></a><span class="lineno"> 1417</span>&#160;<span class="comment"></span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l01418"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a35e1ec347850959af0bc7cbdf61b9da3"> 1418</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a35e1ec347850959af0bc7cbdf61b9da3">vectorizeAsLinalgGeneric</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="structVectorizationState.html">VectorizationState</a> &amp;state,</div>
<div class="line"><a name="l01419"></a><span class="lineno"> 1419</span>&#160;                         LinalgOp linalgOp,</div>
<div class="line"><a name="l01420"></a><span class="lineno"> 1420</span>&#160;                         <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults) {</div>
<div class="line"><a name="l01421"></a><span class="lineno"> 1421</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorizing operation as linalg generic/n&quot;</span>;</div>
<div class="line"><a name="l01422"></a><span class="lineno"> 1422</span>&#160;  <a class="code" href="classmlir_1_1Block.html">Block</a> *block = linalgOp.getBlock();</div>
<div class="line"><a name="l01423"></a><span class="lineno"> 1423</span>&#160; </div>
<div class="line"><a name="l01424"></a><span class="lineno"> 1424</span>&#160;  <span class="comment">// 2. Values defined above the region can only be broadcast for now. Make them</span></div>
<div class="line"><a name="l01425"></a><span class="lineno"> 1425</span>&#160;  <span class="comment">// map to themselves.</span></div>
<div class="line"><a name="l01426"></a><span class="lineno"> 1426</span>&#160;  <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> bvm;</div>
<div class="line"><a name="l01427"></a><span class="lineno"> 1427</span>&#160;  <a class="code" href="classllvm_1_1SetVector.html">SetVector&lt;Value&gt;</a> valuesSet;</div>
<div class="line"><a name="l01428"></a><span class="lineno"> 1428</span>&#160;  <a class="code" href="namespacemlir.html#a98f08e970a346cd42559db87f97f0b91">mlir::getUsedValuesDefinedAbove</a>(linalgOp-&gt;getRegion(0), valuesSet);</div>
<div class="line"><a name="l01429"></a><span class="lineno"> 1429</span>&#160;  bvm.<a class="code" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(valuesSet.getArrayRef(), valuesSet.getArrayRef());</div>
<div class="line"><a name="l01430"></a><span class="lineno"> 1430</span>&#160; </div>
<div class="line"><a name="l01431"></a><span class="lineno"> 1431</span>&#160;  <span class="keywordflow">if</span> (linalgOp.getNumDpsInits() == 0)</div>
<div class="line"><a name="l01432"></a><span class="lineno"> 1432</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l01433"></a><span class="lineno"> 1433</span>&#160; </div>
<div class="line"><a name="l01434"></a><span class="lineno"> 1434</span>&#160;  <span class="comment">// 3. Turn all BBArgs into vector.transfer_read / load.</span></div>
<div class="line"><a name="l01435"></a><span class="lineno"> 1435</span>&#160;  <a class="code" href="classmlir_1_1Location.html">Location</a> loc = linalgOp.getLoc();</div>
<div class="line"><a name="l01436"></a><span class="lineno"> 1436</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> zero = <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0);</div>
<div class="line"><a name="l01437"></a><span class="lineno"> 1437</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> *opOperand : linalgOp.getOpOperandsMatchingBBargs()) {</div>
<div class="line"><a name="l01438"></a><span class="lineno"> 1438</span>&#160;    <a class="code" href="classmlir_1_1BlockArgument.html">BlockArgument</a> bbarg = linalgOp.getMatchingBlockArgument(opOperand);</div>
<div class="line"><a name="l01439"></a><span class="lineno"> 1439</span>&#160;    <span class="keywordflow">if</span> (linalgOp.isScalar(opOperand)) {</div>
<div class="line"><a name="l01440"></a><span class="lineno"> 1440</span>&#160;      bvm.<a class="code" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(bbarg, opOperand-&gt;get());</div>
<div class="line"><a name="l01441"></a><span class="lineno"> 1441</span>&#160;      <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l01442"></a><span class="lineno"> 1442</span>&#160;    }</div>
<div class="line"><a name="l01443"></a><span class="lineno"> 1443</span>&#160; </div>
<div class="line"><a name="l01444"></a><span class="lineno"> 1444</span>&#160;    <span class="comment">// 3.a. Convert the indexing map for this input/output to a transfer read</span></div>
<div class="line"><a name="l01445"></a><span class="lineno"> 1445</span>&#160;    <span class="comment">// permutation map and masking map.</span></div>
<div class="line"><a name="l01446"></a><span class="lineno"> 1446</span>&#160;    <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> indexingMap = linalgOp.getMatchingIndexingMap(opOperand);</div>
<div class="line"><a name="l01447"></a><span class="lineno"> 1447</span>&#160; </div>
<div class="line"><a name="l01448"></a><span class="lineno"> 1448</span>&#160;    <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> readMap;</div>
<div class="line"><a name="l01449"></a><span class="lineno"> 1449</span>&#160;    VectorType readType;</div>
<div class="line"><a name="l01450"></a><span class="lineno"> 1450</span>&#160;    <a class="code" href="classmlir_1_1Type.html">Type</a> elemType = <a class="code" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(opOperand-&gt;get());</div>
<div class="line"><a name="l01451"></a><span class="lineno"> 1451</span>&#160;    <span class="keywordflow">if</span> (linalgOp.isDpsInput(opOperand)) {</div>
<div class="line"><a name="l01452"></a><span class="lineno"> 1452</span>&#160;      <span class="comment">// 3.a.i. For input reads we use the canonical vector shape.</span></div>
<div class="line"><a name="l01453"></a><span class="lineno"> 1453</span>&#160;      readMap = <a class="code" href="namespacemlir.html#a39612be2ef116102866d3bb9c6a8ca88">inverseAndBroadcastProjectedPermutation</a>(indexingMap);</div>
<div class="line"><a name="l01454"></a><span class="lineno"> 1454</span>&#160;      readType = state.getCanonicalVecType(elemType);</div>
<div class="line"><a name="l01455"></a><span class="lineno"> 1455</span>&#160;    } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l01456"></a><span class="lineno"> 1456</span>&#160;      <span class="comment">// 3.a.ii. For output reads (iteration-carried dependence, e.g.,</span></div>
<div class="line"><a name="l01457"></a><span class="lineno"> 1457</span>&#160;      <span class="comment">// reductions), the vector shape is computed by mapping the canonical</span></div>
<div class="line"><a name="l01458"></a><span class="lineno"> 1458</span>&#160;      <span class="comment">// vector shape to the output domain and back to the canonical domain.</span></div>
<div class="line"><a name="l01459"></a><span class="lineno"> 1459</span>&#160;      readMap = <a class="code" href="namespacemlir.html#a52b322818d83a2256d4e4391acbf78a2">inversePermutation</a>(<a class="code" href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">reindexIndexingMap</a>(indexingMap));</div>
<div class="line"><a name="l01460"></a><span class="lineno"> 1460</span>&#160;      readType =</div>
<div class="line"><a name="l01461"></a><span class="lineno"> 1461</span>&#160;          state.getCanonicalVecType(elemType, readMap.<a class="code" href="classmlir_1_1AffineMap.html#af2baf4561cf7d74a9959fd9e875c9a82">compose</a>(indexingMap));</div>
<div class="line"><a name="l01462"></a><span class="lineno"> 1462</span>&#160;    }</div>
<div class="line"><a name="l01463"></a><span class="lineno"> 1463</span>&#160; </div>
<div class="line"><a name="l01464"></a><span class="lineno"> 1464</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> indices(linalgOp.getShape(opOperand).size(), zero);</div>
<div class="line"><a name="l01465"></a><span class="lineno"> 1465</span>&#160; </div>
<div class="line"><a name="l01466"></a><span class="lineno"> 1466</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *read = vector::TransferReadOp::create(</div>
<div class="line"><a name="l01467"></a><span class="lineno"> 1467</span>&#160;        rewriter, loc, readType, opOperand-&gt;get(), indices,</div>
<div class="line"><a name="l01468"></a><span class="lineno"> 1468</span>&#160;        <span class="comment">/*padding=*/</span>std::nullopt, readMap);</div>
<div class="line"><a name="l01469"></a><span class="lineno"> 1469</span>&#160;    read = state.maskOperation(rewriter, read, linalgOp, indexingMap);</div>
<div class="line"><a name="l01470"></a><span class="lineno"> 1470</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a> = read-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0);</div>
<div class="line"><a name="l01471"></a><span class="lineno"> 1471</span>&#160; </div>
<div class="line"><a name="l01472"></a><span class="lineno"> 1472</span>&#160;    <span class="comment">// 3.b. If masked, set in-bounds to true. Masking guarantees that the access</span></div>
<div class="line"><a name="l01473"></a><span class="lineno"> 1473</span>&#160;    <span class="comment">// will be in-bounds.</span></div>
<div class="line"><a name="l01474"></a><span class="lineno"> 1474</span>&#160;    <span class="keywordflow">if</span> (<span class="keyword">auto</span> maskOp = dyn_cast&lt;vector::MaskingOpInterface&gt;(read)) {</div>
<div class="line"><a name="l01475"></a><span class="lineno"> 1475</span>&#160;      <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(readType.getRank(), <span class="keyword">true</span>);</div>
<div class="line"><a name="l01476"></a><span class="lineno"> 1476</span>&#160;      cast&lt;vector::TransferReadOp&gt;(maskOp.getMaskableOp())</div>
<div class="line"><a name="l01477"></a><span class="lineno"> 1477</span>&#160;          .setInBoundsAttr(rewriter.<a class="code" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a name="l01478"></a><span class="lineno"> 1478</span>&#160;    }</div>
<div class="line"><a name="l01479"></a><span class="lineno"> 1479</span>&#160; </div>
<div class="line"><a name="l01480"></a><span class="lineno"> 1480</span>&#160;    <span class="comment">// 3.c. Not all ops support 0-d vectors, extract the scalar for now.</span></div>
<div class="line"><a name="l01481"></a><span class="lineno"> 1481</span>&#160;    <span class="comment">// TODO: remove this.</span></div>
<div class="line"><a name="l01482"></a><span class="lineno"> 1482</span>&#160;    <span class="keywordflow">if</span> (readType.getRank() == 0)</div>
<div class="line"><a name="l01483"></a><span class="lineno"> 1483</span>&#160;      <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a> = vector::ExtractOp::create(rewriter, loc, <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a>,</div>
<div class="line"><a name="l01484"></a><span class="lineno"> 1484</span>&#160;                                            <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>());</div>
<div class="line"><a name="l01485"></a><span class="lineno"> 1485</span>&#160; </div>
<div class="line"><a name="l01486"></a><span class="lineno"> 1486</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;New vectorized bbarg(&quot;</span> &lt;&lt; bbarg.<a class="code" href="classmlir_1_1BlockArgument.html#a5396ce59c00cd3ef7a8a500c59af295c">getArgNumber</a>()</div>
<div class="line"><a name="l01487"></a><span class="lineno"> 1487</span>&#160;           &lt;&lt; <span class="stringliteral">&quot;): &quot;</span> &lt;&lt; <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a>;</div>
<div class="line"><a name="l01488"></a><span class="lineno"> 1488</span>&#160;    bvm.<a class="code" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(bbarg, <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a>);</div>
<div class="line"><a name="l01489"></a><span class="lineno"> 1489</span>&#160;    bvm.<a class="code" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(opOperand-&gt;get(), <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a>);</div>
<div class="line"><a name="l01490"></a><span class="lineno"> 1490</span>&#160;  }</div>
<div class="line"><a name="l01491"></a><span class="lineno"> 1491</span>&#160; </div>
<div class="line"><a name="l01492"></a><span class="lineno"> 1492</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;CustomVectorizationHook&gt;</a> hooks;</div>
<div class="line"><a name="l01493"></a><span class="lineno"> 1493</span>&#160;  <span class="comment">// 4a. Register CustomVectorizationHook for yieldOp.</span></div>
<div class="line"><a name="l01494"></a><span class="lineno"> 1494</span>&#160;  <a class="code" href="Vectorization_8cpp.html#a8a252028bd6c5a6051cc0e8a48c72afb">CustomVectorizationHook</a> vectorizeYield =</div>
<div class="line"><a name="l01495"></a><span class="lineno"> 1495</span>&#160;      [&amp;](<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keyword">const</span> <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) -&gt; <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a> {</div>
<div class="line"><a name="l01496"></a><span class="lineno"> 1496</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#af85a26f7c1860388d0e83d22745a27aa">vectorizeLinalgYield</a>(rewriter, op, bvm, state, linalgOp, newResults);</div>
<div class="line"><a name="l01497"></a><span class="lineno"> 1497</span>&#160;  };</div>
<div class="line"><a name="l01498"></a><span class="lineno"> 1498</span>&#160;  hooks.push_back(vectorizeYield);</div>
<div class="line"><a name="l01499"></a><span class="lineno"> 1499</span>&#160; </div>
<div class="line"><a name="l01500"></a><span class="lineno"> 1500</span>&#160;  <span class="comment">// 4b. Register CustomVectorizationHook for indexOp.</span></div>
<div class="line"><a name="l01501"></a><span class="lineno"> 1501</span>&#160;  <a class="code" href="Vectorization_8cpp.html#a8a252028bd6c5a6051cc0e8a48c72afb">CustomVectorizationHook</a> vectorizeIndex =</div>
<div class="line"><a name="l01502"></a><span class="lineno"> 1502</span>&#160;      [&amp;](<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keyword">const</span> <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) -&gt; <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a> {</div>
<div class="line"><a name="l01503"></a><span class="lineno"> 1503</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a280bd1ab81d418cd32713eeb0a2dfffd">vectorizeLinalgIndex</a>(rewriter, state, op, linalgOp);</div>
<div class="line"><a name="l01504"></a><span class="lineno"> 1504</span>&#160;  };</div>
<div class="line"><a name="l01505"></a><span class="lineno"> 1505</span>&#160;  hooks.push_back(vectorizeIndex);</div>
<div class="line"><a name="l01506"></a><span class="lineno"> 1506</span>&#160; </div>
<div class="line"><a name="l01507"></a><span class="lineno"> 1507</span>&#160;  <span class="comment">// 4c. Register CustomVectorizationHook for extractOp.</span></div>
<div class="line"><a name="l01508"></a><span class="lineno"> 1508</span>&#160;  <a class="code" href="Vectorization_8cpp.html#a8a252028bd6c5a6051cc0e8a48c72afb">CustomVectorizationHook</a> vectorizeExtract =</div>
<div class="line"><a name="l01509"></a><span class="lineno"> 1509</span>&#160;      [&amp;](<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keyword">const</span> <a class="code" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) -&gt; <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a> {</div>
<div class="line"><a name="l01510"></a><span class="lineno"> 1510</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a26cb5e24425fdce30baaba6f7c0f5c84">vectorizeTensorExtract</a>(rewriter, state, op, linalgOp, bvm);</div>
<div class="line"><a name="l01511"></a><span class="lineno"> 1511</span>&#160;  };</div>
<div class="line"><a name="l01512"></a><span class="lineno"> 1512</span>&#160;  hooks.push_back(vectorizeExtract);</div>
<div class="line"><a name="l01513"></a><span class="lineno"> 1513</span>&#160; </div>
<div class="line"><a name="l01514"></a><span class="lineno"> 1514</span>&#160;  <span class="comment">// 5. Iteratively call `vectorizeOneOp` to each op in the slice.</span></div>
<div class="line"><a name="l01515"></a><span class="lineno"> 1515</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1Operation.html">Operation</a> &amp;op : block-&gt;<a class="code" href="classmlir_1_1Block.html#a983ab2de9394598ad42fea4d142f5d8b">getOperations</a>()) {</div>
<div class="line"><a name="l01516"></a><span class="lineno"> 1516</span>&#160;    <a class="code" href="structVectorizationHookResult.html">VectorizationHookResult</a> result =</div>
<div class="line"><a name="l01517"></a><span class="lineno"> 1517</span>&#160;        <a class="code" href="Vectorization_8cpp.html#a455f83de6534e53da06be057973f7e38">vectorizeOneOp</a>(rewriter, state, linalgOp, &amp;op, bvm, hooks);</div>
<div class="line"><a name="l01518"></a><span class="lineno"> 1518</span>&#160;    <span class="keywordflow">if</span> (result.<a class="code" href="structVectorizationHookResult.html#a325ec6cd37d3dcf718897f5e68a37b91">status</a> == <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>) {</div>
<div class="line"><a name="l01519"></a><span class="lineno"> 1519</span>&#160;      LDBG() &lt;&lt; <span class="stringliteral">&quot;failed to vectorize: &quot;</span> &lt;&lt; op;</div>
<div class="line"><a name="l01520"></a><span class="lineno"> 1520</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l01521"></a><span class="lineno"> 1521</span>&#160;    }</div>
<div class="line"><a name="l01522"></a><span class="lineno"> 1522</span>&#160;    <span class="keywordflow">if</span> (result.<a class="code" href="structVectorizationHookResult.html#a325ec6cd37d3dcf718897f5e68a37b91">status</a> == <a class="code" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>) {</div>
<div class="line"><a name="l01523"></a><span class="lineno"> 1523</span>&#160;      <a class="code" href="classmlir_1_1Operation.html">Operation</a> *maybeMaskedOp =</div>
<div class="line"><a name="l01524"></a><span class="lineno"> 1524</span>&#160;          state.maskOperation(rewriter, result.<a class="code" href="structVectorizationHookResult.html#ab9025f3486cb1c8f0c6461db368c1a50">newOp</a>, linalgOp);</div>
<div class="line"><a name="l01525"></a><span class="lineno"> 1525</span>&#160;      LDBG() &lt;&lt; <span class="stringliteral">&quot;New vector op: &quot;</span> &lt;&lt; *maybeMaskedOp;</div>
<div class="line"><a name="l01526"></a><span class="lineno"> 1526</span>&#160;      bvm.<a class="code" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(op.<a class="code" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>(), maybeMaskedOp-&gt;<a class="code" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>());</div>
<div class="line"><a name="l01527"></a><span class="lineno"> 1527</span>&#160;    }</div>
<div class="line"><a name="l01528"></a><span class="lineno"> 1528</span>&#160;  }</div>
<div class="line"><a name="l01529"></a><span class="lineno"> 1529</span>&#160; </div>
<div class="line"><a name="l01530"></a><span class="lineno"> 1530</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l01531"></a><span class="lineno"> 1531</span>&#160;}</div>
<div class="line"><a name="l01532"></a><span class="lineno"> 1532</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01533"></a><span class="lineno"> 1533</span>&#160;<span class="comment">/// Given a linalg::PackOp, return the `dest` shape before any packing</span></div>
<div class="line"><a name="l01534"></a><span class="lineno"> 1534</span>&#160;<span class="comment">/// permutations.</span></div>
<div class="line"><a name="l01535"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#abea66cfdf6b9e3285381e7d3543c894c"> 1535</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> <a class="code" href="Vectorization_8cpp.html#abea66cfdf6b9e3285381e7d3543c894c">getTiledPackShape</a>(linalg::PackOp packOp,</div>
<div class="line"><a name="l01536"></a><span class="lineno"> 1536</span>&#160;                                              <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> destShape) {</div>
<div class="line"><a name="l01537"></a><span class="lineno"> 1537</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacemlir.html#a44886de1f618c57e6589a875d1407830">applyPermutation</a>(destShape, <a class="code" href="namespacemlir_1_1linalg.html#a5c34dd63bd77acc711bdf98d6e2c7b75">linalg::getPackInverseDestPerm</a>(packOp));</div>
<div class="line"><a name="l01538"></a><span class="lineno"> 1538</span>&#160;}</div>
<div class="line"><a name="l01539"></a><span class="lineno"> 1539</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01540"></a><span class="lineno"> 1540</span>&#160;<span class="comment">/// Determines whether a mask for xfer_write is trivially &quot;all true&quot;</span></div>
<div class="line"><a name="l01541"></a><span class="lineno"> 1541</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01542"></a><span class="lineno"> 1542</span>&#160;<span class="comment">/// Given all the inputs required to generate a mask (mask sizes and shapes),</span></div>
<div class="line"><a name="l01543"></a><span class="lineno"> 1543</span>&#160;<span class="comment">/// and an xfer_write operation (write indices and the destination tensor</span></div>
<div class="line"><a name="l01544"></a><span class="lineno"> 1544</span>&#160;<span class="comment">/// shape), determines whether the corresponding mask would be trivially</span></div>
<div class="line"><a name="l01545"></a><span class="lineno"> 1545</span>&#160;<span class="comment">/// foldable (i.e., trivially &quot;all true&quot;).</span></div>
<div class="line"><a name="l01546"></a><span class="lineno"> 1546</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01547"></a><span class="lineno"> 1547</span>&#160;<span class="comment">/// Use this method to avoid generating spurious masks and relaying on</span></div>
<div class="line"><a name="l01548"></a><span class="lineno"> 1548</span>&#160;<span class="comment">/// vectorization post-processing to remove them.</span></div>
<div class="line"><a name="l01549"></a><span class="lineno"> 1549</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01550"></a><span class="lineno"> 1550</span>&#160;<span class="comment">/// Pre-conditions for a mask to be trivially foldable:</span></div>
<div class="line"><a name="l01551"></a><span class="lineno"> 1551</span>&#160;<span class="comment">///   * All involved shapes (mask + destination tensor) are static.</span></div>
<div class="line"><a name="l01552"></a><span class="lineno"> 1552</span>&#160;<span class="comment">///   * All write indices are constant.</span></div>
<div class="line"><a name="l01553"></a><span class="lineno"> 1553</span>&#160;<span class="comment">///   * All mask sizes are constant (including `arith.constant`).</span></div>
<div class="line"><a name="l01554"></a><span class="lineno"> 1554</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01555"></a><span class="lineno"> 1555</span>&#160;<span class="comment">/// If the pre-conditions are met, the method checks for each destination</span></div>
<div class="line"><a name="l01556"></a><span class="lineno"> 1556</span>&#160;<span class="comment">/// dimension `d`:</span></div>
<div class="line"><a name="l01557"></a><span class="lineno"> 1557</span>&#160;<span class="comment">///   (1) destDimSize[rankDiff + d] &lt;= maskShape[d]</span></div>
<div class="line"><a name="l01558"></a><span class="lineno"> 1558</span>&#160;<span class="comment">///   (2) destDimSize[rankDiff + d] &lt;= writeIndex[d] + maskSize[d]</span></div>
<div class="line"><a name="l01559"></a><span class="lineno"> 1559</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01560"></a><span class="lineno"> 1560</span>&#160;<span class="comment">/// rankDiff = rank(dest) - rank(mask).</span></div>
<div class="line"><a name="l01561"></a><span class="lineno"> 1561</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01562"></a><span class="lineno"> 1562</span>&#160;<span class="comment">/// This method takes a conservative view: it may return false even if the mask</span></div>
<div class="line"><a name="l01563"></a><span class="lineno"> 1563</span>&#160;<span class="comment">/// is technically foldable.</span></div>
<div class="line"><a name="l01564"></a><span class="lineno"> 1564</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01565"></a><span class="lineno"> 1565</span>&#160;<span class="comment">/// EXAMPLE 1 (trivially foldable, all shapes match, mask sizes match the shape</span></div>
<div class="line"><a name="l01566"></a><span class="lineno"> 1566</span>&#160;<span class="comment">/// of the dest tensor):</span></div>
<div class="line"><a name="l01567"></a><span class="lineno"> 1567</span>&#160;<span class="comment">///   %c0 = arith.constant 0 : index</span></div>
<div class="line"><a name="l01568"></a><span class="lineno"> 1568</span>&#160;<span class="comment">///   %mask = vector.create_mask 5, 1</span></div>
<div class="line"><a name="l01569"></a><span class="lineno"> 1569</span>&#160;<span class="comment">///   vector.mask %mask {</span></div>
<div class="line"><a name="l01570"></a><span class="lineno"> 1570</span>&#160;<span class="comment">///     vector.transfer_write %vecToStore_1, %dest{[%c0, %c0]</span></div>
<div class="line"><a name="l01571"></a><span class="lineno"> 1571</span>&#160;<span class="comment">///       {in_bounds = [true, true]}</span></div>
<div class="line"><a name="l01572"></a><span class="lineno"> 1572</span>&#160;<span class="comment">///     : vector&lt;5x1xi32&gt;, tensor&lt;5x1xi32&gt;</span></div>
<div class="line"><a name="l01573"></a><span class="lineno"> 1573</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l01574"></a><span class="lineno"> 1574</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01575"></a><span class="lineno"> 1575</span>&#160;<span class="comment">/// EXAMPLE 2 (not trivially foldable - vector shape exceeds the tensor shape,</span></div>
<div class="line"><a name="l01576"></a><span class="lineno"> 1576</span>&#160;<span class="comment">/// mask is required to avoid out-of-bounds write):</span></div>
<div class="line"><a name="l01577"></a><span class="lineno"> 1577</span>&#160;<span class="comment">///   %c0 = arith.constant 0 : index</span></div>
<div class="line"><a name="l01578"></a><span class="lineno"> 1578</span>&#160;<span class="comment">///   %mask = vector.create_mask 5, 1</span></div>
<div class="line"><a name="l01579"></a><span class="lineno"> 1579</span>&#160;<span class="comment">///   vector.mask %mask {</span></div>
<div class="line"><a name="l01580"></a><span class="lineno"> 1580</span>&#160;<span class="comment">///     vector.transfer_write %vecToStore_2, %dest[%c0, %c0]</span></div>
<div class="line"><a name="l01581"></a><span class="lineno"> 1581</span>&#160;<span class="comment">///      {in_bounds = [true, true]}</span></div>
<div class="line"><a name="l01582"></a><span class="lineno"> 1582</span>&#160;<span class="comment">///     : vector&lt;8x1xi32&gt;, tensor&lt;5x1xi32&gt;</span></div>
<div class="line"><a name="l01583"></a><span class="lineno"> 1583</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l01584"></a><span class="lineno"> 1584</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01585"></a><span class="lineno"> 1585</span>&#160;<span class="comment">/// TODO: Re-use in createReadOrMaskedRead</span></div>
<div class="line"><a name="l01586"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a1bedce144a30ca3ef5eac6628b35d4a9"> 1586</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code" href="Vectorization_8cpp.html#a1bedce144a30ca3ef5eac6628b35d4a9">isMaskTriviallyFoldable</a>(<a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;OpFoldResult&gt;</a> &amp;maskSizes,</div>
<div class="line"><a name="l01587"></a><span class="lineno"> 1587</span>&#160;                                    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> &amp;writeIdxs,</div>
<div class="line"><a name="l01588"></a><span class="lineno"> 1588</span>&#160;                                    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> destShape,</div>
<div class="line"><a name="l01589"></a><span class="lineno"> 1589</span>&#160;                                    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> maskShape) {</div>
<div class="line"><a name="l01590"></a><span class="lineno"> 1590</span>&#160;  <span class="comment">// Masking is unavoidable in the case of dynamic tensors.</span></div>
<div class="line"><a name="l01591"></a><span class="lineno"> 1591</span>&#160;  <span class="keywordflow">if</span> (ShapedType::isDynamicShape(destShape))</div>
<div class="line"><a name="l01592"></a><span class="lineno"> 1592</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l01593"></a><span class="lineno"> 1593</span>&#160; </div>
<div class="line"><a name="l01594"></a><span class="lineno"> 1594</span>&#160;  <span class="comment">// Collect all constant mask sizes.</span></div>
<div class="line"><a name="l01595"></a><span class="lineno"> 1595</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t, 4&gt;</a> cstMaskSizes;</div>
<div class="line"><a name="l01596"></a><span class="lineno"> 1596</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, dimSize] : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">llvm::enumerate</a>(maskSizes)) {</div>
<div class="line"><a name="l01597"></a><span class="lineno"> 1597</span>&#160;    <span class="keywordflow">if</span> (<span class="keyword">auto</span> intSize = <a class="code" href="namespacemlir.html#a22bfcc5fa9deffb32e7c39183f732c90">getConstantIntValue</a>(dimSize)) {</div>
<div class="line"><a name="l01598"></a><span class="lineno"> 1598</span>&#160;      cstMaskSizes.push_back(*intSize);</div>
<div class="line"><a name="l01599"></a><span class="lineno"> 1599</span>&#160;    }</div>
<div class="line"><a name="l01600"></a><span class="lineno"> 1600</span>&#160;  }</div>
<div class="line"><a name="l01601"></a><span class="lineno"> 1601</span>&#160; </div>
<div class="line"><a name="l01602"></a><span class="lineno"> 1602</span>&#160;  <span class="comment">// If any of the mask sizes is non-constant, bail out.</span></div>
<div class="line"><a name="l01603"></a><span class="lineno"> 1603</span>&#160;  <span class="keywordflow">if</span> (cstMaskSizes.size() != maskShape.size())</div>
<div class="line"><a name="l01604"></a><span class="lineno"> 1604</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l01605"></a><span class="lineno"> 1605</span>&#160; </div>
<div class="line"><a name="l01606"></a><span class="lineno"> 1606</span>&#160;  <span class="comment">// Collect all constant write indices.</span></div>
<div class="line"><a name="l01607"></a><span class="lineno"> 1607</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t, 4&gt;</a> cstWriteIdxs;</div>
<div class="line"><a name="l01608"></a><span class="lineno"> 1608</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, idx] : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">llvm::enumerate</a>(writeIdxs)) {</div>
<div class="line"><a name="l01609"></a><span class="lineno"> 1609</span>&#160;    APSInt intVal;</div>
<div class="line"><a name="l01610"></a><span class="lineno"> 1610</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="namespacemlir.html#a0190228b09e7b51a4bc1e013c01d404c">matchPattern</a>(idx, <a class="code" href="namespacemlir.html#a091c0686ba6d6f3ad4af9db1aea8063f">m_ConstantInt</a>(&amp;intVal))) {</div>
<div class="line"><a name="l01611"></a><span class="lineno"> 1611</span>&#160;      cstWriteIdxs.push_back(intVal.getSExtValue());</div>
<div class="line"><a name="l01612"></a><span class="lineno"> 1612</span>&#160;    }</div>
<div class="line"><a name="l01613"></a><span class="lineno"> 1613</span>&#160;  }</div>
<div class="line"><a name="l01614"></a><span class="lineno"> 1614</span>&#160; </div>
<div class="line"><a name="l01615"></a><span class="lineno"> 1615</span>&#160;  <span class="comment">// If any of the write indices is non-constant, bail out.</span></div>
<div class="line"><a name="l01616"></a><span class="lineno"> 1616</span>&#160;  <span class="keywordflow">if</span> (cstWriteIdxs.size() != destShape.size())</div>
<div class="line"><a name="l01617"></a><span class="lineno"> 1617</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l01618"></a><span class="lineno"> 1618</span>&#160; </div>
<div class="line"><a name="l01619"></a><span class="lineno"> 1619</span>&#160;  <span class="comment">// Go over all destination dims and check (1) and (2). Take into account that:</span></div>
<div class="line"><a name="l01620"></a><span class="lineno"> 1620</span>&#160;  <span class="comment">//  * The number of mask sizes will match the rank of the vector to store.</span></div>
<div class="line"><a name="l01621"></a><span class="lineno"> 1621</span>&#160;  <span class="comment">//    This could be lower than the rank of the destination tensor.</span></div>
<div class="line"><a name="l01622"></a><span class="lineno"> 1622</span>&#160;  <span class="comment">//  * Mask sizes could be larger than the corresponding mask shape (hence</span></div>
<div class="line"><a name="l01623"></a><span class="lineno"> 1623</span>&#160;  <span class="comment">//  `clamp`).</span></div>
<div class="line"><a name="l01624"></a><span class="lineno"> 1624</span>&#160;  <span class="comment">// TODO: The 2nd item should be rejected by the verifier.</span></div>
<div class="line"><a name="l01625"></a><span class="lineno"> 1625</span>&#160;  int64_t rankDiff = destShape.size() - cstMaskSizes.size();</div>
<div class="line"><a name="l01626"></a><span class="lineno"> 1626</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, idx] : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">llvm::enumerate</a>(cstMaskSizes)) {</div>
<div class="line"><a name="l01627"></a><span class="lineno"> 1627</span>&#160;    <span class="keywordflow">if</span> (<span class="comment">/*(1)*/</span> maskShape[i] &gt; destShape[rankDiff + i] ||</div>
<div class="line"><a name="l01628"></a><span class="lineno"> 1628</span>&#160;        <span class="comment">/*(2)*/</span> destShape[rankDiff + i] &lt;</div>
<div class="line"><a name="l01629"></a><span class="lineno"> 1629</span>&#160;            (<a class="code" href="PolynomialApproximation_8cpp.html#aaf0f5c82a4c61c0e930f33c21058f82e">std::clamp</a>(cstMaskSizes[i], int64_t(0), maskShape[i]) +</div>
<div class="line"><a name="l01630"></a><span class="lineno"> 1630</span>&#160;             cstWriteIdxs[i]))</div>
<div class="line"><a name="l01631"></a><span class="lineno"> 1631</span>&#160;      <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l01632"></a><span class="lineno"> 1632</span>&#160;  }</div>
<div class="line"><a name="l01633"></a><span class="lineno"> 1633</span>&#160; </div>
<div class="line"><a name="l01634"></a><span class="lineno"> 1634</span>&#160;  <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l01635"></a><span class="lineno"> 1635</span>&#160;}</div>
<div class="line"><a name="l01636"></a><span class="lineno"> 1636</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01637"></a><span class="lineno"> 1637</span>&#160;<span class="comment">/// Creates an optionally masked TransferWriteOp</span></div>
<div class="line"><a name="l01638"></a><span class="lineno"> 1638</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01639"></a><span class="lineno"> 1639</span>&#160;<span class="comment">/// Generates the following operation:</span></div>
<div class="line"><a name="l01640"></a><span class="lineno"> 1640</span>&#160;<span class="comment">///   %res = vector.transfer_write %vecToStore into %dest</span></div>
<div class="line"><a name="l01641"></a><span class="lineno"> 1641</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01642"></a><span class="lineno"> 1642</span>&#160;<span class="comment">/// If shape(vecToStore) != shape(dest), masking is used to ensure correctness:</span></div>
<div class="line"><a name="l01643"></a><span class="lineno"> 1643</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01644"></a><span class="lineno"> 1644</span>&#160;<span class="comment">///   %mask = vector.create_mask(%destShape) : %vecToStoreShape</span></div>
<div class="line"><a name="l01645"></a><span class="lineno"> 1645</span>&#160;<span class="comment">///   %res = vector.mask %mask {</span></div>
<div class="line"><a name="l01646"></a><span class="lineno"> 1646</span>&#160;<span class="comment">///     vector.transfer_write %vecToStore into %dest</span></div>
<div class="line"><a name="l01647"></a><span class="lineno"> 1647</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l01648"></a><span class="lineno"> 1648</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01649"></a><span class="lineno"> 1649</span>&#160;<span class="comment">/// The mask shape is identical to `vecToStore` (with the element type ==</span></div>
<div class="line"><a name="l01650"></a><span class="lineno"> 1650</span>&#160;<span class="comment">/// i1), and the mask values are based on the shape of the `dest` tensor.</span></div>
<div class="line"><a name="l01651"></a><span class="lineno"> 1651</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01652"></a><span class="lineno"> 1652</span>&#160;<span class="comment">/// If `useInBoundsInsteadOfMasking` is set to `true`, the `in_bounds` attribute</span></div>
<div class="line"><a name="l01653"></a><span class="lineno"> 1653</span>&#160;<span class="comment">/// is used instead of masking:</span></div>
<div class="line"><a name="l01654"></a><span class="lineno"> 1654</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01655"></a><span class="lineno"> 1655</span>&#160;<span class="comment">///   %write = vector.transfer_write %vecToStore into %dest</span></div>
<div class="line"><a name="l01656"></a><span class="lineno"> 1656</span>&#160;<span class="comment">///   in_bounds_flags = (...)</span></div>
<div class="line"><a name="l01657"></a><span class="lineno"> 1657</span>&#160;<span class="comment">///   %res = vector.transfer_write %input into %dest</span></div>
<div class="line"><a name="l01658"></a><span class="lineno"> 1658</span>&#160;<span class="comment">///       {in_bounds = in_bounds_flags}</span></div>
<div class="line"><a name="l01659"></a><span class="lineno"> 1659</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01660"></a><span class="lineno"> 1660</span>&#160;<span class="comment">/// Finally, `writeIndices` specifies the offsets to use. If empty, all indices</span></div>
<div class="line"><a name="l01661"></a><span class="lineno"> 1661</span>&#160;<span class="comment">/// are set to 0.</span></div>
<div class="line"><a name="l01662"></a><span class="lineno"> 1662</span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classmlir_1_1Operation.html">Operation</a> *</div>
<div class="line"><a name="l01663"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a4cc023e06de6664a1cd635d77118db19"> 1663</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a4cc023e06de6664a1cd635d77118db19">createWriteOrMaskedWrite</a>(<a class="code" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;builder, <a class="code" href="classmlir_1_1Location.html">Location</a> loc, <a class="code" href="classmlir_1_1Value.html">Value</a> vecToStore,</div>
<div class="line"><a name="l01664"></a><span class="lineno"> 1664</span>&#160;                         <a class="code" href="classmlir_1_1Value.html">Value</a> dest, <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> writeIndices = {},</div>
<div class="line"><a name="l01665"></a><span class="lineno"> 1665</span>&#160;                         <span class="keywordtype">bool</span> useInBoundsInsteadOfMasking = <span class="keyword">false</span>) {</div>
<div class="line"><a name="l01666"></a><span class="lineno"> 1666</span>&#160; </div>
<div class="line"><a name="l01667"></a><span class="lineno"> 1667</span>&#160;  ShapedType destType = cast&lt;ShapedType&gt;(dest.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l01668"></a><span class="lineno"> 1668</span>&#160;  int64_t destRank = destType.getRank();</div>
<div class="line"><a name="l01669"></a><span class="lineno"> 1669</span>&#160;  <span class="keyword">auto</span> destShape = destType.getShape();</div>
<div class="line"><a name="l01670"></a><span class="lineno"> 1670</span>&#160; </div>
<div class="line"><a name="l01671"></a><span class="lineno"> 1671</span>&#160;  VectorType vecToStoreType = cast&lt;VectorType&gt;(vecToStore.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l01672"></a><span class="lineno"> 1672</span>&#160;  int64_t vecToStoreRank = vecToStoreType.getRank();</div>
<div class="line"><a name="l01673"></a><span class="lineno"> 1673</span>&#160;  <span class="keyword">auto</span> vecToStoreShape = vecToStoreType.getShape();</div>
<div class="line"><a name="l01674"></a><span class="lineno"> 1674</span>&#160; </div>
<div class="line"><a name="l01675"></a><span class="lineno"> 1675</span>&#160;  <span class="comment">// Compute the in_bounds attribute</span></div>
<div class="line"><a name="l01676"></a><span class="lineno"> 1676</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBoundsVal(vecToStoreRank, <span class="keyword">true</span>);</div>
<div class="line"><a name="l01677"></a><span class="lineno"> 1677</span>&#160;  <span class="keywordflow">if</span> (useInBoundsInsteadOfMasking) {</div>
<div class="line"><a name="l01678"></a><span class="lineno"> 1678</span>&#160;    <span class="comment">// Update the inBounds attribute.</span></div>
<div class="line"><a name="l01679"></a><span class="lineno"> 1679</span>&#160;    <span class="comment">// FIXME: This computation is too weak - it ignores the write indices.</span></div>
<div class="line"><a name="l01680"></a><span class="lineno"> 1680</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; vecToStoreRank; i++)</div>
<div class="line"><a name="l01681"></a><span class="lineno"> 1681</span>&#160;      inBoundsVal[i] =</div>
<div class="line"><a name="l01682"></a><span class="lineno"> 1682</span>&#160;          (destShape[destRank - vecToStoreRank + i] &gt;= vecToStoreShape[i]) &amp;&amp;</div>
<div class="line"><a name="l01683"></a><span class="lineno"> 1683</span>&#160;          ShapedType::isStatic(destShape[destRank - vecToStoreRank + i]);</div>
<div class="line"><a name="l01684"></a><span class="lineno"> 1684</span>&#160;  }</div>
<div class="line"><a name="l01685"></a><span class="lineno"> 1685</span>&#160; </div>
<div class="line"><a name="l01686"></a><span class="lineno"> 1686</span>&#160;  <span class="comment">// If missing, initialize the write indices to 0.</span></div>
<div class="line"><a name="l01687"></a><span class="lineno"> 1687</span>&#160;  assert((writeIndices.empty() ||</div>
<div class="line"><a name="l01688"></a><span class="lineno"> 1688</span>&#160;          writeIndices.size() == <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(destRank)) &amp;&amp;</div>
<div class="line"><a name="l01689"></a><span class="lineno"> 1689</span>&#160;         <span class="stringliteral">&quot;Invalid number of write indices!&quot;</span>);</div>
<div class="line"><a name="l01690"></a><span class="lineno"> 1690</span>&#160;  <span class="keywordflow">if</span> (writeIndices.empty()) {</div>
<div class="line"><a name="l01691"></a><span class="lineno"> 1691</span>&#160;    <span class="keyword">auto</span> zero = <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(builder, loc, 0);</div>
<div class="line"><a name="l01692"></a><span class="lineno"> 1692</span>&#160;    writeIndices.assign(destRank, zero);</div>
<div class="line"><a name="l01693"></a><span class="lineno"> 1693</span>&#160;  }</div>
<div class="line"><a name="l01694"></a><span class="lineno"> 1694</span>&#160; </div>
<div class="line"><a name="l01695"></a><span class="lineno"> 1695</span>&#160;  <span class="comment">// Generate the xfer_write Op</span></div>
<div class="line"><a name="l01696"></a><span class="lineno"> 1696</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *write = vector::TransferWriteOp::create(builder, loc,</div>
<div class="line"><a name="l01697"></a><span class="lineno"> 1697</span>&#160;                                                     <span class="comment">/*vector=*/</span>vecToStore,</div>
<div class="line"><a name="l01698"></a><span class="lineno"> 1698</span>&#160;                                                     <span class="comment">/*source=*/</span>dest,</div>
<div class="line"><a name="l01699"></a><span class="lineno"> 1699</span>&#160;                                                     <span class="comment">/*indices=*/</span>writeIndices,</div>
<div class="line"><a name="l01700"></a><span class="lineno"> 1700</span>&#160;                                                     <span class="comment">/*inBounds=*/</span>inBoundsVal);</div>
<div class="line"><a name="l01701"></a><span class="lineno"> 1701</span>&#160; </div>
<div class="line"><a name="l01702"></a><span class="lineno"> 1702</span>&#160;  <span class="comment">// If masking is disabled, exit.</span></div>
<div class="line"><a name="l01703"></a><span class="lineno"> 1703</span>&#160;  <span class="keywordflow">if</span> (useInBoundsInsteadOfMasking)</div>
<div class="line"><a name="l01704"></a><span class="lineno"> 1704</span>&#160;    <span class="keywordflow">return</span> write;</div>
<div class="line"><a name="l01705"></a><span class="lineno"> 1705</span>&#160; </div>
<div class="line"><a name="l01706"></a><span class="lineno"> 1706</span>&#160;  <span class="comment">// Check if masking is needed. If not, exit.</span></div>
<div class="line"><a name="l01707"></a><span class="lineno"> 1707</span>&#160;  <span class="keywordflow">if</span> (llvm::equal(vecToStoreShape, destShape.take_back(vecToStoreRank)))</div>
<div class="line"><a name="l01708"></a><span class="lineno"> 1708</span>&#160;    <span class="keywordflow">return</span> write;</div>
<div class="line"><a name="l01709"></a><span class="lineno"> 1709</span>&#160; </div>
<div class="line"><a name="l01710"></a><span class="lineno"> 1710</span>&#160;  <span class="comment">// Compute the mask and mask the write Op.</span></div>
<div class="line"><a name="l01711"></a><span class="lineno"> 1711</span>&#160;  <span class="keyword">auto</span> writeMaskType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(vecToStoreShape, builder.<a class="code" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>(),</div>
<div class="line"><a name="l01712"></a><span class="lineno"> 1712</span>&#160;                                       vecToStoreType.getScalableDims());</div>
<div class="line"><a name="l01713"></a><span class="lineno"> 1713</span>&#160; </div>
<div class="line"><a name="l01714"></a><span class="lineno"> 1714</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;OpFoldResult&gt;</a> destSizes =</div>
<div class="line"><a name="l01715"></a><span class="lineno"> 1715</span>&#160;      isa&lt;MemRefType&gt;(dest.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>())</div>
<div class="line"><a name="l01716"></a><span class="lineno"> 1716</span>&#160;          ? <a class="code" href="namespacemlir_1_1memref.html#ab0c13e32e47a301b4ccac4b27404de51">memref::getMixedSizes</a>(builder, loc, dest)</div>
<div class="line"><a name="l01717"></a><span class="lineno"> 1717</span>&#160;          : tensor::<a class="code" href="namespacemlir_1_1memref.html#ab0c13e32e47a301b4ccac4b27404de51">getMixedSizes</a>(builder, loc, dest);</div>
<div class="line"><a name="l01718"></a><span class="lineno"> 1718</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;OpFoldResult&gt;</a> maskSizes(destSizes.end() - vecToStoreRank,</div>
<div class="line"><a name="l01719"></a><span class="lineno"> 1719</span>&#160;                                      destSizes.end());</div>
<div class="line"><a name="l01720"></a><span class="lineno"> 1720</span>&#160; </div>
<div class="line"><a name="l01721"></a><span class="lineno"> 1721</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="Vectorization_8cpp.html#a1bedce144a30ca3ef5eac6628b35d4a9">isMaskTriviallyFoldable</a>(maskSizes, writeIndices, destShape,</div>
<div class="line"><a name="l01722"></a><span class="lineno"> 1722</span>&#160;                              vecToStoreShape))</div>
<div class="line"><a name="l01723"></a><span class="lineno"> 1723</span>&#160;    <span class="keywordflow">return</span> write;</div>
<div class="line"><a name="l01724"></a><span class="lineno"> 1724</span>&#160; </div>
<div class="line"><a name="l01725"></a><span class="lineno"> 1725</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> maskForWrite =</div>
<div class="line"><a name="l01726"></a><span class="lineno"> 1726</span>&#160;      builder.<a class="code" href="classmlir_1_1OpBuilder.html#a9bfa9ca1c08777d5eba6276c24c0cf9a">createOrFold</a>&lt;vector::CreateMaskOp&gt;(loc, writeMaskType, maskSizes);</div>
<div class="line"><a name="l01727"></a><span class="lineno"> 1727</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacemlir_1_1vector.html#a4f68d86708480673ecc59b2714973a65">mlir::vector::maskOperation</a>(builder, write, maskForWrite);</div>
<div class="line"><a name="l01728"></a><span class="lineno"> 1728</span>&#160;}</div>
<div class="line"><a name="l01729"></a><span class="lineno"> 1729</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01730"></a><span class="lineno"> 1730</span>&#160;<span class="comment">/// Vectorize linalg::PackOp with (1) static inner_tiles (2) constant</span></div>
<div class="line"><a name="l01731"></a><span class="lineno"> 1731</span>&#160;<span class="comment">/// padding value and (3) input vector sizes into:</span></div>
<div class="line"><a name="l01732"></a><span class="lineno"> 1732</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01733"></a><span class="lineno"> 1733</span>&#160;<span class="comment">///   masked_transfer_read-&gt;shape_cast-&gt;transpose-&gt;transfer_write_in_bounds</span></div>
<div class="line"><a name="l01734"></a><span class="lineno"> 1734</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01735"></a><span class="lineno"> 1735</span>&#160;<span class="comment">/// As in the following example:</span></div>
<div class="line"><a name="l01736"></a><span class="lineno"> 1736</span>&#160;<span class="comment">/// %pack = tensor.pack %src inner_dims_pos = [2, 1] inner_tiles = [16, 2]</span></div>
<div class="line"><a name="l01737"></a><span class="lineno"> 1737</span>&#160;<span class="comment">///     into %dst : tensor&lt;32x8x16xf32&gt; -&gt; tensor&lt;32x4x1x16x2xf32&gt;</span></div>
<div class="line"><a name="l01738"></a><span class="lineno"> 1738</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01739"></a><span class="lineno"> 1739</span>&#160;<span class="comment">/// This pack would be vectorized to:</span></div>
<div class="line"><a name="l01740"></a><span class="lineno"> 1740</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01741"></a><span class="lineno"> 1741</span>&#160;<span class="comment">/// %load = vector.mask %mask {</span></div>
<div class="line"><a name="l01742"></a><span class="lineno"> 1742</span>&#160;<span class="comment">///     vector.transfer_read %arg0[%c0, %c0, %c0], %cst</span></div>
<div class="line"><a name="l01743"></a><span class="lineno"> 1743</span>&#160;<span class="comment">///         {in_bounds = [true, true, true]} :</span></div>
<div class="line"><a name="l01744"></a><span class="lineno"> 1744</span>&#160;<span class="comment">///         tensor&lt;32x7x16xf32&gt;, vector&lt;32x8x16xf32&gt;</span></div>
<div class="line"><a name="l01745"></a><span class="lineno"> 1745</span>&#160;<span class="comment">/// } : vector&lt;32x8x16xi1&gt; -&gt; vector&lt;32x8x16xf32&gt;</span></div>
<div class="line"><a name="l01746"></a><span class="lineno"> 1746</span>&#160;<span class="comment">/// %shape_cast = vector.shape_cast %load : vector&lt;32x8x16xf32&gt;</span></div>
<div class="line"><a name="l01747"></a><span class="lineno"> 1747</span>&#160;<span class="comment">///                                         to vector&lt;32x4x2x1x16xf32&gt;</span></div>
<div class="line"><a name="l01748"></a><span class="lineno"> 1748</span>&#160;<span class="comment">/// %transpose = vector.transpose %shape_cast, [0, 1, 3, 4, 2]</span></div>
<div class="line"><a name="l01749"></a><span class="lineno"> 1749</span>&#160;<span class="comment">///     : vector&lt;32x4x2x1x16xf32&gt; to vector&lt;32x4x1x16x2xf32&gt;</span></div>
<div class="line"><a name="l01750"></a><span class="lineno"> 1750</span>&#160;<span class="comment">/// %write = vector.transfer_write %transpose,</span></div>
<div class="line"><a name="l01751"></a><span class="lineno"> 1751</span>&#160;<span class="comment">///     %empty[%c0_0, %c0_0, %c0_0, %c0_0, %c0_0]</span></div>
<div class="line"><a name="l01752"></a><span class="lineno"> 1752</span>&#160;<span class="comment">///     {in_bounds = [true, true, true, true, true]}</span></div>
<div class="line"><a name="l01753"></a><span class="lineno"> 1753</span>&#160;<span class="comment">///     : vector&lt;32x4x1x16x2xf32&gt;, tensor&lt;32x4x1x16x2xf32&gt;</span></div>
<div class="line"><a name="l01754"></a><span class="lineno"> 1754</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01755"></a><span class="lineno"> 1755</span>&#160;<span class="comment">/// If the (3) input vector sizes are not provided, the vector sizes are</span></div>
<div class="line"><a name="l01756"></a><span class="lineno"> 1756</span>&#160;<span class="comment">/// determined by the result tensor shape and the `in_bounds`</span></div>
<div class="line"><a name="l01757"></a><span class="lineno"> 1757</span>&#160;<span class="comment">/// attribute is used instead of masking to mark out-of-bounds accesses.</span></div>
<div class="line"><a name="l01758"></a><span class="lineno"> 1758</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01759"></a><span class="lineno"> 1759</span>&#160;<span class="comment">/// NOTE: The input vector sizes specify the dimensions corresponding to the</span></div>
<div class="line"><a name="l01760"></a><span class="lineno"> 1760</span>&#160;<span class="comment">/// outer dimensions of the output tensor. The remaining dimensions are</span></div>
<div class="line"><a name="l01761"></a><span class="lineno"> 1761</span>&#160;<span class="comment">/// computed based on, e.g., the static inner tiles.</span></div>
<div class="line"><a name="l01762"></a><span class="lineno"> 1762</span>&#160;<span class="comment">/// Supporting dynamic inner tiles will require the user to specify the</span></div>
<div class="line"><a name="l01763"></a><span class="lineno"> 1763</span>&#160;<span class="comment">/// missing vector sizes. This is left as a TODO.</span></div>
<div class="line"><a name="l01764"></a><span class="lineno"> 1764</span>&#160;<span class="comment"></span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l01765"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a042126c1ec44e80d376fb8e5baa1efd0"> 1765</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a042126c1ec44e80d376fb8e5baa1efd0">vectorizeAsTensorPackOp</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, linalg::PackOp packOp,</div>
<div class="line"><a name="l01766"></a><span class="lineno"> 1766</span>&#160;                        <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l01767"></a><span class="lineno"> 1767</span>&#160;                        <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults) {</div>
<div class="line"><a name="l01768"></a><span class="lineno"> 1768</span>&#160;  <span class="comment">// TODO: Introduce a parent class that will handle the insertion point update.</span></div>
<div class="line"><a name="l01769"></a><span class="lineno"> 1769</span>&#160;  <a class="code" href="classmlir_1_1OpBuilder_1_1InsertionGuard.html">OpBuilder::InsertionGuard</a> g(rewriter);</div>
<div class="line"><a name="l01770"></a><span class="lineno"> 1770</span>&#160;  rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(packOp);</div>
<div class="line"><a name="l01771"></a><span class="lineno"> 1771</span>&#160; </div>
<div class="line"><a name="l01772"></a><span class="lineno"> 1772</span>&#160;  <a class="code" href="classmlir_1_1Location.html">Location</a> loc = packOp.getLoc();</div>
<div class="line"><a name="l01773"></a><span class="lineno"> 1773</span>&#160;  <span class="keyword">auto</span> padValue = packOp.getPaddingValue();</div>
<div class="line"><a name="l01774"></a><span class="lineno"> 1774</span>&#160;  <span class="keywordflow">if</span> (!padValue) {</div>
<div class="line"><a name="l01775"></a><span class="lineno"> 1775</span>&#160;    padValue = arith::ConstantOp::create(</div>
<div class="line"><a name="l01776"></a><span class="lineno"> 1776</span>&#160;        rewriter, loc,</div>
<div class="line"><a name="l01777"></a><span class="lineno"> 1777</span>&#160;        rewriter.<a class="code" href="classmlir_1_1Builder.html#a8e943986e58a8b0c88fcd51b0f0afafb">getZeroAttr</a>(packOp.getSourceType().getElementType()));</div>
<div class="line"><a name="l01778"></a><span class="lineno"> 1778</span>&#160;  }</div>
<div class="line"><a name="l01779"></a><span class="lineno"> 1779</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">ReifiedRankedShapedTypeDims</a> reifiedReturnShapes;</div>
<div class="line"><a name="l01780"></a><span class="lineno"> 1780</span>&#160;  LogicalResult status =</div>
<div class="line"><a name="l01781"></a><span class="lineno"> 1781</span>&#160;      cast&lt;ReifyRankedShapedTypeOpInterface&gt;(packOp.getOperation())</div>
<div class="line"><a name="l01782"></a><span class="lineno"> 1782</span>&#160;          .reifyResultShapes(rewriter, reifiedReturnShapes);</div>
<div class="line"><a name="l01783"></a><span class="lineno"> 1783</span>&#160;  (void)status; <span class="comment">// prevent unused variable warning on non-assert builds.</span></div>
<div class="line"><a name="l01784"></a><span class="lineno"> 1784</span>&#160;  assert(succeeded(status) &amp;&amp; <span class="stringliteral">&quot;failed to reify result shapes&quot;</span>);</div>
<div class="line"><a name="l01785"></a><span class="lineno"> 1785</span>&#160; </div>
<div class="line"><a name="l01786"></a><span class="lineno"> 1786</span>&#160;  <span class="comment">// If the input vector sizes are not provided, then the vector sizes are</span></div>
<div class="line"><a name="l01787"></a><span class="lineno"> 1787</span>&#160;  <span class="comment">// determined by the result tensor shape. In case the vector sizes aren&#39;t</span></div>
<div class="line"><a name="l01788"></a><span class="lineno"> 1788</span>&#160;  <span class="comment">// provided, we update the inBounds attribute instead of masking.</span></div>
<div class="line"><a name="l01789"></a><span class="lineno"> 1789</span>&#160;  <span class="keywordtype">bool</span> useInBoundsInsteadOfMasking = <span class="keyword">false</span>;</div>
<div class="line"><a name="l01790"></a><span class="lineno"> 1790</span>&#160;  <span class="keywordflow">if</span> (inputVectorSizes.empty()) {</div>
<div class="line"><a name="l01791"></a><span class="lineno"> 1791</span>&#160;    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> resultTensorShape = packOp.getDestType().getShape();</div>
<div class="line"><a name="l01792"></a><span class="lineno"> 1792</span>&#160;    inputVectorSizes = resultTensorShape.take_front(packOp.getSourceRank());</div>
<div class="line"><a name="l01793"></a><span class="lineno"> 1793</span>&#160;    useInBoundsInsteadOfMasking = <span class="keyword">true</span>;</div>
<div class="line"><a name="l01794"></a><span class="lineno"> 1794</span>&#160;  }</div>
<div class="line"><a name="l01795"></a><span class="lineno"> 1795</span>&#160; </div>
<div class="line"><a name="l01796"></a><span class="lineno"> 1796</span>&#160;  <span class="comment">// Create masked TransferReadOp.</span></div>
<div class="line"><a name="l01797"></a><span class="lineno"> 1797</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> inputShape(inputVectorSizes);</div>
<div class="line"><a name="l01798"></a><span class="lineno"> 1798</span>&#160;  <span class="keyword">auto</span> <a class="code" href="LinalgOps_8cpp.html#a4e9957a01583cd463e0cb458fc18013c">innerTiles</a> = packOp.getStaticInnerTiles();</div>
<div class="line"><a name="l01799"></a><span class="lineno"> 1799</span>&#160;  <span class="keyword">auto</span> <a class="code" href="LinalgOps_8cpp.html#aa7b25f95711cd673d4f468989b6fbad1">innerDimsPos</a> = packOp.getInnerDimsPos();</div>
<div class="line"><a name="l01800"></a><span class="lineno"> 1800</span>&#160;  <span class="keyword">auto</span> <a class="code" href="LinalgOps_8cpp.html#a2f749fca1dfad319b229d0c4884bf113">outerDimsPerm</a> = packOp.getOuterDimsPerm();</div>
<div class="line"><a name="l01801"></a><span class="lineno"> 1801</span>&#160;  <span class="keywordflow">if</span> (!<a class="code" href="LinalgOps_8cpp.html#a2f749fca1dfad319b229d0c4884bf113">outerDimsPerm</a>.empty())</div>
<div class="line"><a name="l01802"></a><span class="lineno"> 1802</span>&#160;    <a class="code" href="namespacemlir.html#adbcff71555e8c1965e508f324f43a55a">applyPermutationToVector</a>(inputShape,</div>
<div class="line"><a name="l01803"></a><span class="lineno"> 1803</span>&#160;                             <a class="code" href="namespacemlir.html#afc254f56cba37671e1e5b2b933c6a090">invertPermutationVector</a>(<a class="code" href="LinalgOps_8cpp.html#a2f749fca1dfad319b229d0c4884bf113">outerDimsPerm</a>));</div>
<div class="line"><a name="l01804"></a><span class="lineno"> 1804</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [idx, size] : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">enumerate</a>(<a class="code" href="LinalgOps_8cpp.html#a4e9957a01583cd463e0cb458fc18013c">innerTiles</a>))</div>
<div class="line"><a name="l01805"></a><span class="lineno"> 1805</span>&#160;    inputShape[<a class="code" href="LinalgOps_8cpp.html#aa7b25f95711cd673d4f468989b6fbad1">innerDimsPos</a>[idx]] *= size;</div>
<div class="line"><a name="l01806"></a><span class="lineno"> 1806</span>&#160;  <span class="keyword">auto</span> maskedRead = <a class="code" href="namespacemlir_1_1vector.html#ab9c7ed08068bf03fb4bd625cd3bbd98c">vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a name="l01807"></a><span class="lineno"> 1807</span>&#160;      rewriter, loc, packOp.getSource(), inputShape, padValue,</div>
<div class="line"><a name="l01808"></a><span class="lineno"> 1808</span>&#160;      useInBoundsInsteadOfMasking);</div>
<div class="line"><a name="l01809"></a><span class="lineno"> 1809</span>&#160; </div>
<div class="line"><a name="l01810"></a><span class="lineno"> 1810</span>&#160;  <span class="comment">// Create ShapeCastOp.</span></div>
<div class="line"><a name="l01811"></a><span class="lineno"> 1811</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> destShape(inputVectorSizes);</div>
<div class="line"><a name="l01812"></a><span class="lineno"> 1812</span>&#160;  destShape.append(<a class="code" href="LinalgOps_8cpp.html#a4e9957a01583cd463e0cb458fc18013c">innerTiles</a>.begin(), <a class="code" href="LinalgOps_8cpp.html#a4e9957a01583cd463e0cb458fc18013c">innerTiles</a>.end());</div>
<div class="line"><a name="l01813"></a><span class="lineno"> 1813</span>&#160;  <span class="keyword">auto</span> tiledPackType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(<a class="code" href="Vectorization_8cpp.html#abea66cfdf6b9e3285381e7d3543c894c">getTiledPackShape</a>(packOp, destShape),</div>
<div class="line"><a name="l01814"></a><span class="lineno"> 1814</span>&#160;                                       packOp.getDestType().getElementType());</div>
<div class="line"><a name="l01815"></a><span class="lineno"> 1815</span>&#160;  <span class="keyword">auto</span> shapeCastOp =</div>
<div class="line"><a name="l01816"></a><span class="lineno"> 1816</span>&#160;      vector::ShapeCastOp::create(rewriter, loc, tiledPackType, maskedRead);</div>
<div class="line"><a name="l01817"></a><span class="lineno"> 1817</span>&#160; </div>
<div class="line"><a name="l01818"></a><span class="lineno"> 1818</span>&#160;  <span class="comment">// Create TransposeOp.</span></div>
<div class="line"><a name="l01819"></a><span class="lineno"> 1819</span>&#160;  <span class="keyword">auto</span> destPermutation =</div>
<div class="line"><a name="l01820"></a><span class="lineno"> 1820</span>&#160;      <a class="code" href="namespacemlir.html#afc254f56cba37671e1e5b2b933c6a090">invertPermutationVector</a>(<a class="code" href="namespacemlir_1_1linalg.html#a5c34dd63bd77acc711bdf98d6e2c7b75">getPackInverseDestPerm</a>(packOp));</div>
<div class="line"><a name="l01821"></a><span class="lineno"> 1821</span>&#160;  <span class="keyword">auto</span> transposeOp = vector::TransposeOp::create(</div>
<div class="line"><a name="l01822"></a><span class="lineno"> 1822</span>&#160;      rewriter, loc, shapeCastOp.getResult(), destPermutation);</div>
<div class="line"><a name="l01823"></a><span class="lineno"> 1823</span>&#160; </div>
<div class="line"><a name="l01824"></a><span class="lineno"> 1824</span>&#160;  <span class="comment">// Create TransferWriteOp.</span></div>
<div class="line"><a name="l01825"></a><span class="lineno"> 1825</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> dest = tensor::EmptyOp::create(</div>
<div class="line"><a name="l01826"></a><span class="lineno"> 1826</span>&#160;      rewriter, loc, reifiedReturnShapes[0],</div>
<div class="line"><a name="l01827"></a><span class="lineno"> 1827</span>&#160;      transposeOp.getResult().getType().getElementType());</div>
<div class="line"><a name="l01828"></a><span class="lineno"> 1828</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *write =</div>
<div class="line"><a name="l01829"></a><span class="lineno"> 1829</span>&#160;      <a class="code" href="Vectorization_8cpp.html#a4cc023e06de6664a1cd635d77118db19">createWriteOrMaskedWrite</a>(rewriter, loc, transposeOp.getResult(), dest);</div>
<div class="line"><a name="l01830"></a><span class="lineno"> 1830</span>&#160;  newResults.push_back(write-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a name="l01831"></a><span class="lineno"> 1831</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l01832"></a><span class="lineno"> 1832</span>&#160;}</div>
<div class="line"><a name="l01833"></a><span class="lineno"> 1833</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01834"></a><span class="lineno"> 1834</span>&#160;<span class="comment">/// Given the re-associations, &quot;collapses&quot; the input Vector type</span></div>
<div class="line"><a name="l01835"></a><span class="lineno"> 1835</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01836"></a><span class="lineno"> 1836</span>&#160;<span class="comment">/// This is similar to CollapseShapeOp::inferCollapsedType with two notable</span></div>
<div class="line"><a name="l01837"></a><span class="lineno"> 1837</span>&#160;<span class="comment">/// differences:</span></div>
<div class="line"><a name="l01838"></a><span class="lineno"> 1838</span>&#160;<span class="comment">///   * We can safely assume that there are no dynamic sizes.</span></div>
<div class="line"><a name="l01839"></a><span class="lineno"> 1839</span>&#160;<span class="comment">///   * Scalable flags are updated alongside regular dims.</span></div>
<div class="line"><a name="l01840"></a><span class="lineno"> 1840</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01841"></a><span class="lineno"> 1841</span>&#160;<span class="comment">/// When collapsing scalable flags, conservatively avoids cases with two</span></div>
<div class="line"><a name="l01842"></a><span class="lineno"> 1842</span>&#160;<span class="comment">/// scalable dims. We could re-visit this in the future.</span></div>
<div class="line"><a name="l01843"></a><span class="lineno"> 1843</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l01844"></a><span class="lineno"> 1844</span>&#160;<span class="comment">/// EXAMPLE:</span></div>
<div class="line"><a name="l01845"></a><span class="lineno"> 1845</span>&#160;<span class="comment">///  type = vector&lt;4x16x[8]x16xf32&gt;</span></div>
<div class="line"><a name="l01846"></a><span class="lineno"> 1846</span>&#160;<span class="comment">///  reassociation =  [(d0, d1, d2, d3) -&gt; (d0, d1),</span></div>
<div class="line"><a name="l01847"></a><span class="lineno"> 1847</span>&#160;<span class="comment">///                    (d0, d1, d2, d3) -&gt; (d2, d3)]</span></div>
<div class="line"><a name="l01848"></a><span class="lineno"> 1848</span>&#160;<span class="comment">///  Result:</span></div>
<div class="line"><a name="l01849"></a><span class="lineno"> 1849</span>&#160;<span class="comment">///   vector&lt;64x[128]xf32&gt;</span></div>
<div class="line"><a name="l01850"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a8019302085ef04a05864f2bb3f198f5c"> 1850</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> VectorType <a class="code" href="Vectorization_8cpp.html#a8019302085ef04a05864f2bb3f198f5c">getCollapsedVecType</a>(VectorType type,</div>
<div class="line"><a name="l01851"></a><span class="lineno"> 1851</span>&#160;                                      <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;AffineMap&gt;</a> reassociation) {</div>
<div class="line"><a name="l01852"></a><span class="lineno"> 1852</span>&#160;  assert(type.getNumScalableDims() &lt; 2 &amp;&amp;</div>
<div class="line"><a name="l01853"></a><span class="lineno"> 1853</span>&#160;         <span class="stringliteral">&quot;Collapsing more than 1 scalable dim is not supported ATM&quot;</span>);</div>
<div class="line"><a name="l01854"></a><span class="lineno"> 1854</span>&#160; </div>
<div class="line"><a name="l01855"></a><span class="lineno"> 1855</span>&#160;  <span class="comment">// Use the fact that reassociation is valid to simplify the logic: only use</span></div>
<div class="line"><a name="l01856"></a><span class="lineno"> 1856</span>&#160;  <span class="comment">// each map&#39;s rank.</span></div>
<div class="line"><a name="l01857"></a><span class="lineno"> 1857</span>&#160;  assert(<a class="code" href="namespacemlir.html#a9e3d6f94b6a941066c3e7e5535817a9b">isReassociationValid</a>(reassociation) &amp;&amp; <span class="stringliteral">&quot;invalid reassociation&quot;</span>);</div>
<div class="line"><a name="l01858"></a><span class="lineno"> 1858</span>&#160; </div>
<div class="line"><a name="l01859"></a><span class="lineno"> 1859</span>&#160;  <span class="keyword">auto</span> shape = type.getShape();</div>
<div class="line"><a name="l01860"></a><span class="lineno"> 1860</span>&#160;  <span class="keyword">auto</span> scalableFlags = type.getScalableDims();</div>
<div class="line"><a name="l01861"></a><span class="lineno"> 1861</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> newShape;</div>
<div class="line"><a name="l01862"></a><span class="lineno"> 1862</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> newScalableFlags;</div>
<div class="line"><a name="l01863"></a><span class="lineno"> 1863</span>&#160; </div>
<div class="line"><a name="l01864"></a><span class="lineno"> 1864</span>&#160;  <span class="keywordtype">unsigned</span> currentDim = 0;</div>
<div class="line"><a name="l01865"></a><span class="lineno"> 1865</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> m : reassociation) {</div>
<div class="line"><a name="l01866"></a><span class="lineno"> 1866</span>&#160;    <span class="keywordtype">unsigned</span> dim = m.getNumResults();</div>
<div class="line"><a name="l01867"></a><span class="lineno"> 1867</span>&#160;    int64_t size = 1;</div>
<div class="line"><a name="l01868"></a><span class="lineno"> 1868</span>&#160;    <span class="keywordtype">bool</span> flag = <span class="keyword">false</span>;</div>
<div class="line"><a name="l01869"></a><span class="lineno"> 1869</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> d = 0; d &lt; dim; ++d) {</div>
<div class="line"><a name="l01870"></a><span class="lineno"> 1870</span>&#160;      size *= shape[currentDim + d];</div>
<div class="line"><a name="l01871"></a><span class="lineno"> 1871</span>&#160;      flag |= scalableFlags[currentDim + d];</div>
<div class="line"><a name="l01872"></a><span class="lineno"> 1872</span>&#160;    }</div>
<div class="line"><a name="l01873"></a><span class="lineno"> 1873</span>&#160;    newShape.push_back(size);</div>
<div class="line"><a name="l01874"></a><span class="lineno"> 1874</span>&#160;    newScalableFlags.push_back(flag);</div>
<div class="line"><a name="l01875"></a><span class="lineno"> 1875</span>&#160;    currentDim += dim;</div>
<div class="line"><a name="l01876"></a><span class="lineno"> 1876</span>&#160;  }</div>
<div class="line"><a name="l01877"></a><span class="lineno"> 1877</span>&#160; </div>
<div class="line"><a name="l01878"></a><span class="lineno"> 1878</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(newShape, type.getElementType(), newScalableFlags);</div>
<div class="line"><a name="l01879"></a><span class="lineno"> 1879</span>&#160;}</div>
<div class="line"><a name="l01880"></a><span class="lineno"> 1880</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01881"></a><span class="lineno"> 1881</span>&#160;<span class="comment">/// Vectorize a `linalg::UnPackOp` to these 4 Ops:</span></div>
<div class="line"><a name="l01882"></a><span class="lineno"> 1882</span>&#160;<span class="comment">///   Vector::TransferReadOp - Reads a vector from the source tensor</span></div>
<div class="line"><a name="l01883"></a><span class="lineno"> 1883</span>&#160;<span class="comment">///   vector::TransposeOp - Transpose the Source tensor</span></div>
<div class="line"><a name="l01884"></a><span class="lineno"> 1884</span>&#160;<span class="comment">///   ShapeCastOp - Reshape the data based on the target.</span></div>
<div class="line"><a name="l01885"></a><span class="lineno"> 1885</span>&#160;<span class="comment">///   vector::TransferWriteOp. - Write the result vector back to the destination</span></div>
<div class="line"><a name="l01886"></a><span class="lineno"> 1886</span>&#160;<span class="comment">///   tensor.</span></div>
<div class="line"><a name="l01887"></a><span class="lineno"> 1887</span>&#160;<span class="comment">///   If the vector sizes are not provided:</span></div>
<div class="line"><a name="l01888"></a><span class="lineno"> 1888</span>&#160;<span class="comment">///   * the vector sizes are determined by the input operand and attributes,</span></div>
<div class="line"><a name="l01889"></a><span class="lineno"> 1889</span>&#160;<span class="comment">///   * update the inBounds attribute instead of masking.</span></div>
<div class="line"><a name="l01890"></a><span class="lineno"> 1890</span>&#160;<span class="comment"></span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l01891"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a026c54c12deb9d84b6fc83be82d1c183"> 1891</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a026c54c12deb9d84b6fc83be82d1c183">vectorizeAsTensorUnpackOp</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, linalg::UnPackOp unpackOp,</div>
<div class="line"><a name="l01892"></a><span class="lineno"> 1892</span>&#160;                          <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l01893"></a><span class="lineno"> 1893</span>&#160;                          <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults) {</div>
<div class="line"><a name="l01894"></a><span class="lineno"> 1894</span>&#160; </div>
<div class="line"><a name="l01895"></a><span class="lineno"> 1895</span>&#160;  <span class="comment">// TODO: Introduce a parent class that will handle the insertion point update.</span></div>
<div class="line"><a name="l01896"></a><span class="lineno"> 1896</span>&#160;  <a class="code" href="classmlir_1_1OpBuilder_1_1InsertionGuard.html">OpBuilder::InsertionGuard</a> g(rewriter);</div>
<div class="line"><a name="l01897"></a><span class="lineno"> 1897</span>&#160;  rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(unpackOp);</div>
<div class="line"><a name="l01898"></a><span class="lineno"> 1898</span>&#160; </div>
<div class="line"><a name="l01899"></a><span class="lineno"> 1899</span>&#160;  RankedTensorType unpackTensorType = unpackOp.getSourceType();</div>
<div class="line"><a name="l01900"></a><span class="lineno"> 1900</span>&#160; </div>
<div class="line"><a name="l01901"></a><span class="lineno"> 1901</span>&#160;  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> innerDimPos = unpackOp.getInnerDimsPos();</div>
<div class="line"><a name="l01902"></a><span class="lineno"> 1902</span>&#160;  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> <a class="code" href="LinalgOps_8cpp.html#a4e9957a01583cd463e0cb458fc18013c">innerTiles</a> = unpackOp.getStaticInnerTiles();</div>
<div class="line"><a name="l01903"></a><span class="lineno"> 1903</span>&#160;  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> sourceShape = unpackTensorType.getShape();</div>
<div class="line"><a name="l01904"></a><span class="lineno"> 1904</span>&#160;  <span class="keywordtype">bool</span> useInBoundsInsteadOfMasking = <span class="keyword">false</span>;</div>
<div class="line"><a name="l01905"></a><span class="lineno"> 1905</span>&#160;  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> <a class="code" href="LinalgOps_8cpp.html#a2f749fca1dfad319b229d0c4884bf113">outerDimsPerm</a> = unpackOp.getOuterDimsPerm();</div>
<div class="line"><a name="l01906"></a><span class="lineno"> 1906</span>&#160; </div>
<div class="line"><a name="l01907"></a><span class="lineno"> 1907</span>&#160;  <span class="keyword">auto</span> destSize = unpackOp.getDestRank();</div>
<div class="line"><a name="l01908"></a><span class="lineno"> 1908</span>&#160; </div>
<div class="line"><a name="l01909"></a><span class="lineno"> 1909</span>&#160;  <span class="keywordflow">if</span> (!inputVectorSizes.empty())</div>
<div class="line"><a name="l01910"></a><span class="lineno"> 1910</span>&#160;    assert(inputVectorSizes.size() == destSize &amp;&amp;</div>
<div class="line"><a name="l01911"></a><span class="lineno"> 1911</span>&#160;           <span class="stringliteral">&quot;Incorrect number of input vector sizes&quot;</span>);</div>
<div class="line"><a name="l01912"></a><span class="lineno"> 1912</span>&#160; </div>
<div class="line"><a name="l01913"></a><span class="lineno"> 1913</span>&#160;  <span class="comment">// vectorSizes is the shape of the vector that will be used to do final</span></div>
<div class="line"><a name="l01914"></a><span class="lineno"> 1914</span>&#160;  <span class="comment">// write on the destination tensor. It is set like this: Let&#39;s say the</span></div>
<div class="line"><a name="l01915"></a><span class="lineno"> 1915</span>&#160;  <span class="comment">// source tensor is rank &#39;M&#39; and the dest tensor rank &#39;N&#39;, where N &lt;= M.</span></div>
<div class="line"><a name="l01916"></a><span class="lineno"> 1916</span>&#160;  <span class="comment">// Thus:</span></div>
<div class="line"><a name="l01917"></a><span class="lineno"> 1917</span>&#160;  <span class="comment">// 1. vectorSizes = sourceShape.take_front(N)</span></div>
<div class="line"><a name="l01918"></a><span class="lineno"> 1918</span>&#160;  <span class="comment">// 2. if outer_dims_perms is present: do that permutation on vectorSizes.</span></div>
<div class="line"><a name="l01919"></a><span class="lineno"> 1919</span>&#160;  <span class="comment">// 3. multiply all the locations in vectorSize pointed by innerDimPos by the</span></div>
<div class="line"><a name="l01920"></a><span class="lineno"> 1920</span>&#160;  <span class="comment">//    innerTiles attribute value.</span></div>
<div class="line"><a name="l01921"></a><span class="lineno"> 1921</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> vectorSizes(inputVectorSizes);</div>
<div class="line"><a name="l01922"></a><span class="lineno"> 1922</span>&#160;  <span class="keywordflow">if</span> (vectorSizes.empty()) {</div>
<div class="line"><a name="l01923"></a><span class="lineno"> 1923</span>&#160;    llvm::append_range(vectorSizes, sourceShape.take_front(destSize));</div>
<div class="line"><a name="l01924"></a><span class="lineno"> 1924</span>&#160;    <span class="keywordflow">if</span> (!<a class="code" href="LinalgOps_8cpp.html#a2f749fca1dfad319b229d0c4884bf113">outerDimsPerm</a>.empty())</div>
<div class="line"><a name="l01925"></a><span class="lineno"> 1925</span>&#160;      <a class="code" href="namespacemlir.html#adbcff71555e8c1965e508f324f43a55a">applyPermutationToVector</a>(vectorSizes, <a class="code" href="LinalgOps_8cpp.html#a2f749fca1dfad319b229d0c4884bf113">outerDimsPerm</a>);</div>
<div class="line"><a name="l01926"></a><span class="lineno"> 1926</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, pos] : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">llvm::enumerate</a>(innerDimPos))</div>
<div class="line"><a name="l01927"></a><span class="lineno"> 1927</span>&#160;      vectorSizes[pos] *= <a class="code" href="LinalgOps_8cpp.html#a4e9957a01583cd463e0cb458fc18013c">innerTiles</a>[i];</div>
<div class="line"><a name="l01928"></a><span class="lineno"> 1928</span>&#160; </div>
<div class="line"><a name="l01929"></a><span class="lineno"> 1929</span>&#160;    useInBoundsInsteadOfMasking = <span class="keyword">true</span>;</div>
<div class="line"><a name="l01930"></a><span class="lineno"> 1930</span>&#160;  }</div>
<div class="line"><a name="l01931"></a><span class="lineno"> 1931</span>&#160; </div>
<div class="line"><a name="l01932"></a><span class="lineno"> 1932</span>&#160;  <span class="comment">// readVectorSizes is the size of tensor used to read and apply mask. It is</span></div>
<div class="line"><a name="l01933"></a><span class="lineno"> 1933</span>&#160;  <span class="comment">// set like this: Let&#39;s say the vectorSize (VS) array is size &#39;N&#39; and</span></div>
<div class="line"><a name="l01934"></a><span class="lineno"> 1934</span>&#160;  <span class="comment">// the sourceShape(SS) is &#39;M&#39; where M &gt;= N and InnerTileSizes (IT) of</span></div>
<div class="line"><a name="l01935"></a><span class="lineno"> 1935</span>&#160;  <span class="comment">// size M-N</span></div>
<div class="line"><a name="l01936"></a><span class="lineno"> 1936</span>&#160;  <span class="comment">// Thus:</span></div>
<div class="line"><a name="l01937"></a><span class="lineno"> 1937</span>&#160;  <span class="comment">// - initially: readVectorSizes = vectorInputSizes</span></div>
<div class="line"><a name="l01938"></a><span class="lineno"> 1938</span>&#160;  <span class="comment">// - Divide all the readMaskShape locations pointed by innerDimPos</span></div>
<div class="line"><a name="l01939"></a><span class="lineno"> 1939</span>&#160;  <span class="comment">//   by the innerTileSize attribute value.</span></div>
<div class="line"><a name="l01940"></a><span class="lineno"> 1940</span>&#160;  <span class="comment">// - if outer_dims_perms is present: do that permutation on readVectorSizes.</span></div>
<div class="line"><a name="l01941"></a><span class="lineno"> 1941</span>&#160;  <span class="comment">// - Append the remaining shape from SS</span></div>
<div class="line"><a name="l01942"></a><span class="lineno"> 1942</span>&#160;  <span class="comment">// E.g. let&#39;s say let&#39;s say unpackTensorType.getShape() = &lt;8x8x32x16&gt;</span></div>
<div class="line"><a name="l01943"></a><span class="lineno"> 1943</span>&#160;  <span class="comment">// inner Dim Pos = [0, 1] and Inner Tiles = [32, 16], vector_sizes are [512,</span></div>
<div class="line"><a name="l01944"></a><span class="lineno"> 1944</span>&#160;  <span class="comment">// 128] and outer_dims_perm is [1, 0] then read shape is:</span></div>
<div class="line"><a name="l01945"></a><span class="lineno"> 1945</span>&#160;  <span class="comment">//   ReadVectorSizes(initial): [512, 128]</span></div>
<div class="line"><a name="l01946"></a><span class="lineno"> 1946</span>&#160;  <span class="comment">//   Final Value(after innerDim Adjustment): [512/32, 128/16]</span></div>
<div class="line"><a name="l01947"></a><span class="lineno"> 1947</span>&#160;  <span class="comment">//                                           = [16, 8]</span></div>
<div class="line"><a name="l01948"></a><span class="lineno"> 1948</span>&#160;  <span class="comment">//   After applying outer_dims_perm: [8, 16]</span></div>
<div class="line"><a name="l01949"></a><span class="lineno"> 1949</span>&#160;  <span class="comment">//   After appending the rest of the sourceShape: [8, 16, 32, 16]</span></div>
<div class="line"><a name="l01950"></a><span class="lineno"> 1950</span>&#160; </div>
<div class="line"><a name="l01951"></a><span class="lineno"> 1951</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> readVectorSizes(vectorSizes.begin(), vectorSizes.end());</div>
<div class="line"><a name="l01952"></a><span class="lineno"> 1952</span>&#160; </div>
<div class="line"><a name="l01953"></a><span class="lineno"> 1953</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [index, size] : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">enumerate</a>(<a class="code" href="LinalgOps_8cpp.html#a4e9957a01583cd463e0cb458fc18013c">innerTiles</a>)) {</div>
<div class="line"><a name="l01954"></a><span class="lineno"> 1954</span>&#160;    readVectorSizes[innerDimPos[index]] =</div>
<div class="line"><a name="l01955"></a><span class="lineno"> 1955</span>&#160;        <a class="code" href="namespacemlir_1_1detail.html#a98a07efa628a8720c45b577162e4fe66">llvm::divideCeil</a>(readVectorSizes[innerDimPos[index]], size);</div>
<div class="line"><a name="l01956"></a><span class="lineno"> 1956</span>&#160;  }</div>
<div class="line"><a name="l01957"></a><span class="lineno"> 1957</span>&#160;  <span class="keywordflow">if</span> (!<a class="code" href="LinalgOps_8cpp.html#a2f749fca1dfad319b229d0c4884bf113">outerDimsPerm</a>.empty()) {</div>
<div class="line"><a name="l01958"></a><span class="lineno"> 1958</span>&#160;    <a class="code" href="namespacemlir.html#adbcff71555e8c1965e508f324f43a55a">applyPermutationToVector</a>(readVectorSizes, <a class="code" href="LinalgOps_8cpp.html#a2f749fca1dfad319b229d0c4884bf113">outerDimsPerm</a>);</div>
<div class="line"><a name="l01959"></a><span class="lineno"> 1959</span>&#160;  }</div>
<div class="line"><a name="l01960"></a><span class="lineno"> 1960</span>&#160;  readVectorSizes.append(sourceShape.begin() + vectorSizes.size(),</div>
<div class="line"><a name="l01961"></a><span class="lineno"> 1961</span>&#160;                         sourceShape.end());</div>
<div class="line"><a name="l01962"></a><span class="lineno"> 1962</span>&#160; </div>
<div class="line"><a name="l01963"></a><span class="lineno"> 1963</span>&#160;  <a class="code" href="classmlir_1_1Location.html">Location</a> loc = unpackOp-&gt;getLoc();</div>
<div class="line"><a name="l01964"></a><span class="lineno"> 1964</span>&#160; </div>
<div class="line"><a name="l01965"></a><span class="lineno"> 1965</span>&#160;  <span class="keyword">auto</span> padValue = arith::ConstantOp::create(</div>
<div class="line"><a name="l01966"></a><span class="lineno"> 1966</span>&#160;      rewriter, loc,</div>
<div class="line"><a name="l01967"></a><span class="lineno"> 1967</span>&#160;      rewriter.<a class="code" href="classmlir_1_1Builder.html#a8e943986e58a8b0c88fcd51b0f0afafb">getZeroAttr</a>(unpackOp.getSourceType().getElementType()));</div>
<div class="line"><a name="l01968"></a><span class="lineno"> 1968</span>&#160; </div>
<div class="line"><a name="l01969"></a><span class="lineno"> 1969</span>&#160;  <span class="comment">// Read result, mask if necessary. If transferReadOp shape is not equal</span></div>
<div class="line"><a name="l01970"></a><span class="lineno"> 1970</span>&#160;  <span class="comment">// to shape of source, then a mask is necessary.</span></div>
<div class="line"><a name="l01971"></a><span class="lineno"> 1971</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> readResult = <a class="code" href="namespacemlir_1_1vector.html#ab9c7ed08068bf03fb4bd625cd3bbd98c">vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a name="l01972"></a><span class="lineno"> 1972</span>&#160;      rewriter, loc, unpackOp.getSource(), readVectorSizes, padValue,</div>
<div class="line"><a name="l01973"></a><span class="lineno"> 1973</span>&#160;      <span class="comment">/*useInBoundsInsteadOfMasking=*/</span><span class="keyword">false</span>);</div>
<div class="line"><a name="l01974"></a><span class="lineno"> 1974</span>&#160; </div>
<div class="line"><a name="l01975"></a><span class="lineno"> 1975</span>&#160;  PackingMetadata packMetadata;</div>
<div class="line"><a name="l01976"></a><span class="lineno"> 1976</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> lastDimToInsertPosPerm =</div>
<div class="line"><a name="l01977"></a><span class="lineno"> 1977</span>&#160;      <a class="code" href="namespacemlir_1_1linalg.html#aa9d51592527f88974d4540b6dd73a59d">getUnPackInverseSrcPerm</a>(unpackOp, packMetadata);</div>
<div class="line"><a name="l01978"></a><span class="lineno"> 1978</span>&#160;  <span class="comment">// Transpose the appropriate rows to match output.</span></div>
<div class="line"><a name="l01979"></a><span class="lineno"> 1979</span>&#160;  vector::TransposeOp transposeOp = vector::TransposeOp::create(</div>
<div class="line"><a name="l01980"></a><span class="lineno"> 1980</span>&#160;      rewriter, loc, readResult, lastDimToInsertPosPerm);</div>
<div class="line"><a name="l01981"></a><span class="lineno"> 1981</span>&#160; </div>
<div class="line"><a name="l01982"></a><span class="lineno"> 1982</span>&#160;  <span class="comment">// Collapse the vector to the size required by result.</span></div>
<div class="line"><a name="l01983"></a><span class="lineno"> 1983</span>&#160;  VectorType collapsedVecType = <a class="code" href="Vectorization_8cpp.html#a8019302085ef04a05864f2bb3f198f5c">getCollapsedVecType</a>(</div>
<div class="line"><a name="l01984"></a><span class="lineno"> 1984</span>&#160;      transposeOp.getType(),</div>
<div class="line"><a name="l01985"></a><span class="lineno"> 1985</span>&#160;      <a class="code" href="namespacemlir.html#a561d5231fcefc471a4c9069fce2eaf87">getSymbolLessAffineMaps</a>(<a class="code" href="namespacemlir.html#a9b2799e8f52860dadc460b88a8f2df32">convertReassociationIndicesToExprs</a>(</div>
<div class="line"><a name="l01986"></a><span class="lineno"> 1986</span>&#160;          rewriter.<a class="code" href="classmlir_1_1Builder.html#aa6d1e114c8047cad1b014b504688a868">getContext</a>(), packMetadata.reassociations)));</div>
<div class="line"><a name="l01987"></a><span class="lineno"> 1987</span>&#160;  vector::ShapeCastOp shapeCastOp = vector::ShapeCastOp::create(</div>
<div class="line"><a name="l01988"></a><span class="lineno"> 1988</span>&#160;      rewriter, loc, collapsedVecType, transposeOp-&gt;getResult(0));</div>
<div class="line"><a name="l01989"></a><span class="lineno"> 1989</span>&#160; </div>
<div class="line"><a name="l01990"></a><span class="lineno"> 1990</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *write = <a class="code" href="Vectorization_8cpp.html#a4cc023e06de6664a1cd635d77118db19">createWriteOrMaskedWrite</a>(</div>
<div class="line"><a name="l01991"></a><span class="lineno"> 1991</span>&#160;      rewriter, loc, shapeCastOp.getResult(), unpackOp.getDest(),</div>
<div class="line"><a name="l01992"></a><span class="lineno"> 1992</span>&#160;      <span class="comment">/*writeIndices=*/</span>{}, useInBoundsInsteadOfMasking);</div>
<div class="line"><a name="l01993"></a><span class="lineno"> 1993</span>&#160;  newResults.push_back(write-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a name="l01994"></a><span class="lineno"> 1994</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l01995"></a><span class="lineno"> 1995</span>&#160;}</div>
<div class="line"><a name="l01996"></a><span class="lineno"> 1996</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l01997"></a><span class="lineno"> 1997</span>&#160;<span class="comment">/// Vectorize a `padOp` with (1) static result type, (2) constant padding value</span></div>
<div class="line"><a name="l01998"></a><span class="lineno"> 1998</span>&#160;<span class="comment">/// and (3) all-zero lowPad to</span></div>
<div class="line"><a name="l01999"></a><span class="lineno"> 1999</span>&#160;<span class="comment">///   `transfer_write_in_bounds(transfer_read_masked(pad_source, pad_value))`.</span></div>
<div class="line"><a name="l02000"></a><span class="lineno"> 2000</span>&#160;<span class="comment"></span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l02001"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#af8d343eff4117b4738a97dea5eb4d4bd"> 2001</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#af8d343eff4117b4738a97dea5eb4d4bd">vectorizeAsTensorPadOp</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, tensor::PadOp padOp,</div>
<div class="line"><a name="l02002"></a><span class="lineno"> 2002</span>&#160;                       <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l02003"></a><span class="lineno"> 2003</span>&#160;                       <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults) {</div>
<div class="line"><a name="l02004"></a><span class="lineno"> 2004</span>&#160;  <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a name="l02005"></a><span class="lineno"> 2005</span>&#160;  <a class="code" href="classmlir_1_1Location.html">Location</a> loc = padOp.getLoc();</div>
<div class="line"><a name="l02006"></a><span class="lineno"> 2006</span>&#160; </div>
<div class="line"><a name="l02007"></a><span class="lineno"> 2007</span>&#160;  <span class="comment">// TODO: Introduce a parent class that will handle the insertion point update.</span></div>
<div class="line"><a name="l02008"></a><span class="lineno"> 2008</span>&#160;  <a class="code" href="classmlir_1_1OpBuilder_1_1InsertionGuard.html">OpBuilder::InsertionGuard</a> g(rewriter);</div>
<div class="line"><a name="l02009"></a><span class="lineno"> 2009</span>&#160;  rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(padOp);</div>
<div class="line"><a name="l02010"></a><span class="lineno"> 2010</span>&#160; </div>
<div class="line"><a name="l02011"></a><span class="lineno"> 2011</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">ReifiedRankedShapedTypeDims</a> reifiedReturnShapes;</div>
<div class="line"><a name="l02012"></a><span class="lineno"> 2012</span>&#160;  LogicalResult status =</div>
<div class="line"><a name="l02013"></a><span class="lineno"> 2013</span>&#160;      cast&lt;ReifyRankedShapedTypeOpInterface&gt;(padOp.getOperation())</div>
<div class="line"><a name="l02014"></a><span class="lineno"> 2014</span>&#160;          .reifyResultShapes(rewriter, reifiedReturnShapes);</div>
<div class="line"><a name="l02015"></a><span class="lineno"> 2015</span>&#160;  (void)status; <span class="comment">// prevent unused variable warning on non-assert builds</span></div>
<div class="line"><a name="l02016"></a><span class="lineno"> 2016</span>&#160;  assert(succeeded(status) &amp;&amp; <span class="stringliteral">&quot;failed to reify result shapes&quot;</span>);</div>
<div class="line"><a name="l02017"></a><span class="lineno"> 2017</span>&#160;  <span class="keyword">auto</span> maskedRead = <a class="code" href="namespacemlir_1_1vector.html#ab9c7ed08068bf03fb4bd625cd3bbd98c">vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a name="l02018"></a><span class="lineno"> 2018</span>&#160;      rewriter, loc, padOp.getSource(), inputVectorSizes, padValue,</div>
<div class="line"><a name="l02019"></a><span class="lineno"> 2019</span>&#160;      <span class="comment">/*useInBoundsInsteadOfMasking=*/</span><span class="keyword">false</span>);</div>
<div class="line"><a name="l02020"></a><span class="lineno"> 2020</span>&#160; </div>
<div class="line"><a name="l02021"></a><span class="lineno"> 2021</span>&#160;  <span class="comment">// Create Xfer write Op</span></div>
<div class="line"><a name="l02022"></a><span class="lineno"> 2022</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> dest = tensor::EmptyOp::create(rewriter, loc, reifiedReturnShapes[0],</div>
<div class="line"><a name="l02023"></a><span class="lineno"> 2023</span>&#160;                                       padOp.getResultType().getElementType());</div>
<div class="line"><a name="l02024"></a><span class="lineno"> 2024</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *write = <a class="code" href="Vectorization_8cpp.html#a4cc023e06de6664a1cd635d77118db19">createWriteOrMaskedWrite</a>(rewriter, loc, maskedRead, dest);</div>
<div class="line"><a name="l02025"></a><span class="lineno"> 2025</span>&#160;  newResults.push_back(write-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a name="l02026"></a><span class="lineno"> 2026</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02027"></a><span class="lineno"> 2027</span>&#160;}</div>
<div class="line"><a name="l02028"></a><span class="lineno"> 2028</span>&#160; </div>
<div class="line"><a name="l02029"></a><span class="lineno"> 2029</span>&#160;<span class="comment">// TODO: probably need some extra checks for reduction followed by consumer</span></div>
<div class="line"><a name="l02030"></a><span class="lineno"> 2030</span>&#160;<span class="comment">// ops that may not commute (e.g. linear reduction + non-linear instructions).</span></div>
<div class="line"><a name="l02031"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a1ee50532663d56946548afe0ff92509c"> 2031</a></span>&#160;<span class="keyword">static</span> LogicalResult <a class="code" href="Vectorization_8cpp.html#a1ee50532663d56946548afe0ff92509c">reductionPreconditions</a>(LinalgOp op) {</div>
<div class="line"><a name="l02032"></a><span class="lineno"> 2032</span>&#160;  <span class="keywordflow">if</span> (llvm::none_of(op.getIteratorTypesArray(), <a class="code" href="namespacemlir_1_1linalg.html#a5377722f56e02541897c157260bd1eee">isReductionIterator</a>)) {</div>
<div class="line"><a name="l02033"></a><span class="lineno"> 2033</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;reduction precondition failed: no reduction iterator&quot;</span>;</div>
<div class="line"><a name="l02034"></a><span class="lineno"> 2034</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02035"></a><span class="lineno"> 2035</span>&#160;  }</div>
<div class="line"><a name="l02036"></a><span class="lineno"> 2036</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> &amp;opOperand : op.getDpsInitsMutable()) {</div>
<div class="line"><a name="l02037"></a><span class="lineno"> 2037</span>&#160;    <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> indexingMap = op.getMatchingIndexingMap(&amp;opOperand);</div>
<div class="line"><a name="l02038"></a><span class="lineno"> 2038</span>&#160;    <span class="keywordflow">if</span> (indexingMap.<a class="code" href="classmlir_1_1AffineMap.html#af6e665372add0df0668e1ebd231488b4">isPermutation</a>())</div>
<div class="line"><a name="l02039"></a><span class="lineno"> 2039</span>&#160;      <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l02040"></a><span class="lineno"> 2040</span>&#160; </div>
<div class="line"><a name="l02041"></a><span class="lineno"> 2041</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *reduceOp = <a class="code" href="Vectorization_8cpp.html#a69cbb7a1a1669d28a2e2f4b221a2132f">matchLinalgReduction</a>(&amp;opOperand);</div>
<div class="line"><a name="l02042"></a><span class="lineno"> 2042</span>&#160;    <span class="keywordflow">if</span> (!reduceOp || !<a class="code" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp)) {</div>
<div class="line"><a name="l02043"></a><span class="lineno"> 2043</span>&#160;      LDBG() &lt;&lt; <span class="stringliteral">&quot;reduction precondition failed: reduction detection failed&quot;</span>;</div>
<div class="line"><a name="l02044"></a><span class="lineno"> 2044</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02045"></a><span class="lineno"> 2045</span>&#160;    }</div>
<div class="line"><a name="l02046"></a><span class="lineno"> 2046</span>&#160;  }</div>
<div class="line"><a name="l02047"></a><span class="lineno"> 2047</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02048"></a><span class="lineno"> 2048</span>&#160;}</div>
<div class="line"><a name="l02049"></a><span class="lineno"> 2049</span>&#160; </div>
<div class="line"><a name="l02050"></a><span class="lineno"> 2050</span>&#160;<span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l02051"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ad6ef02407dc9f6a46da43369638fbbe8"> 2051</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#ad6ef02407dc9f6a46da43369638fbbe8">vectorizeDynamicConvOpPrecondition</a>(linalg::LinalgOp conv,</div>
<div class="line"><a name="l02052"></a><span class="lineno"> 2052</span>&#160;                                   <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a name="l02053"></a><span class="lineno"> 2053</span>&#160;  <span class="keywordflow">if</span> (flatten1DDepthwiseConv) {</div>
<div class="line"><a name="l02054"></a><span class="lineno"> 2054</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorization of flattened convs with dynamic shapes is not &quot;</span></div>
<div class="line"><a name="l02055"></a><span class="lineno"> 2055</span>&#160;              <span class="stringliteral">&quot;supported&quot;</span>;</div>
<div class="line"><a name="l02056"></a><span class="lineno"> 2056</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02057"></a><span class="lineno"> 2057</span>&#160;  }</div>
<div class="line"><a name="l02058"></a><span class="lineno"> 2058</span>&#160; </div>
<div class="line"><a name="l02059"></a><span class="lineno"> 2059</span>&#160;  <span class="keywordflow">if</span> (!isa&lt;linalg::DepthwiseConv1DNwcWcOp&gt;(conv)) {</div>
<div class="line"><a name="l02060"></a><span class="lineno"> 2060</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Not a 1D depth-wise WC conv, dynamic shapes are not supported&quot;</span>;</div>
<div class="line"><a name="l02061"></a><span class="lineno"> 2061</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02062"></a><span class="lineno"> 2062</span>&#160;  }</div>
<div class="line"><a name="l02063"></a><span class="lineno"> 2063</span>&#160; </div>
<div class="line"><a name="l02064"></a><span class="lineno"> 2064</span>&#160;  <span class="comment">// Support dynamic shapes in 1D depthwise convolution, but only in the</span></div>
<div class="line"><a name="l02065"></a><span class="lineno"> 2065</span>&#160;  <span class="comment">// _channel_ dimension.</span></div>
<div class="line"><a name="l02066"></a><span class="lineno"> 2066</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> lhs = conv.getDpsInputOperand(0)-&gt;get();</div>
<div class="line"><a name="l02067"></a><span class="lineno"> 2067</span>&#160;  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> lhsShape = cast&lt;ShapedType&gt;(lhs.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()).getShape();</div>
<div class="line"><a name="l02068"></a><span class="lineno"> 2068</span>&#160;  <span class="keyword">auto</span> shapeWithoutCh = lhsShape.drop_back(1);</div>
<div class="line"><a name="l02069"></a><span class="lineno"> 2069</span>&#160;  <span class="keywordflow">if</span> (ShapedType::isDynamicShape(shapeWithoutCh)) {</div>
<div class="line"><a name="l02070"></a><span class="lineno"> 2070</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Dynamically-shaped op vectorization precondition failed: only &quot;</span></div>
<div class="line"><a name="l02071"></a><span class="lineno"> 2071</span>&#160;              <span class="stringliteral">&quot;channel dim can be dynamic&quot;</span>;</div>
<div class="line"><a name="l02072"></a><span class="lineno"> 2072</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02073"></a><span class="lineno"> 2073</span>&#160;  }</div>
<div class="line"><a name="l02074"></a><span class="lineno"> 2074</span>&#160; </div>
<div class="line"><a name="l02075"></a><span class="lineno"> 2075</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02076"></a><span class="lineno"> 2076</span>&#160;}</div>
<div class="line"><a name="l02077"></a><span class="lineno"> 2077</span>&#160; </div>
<div class="line"><a name="l02078"></a><span class="lineno"> 2078</span>&#160;<span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l02079"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a9361ccf3f87080ceace5da1af0d2e522"> 2079</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a9361ccf3f87080ceace5da1af0d2e522">vectorizeDynamicLinalgOpPrecondition</a>(linalg::LinalgOp op,</div>
<div class="line"><a name="l02080"></a><span class="lineno"> 2080</span>&#160;                                     <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a name="l02081"></a><span class="lineno"> 2081</span>&#160;  <span class="keywordflow">if</span> (isa&lt;ConvolutionOpInterface&gt;(op.getOperation()))</div>
<div class="line"><a name="l02082"></a><span class="lineno"> 2082</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#ad6ef02407dc9f6a46da43369638fbbe8">vectorizeDynamicConvOpPrecondition</a>(op, flatten1DDepthwiseConv);</div>
<div class="line"><a name="l02083"></a><span class="lineno"> 2083</span>&#160; </div>
<div class="line"><a name="l02084"></a><span class="lineno"> 2084</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">hasReductionIterator</a>(op))</div>
<div class="line"><a name="l02085"></a><span class="lineno"> 2085</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a1ee50532663d56946548afe0ff92509c">reductionPreconditions</a>(op);</div>
<div class="line"><a name="l02086"></a><span class="lineno"> 2086</span>&#160; </div>
<div class="line"><a name="l02087"></a><span class="lineno"> 2087</span>&#160;  <span class="comment">// TODO: Masking only supports dynamic element-wise ops, linalg.generic ops,</span></div>
<div class="line"><a name="l02088"></a><span class="lineno"> 2088</span>&#160;  <span class="comment">// linalg.copy ops and ops that implement ContractionOpInterface for now.</span></div>
<div class="line"><a name="l02089"></a><span class="lineno"> 2089</span>&#160;  <span class="keywordflow">if</span> (!<a class="code" href="namespacemlir_1_1linalg.html#a8b1c347bc995910212c197f9f8728b12">isElementwise</a>(op) &amp;&amp;</div>
<div class="line"><a name="l02090"></a><span class="lineno"> 2090</span>&#160;      !isa&lt;linalg::GenericOp, linalg::CopyOp, linalg::ContractionOpInterface&gt;(</div>
<div class="line"><a name="l02091"></a><span class="lineno"> 2091</span>&#160;          op.getOperation()))</div>
<div class="line"><a name="l02092"></a><span class="lineno"> 2092</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02093"></a><span class="lineno"> 2093</span>&#160; </div>
<div class="line"><a name="l02094"></a><span class="lineno"> 2094</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Dynamically-shaped op meets vectorization pre-conditions&quot;</span>;</div>
<div class="line"><a name="l02095"></a><span class="lineno"> 2095</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02096"></a><span class="lineno"> 2096</span>&#160;}</div>
<div class="line"><a name="l02097"></a><span class="lineno"> 2097</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l02098"></a><span class="lineno"> 2098</span>&#160;<span class="comment">/// Need to check if the inner-tiles are static/constant.</span></div>
<div class="line"><a name="l02099"></a><span class="lineno"> 2099</span>&#160;<span class="comment"></span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l02100"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#af7adb8d1e2203f372dfc75ab40903520"> 2100</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#af7adb8d1e2203f372dfc75ab40903520">vectorizeUnPackOpPrecondition</a>(linalg::UnPackOp unpackOp,</div>
<div class="line"><a name="l02101"></a><span class="lineno"> 2101</span>&#160;                              <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes) {</div>
<div class="line"><a name="l02102"></a><span class="lineno"> 2102</span>&#160; </div>
<div class="line"><a name="l02103"></a><span class="lineno"> 2103</span>&#160;  <span class="keywordflow">if</span> (llvm::any_of(unpackOp.getInnerTiles(), [](<a class="code" href="classmlir_1_1OpFoldResult.html">OpFoldResult</a> res) {</div>
<div class="line"><a name="l02104"></a><span class="lineno"> 2104</span>&#160;        return !getConstantIntValue(res).has_value();</div>
<div class="line"><a name="l02105"></a><span class="lineno"> 2105</span>&#160;      })) {</div>
<div class="line"><a name="l02106"></a><span class="lineno"> 2106</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Inner-tiles must be constant: &quot;</span> &lt;&lt; unpackOp;</div>
<div class="line"><a name="l02107"></a><span class="lineno"> 2107</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02108"></a><span class="lineno"> 2108</span>&#160;  }</div>
<div class="line"><a name="l02109"></a><span class="lineno"> 2109</span>&#160;  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> resultShape = unpackOp.getDestType().getShape();</div>
<div class="line"><a name="l02110"></a><span class="lineno"> 2110</span>&#160;  <span class="keywordtype">bool</span> satisfyEmptyCond = inputVectorSizes.empty() &amp;&amp;</div>
<div class="line"><a name="l02111"></a><span class="lineno"> 2111</span>&#160;                          unpackOp.getDestType().hasStaticShape() &amp;&amp;</div>
<div class="line"><a name="l02112"></a><span class="lineno"> 2112</span>&#160;                          unpackOp.getSourceType().hasStaticShape();</div>
<div class="line"><a name="l02113"></a><span class="lineno"> 2113</span>&#160;  <span class="keywordflow">if</span> (!satisfyEmptyCond &amp;&amp;</div>
<div class="line"><a name="l02114"></a><span class="lineno"> 2114</span>&#160;      failed(<a class="code" href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">vector::isValidMaskedInputVector</a>(resultShape, inputVectorSizes)))</div>
<div class="line"><a name="l02115"></a><span class="lineno"> 2115</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02116"></a><span class="lineno"> 2116</span>&#160; </div>
<div class="line"><a name="l02117"></a><span class="lineno"> 2117</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02118"></a><span class="lineno"> 2118</span>&#160;}</div>
<div class="line"><a name="l02119"></a><span class="lineno"> 2119</span>&#160; </div>
<div class="line"><a name="l02120"></a><span class="lineno"> 2120</span>&#160;<span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l02121"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ab6ce64f69fae16d29646e68dab583d58"> 2121</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#ab6ce64f69fae16d29646e68dab583d58">vectorizeInsertSliceOpPrecondition</a>(tensor::InsertSliceOp sliceOp,</div>
<div class="line"><a name="l02122"></a><span class="lineno"> 2122</span>&#160;                                   <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes) {</div>
<div class="line"><a name="l02123"></a><span class="lineno"> 2123</span>&#160; </div>
<div class="line"><a name="l02124"></a><span class="lineno"> 2124</span>&#160;  <a class="code" href="namespacemlir.html#a39768b5816332d4970911da09de5cec4">TypedValue&lt;RankedTensorType&gt;</a> source = sliceOp.getSource();</div>
<div class="line"><a name="l02125"></a><span class="lineno"> 2125</span>&#160;  <span class="keyword">auto</span> sourceType = source.getType();</div>
<div class="line"><a name="l02126"></a><span class="lineno"> 2126</span>&#160;  <span class="keywordflow">if</span> (!VectorType::isValidElementType(sourceType.getElementType()))</div>
<div class="line"><a name="l02127"></a><span class="lineno"> 2127</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02128"></a><span class="lineno"> 2128</span>&#160; </div>
<div class="line"><a name="l02129"></a><span class="lineno"> 2129</span>&#160;  <span class="comment">// Get the pad value.</span></div>
<div class="line"><a name="l02130"></a><span class="lineno"> 2130</span>&#160;  <span class="comment">// TransferReadOp (which is used to vectorize InsertSliceOp), requires a</span></div>
<div class="line"><a name="l02131"></a><span class="lineno"> 2131</span>&#160;  <span class="comment">// scalar padding value. Note that:</span></div>
<div class="line"><a name="l02132"></a><span class="lineno"> 2132</span>&#160;  <span class="comment">//    * for in-bounds accesses,</span></div>
<div class="line"><a name="l02133"></a><span class="lineno"> 2133</span>&#160;  <span class="comment">// the value is actually irrelevant. There are 2 cases in which xfer.read</span></div>
<div class="line"><a name="l02134"></a><span class="lineno"> 2134</span>&#160;  <span class="comment">// accesses are known to be in-bounds:</span></div>
<div class="line"><a name="l02135"></a><span class="lineno"> 2135</span>&#160;  <span class="comment">//  1. The source shape is static (output vector sizes would be based on</span></div>
<div class="line"><a name="l02136"></a><span class="lineno"> 2136</span>&#160;  <span class="comment">//     the source shape and hence all memory accesses would be in-bounds),</span></div>
<div class="line"><a name="l02137"></a><span class="lineno"> 2137</span>&#160;  <span class="comment">//  2. Masking is used, i.e. the output vector sizes are user-provided. In</span></div>
<div class="line"><a name="l02138"></a><span class="lineno"> 2138</span>&#160;  <span class="comment">//     this case it is safe to assume that all memory accesses are in-bounds.</span></div>
<div class="line"><a name="l02139"></a><span class="lineno"> 2139</span>&#160;  <span class="comment">//</span></div>
<div class="line"><a name="l02140"></a><span class="lineno"> 2140</span>&#160;  <span class="comment">// When the value is not known and not needed, use 0. Otherwise, bail out.</span></div>
<div class="line"><a name="l02141"></a><span class="lineno"> 2141</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> padValue = <a class="code" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(sliceOp);</div>
<div class="line"><a name="l02142"></a><span class="lineno"> 2142</span>&#160;  <span class="keywordtype">bool</span> isOutOfBoundsRead =</div>
<div class="line"><a name="l02143"></a><span class="lineno"> 2143</span>&#160;      !sourceType.hasStaticShape() &amp;&amp; inputVectorSizes.empty();</div>
<div class="line"><a name="l02144"></a><span class="lineno"> 2144</span>&#160; </div>
<div class="line"><a name="l02145"></a><span class="lineno"> 2145</span>&#160;  <span class="keywordflow">if</span> (!padValue &amp;&amp; isOutOfBoundsRead) {</div>
<div class="line"><a name="l02146"></a><span class="lineno"> 2146</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Failed to get a pad value for out-of-bounds read access&quot;</span>;</div>
<div class="line"><a name="l02147"></a><span class="lineno"> 2147</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02148"></a><span class="lineno"> 2148</span>&#160;  }</div>
<div class="line"><a name="l02149"></a><span class="lineno"> 2149</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02150"></a><span class="lineno"> 2150</span>&#160;}</div>
<div class="line"><a name="l02151"></a><span class="lineno"> 2151</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l02152"></a><span class="lineno"> 2152</span>&#160;<span class="comment">/// Vectorize a named linalg contraction op into:</span></div>
<div class="line"><a name="l02153"></a><span class="lineno"> 2153</span>&#160;<span class="comment">///   vector::TransferReadOp - Reads vectors from the operands</span></div>
<div class="line"><a name="l02154"></a><span class="lineno"> 2154</span>&#160;<span class="comment">///   vector::ContractionOp - Performs contraction</span></div>
<div class="line"><a name="l02155"></a><span class="lineno"> 2155</span>&#160;<span class="comment">///   vector::TransferWriteOp - Write the result vector back to the</span></div>
<div class="line"><a name="l02156"></a><span class="lineno"> 2156</span>&#160;<span class="comment">///   destination</span></div>
<div class="line"><a name="l02157"></a><span class="lineno"> 2157</span>&#160;<span class="comment">/// The operands shapes are preserved and loaded directly into vectors.</span></div>
<div class="line"><a name="l02158"></a><span class="lineno"> 2158</span>&#160;<span class="comment">/// Any further permutations or numerical casting remain within contraction op.</span></div>
<div class="line"><a name="l02159"></a><span class="lineno"> 2159</span>&#160;<span class="comment"></span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l02160"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a9936412c5d68fa78d0d1998d6af2219f"> 2160</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a9936412c5d68fa78d0d1998d6af2219f">vectorizeAsLinalgContraction</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="structVectorizationState.html">VectorizationState</a> &amp;state,</div>
<div class="line"><a name="l02161"></a><span class="lineno"> 2161</span>&#160;                             LinalgOp linalgOp,</div>
<div class="line"><a name="l02162"></a><span class="lineno"> 2162</span>&#160;                             <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults) {</div>
<div class="line"><a name="l02163"></a><span class="lineno"> 2163</span>&#160;  <a class="code" href="classmlir_1_1Location.html">Location</a> loc = linalgOp.getLoc();</div>
<div class="line"><a name="l02164"></a><span class="lineno"> 2164</span>&#160;  <a class="code" href="classmlir_1_1MLIRContext.html">MLIRContext</a> *ctx = linalgOp.getContext();</div>
<div class="line"><a name="l02165"></a><span class="lineno"> 2165</span>&#160; </div>
<div class="line"><a name="l02166"></a><span class="lineno"> 2166</span>&#160;  <span class="comment">// For simplicity, contraction vectorization is limited to linalg named ops.</span></div>
<div class="line"><a name="l02167"></a><span class="lineno"> 2167</span>&#160;  <span class="comment">// Generic op is ignored as not every arbitrary contraction body can be</span></div>
<div class="line"><a name="l02168"></a><span class="lineno"> 2168</span>&#160;  <span class="comment">// expressed by a vector.contract.</span></div>
<div class="line"><a name="l02169"></a><span class="lineno"> 2169</span>&#160;  <span class="keywordflow">if</span> (!isa&lt;ContractionOpInterface&gt;(linalgOp.getOperation()))</div>
<div class="line"><a name="l02170"></a><span class="lineno"> 2170</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02171"></a><span class="lineno"> 2171</span>&#160; </div>
<div class="line"><a name="l02172"></a><span class="lineno"> 2172</span>&#160;  <a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> *outOperand = linalgOp.getDpsInitOperand(0);</div>
<div class="line"><a name="l02173"></a><span class="lineno"> 2173</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *reduceOp = <a class="code" href="Vectorization_8cpp.html#a69cbb7a1a1669d28a2e2f4b221a2132f">matchLinalgReduction</a>(outOperand);</div>
<div class="line"><a name="l02174"></a><span class="lineno"> 2174</span>&#160;  <span class="keyword">auto</span> maybeKind = <a class="code" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp);</div>
<div class="line"><a name="l02175"></a><span class="lineno"> 2175</span>&#160;  <span class="keywordflow">if</span> (!maybeKind) {</div>
<div class="line"><a name="l02176"></a><span class="lineno"> 2176</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Failed to determine contraction combining kind.&quot;</span>;</div>
<div class="line"><a name="l02177"></a><span class="lineno"> 2177</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02178"></a><span class="lineno"> 2178</span>&#160;  }</div>
<div class="line"><a name="l02179"></a><span class="lineno"> 2179</span>&#160; </div>
<div class="line"><a name="l02180"></a><span class="lineno"> 2180</span>&#160;  <span class="comment">// Check that all dimensions are present in the input operands.</span></div>
<div class="line"><a name="l02181"></a><span class="lineno"> 2181</span>&#160;  <span class="comment">// Arbitrary broadcasts are not supported by the vector contraction.</span></div>
<div class="line"><a name="l02182"></a><span class="lineno"> 2182</span>&#160;  <span class="comment">// Broadcasts are expected to be decomposed before vectorization.</span></div>
<div class="line"><a name="l02183"></a><span class="lineno"> 2183</span>&#160;  <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> lhsMap = linalgOp.getIndexingMapsArray()[0];</div>
<div class="line"><a name="l02184"></a><span class="lineno"> 2184</span>&#160;  <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> rhsMap = linalgOp.getIndexingMapsArray()[1];</div>
<div class="line"><a name="l02185"></a><span class="lineno"> 2185</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="namespacemlir.html#ac61c6bb6068af953a0711cf404a99645">getUnusedDimsBitVector</a>({lhsMap, rhsMap}).any()) {</div>
<div class="line"><a name="l02186"></a><span class="lineno"> 2186</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Contractions with broadcasts are not supported.&quot;</span>;</div>
<div class="line"><a name="l02187"></a><span class="lineno"> 2187</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02188"></a><span class="lineno"> 2188</span>&#160;  }</div>
<div class="line"><a name="l02189"></a><span class="lineno"> 2189</span>&#160; </div>
<div class="line"><a name="l02190"></a><span class="lineno"> 2190</span>&#160;  <span class="comment">// Load operands.</span></div>
<div class="line"><a name="l02191"></a><span class="lineno"> 2191</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> vecOperands;</div>
<div class="line"><a name="l02192"></a><span class="lineno"> 2192</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> &amp;opOperand : linalgOp-&gt;getOpOperands()) {</div>
<div class="line"><a name="l02193"></a><span class="lineno"> 2193</span>&#160;    <span class="comment">// The operand vector shape is computed by mapping the canonical vector</span></div>
<div class="line"><a name="l02194"></a><span class="lineno"> 2194</span>&#160;    <span class="comment">// shape to the operand&#39;s domain. Further permutations are left as a part of</span></div>
<div class="line"><a name="l02195"></a><span class="lineno"> 2195</span>&#160;    <span class="comment">// the contraction.</span></div>
<div class="line"><a name="l02196"></a><span class="lineno"> 2196</span>&#160;    <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> indexingMap = linalgOp.getMatchingIndexingMap(&amp;opOperand);</div>
<div class="line"><a name="l02197"></a><span class="lineno"> 2197</span>&#160;    <a class="code" href="classmlir_1_1AffineMap.html">AffineMap</a> readMap = <a class="code" href="classmlir_1_1AffineMap.html#a39ed2c2a4c743450a4a999fa6db1bf84">AffineMap::getMultiDimIdentityMap</a>(</div>
<div class="line"><a name="l02198"></a><span class="lineno"> 2198</span>&#160;        indexingMap.<a class="code" href="classmlir_1_1AffineMap.html#a96f194ae3b4baf33c67b10c9f795b564">getNumResults</a>(), rewriter.<a class="code" href="classmlir_1_1Builder.html#aa6d1e114c8047cad1b014b504688a868">getContext</a>());</div>
<div class="line"><a name="l02199"></a><span class="lineno"> 2199</span>&#160;    <a class="code" href="classmlir_1_1Type.html">Type</a> elemType = <a class="code" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(opOperand.get());</div>
<div class="line"><a name="l02200"></a><span class="lineno"> 2200</span>&#160;    VectorType readType =</div>
<div class="line"><a name="l02201"></a><span class="lineno"> 2201</span>&#160;        state.getCanonicalVecType(elemType, readMap.<a class="code" href="classmlir_1_1AffineMap.html#af2baf4561cf7d74a9959fd9e875c9a82">compose</a>(indexingMap));</div>
<div class="line"><a name="l02202"></a><span class="lineno"> 2202</span>&#160; </div>
<div class="line"><a name="l02203"></a><span class="lineno"> 2203</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> read = <a class="code" href="namespacemlir_1_1vector.html#ab9c7ed08068bf03fb4bd625cd3bbd98c">mlir::vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a name="l02204"></a><span class="lineno"> 2204</span>&#160;        rewriter, loc, opOperand.get(), readType.getShape(),</div>
<div class="line"><a name="l02205"></a><span class="lineno"> 2205</span>&#160;        <span class="comment">/*padding=*/</span><a class="code" href="namespacemlir_1_1arith.html#af73ab4d70d330c6212d9ccd87a38056b">arith::getZeroConstant</a>(rewriter, loc, elemType),</div>
<div class="line"><a name="l02206"></a><span class="lineno"> 2206</span>&#160;        <span class="comment">/*useInBoundsInsteadOfMasking=*/</span><span class="keyword">false</span>, readType.getScalableDims());</div>
<div class="line"><a name="l02207"></a><span class="lineno"> 2207</span>&#160;    vecOperands.push_back(read);</div>
<div class="line"><a name="l02208"></a><span class="lineno"> 2208</span>&#160;  }</div>
<div class="line"><a name="l02209"></a><span class="lineno"> 2209</span>&#160; </div>
<div class="line"><a name="l02210"></a><span class="lineno"> 2210</span>&#160;  <span class="comment">// Remap iterators from linalg to vector.</span></div>
<div class="line"><a name="l02211"></a><span class="lineno"> 2211</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Attribute&gt;</a> iterAttrs;</div>
<div class="line"><a name="l02212"></a><span class="lineno"> 2212</span>&#160;  <span class="keyword">auto</span> iterators = linalgOp.getIteratorTypesArray();</div>
<div class="line"><a name="l02213"></a><span class="lineno"> 2213</span>&#160;  <span class="keywordflow">for</span> (utils::IteratorType iter : iterators) {</div>
<div class="line"><a name="l02214"></a><span class="lineno"> 2214</span>&#160;    <span class="keyword">auto</span> vecIter = iter == utils::IteratorType::parallel</div>
<div class="line"><a name="l02215"></a><span class="lineno"> 2215</span>&#160;                       ? vector::IteratorType::parallel</div>
<div class="line"><a name="l02216"></a><span class="lineno"> 2216</span>&#160;                       : vector::IteratorType::reduction;</div>
<div class="line"><a name="l02217"></a><span class="lineno"> 2217</span>&#160;    iterAttrs.push_back(<a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">vector::IteratorTypeAttr::get</a>(ctx, vecIter));</div>
<div class="line"><a name="l02218"></a><span class="lineno"> 2218</span>&#160;  }</div>
<div class="line"><a name="l02219"></a><span class="lineno"> 2219</span>&#160; </div>
<div class="line"><a name="l02220"></a><span class="lineno"> 2220</span>&#160;  <span class="comment">// Create contraction.</span></div>
<div class="line"><a name="l02221"></a><span class="lineno"> 2221</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *contractOp = vector::ContractionOp::create(</div>
<div class="line"><a name="l02222"></a><span class="lineno"> 2222</span>&#160;      rewriter, loc, <span class="comment">/*lhs=*/</span>vecOperands[0],</div>
<div class="line"><a name="l02223"></a><span class="lineno"> 2223</span>&#160;      <span class="comment">/*rhs=*/</span>vecOperands[1], <span class="comment">/*acc=*/</span>vecOperands[2],</div>
<div class="line"><a name="l02224"></a><span class="lineno"> 2224</span>&#160;      linalgOp.getIndexingMaps(), rewriter.<a class="code" href="classmlir_1_1Builder.html#ac9e0170e1b16f9c7464823b7b2fcb042">getArrayAttr</a>(iterAttrs), *maybeKind);</div>
<div class="line"><a name="l02225"></a><span class="lineno"> 2225</span>&#160;  contractOp = state.maskOperation(rewriter, contractOp, linalgOp);</div>
<div class="line"><a name="l02226"></a><span class="lineno"> 2226</span>&#160; </div>
<div class="line"><a name="l02227"></a><span class="lineno"> 2227</span>&#160;  <span class="comment">// Store result.</span></div>
<div class="line"><a name="l02228"></a><span class="lineno"> 2228</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *write = <a class="code" href="Vectorization_8cpp.html#a4cc023e06de6664a1cd635d77118db19">createWriteOrMaskedWrite</a>(</div>
<div class="line"><a name="l02229"></a><span class="lineno"> 2229</span>&#160;      rewriter, loc, contractOp-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0), outOperand-&gt;<a class="code" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>());</div>
<div class="line"><a name="l02230"></a><span class="lineno"> 2230</span>&#160; </div>
<div class="line"><a name="l02231"></a><span class="lineno"> 2231</span>&#160;  <span class="comment">// Finalize.</span></div>
<div class="line"><a name="l02232"></a><span class="lineno"> 2232</span>&#160;  <span class="keywordflow">if</span> (!write-&gt;<a class="code" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>().empty())</div>
<div class="line"><a name="l02233"></a><span class="lineno"> 2233</span>&#160;    newResults.push_back(write-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a name="l02234"></a><span class="lineno"> 2234</span>&#160; </div>
<div class="line"><a name="l02235"></a><span class="lineno"> 2235</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02236"></a><span class="lineno"> 2236</span>&#160;}</div>
<div class="line"><a name="l02237"></a><span class="lineno"> 2237</span>&#160; </div>
<div class="line"><a name="l02238"></a><span class="lineno"> 2238</span>&#160;<span class="keyword">namespace </span>{</div>
<div class="line"><a name="l02239"></a><span class="lineno"> 2239</span>&#160;<span class="keyword">enum class</span> ConvOperationKind { Conv, Pool };</div>
<div class="line"><a name="l02240"></a><span class="lineno"> 2240</span>&#160;} <span class="comment">// namespace</span></div>
<div class="line"><a name="l02241"></a><span class="lineno"> 2241</span>&#160; </div>
<div class="line"><a name="l02242"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a33cb68fa87ea3bda8e98058b464af807"> 2242</a></span>&#160;<span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code" href="Vectorization_8cpp.html#a33cb68fa87ea3bda8e98058b464af807">isCastOfBlockArgument</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op) {</div>
<div class="line"><a name="l02243"></a><span class="lineno"> 2243</span>&#160;  <span class="keywordflow">return</span> isa&lt;CastOpInterface&gt;(op) &amp;&amp; op-&gt;<a class="code" href="classmlir_1_1Operation.html#a80db2165a86e0837b30f5f3e0dc899df">getNumOperands</a>() == 1 &amp;&amp;</div>
<div class="line"><a name="l02244"></a><span class="lineno"> 2244</span>&#160;         isa&lt;BlockArgument&gt;(op-&gt;<a class="code" href="classmlir_1_1Operation.html#a1eecfffb7445e24f9fbdec2d619251ff">getOperand</a>(0));</div>
<div class="line"><a name="l02245"></a><span class="lineno"> 2245</span>&#160;}</div>
<div class="line"><a name="l02246"></a><span class="lineno"> 2246</span>&#160; </div>
<div class="line"><a name="l02247"></a><span class="lineno"> 2247</span>&#160;<span class="comment">// Returns the ConvOperationKind of the op using reduceOp of the generic</span></div>
<div class="line"><a name="l02248"></a><span class="lineno"> 2248</span>&#160;<span class="comment">// payload. If it is neither a convolution nor a pooling, it returns</span></div>
<div class="line"><a name="l02249"></a><span class="lineno"> 2249</span>&#160;<span class="comment">// std::nullopt.</span></div>
<div class="line"><a name="l02250"></a><span class="lineno"> 2250</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l02251"></a><span class="lineno"> 2251</span>&#160;<span class="comment">// If (region has 2 ops (reduction + yield) or 3 ops (extension + reduction</span></div>
<div class="line"><a name="l02252"></a><span class="lineno"> 2252</span>&#160;<span class="comment">// + yield) and rhs is not used) then it is the body of a pooling</span></div>
<div class="line"><a name="l02253"></a><span class="lineno"> 2253</span>&#160;<span class="comment">// If conv, check for single `mul` predecessor. The `mul` operands must be</span></div>
<div class="line"><a name="l02254"></a><span class="lineno"> 2254</span>&#160;<span class="comment">// block arguments or extension of block arguments.</span></div>
<div class="line"><a name="l02255"></a><span class="lineno"> 2255</span>&#160;<span class="comment">// Otherwise, check for one or zero `ext` predecessor. The `ext` operands</span></div>
<div class="line"><a name="l02256"></a><span class="lineno"> 2256</span>&#160;<span class="comment">// must be block arguments or extension of block arguments.</span></div>
<div class="line"><a name="l02257"></a><span class="lineno"> 2257</span>&#160;<span class="keyword">static</span> std::optional&lt;ConvOperationKind&gt;</div>
<div class="line"><a name="l02258"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a007245f85f137cf2008229e2a4932915"> 2258</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a007245f85f137cf2008229e2a4932915">getConvOperationKind</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *reduceOp) {</div>
<div class="line"><a name="l02259"></a><span class="lineno"> 2259</span>&#160;  <span class="keywordtype">int</span> numBlockArguments =</div>
<div class="line"><a name="l02260"></a><span class="lineno"> 2260</span>&#160;      llvm::count_if(reduceOp-&gt;<a class="code" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(), llvm::IsaPred&lt;BlockArgument&gt;);</div>
<div class="line"><a name="l02261"></a><span class="lineno"> 2261</span>&#160; </div>
<div class="line"><a name="l02262"></a><span class="lineno"> 2262</span>&#160;  <span class="keywordflow">switch</span> (numBlockArguments) {</div>
<div class="line"><a name="l02263"></a><span class="lineno"> 2263</span>&#160;  <span class="keywordflow">case</span> 1: {</div>
<div class="line"><a name="l02264"></a><span class="lineno"> 2264</span>&#160;    <span class="comment">// Will be convolution if feeder is a MulOp.</span></div>
<div class="line"><a name="l02265"></a><span class="lineno"> 2265</span>&#160;    <span class="comment">// A strength reduced version of MulOp for i1 type is AndOp which is also</span></div>
<div class="line"><a name="l02266"></a><span class="lineno"> 2266</span>&#160;    <span class="comment">// supported. Otherwise, it can be pooling. This strength reduction logic</span></div>
<div class="line"><a name="l02267"></a><span class="lineno"> 2267</span>&#160;    <span class="comment">// is in `buildBinaryFn` helper in the Linalg dialect.</span></div>
<div class="line"><a name="l02268"></a><span class="lineno"> 2268</span>&#160;    <span class="keyword">auto</span> feedValIt = llvm::find_if_not(reduceOp-&gt;<a class="code" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(),</div>
<div class="line"><a name="l02269"></a><span class="lineno"> 2269</span>&#160;                                       llvm::IsaPred&lt;BlockArgument&gt;);</div>
<div class="line"><a name="l02270"></a><span class="lineno"> 2270</span>&#160;    assert(feedValIt != reduceOp-&gt;<a class="code" href="classmlir_1_1Operation.html#a9d3b09f8e60b126070e82957d78d9fd0">operand_end</a>() &amp;&amp;</div>
<div class="line"><a name="l02271"></a><span class="lineno"> 2271</span>&#160;           <span class="stringliteral">&quot;Expected a non-block argument operand&quot;</span>);</div>
<div class="line"><a name="l02272"></a><span class="lineno"> 2272</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *feedOp = (*feedValIt).getDefiningOp();</div>
<div class="line"><a name="l02273"></a><span class="lineno"> 2273</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="Vectorization_8cpp.html#a33cb68fa87ea3bda8e98058b464af807">isCastOfBlockArgument</a>(feedOp)) {</div>
<div class="line"><a name="l02274"></a><span class="lineno"> 2274</span>&#160;      <span class="keywordflow">return</span> ConvOperationKind::Pool;</div>
<div class="line"><a name="l02275"></a><span class="lineno"> 2275</span>&#160;    }</div>
<div class="line"><a name="l02276"></a><span class="lineno"> 2276</span>&#160; </div>
<div class="line"><a name="l02277"></a><span class="lineno"> 2277</span>&#160;    <span class="keywordflow">if</span> (!((isa&lt;arith::MulIOp, arith::MulFOp&gt;(feedOp) ||</div>
<div class="line"><a name="l02278"></a><span class="lineno"> 2278</span>&#160;           (isa&lt;arith::AndIOp&gt;(feedOp) &amp;&amp;</div>
<div class="line"><a name="l02279"></a><span class="lineno"> 2279</span>&#160;            feedOp-&gt;<a class="code" href="classmlir_1_1Operation.html#ac3095b4b7756a4974ba1c21b0e8ed762">getResultTypes</a>()[0].isInteger(1))) &amp;&amp;</div>
<div class="line"><a name="l02280"></a><span class="lineno"> 2280</span>&#160;          llvm::all_of(feedOp-&gt;<a class="code" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(), [](<a class="code" href="classmlir_1_1Value.html">Value</a> v) {</div>
<div class="line"><a name="l02281"></a><span class="lineno"> 2281</span>&#160;            if (isa&lt;BlockArgument&gt;(v))</div>
<div class="line"><a name="l02282"></a><span class="lineno"> 2282</span>&#160;              return true;</div>
<div class="line"><a name="l02283"></a><span class="lineno"> 2283</span>&#160;            if (Operation *op = v.getDefiningOp())</div>
<div class="line"><a name="l02284"></a><span class="lineno"> 2284</span>&#160;              return isCastOfBlockArgument(op);</div>
<div class="line"><a name="l02285"></a><span class="lineno"> 2285</span>&#160;            return false;</div>
<div class="line"><a name="l02286"></a><span class="lineno"> 2286</span>&#160;          }))) {</div>
<div class="line"><a name="l02287"></a><span class="lineno"> 2287</span>&#160;      <span class="keywordflow">return</span> std::nullopt;</div>
<div class="line"><a name="l02288"></a><span class="lineno"> 2288</span>&#160;    }</div>
<div class="line"><a name="l02289"></a><span class="lineno"> 2289</span>&#160; </div>
<div class="line"><a name="l02290"></a><span class="lineno"> 2290</span>&#160;    <span class="keywordflow">return</span> ConvOperationKind::Conv;</div>
<div class="line"><a name="l02291"></a><span class="lineno"> 2291</span>&#160;  }</div>
<div class="line"><a name="l02292"></a><span class="lineno"> 2292</span>&#160;  <span class="keywordflow">case</span> 2:</div>
<div class="line"><a name="l02293"></a><span class="lineno"> 2293</span>&#160;    <span class="comment">// Must be pooling</span></div>
<div class="line"><a name="l02294"></a><span class="lineno"> 2294</span>&#160;    <span class="keywordflow">return</span> ConvOperationKind::Pool;</div>
<div class="line"><a name="l02295"></a><span class="lineno"> 2295</span>&#160;  <span class="keywordflow">default</span>:</div>
<div class="line"><a name="l02296"></a><span class="lineno"> 2296</span>&#160;    <span class="keywordflow">return</span> std::nullopt;</div>
<div class="line"><a name="l02297"></a><span class="lineno"> 2297</span>&#160;  }</div>
<div class="line"><a name="l02298"></a><span class="lineno"> 2298</span>&#160;}</div>
<div class="line"><a name="l02299"></a><span class="lineno"> 2299</span>&#160; </div>
<div class="line"><a name="l02300"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a9f962c6d10f2f4f71699143aa472289f"> 2300</a></span>&#160;<span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code" href="Vectorization_8cpp.html#a9f962c6d10f2f4f71699143aa472289f">isSupportedPoolKind</a>(vector::CombiningKind <a class="code" href="LinalgOps_8cpp.html#a28955b1aca39affb65f8316b45796bfa">kind</a>) {</div>
<div class="line"><a name="l02301"></a><span class="lineno"> 2301</span>&#160;  <span class="keywordflow">switch</span> (<a class="code" href="LinalgOps_8cpp.html#a28955b1aca39affb65f8316b45796bfa">kind</a>) {</div>
<div class="line"><a name="l02302"></a><span class="lineno"> 2302</span>&#160;  <span class="keywordflow">case</span> vector::CombiningKind::ADD:</div>
<div class="line"><a name="l02303"></a><span class="lineno"> 2303</span>&#160;  <span class="keywordflow">case</span> vector::CombiningKind::MAXNUMF:</div>
<div class="line"><a name="l02304"></a><span class="lineno"> 2304</span>&#160;  <span class="keywordflow">case</span> vector::CombiningKind::MAXIMUMF:</div>
<div class="line"><a name="l02305"></a><span class="lineno"> 2305</span>&#160;  <span class="keywordflow">case</span> vector::CombiningKind::MAXSI:</div>
<div class="line"><a name="l02306"></a><span class="lineno"> 2306</span>&#160;  <span class="keywordflow">case</span> vector::CombiningKind::MAXUI:</div>
<div class="line"><a name="l02307"></a><span class="lineno"> 2307</span>&#160;  <span class="keywordflow">case</span> vector::CombiningKind::MINNUMF:</div>
<div class="line"><a name="l02308"></a><span class="lineno"> 2308</span>&#160;  <span class="keywordflow">case</span> vector::CombiningKind::MINIMUMF:</div>
<div class="line"><a name="l02309"></a><span class="lineno"> 2309</span>&#160;  <span class="keywordflow">case</span> vector::CombiningKind::MINSI:</div>
<div class="line"><a name="l02310"></a><span class="lineno"> 2310</span>&#160;  <span class="keywordflow">case</span> <a class="code" href="SparseTensorIterator_8cpp.html#ace3cf96892ab9fd15d9e7b6b35044b43">vector::CombiningKind::MINUI</a>:</div>
<div class="line"><a name="l02311"></a><span class="lineno"> 2311</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l02312"></a><span class="lineno"> 2312</span>&#160;  <span class="keywordflow">default</span>:</div>
<div class="line"><a name="l02313"></a><span class="lineno"> 2313</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l02314"></a><span class="lineno"> 2314</span>&#160;  }</div>
<div class="line"><a name="l02315"></a><span class="lineno"> 2315</span>&#160;}</div>
<div class="line"><a name="l02316"></a><span class="lineno"> 2316</span>&#160; </div>
<div class="line"><a name="l02317"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a8c5b389af0339b5680716058382108fc"> 2317</a></span>&#160;<span class="keyword">static</span> LogicalResult <a class="code" href="Vectorization_8cpp.html#a8c5b389af0339b5680716058382108fc">vectorizeConvOpPrecondition</a>(linalg::LinalgOp convOp) {</div>
<div class="line"><a name="l02318"></a><span class="lineno"> 2318</span>&#160;  <span class="keyword">auto</span> getOperandType = [&amp;](<span class="keyword">auto</span> operand) {</div>
<div class="line"><a name="l02319"></a><span class="lineno"> 2319</span>&#160;    <span class="keywordflow">return</span> dyn_cast&lt;ShapedType&gt;((operand-&gt;get()).getType());</div>
<div class="line"><a name="l02320"></a><span class="lineno"> 2320</span>&#160;  };</div>
<div class="line"><a name="l02321"></a><span class="lineno"> 2321</span>&#160;  ShapedType lhsShapedType = getOperandType(convOp.getDpsInputOperand(0));</div>
<div class="line"><a name="l02322"></a><span class="lineno"> 2322</span>&#160;  ShapedType rhsShapedType = getOperandType(convOp.getDpsInputOperand(1));</div>
<div class="line"><a name="l02323"></a><span class="lineno"> 2323</span>&#160;  ShapedType resShapedType = getOperandType(convOp.getDpsInitOperand(0));</div>
<div class="line"><a name="l02324"></a><span class="lineno"> 2324</span>&#160;  <span class="comment">// (LHS has dimension NCW/NWC and RES has dimension NFW/NCW/NWF/NWC) OR</span></div>
<div class="line"><a name="l02325"></a><span class="lineno"> 2325</span>&#160;  <span class="comment">// (non-channeled convolution -&gt; LHS and RHS both have single dimensions).</span></div>
<div class="line"><a name="l02326"></a><span class="lineno"> 2326</span>&#160;  <span class="comment">// Note that this also ensures 2D and 3D convolutions are rejected.</span></div>
<div class="line"><a name="l02327"></a><span class="lineno"> 2327</span>&#160;  <span class="keywordflow">if</span> ((lhsShapedType.getRank() != 3 || resShapedType.getRank() != 3) &amp;&amp;</div>
<div class="line"><a name="l02328"></a><span class="lineno"> 2328</span>&#160;      (lhsShapedType.getRank() != 1 || resShapedType.getRank() != 1))</div>
<div class="line"><a name="l02329"></a><span class="lineno"> 2329</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02330"></a><span class="lineno"> 2330</span>&#160; </div>
<div class="line"><a name="l02331"></a><span class="lineno"> 2331</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *reduceOp = <a class="code" href="Vectorization_8cpp.html#a69cbb7a1a1669d28a2e2f4b221a2132f">matchLinalgReduction</a>(convOp.getDpsInitOperand(0));</div>
<div class="line"><a name="l02332"></a><span class="lineno"> 2332</span>&#160;  <span class="keywordflow">if</span> (!reduceOp)</div>
<div class="line"><a name="l02333"></a><span class="lineno"> 2333</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02334"></a><span class="lineno"> 2334</span>&#160; </div>
<div class="line"><a name="l02335"></a><span class="lineno"> 2335</span>&#160;  <span class="keyword">auto</span> maybeOper = <a class="code" href="Vectorization_8cpp.html#a007245f85f137cf2008229e2a4932915">getConvOperationKind</a>(reduceOp);</div>
<div class="line"><a name="l02336"></a><span class="lineno"> 2336</span>&#160;  <span class="keywordflow">if</span> (!maybeOper.has_value())</div>
<div class="line"><a name="l02337"></a><span class="lineno"> 2337</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02338"></a><span class="lineno"> 2338</span>&#160; </div>
<div class="line"><a name="l02339"></a><span class="lineno"> 2339</span>&#160;  <span class="keyword">auto</span> maybeKind = <a class="code" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp);</div>
<div class="line"><a name="l02340"></a><span class="lineno"> 2340</span>&#160;  <span class="comment">// Typically convolution will have a `Add` CombiningKind but for i1 type it</span></div>
<div class="line"><a name="l02341"></a><span class="lineno"> 2341</span>&#160;  <span class="comment">// can get strength reduced to `OR` which is also supported. This strength</span></div>
<div class="line"><a name="l02342"></a><span class="lineno"> 2342</span>&#160;  <span class="comment">// reduction logic is in `buildBinaryFn` helper in the Linalg dialect.</span></div>
<div class="line"><a name="l02343"></a><span class="lineno"> 2343</span>&#160;  <span class="keywordflow">if</span> (!maybeKind || ((*maybeKind != vector::CombiningKind::ADD &amp;&amp;</div>
<div class="line"><a name="l02344"></a><span class="lineno"> 2344</span>&#160;                      *maybeKind != vector::CombiningKind::OR) &amp;&amp;</div>
<div class="line"><a name="l02345"></a><span class="lineno"> 2345</span>&#160;                     (*maybeOper != ConvOperationKind::Pool ||</div>
<div class="line"><a name="l02346"></a><span class="lineno"> 2346</span>&#160;                      !<a class="code" href="Vectorization_8cpp.html#a9f962c6d10f2f4f71699143aa472289f">isSupportedPoolKind</a>(*maybeKind)))) {</div>
<div class="line"><a name="l02347"></a><span class="lineno"> 2347</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02348"></a><span class="lineno"> 2348</span>&#160;  }</div>
<div class="line"><a name="l02349"></a><span class="lineno"> 2349</span>&#160; </div>
<div class="line"><a name="l02350"></a><span class="lineno"> 2350</span>&#160;  <span class="keyword">auto</span> rhsRank = rhsShapedType.getRank();</div>
<div class="line"><a name="l02351"></a><span class="lineno"> 2351</span>&#160;  <span class="keywordflow">if</span> (*maybeOper == ConvOperationKind::Pool) {</div>
<div class="line"><a name="l02352"></a><span class="lineno"> 2352</span>&#160;    <span class="keywordflow">if</span> (rhsRank != 1)</div>
<div class="line"><a name="l02353"></a><span class="lineno"> 2353</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02354"></a><span class="lineno"> 2354</span>&#160;  } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l02355"></a><span class="lineno"> 2355</span>&#160;    <span class="keywordflow">if</span> (rhsRank != 1 &amp;&amp; rhsRank != 2 &amp;&amp; rhsRank != 3)</div>
<div class="line"><a name="l02356"></a><span class="lineno"> 2356</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02357"></a><span class="lineno"> 2357</span>&#160;  }</div>
<div class="line"><a name="l02358"></a><span class="lineno"> 2358</span>&#160; </div>
<div class="line"><a name="l02359"></a><span class="lineno"> 2359</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02360"></a><span class="lineno"> 2360</span>&#160;}</div>
<div class="line"><a name="l02361"></a><span class="lineno"> 2361</span>&#160; </div>
<div class="line"><a name="l02362"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#acdd38e6c601b328398794c7d9d092b43"> 2362</a></span>&#160;<span class="keyword">static</span> LogicalResult <a class="code" href="Vectorization_8cpp.html#acdd38e6c601b328398794c7d9d092b43">vectorizeLinalgOpPrecondition</a>(</div>
<div class="line"><a name="l02363"></a><span class="lineno"> 2363</span>&#160;    LinalgOp linalgOp, <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l02364"></a><span class="lineno"> 2364</span>&#160;    <span class="keywordtype">bool</span> vectorizeNDExtract, <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a name="l02365"></a><span class="lineno"> 2365</span>&#160;  <span class="comment">// tensor with dimension of 0 cannot be vectorized.</span></div>
<div class="line"><a name="l02366"></a><span class="lineno"> 2366</span>&#160;  <span class="keywordflow">if</span> (llvm::any_of(linalgOp-&gt;getOpOperands(), [&amp;](<a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> &amp;operand) {</div>
<div class="line"><a name="l02367"></a><span class="lineno"> 2367</span>&#160;        return llvm::is_contained(linalgOp.getShape(&amp;operand), 0);</div>
<div class="line"><a name="l02368"></a><span class="lineno"> 2368</span>&#160;      }))</div>
<div class="line"><a name="l02369"></a><span class="lineno"> 2369</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02370"></a><span class="lineno"> 2370</span>&#160;  <span class="comment">// Check API contract for input vector sizes.</span></div>
<div class="line"><a name="l02371"></a><span class="lineno"> 2371</span>&#160;  <span class="keywordflow">if</span> (!inputVectorSizes.empty() &amp;&amp;</div>
<div class="line"><a name="l02372"></a><span class="lineno"> 2372</span>&#160;      failed(<a class="code" href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">vector::isValidMaskedInputVector</a>(linalgOp.getStaticLoopRanges(),</div>
<div class="line"><a name="l02373"></a><span class="lineno"> 2373</span>&#160;                                              inputVectorSizes)))</div>
<div class="line"><a name="l02374"></a><span class="lineno"> 2374</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02375"></a><span class="lineno"> 2375</span>&#160; </div>
<div class="line"><a name="l02376"></a><span class="lineno"> 2376</span>&#160;  <span class="keywordflow">if</span> (linalgOp.hasDynamicShape() &amp;&amp; failed(<a class="code" href="Vectorization_8cpp.html#a9361ccf3f87080ceace5da1af0d2e522">vectorizeDynamicLinalgOpPrecondition</a>(</div>
<div class="line"><a name="l02377"></a><span class="lineno"> 2377</span>&#160;                                        linalgOp, flatten1DDepthwiseConv))) {</div>
<div class="line"><a name="l02378"></a><span class="lineno"> 2378</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Dynamically-shaped op failed vectorization pre-conditions&quot;</span>;</div>
<div class="line"><a name="l02379"></a><span class="lineno"> 2379</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02380"></a><span class="lineno"> 2380</span>&#160;  }</div>
<div class="line"><a name="l02381"></a><span class="lineno"> 2381</span>&#160; </div>
<div class="line"><a name="l02382"></a><span class="lineno"> 2382</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;CustomVectorizationPrecondition&gt;</a> customPreconditions;</div>
<div class="line"><a name="l02383"></a><span class="lineno"> 2383</span>&#160; </div>
<div class="line"><a name="l02384"></a><span class="lineno"> 2384</span>&#160;  <span class="comment">// Register CustomVectorizationPrecondition for extractOp.</span></div>
<div class="line"><a name="l02385"></a><span class="lineno"> 2385</span>&#160;  customPreconditions.push_back(<a class="code" href="Vectorization_8cpp.html#ad09df73d48432e3de8291c7076164ba7">tensorExtractVectorizationPrecondition</a>);</div>
<div class="line"><a name="l02386"></a><span class="lineno"> 2386</span>&#160; </div>
<div class="line"><a name="l02387"></a><span class="lineno"> 2387</span>&#160;  <span class="comment">// All types in the body should be a supported element type for VectorType.</span></div>
<div class="line"><a name="l02388"></a><span class="lineno"> 2388</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1Operation.html">Operation</a> &amp;innerOp : linalgOp-&gt;<a class="code" href="classmlir_1_1Operation.html#aa01ae296df28a63def56ea015dea9929">getRegion</a>(0).<a class="code" href="classmlir_1_1Region.html#ac5f83e51909b69039a7506737b458452">front</a>()) {</div>
<div class="line"><a name="l02389"></a><span class="lineno"> 2389</span>&#160;    <span class="comment">// Check if any custom hook can vectorize the inner op.</span></div>
<div class="line"><a name="l02390"></a><span class="lineno"> 2390</span>&#160;    <span class="keywordflow">if</span> (llvm::any_of(</div>
<div class="line"><a name="l02391"></a><span class="lineno"> 2391</span>&#160;            customPreconditions,</div>
<div class="line"><a name="l02392"></a><span class="lineno"> 2392</span>&#160;            [&amp;](<span class="keyword">const</span> <a class="code" href="Vectorization_8cpp.html#a9b7d2592a2bad4ef2be89bf0d7efd19a">CustomVectorizationPrecondition</a> &amp;customPrecondition) {</div>
<div class="line"><a name="l02393"></a><span class="lineno"> 2393</span>&#160;              <span class="keywordflow">return</span> succeeded(</div>
<div class="line"><a name="l02394"></a><span class="lineno"> 2394</span>&#160;                  customPrecondition(&amp;innerOp, vectorizeNDExtract));</div>
<div class="line"><a name="l02395"></a><span class="lineno"> 2395</span>&#160;            })) {</div>
<div class="line"><a name="l02396"></a><span class="lineno"> 2396</span>&#160;      <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l02397"></a><span class="lineno"> 2397</span>&#160;    }</div>
<div class="line"><a name="l02398"></a><span class="lineno"> 2398</span>&#160;    <span class="keywordflow">if</span> (!llvm::all_of(innerOp.getOperandTypes(),</div>
<div class="line"><a name="l02399"></a><span class="lineno"> 2399</span>&#160;                      VectorType::isValidElementType)) {</div>
<div class="line"><a name="l02400"></a><span class="lineno"> 2400</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02401"></a><span class="lineno"> 2401</span>&#160;    }</div>
<div class="line"><a name="l02402"></a><span class="lineno"> 2402</span>&#160;    <span class="keywordflow">if</span> (!llvm::all_of(innerOp.getResultTypes(),</div>
<div class="line"><a name="l02403"></a><span class="lineno"> 2403</span>&#160;                      VectorType::isValidElementType)) {</div>
<div class="line"><a name="l02404"></a><span class="lineno"> 2404</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02405"></a><span class="lineno"> 2405</span>&#160;    }</div>
<div class="line"><a name="l02406"></a><span class="lineno"> 2406</span>&#160;  }</div>
<div class="line"><a name="l02407"></a><span class="lineno"> 2407</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="namespacemlir_1_1linalg.html#a8b1c347bc995910212c197f9f8728b12">isElementwise</a>(linalgOp))</div>
<div class="line"><a name="l02408"></a><span class="lineno"> 2408</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02409"></a><span class="lineno"> 2409</span>&#160; </div>
<div class="line"><a name="l02410"></a><span class="lineno"> 2410</span>&#160;  <span class="comment">// TODO: isaConvolutionOpInterface that can also infer from generic</span></div>
<div class="line"><a name="l02411"></a><span class="lineno"> 2411</span>&#160;  <span class="comment">// features. But we will still need stride/dilation attributes that will be</span></div>
<div class="line"><a name="l02412"></a><span class="lineno"> 2412</span>&#160;  <span class="comment">// annoying to reverse-engineer...</span></div>
<div class="line"><a name="l02413"></a><span class="lineno"> 2413</span>&#160;  <span class="keywordflow">if</span> (isa&lt;ConvolutionOpInterface&gt;(linalgOp.getOperation()))</div>
<div class="line"><a name="l02414"></a><span class="lineno"> 2414</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a8c5b389af0339b5680716058382108fc">vectorizeConvOpPrecondition</a>(linalgOp);</div>
<div class="line"><a name="l02415"></a><span class="lineno"> 2415</span>&#160; </div>
<div class="line"><a name="l02416"></a><span class="lineno"> 2416</span>&#160;  <span class="comment">// TODO: the common vector shape is equal to the static loop sizes only when</span></div>
<div class="line"><a name="l02417"></a><span class="lineno"> 2417</span>&#160;  <span class="comment">// all indexing maps are projected permutations. For convs and stencils the</span></div>
<div class="line"><a name="l02418"></a><span class="lineno"> 2418</span>&#160;  <span class="comment">// logic will need to evolve.</span></div>
<div class="line"><a name="l02419"></a><span class="lineno"> 2419</span>&#160;  <span class="keywordflow">if</span> (!<a class="code" href="namespacemlir_1_1linalg.html#a1eda2843cbf0dc5507bc64ec67f46f22">allIndexingsAreProjectedPermutation</a>(linalgOp)) {</div>
<div class="line"><a name="l02420"></a><span class="lineno"> 2420</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;precondition failed: not projected permutations&quot;</span>;</div>
<div class="line"><a name="l02421"></a><span class="lineno"> 2421</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02422"></a><span class="lineno"> 2422</span>&#160;  }</div>
<div class="line"><a name="l02423"></a><span class="lineno"> 2423</span>&#160;  <span class="keywordflow">if</span> (failed(<a class="code" href="Vectorization_8cpp.html#a1ee50532663d56946548afe0ff92509c">reductionPreconditions</a>(linalgOp))) {</div>
<div class="line"><a name="l02424"></a><span class="lineno"> 2424</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;precondition failed: reduction preconditions&quot;</span>;</div>
<div class="line"><a name="l02425"></a><span class="lineno"> 2425</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02426"></a><span class="lineno"> 2426</span>&#160;  }</div>
<div class="line"><a name="l02427"></a><span class="lineno"> 2427</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02428"></a><span class="lineno"> 2428</span>&#160;}</div>
<div class="line"><a name="l02429"></a><span class="lineno"> 2429</span>&#160; </div>
<div class="line"><a name="l02430"></a><span class="lineno"> 2430</span>&#160;<span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l02431"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a5445f8ed0f258de115f0d82727780cb3"> 2431</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a5445f8ed0f258de115f0d82727780cb3">vectorizePackOpPrecondition</a>(linalg::PackOp packOp,</div>
<div class="line"><a name="l02432"></a><span class="lineno"> 2432</span>&#160;                            <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes) {</div>
<div class="line"><a name="l02433"></a><span class="lineno"> 2433</span>&#160;  <span class="keyword">auto</span> padValue = packOp.getPaddingValue();</div>
<div class="line"><a name="l02434"></a><span class="lineno"> 2434</span>&#160;  <a class="code" href="classmlir_1_1Attribute.html">Attribute</a> cstAttr;</div>
<div class="line"><a name="l02435"></a><span class="lineno"> 2435</span>&#160;  <span class="keywordflow">if</span> (padValue &amp;&amp; !<a class="code" href="namespacemlir.html#a0190228b09e7b51a4bc1e013c01d404c">matchPattern</a>(padValue, <a class="code" href="namespacemlir.html#ad402a86ee4c9000c6fa1fceaddab560b">m_Constant</a>(&amp;cstAttr))) {</div>
<div class="line"><a name="l02436"></a><span class="lineno"> 2436</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;pad value is not constant: &quot;</span> &lt;&lt; packOp;</div>
<div class="line"><a name="l02437"></a><span class="lineno"> 2437</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02438"></a><span class="lineno"> 2438</span>&#160;  }</div>
<div class="line"><a name="l02439"></a><span class="lineno"> 2439</span>&#160;  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> resultTensorShape = packOp.getDestType().getShape();</div>
<div class="line"><a name="l02440"></a><span class="lineno"> 2440</span>&#160;  <span class="keywordtype">bool</span> satisfyEmptyCond = <span class="keyword">true</span>;</div>
<div class="line"><a name="l02441"></a><span class="lineno"> 2441</span>&#160;  <span class="keywordflow">if</span> (inputVectorSizes.empty()) {</div>
<div class="line"><a name="l02442"></a><span class="lineno"> 2442</span>&#160;    <span class="keywordflow">if</span> (!packOp.getDestType().hasStaticShape() ||</div>
<div class="line"><a name="l02443"></a><span class="lineno"> 2443</span>&#160;        !packOp.getSourceType().hasStaticShape())</div>
<div class="line"><a name="l02444"></a><span class="lineno"> 2444</span>&#160;      satisfyEmptyCond = <span class="keyword">false</span>;</div>
<div class="line"><a name="l02445"></a><span class="lineno"> 2445</span>&#160;  }</div>
<div class="line"><a name="l02446"></a><span class="lineno"> 2446</span>&#160; </div>
<div class="line"><a name="l02447"></a><span class="lineno"> 2447</span>&#160;  <span class="keywordflow">if</span> (!satisfyEmptyCond &amp;&amp;</div>
<div class="line"><a name="l02448"></a><span class="lineno"> 2448</span>&#160;      failed(<a class="code" href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">vector::isValidMaskedInputVector</a>(</div>
<div class="line"><a name="l02449"></a><span class="lineno"> 2449</span>&#160;          resultTensorShape.take_front(packOp.getSourceRank()),</div>
<div class="line"><a name="l02450"></a><span class="lineno"> 2450</span>&#160;          inputVectorSizes)))</div>
<div class="line"><a name="l02451"></a><span class="lineno"> 2451</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02452"></a><span class="lineno"> 2452</span>&#160; </div>
<div class="line"><a name="l02453"></a><span class="lineno"> 2453</span>&#160;  <span class="keywordflow">if</span> (llvm::any_of(packOp.getInnerTiles(), [](<a class="code" href="classmlir_1_1OpFoldResult.html">OpFoldResult</a> v) {</div>
<div class="line"><a name="l02454"></a><span class="lineno"> 2454</span>&#160;        return !getConstantIntValue(v).has_value();</div>
<div class="line"><a name="l02455"></a><span class="lineno"> 2455</span>&#160;      })) {</div>
<div class="line"><a name="l02456"></a><span class="lineno"> 2456</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;inner_tiles must be constant: &quot;</span> &lt;&lt; packOp;</div>
<div class="line"><a name="l02457"></a><span class="lineno"> 2457</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02458"></a><span class="lineno"> 2458</span>&#160;  }</div>
<div class="line"><a name="l02459"></a><span class="lineno"> 2459</span>&#160; </div>
<div class="line"><a name="l02460"></a><span class="lineno"> 2460</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02461"></a><span class="lineno"> 2461</span>&#160;}</div>
<div class="line"><a name="l02462"></a><span class="lineno"> 2462</span>&#160; </div>
<div class="line"><a name="l02463"></a><span class="lineno"> 2463</span>&#160;<span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l02464"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a2d2260cd7405010dc09da594212af829"> 2464</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a2d2260cd7405010dc09da594212af829">vectorizePadOpPrecondition</a>(tensor::PadOp padOp,</div>
<div class="line"><a name="l02465"></a><span class="lineno"> 2465</span>&#160;                           <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes) {</div>
<div class="line"><a name="l02466"></a><span class="lineno"> 2466</span>&#160;  <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a name="l02467"></a><span class="lineno"> 2467</span>&#160;  <span class="keywordflow">if</span> (!padValue) {</div>
<div class="line"><a name="l02468"></a><span class="lineno"> 2468</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;pad value is not constant: &quot;</span> &lt;&lt; padOp;</div>
<div class="line"><a name="l02469"></a><span class="lineno"> 2469</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02470"></a><span class="lineno"> 2470</span>&#160;  }</div>
<div class="line"><a name="l02471"></a><span class="lineno"> 2471</span>&#160; </div>
<div class="line"><a name="l02472"></a><span class="lineno"> 2472</span>&#160;  <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> resultTensorShape = padOp.getResultType().getShape();</div>
<div class="line"><a name="l02473"></a><span class="lineno"> 2473</span>&#160;  <span class="keywordflow">if</span> (failed(<a class="code" href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">vector::isValidMaskedInputVector</a>(resultTensorShape,</div>
<div class="line"><a name="l02474"></a><span class="lineno"> 2474</span>&#160;                                              inputVectorSizes)))</div>
<div class="line"><a name="l02475"></a><span class="lineno"> 2475</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02476"></a><span class="lineno"> 2476</span>&#160; </div>
<div class="line"><a name="l02477"></a><span class="lineno"> 2477</span>&#160;  <span class="comment">// Padding with non-zero low pad values is not supported, unless the</span></div>
<div class="line"><a name="l02478"></a><span class="lineno"> 2478</span>&#160;  <span class="comment">// corresponding result dim is 1 as this would require shifting the results to</span></div>
<div class="line"><a name="l02479"></a><span class="lineno"> 2479</span>&#160;  <span class="comment">// the right for the low padded dims by the required amount of low padding.</span></div>
<div class="line"><a name="l02480"></a><span class="lineno"> 2480</span>&#160;  <span class="comment">// However, we do support low padding if the dims being low padded have result</span></div>
<div class="line"><a name="l02481"></a><span class="lineno"> 2481</span>&#160;  <span class="comment">// sizes of 1. The reason is when we have a low pad on a unit result dim, the</span></div>
<div class="line"><a name="l02482"></a><span class="lineno"> 2482</span>&#160;  <span class="comment">// input size of that dimension will be dynamically zero (as the sum of the</span></div>
<div class="line"><a name="l02483"></a><span class="lineno"> 2483</span>&#160;  <span class="comment">// low pad and input dim size has to be one) and hence we will create a zero</span></div>
<div class="line"><a name="l02484"></a><span class="lineno"> 2484</span>&#160;  <span class="comment">// mask as the lowering logic just makes the mask one for the input dim size -</span></div>
<div class="line"><a name="l02485"></a><span class="lineno"> 2485</span>&#160;  <span class="comment">// which is zero here. Hence we will load the pad value which is what we want</span></div>
<div class="line"><a name="l02486"></a><span class="lineno"> 2486</span>&#160;  <span class="comment">// in this case. If the low pad is dynamically zero then the lowering is</span></div>
<div class="line"><a name="l02487"></a><span class="lineno"> 2487</span>&#160;  <span class="comment">// correct as well as no shifts are necessary.</span></div>
<div class="line"><a name="l02488"></a><span class="lineno"> 2488</span>&#160;  <span class="keywordflow">if</span> (llvm::any_of(<a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">llvm::enumerate</a>(padOp.getLow()), [&amp;](<span class="keyword">const</span> <span class="keyword">auto</span> &amp;en) {</div>
<div class="line"><a name="l02489"></a><span class="lineno"> 2489</span>&#160;        Value padValue = en.value();</div>
<div class="line"><a name="l02490"></a><span class="lineno"> 2490</span>&#160;        unsigned pos = en.index();</div>
<div class="line"><a name="l02491"></a><span class="lineno"> 2491</span>&#160;        std::optional&lt;int64_t&gt; pad = getConstantIntValue(padValue);</div>
<div class="line"><a name="l02492"></a><span class="lineno"> 2492</span>&#160;        return (!pad.has_value() || pad.value() != 0) &amp;&amp;</div>
<div class="line"><a name="l02493"></a><span class="lineno"> 2493</span>&#160;               resultTensorShape[pos] != 1;</div>
<div class="line"><a name="l02494"></a><span class="lineno"> 2494</span>&#160;      })) {</div>
<div class="line"><a name="l02495"></a><span class="lineno"> 2495</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;low pad must all be zero for all non unit dims: &quot;</span> &lt;&lt; padOp;</div>
<div class="line"><a name="l02496"></a><span class="lineno"> 2496</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02497"></a><span class="lineno"> 2497</span>&#160;  }</div>
<div class="line"><a name="l02498"></a><span class="lineno"> 2498</span>&#160; </div>
<div class="line"><a name="l02499"></a><span class="lineno"> 2499</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02500"></a><span class="lineno"> 2500</span>&#160;}</div>
<div class="line"><a name="l02501"></a><span class="lineno"> 2501</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l02502"></a><span class="lineno"> 2502</span>&#160;<span class="comment">/// Preconditions for scalable vectors. This is quite restrictive - it models</span></div>
<div class="line"><a name="l02503"></a><span class="lineno"> 2503</span>&#160;<span class="comment">/// the fact that in practice we would only make selected dimensions scalable.</span></div>
<div class="line"><a name="l02504"></a><span class="lineno"> 2504</span>&#160;<span class="comment"></span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l02505"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#aed76d5bbb8b5413dcba7a1b210d50f7c"> 2505</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#aed76d5bbb8b5413dcba7a1b210d50f7c">vectorizeScalableVectorPrecondition</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op,</div>
<div class="line"><a name="l02506"></a><span class="lineno"> 2506</span>&#160;                                    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l02507"></a><span class="lineno"> 2507</span>&#160;                                    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputScalableVecDims) {</div>
<div class="line"><a name="l02508"></a><span class="lineno"> 2508</span>&#160;  assert(inputVectorSizes.size() == inputScalableVecDims.size() &amp;&amp;</div>
<div class="line"><a name="l02509"></a><span class="lineno"> 2509</span>&#160;         <span class="stringliteral">&quot;Number of input vector sizes and scalable dims doesn&#39;t match&quot;</span>);</div>
<div class="line"><a name="l02510"></a><span class="lineno"> 2510</span>&#160; </div>
<div class="line"><a name="l02511"></a><span class="lineno"> 2511</span>&#160;  <span class="keywordtype">size_t</span> numOfScalableDims =</div>
<div class="line"><a name="l02512"></a><span class="lineno"> 2512</span>&#160;      llvm::count_if(inputScalableVecDims, [](<span class="keywordtype">bool</span> flag) { <span class="keywordflow">return</span> flag; });</div>
<div class="line"><a name="l02513"></a><span class="lineno"> 2513</span>&#160; </div>
<div class="line"><a name="l02514"></a><span class="lineno"> 2514</span>&#160;  <span class="keywordflow">if</span> (numOfScalableDims == 0)</div>
<div class="line"><a name="l02515"></a><span class="lineno"> 2515</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02516"></a><span class="lineno"> 2516</span>&#160; </div>
<div class="line"><a name="l02517"></a><span class="lineno"> 2517</span>&#160;  <span class="keyword">auto</span> linalgOp = dyn_cast&lt;LinalgOp&gt;(op);</div>
<div class="line"><a name="l02518"></a><span class="lineno"> 2518</span>&#160; </div>
<div class="line"><a name="l02519"></a><span class="lineno"> 2519</span>&#160;  <span class="comment">// Cond 1: There&#39;s been no need for scalable vectorisation of</span></div>
<div class="line"><a name="l02520"></a><span class="lineno"> 2520</span>&#160;  <span class="comment">// non-linalg Ops so far</span></div>
<div class="line"><a name="l02521"></a><span class="lineno"> 2521</span>&#160;  <span class="keywordflow">if</span> (!linalgOp)</div>
<div class="line"><a name="l02522"></a><span class="lineno"> 2522</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02523"></a><span class="lineno"> 2523</span>&#160; </div>
<div class="line"><a name="l02524"></a><span class="lineno"> 2524</span>&#160;  <span class="comment">// Cond 2: There&#39;s been no need for more than 2 scalable dims so far</span></div>
<div class="line"><a name="l02525"></a><span class="lineno"> 2525</span>&#160;  <span class="keywordflow">if</span> (numOfScalableDims &gt; 2)</div>
<div class="line"><a name="l02526"></a><span class="lineno"> 2526</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02527"></a><span class="lineno"> 2527</span>&#160; </div>
<div class="line"><a name="l02528"></a><span class="lineno"> 2528</span>&#160;  <span class="comment">// Cond 3: Look at the configuration in `inputScalableVecDims` and verify that</span></div>
<div class="line"><a name="l02529"></a><span class="lineno"> 2529</span>&#160;  <span class="comment">// it matches one of the supported cases:</span></div>
<div class="line"><a name="l02530"></a><span class="lineno"> 2530</span>&#160;  <span class="comment">//  1. Exactly 1 dim is scalable and that&#39;s the _last_ non-unit parallel dim</span></div>
<div class="line"><a name="l02531"></a><span class="lineno"> 2531</span>&#160;  <span class="comment">//    (*).</span></div>
<div class="line"><a name="l02532"></a><span class="lineno"> 2532</span>&#160;  <span class="comment">//  2. Exactly 2 dims are scalable and those are the _last two adjacent_</span></div>
<div class="line"><a name="l02533"></a><span class="lineno"> 2533</span>&#160;  <span class="comment">//     parallel dims.</span></div>
<div class="line"><a name="l02534"></a><span class="lineno"> 2534</span>&#160;  <span class="comment">//  3. Exactly 1 reduction dim is scalable and that&#39;s the last (innermost)</span></div>
<div class="line"><a name="l02535"></a><span class="lineno"> 2535</span>&#160;  <span class="comment">//  dim.</span></div>
<div class="line"><a name="l02536"></a><span class="lineno"> 2536</span>&#160;  <span class="comment">// The 2nd restriction above means that only Matmul-like Ops are supported</span></div>
<div class="line"><a name="l02537"></a><span class="lineno"> 2537</span>&#160;  <span class="comment">// when 2 dims are scalable, e.g. :</span></div>
<div class="line"><a name="l02538"></a><span class="lineno"> 2538</span>&#160;  <span class="comment">//    * iterators = [parallel, parallel, reduction]</span></div>
<div class="line"><a name="l02539"></a><span class="lineno"> 2539</span>&#160;  <span class="comment">//    * scalable flags = [true, true, false]</span></div>
<div class="line"><a name="l02540"></a><span class="lineno"> 2540</span>&#160;  <span class="comment">//</span></div>
<div class="line"><a name="l02541"></a><span class="lineno"> 2541</span>&#160;  <span class="comment">// (*) Non-unit dims get folded away in practice.</span></div>
<div class="line"><a name="l02542"></a><span class="lineno"> 2542</span>&#160;  <span class="comment">// TODO: Relax these conditions as good motivating examples are identified.</span></div>
<div class="line"><a name="l02543"></a><span class="lineno"> 2543</span>&#160; </div>
<div class="line"><a name="l02544"></a><span class="lineno"> 2544</span>&#160;  <span class="comment">// Find the first scalable flag.</span></div>
<div class="line"><a name="l02545"></a><span class="lineno"> 2545</span>&#160;  <span class="keywordtype">bool</span> seenNonUnitParallel = <span class="keyword">false</span>;</div>
<div class="line"><a name="l02546"></a><span class="lineno"> 2546</span>&#160;  <span class="keyword">auto</span> iterators = linalgOp.getIteratorTypesArray();</div>
<div class="line"><a name="l02547"></a><span class="lineno"> 2547</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> scalableFlags(inputScalableVecDims);</div>
<div class="line"><a name="l02548"></a><span class="lineno"> 2548</span>&#160;  int64_t idx = scalableFlags.size() - 1;</div>
<div class="line"><a name="l02549"></a><span class="lineno"> 2549</span>&#160;  <span class="keywordflow">while</span> (!scalableFlags[idx]) {</div>
<div class="line"><a name="l02550"></a><span class="lineno"> 2550</span>&#160;    <span class="keywordtype">bool</span> isNonUnitDim = (inputVectorSizes[idx] != 1);</div>
<div class="line"><a name="l02551"></a><span class="lineno"> 2551</span>&#160;    seenNonUnitParallel |=</div>
<div class="line"><a name="l02552"></a><span class="lineno"> 2552</span>&#160;        (iterators[idx] == utils::IteratorType::parallel &amp;&amp; isNonUnitDim);</div>
<div class="line"><a name="l02553"></a><span class="lineno"> 2553</span>&#160; </div>
<div class="line"><a name="l02554"></a><span class="lineno"> 2554</span>&#160;    iterators.pop_back();</div>
<div class="line"><a name="l02555"></a><span class="lineno"> 2555</span>&#160;    scalableFlags.pop_back();</div>
<div class="line"><a name="l02556"></a><span class="lineno"> 2556</span>&#160;    --idx;</div>
<div class="line"><a name="l02557"></a><span class="lineno"> 2557</span>&#160;  }</div>
<div class="line"><a name="l02558"></a><span class="lineno"> 2558</span>&#160; </div>
<div class="line"><a name="l02559"></a><span class="lineno"> 2559</span>&#160;  <span class="comment">// Analyze the iterator corresponding to the first scalable dim.</span></div>
<div class="line"><a name="l02560"></a><span class="lineno"> 2560</span>&#160;  <span class="keywordflow">switch</span> (iterators.back()) {</div>
<div class="line"><a name="l02561"></a><span class="lineno"> 2561</span>&#160;  <span class="keywordflow">case</span> utils::IteratorType::reduction: {</div>
<div class="line"><a name="l02562"></a><span class="lineno"> 2562</span>&#160;    <span class="comment">// Check 3. above is met.</span></div>
<div class="line"><a name="l02563"></a><span class="lineno"> 2563</span>&#160;    <span class="keywordflow">if</span> (iterators.size() != inputVectorSizes.size()) {</div>
<div class="line"><a name="l02564"></a><span class="lineno"> 2564</span>&#160;      LDBG() &lt;&lt; <span class="stringliteral">&quot;Non-trailing reduction dim requested for scalable &quot;</span></div>
<div class="line"><a name="l02565"></a><span class="lineno"> 2565</span>&#160;                <span class="stringliteral">&quot;vectorization&quot;</span>;</div>
<div class="line"><a name="l02566"></a><span class="lineno"> 2566</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02567"></a><span class="lineno"> 2567</span>&#160;    }</div>
<div class="line"><a name="l02568"></a><span class="lineno"> 2568</span>&#160;    <span class="keywordflow">if</span> (isa&lt;linalg::MatmulOp&gt;(op) || isa&lt;linalg::MatmulTransposeAOp&gt;(op)) {</div>
<div class="line"><a name="l02569"></a><span class="lineno"> 2569</span>&#160;      LDBG()</div>
<div class="line"><a name="l02570"></a><span class="lineno"> 2570</span>&#160;          &lt;&lt; <span class="stringliteral">&quot;Scalable vectorization of the reduction dim in Matmul-like ops &quot;</span></div>
<div class="line"><a name="l02571"></a><span class="lineno"> 2571</span>&#160;             <span class="stringliteral">&quot;is not supported&quot;</span>;</div>
<div class="line"><a name="l02572"></a><span class="lineno"> 2572</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02573"></a><span class="lineno"> 2573</span>&#160;    }</div>
<div class="line"><a name="l02574"></a><span class="lineno"> 2574</span>&#160;    <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l02575"></a><span class="lineno"> 2575</span>&#160;  }</div>
<div class="line"><a name="l02576"></a><span class="lineno"> 2576</span>&#160;  <span class="keywordflow">case</span> utils::IteratorType::parallel: {</div>
<div class="line"><a name="l02577"></a><span class="lineno"> 2577</span>&#160;    <span class="comment">// Check 1. and 2. above are met.</span></div>
<div class="line"><a name="l02578"></a><span class="lineno"> 2578</span>&#160;    <span class="keywordflow">if</span> (seenNonUnitParallel) {</div>
<div class="line"><a name="l02579"></a><span class="lineno"> 2579</span>&#160;      LDBG() &lt;&lt; <span class="stringliteral">&quot;Inner parallel dim not requested for scalable &quot;</span></div>
<div class="line"><a name="l02580"></a><span class="lineno"> 2580</span>&#160;                <span class="stringliteral">&quot;vectorization&quot;</span>;</div>
<div class="line"><a name="l02581"></a><span class="lineno"> 2581</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02582"></a><span class="lineno"> 2582</span>&#160;    }</div>
<div class="line"><a name="l02583"></a><span class="lineno"> 2583</span>&#160;    <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l02584"></a><span class="lineno"> 2584</span>&#160;  }</div>
<div class="line"><a name="l02585"></a><span class="lineno"> 2585</span>&#160;  }</div>
<div class="line"><a name="l02586"></a><span class="lineno"> 2586</span>&#160; </div>
<div class="line"><a name="l02587"></a><span class="lineno"> 2587</span>&#160;  <span class="comment">// If present, check the 2nd scalable dim. ATM, only Matmul-like Ops are</span></div>
<div class="line"><a name="l02588"></a><span class="lineno"> 2588</span>&#160;  <span class="comment">// supported for which expect the folowing config:</span></div>
<div class="line"><a name="l02589"></a><span class="lineno"> 2589</span>&#160;  <span class="comment">//    * iterators = [parallel, parallel, reduction]</span></div>
<div class="line"><a name="l02590"></a><span class="lineno"> 2590</span>&#160;  <span class="comment">//    * scalable flags = [true, true, false]</span></div>
<div class="line"><a name="l02591"></a><span class="lineno"> 2591</span>&#160;  <span class="keywordflow">if</span> (numOfScalableDims == 2) {</div>
<div class="line"><a name="l02592"></a><span class="lineno"> 2592</span>&#160;    <span class="comment">// Disallow below case which breaks 3. above:</span></div>
<div class="line"><a name="l02593"></a><span class="lineno"> 2593</span>&#160;    <span class="comment">//    * iterators = [..., parallel, reduction]</span></div>
<div class="line"><a name="l02594"></a><span class="lineno"> 2594</span>&#160;    <span class="comment">//    * scalable flags = [..., true, true]</span></div>
<div class="line"><a name="l02595"></a><span class="lineno"> 2595</span>&#160;    <span class="keywordflow">if</span> (iterators.back() == utils::IteratorType::reduction) {</div>
<div class="line"><a name="l02596"></a><span class="lineno"> 2596</span>&#160;      LDBG() &lt;&lt; <span class="stringliteral">&quot;Higher dim than the trailing reduction dim requested for &quot;</span></div>
<div class="line"><a name="l02597"></a><span class="lineno"> 2597</span>&#160;                <span class="stringliteral">&quot;scalable &quot;</span></div>
<div class="line"><a name="l02598"></a><span class="lineno"> 2598</span>&#160;                <span class="stringliteral">&quot;vectorizatio&quot;</span>;</div>
<div class="line"><a name="l02599"></a><span class="lineno"> 2599</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02600"></a><span class="lineno"> 2600</span>&#160;    }</div>
<div class="line"><a name="l02601"></a><span class="lineno"> 2601</span>&#160;    scalableFlags.pop_back();</div>
<div class="line"><a name="l02602"></a><span class="lineno"> 2602</span>&#160;    iterators.pop_back();</div>
<div class="line"><a name="l02603"></a><span class="lineno"> 2603</span>&#160; </div>
<div class="line"><a name="l02604"></a><span class="lineno"> 2604</span>&#160;    <span class="keywordflow">if</span> (!scalableFlags.back() ||</div>
<div class="line"><a name="l02605"></a><span class="lineno"> 2605</span>&#160;        (iterators.back() != utils::IteratorType::parallel))</div>
<div class="line"><a name="l02606"></a><span class="lineno"> 2606</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02607"></a><span class="lineno"> 2607</span>&#160;  }</div>
<div class="line"><a name="l02608"></a><span class="lineno"> 2608</span>&#160; </div>
<div class="line"><a name="l02609"></a><span class="lineno"> 2609</span>&#160;  <span class="comment">// Check to not let go the matmul with extended semantic, through this</span></div>
<div class="line"><a name="l02610"></a><span class="lineno"> 2610</span>&#160;  <span class="comment">// transform.</span></div>
<div class="line"><a name="l02611"></a><span class="lineno"> 2611</span>&#160;  <span class="keywordflow">if</span> (linalgOp.hasUserDefinedMaps())</div>
<div class="line"><a name="l02612"></a><span class="lineno"> 2612</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02613"></a><span class="lineno"> 2613</span>&#160; </div>
<div class="line"><a name="l02614"></a><span class="lineno"> 2614</span>&#160;  <span class="comment">// Cond 4: Only the following ops are supported in the</span></div>
<div class="line"><a name="l02615"></a><span class="lineno"> 2615</span>&#160;  <span class="comment">// presence of scalable vectors</span></div>
<div class="line"><a name="l02616"></a><span class="lineno"> 2616</span>&#160;  <span class="keywordflow">return</span> success(<a class="code" href="namespacemlir_1_1linalg.html#a8b1c347bc995910212c197f9f8728b12">isElementwise</a>(linalgOp) || isa&lt;linalg::MatmulOp&gt;(op) ||</div>
<div class="line"><a name="l02617"></a><span class="lineno"> 2617</span>&#160;                 isa&lt;linalg::MatmulTransposeAOp&gt;(op) ||</div>
<div class="line"><a name="l02618"></a><span class="lineno"> 2618</span>&#160;                 isa&lt;linalg::DepthwiseConv1DNwcWcOp&gt;(op) ||</div>
<div class="line"><a name="l02619"></a><span class="lineno"> 2619</span>&#160;                 isa&lt;linalg::MatvecOp&gt;(op) || isa&lt;linalg::Mmt4DOp&gt;(op) ||</div>
<div class="line"><a name="l02620"></a><span class="lineno"> 2620</span>&#160;                 <a class="code" href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">hasReductionIterator</a>(linalgOp));</div>
<div class="line"><a name="l02621"></a><span class="lineno"> 2621</span>&#160;}</div>
<div class="line"><a name="l02622"></a><span class="lineno"> 2622</span>&#160; </div>
<div class="line"><a name="l02623"></a><span class="lineno"><a class="line" href="namespacemlir_1_1linalg.html#a8d0310adee4f127279f9147a71db0181"> 2623</a></span>&#160;LogicalResult <a class="code" href="namespacemlir_1_1linalg.html#a8d0310adee4f127279f9147a71db0181">mlir::linalg::vectorizeOpPrecondition</a>(</div>
<div class="line"><a name="l02624"></a><span class="lineno"> 2624</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *op, <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l02625"></a><span class="lineno"> 2625</span>&#160;    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputScalableVecDims, <span class="keywordtype">bool</span> vectorizeNDExtract,</div>
<div class="line"><a name="l02626"></a><span class="lineno"> 2626</span>&#160;    <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a name="l02627"></a><span class="lineno"> 2627</span>&#160; </div>
<div class="line"><a name="l02628"></a><span class="lineno"> 2628</span>&#160;  <span class="keywordflow">if</span> (!<a class="code" href="namespacemlir_1_1linalg.html#a142a09c03dbaa0d795e44f62d4b6b395">hasVectorizationImpl</a>(op))</div>
<div class="line"><a name="l02629"></a><span class="lineno"> 2629</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02630"></a><span class="lineno"> 2630</span>&#160; </div>
<div class="line"><a name="l02631"></a><span class="lineno"> 2631</span>&#160;  <span class="keywordflow">if</span> (failed(<a class="code" href="Vectorization_8cpp.html#aed76d5bbb8b5413dcba7a1b210d50f7c">vectorizeScalableVectorPrecondition</a>(op, inputVectorSizes,</div>
<div class="line"><a name="l02632"></a><span class="lineno"> 2632</span>&#160;                                                 inputScalableVecDims)))</div>
<div class="line"><a name="l02633"></a><span class="lineno"> 2633</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02634"></a><span class="lineno"> 2634</span>&#160; </div>
<div class="line"><a name="l02635"></a><span class="lineno"> 2635</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classllvm_1_1TypeSwitch.html">TypeSwitch&lt;Operation *, LogicalResult&gt;</a>(op)</div>
<div class="line"><a name="l02636"></a><span class="lineno"> 2636</span>&#160;      .Case&lt;linalg::LinalgOp&gt;([&amp;](<span class="keyword">auto</span> linalgOp) {</div>
<div class="line"><a name="l02637"></a><span class="lineno"> 2637</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#acdd38e6c601b328398794c7d9d092b43">vectorizeLinalgOpPrecondition</a>(linalgOp, inputVectorSizes,</div>
<div class="line"><a name="l02638"></a><span class="lineno"> 2638</span>&#160;                                             vectorizeNDExtract,</div>
<div class="line"><a name="l02639"></a><span class="lineno"> 2639</span>&#160;                                             flatten1DDepthwiseConv);</div>
<div class="line"><a name="l02640"></a><span class="lineno"> 2640</span>&#160;      })</div>
<div class="line"><a name="l02641"></a><span class="lineno"> 2641</span>&#160;      .Case&lt;tensor::PadOp&gt;([&amp;](<span class="keyword">auto</span> padOp) {</div>
<div class="line"><a name="l02642"></a><span class="lineno"> 2642</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a2d2260cd7405010dc09da594212af829">vectorizePadOpPrecondition</a>(padOp, inputVectorSizes);</div>
<div class="line"><a name="l02643"></a><span class="lineno"> 2643</span>&#160;      })</div>
<div class="line"><a name="l02644"></a><span class="lineno"> 2644</span>&#160;      .Case&lt;linalg::PackOp&gt;([&amp;](<span class="keyword">auto</span> packOp) {</div>
<div class="line"><a name="l02645"></a><span class="lineno"> 2645</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a5445f8ed0f258de115f0d82727780cb3">vectorizePackOpPrecondition</a>(packOp, inputVectorSizes);</div>
<div class="line"><a name="l02646"></a><span class="lineno"> 2646</span>&#160;      })</div>
<div class="line"><a name="l02647"></a><span class="lineno"> 2647</span>&#160;      .Case&lt;linalg::UnPackOp&gt;([&amp;](<span class="keyword">auto</span> unpackOp) {</div>
<div class="line"><a name="l02648"></a><span class="lineno"> 2648</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#af7adb8d1e2203f372dfc75ab40903520">vectorizeUnPackOpPrecondition</a>(unpackOp, inputVectorSizes);</div>
<div class="line"><a name="l02649"></a><span class="lineno"> 2649</span>&#160;      })</div>
<div class="line"><a name="l02650"></a><span class="lineno"> 2650</span>&#160;      .Case&lt;tensor::InsertSliceOp&gt;([&amp;](<span class="keyword">auto</span> sliceOp) {</div>
<div class="line"><a name="l02651"></a><span class="lineno"> 2651</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#ab6ce64f69fae16d29646e68dab583d58">vectorizeInsertSliceOpPrecondition</a>(sliceOp, inputVectorSizes);</div>
<div class="line"><a name="l02652"></a><span class="lineno"> 2652</span>&#160;      })</div>
<div class="line"><a name="l02653"></a><span class="lineno"> 2653</span>&#160;      .Default([](<span class="keyword">auto</span>) { <span class="keywordflow">return</span> failure(); });</div>
<div class="line"><a name="l02654"></a><span class="lineno"> 2654</span>&#160;}</div>
<div class="line"><a name="l02655"></a><span class="lineno"> 2655</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l02656"></a><span class="lineno"> 2656</span>&#160;<span class="comment">/// Converts affine.apply Ops to arithmetic operations.</span></div>
<div class="line"><a name="l02657"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#aab700681cb96772dbfd106a67ec408af"> 2657</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="Vectorization_8cpp.html#aab700681cb96772dbfd106a67ec408af">convertAffineApply</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, LinalgOp linalgOp) {</div>
<div class="line"><a name="l02658"></a><span class="lineno"> 2658</span>&#160;  <a class="code" href="classmlir_1_1OpBuilder_1_1InsertionGuard.html">OpBuilder::InsertionGuard</a> g(rewriter);</div>
<div class="line"><a name="l02659"></a><span class="lineno"> 2659</span>&#160;  <span class="keyword">auto</span> toReplace = linalgOp.getBlock()-&gt;getOps&lt;affine::AffineApplyOp&gt;();</div>
<div class="line"><a name="l02660"></a><span class="lineno"> 2660</span>&#160; </div>
<div class="line"><a name="l02661"></a><span class="lineno"> 2661</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> op : make_early_inc_range(toReplace)) {</div>
<div class="line"><a name="l02662"></a><span class="lineno"> 2662</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(op);</div>
<div class="line"><a name="l02663"></a><span class="lineno"> 2663</span>&#160;    <span class="keyword">auto</span> expanded = <a class="code" href="namespacemlir_1_1affine.html#a39d426a50bbe0eea58b951870ad90c2c">affine::expandAffineExpr</a>(</div>
<div class="line"><a name="l02664"></a><span class="lineno"> 2664</span>&#160;        rewriter, op-&gt;getLoc(), op.getAffineMap().getResult(0),</div>
<div class="line"><a name="l02665"></a><span class="lineno"> 2665</span>&#160;        op.getOperands().take_front(op.getAffineMap().getNumDims()),</div>
<div class="line"><a name="l02666"></a><span class="lineno"> 2666</span>&#160;        op.getOperands().take_back(op.getAffineMap().getNumSymbols()));</div>
<div class="line"><a name="l02667"></a><span class="lineno"> 2667</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(op, expanded);</div>
<div class="line"><a name="l02668"></a><span class="lineno"> 2668</span>&#160;  }</div>
<div class="line"><a name="l02669"></a><span class="lineno"> 2669</span>&#160;}</div>
<div class="line"><a name="l02670"></a><span class="lineno"> 2670</span>&#160; </div>
<div class="line"><a name="l02671"></a><span class="lineno"><a class="line" href="namespacemlir_1_1linalg.html#a142a09c03dbaa0d795e44f62d4b6b395"> 2671</a></span>&#160;<span class="keywordtype">bool</span> <a class="code" href="namespacemlir_1_1linalg.html#a142a09c03dbaa0d795e44f62d4b6b395">mlir::linalg::hasVectorizationImpl</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op) {</div>
<div class="line"><a name="l02672"></a><span class="lineno"> 2672</span>&#160;  <span class="keywordflow">return</span> isa&lt;linalg::LinalgOp, tensor::PadOp, linalg::PackOp, linalg::UnPackOp,</div>
<div class="line"><a name="l02673"></a><span class="lineno"> 2673</span>&#160;             tensor::InsertSliceOp&gt;(op);</div>
<div class="line"><a name="l02674"></a><span class="lineno"> 2674</span>&#160;}</div>
<div class="line"><a name="l02675"></a><span class="lineno"> 2675</span>&#160; </div>
<div class="line"><a name="l02676"></a><span class="lineno"><a class="line" href="namespacemlir_1_1linalg.html#a303bb59c046a82276569e6b906002997"> 2676</a></span>&#160;FailureOr&lt;VectorizationResult&gt; <a class="code" href="namespacemlir_1_1linalg.html#a303bb59c046a82276569e6b906002997">mlir::linalg::vectorize</a>(</div>
<div class="line"><a name="l02677"></a><span class="lineno"> 2677</span>&#160;    <a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *op, <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l02678"></a><span class="lineno"> 2678</span>&#160;    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputScalableVecDims, <span class="keywordtype">bool</span> vectorizeNDExtract,</div>
<div class="line"><a name="l02679"></a><span class="lineno"> 2679</span>&#160;    <span class="keywordtype">bool</span> flatten1DDepthwiseConv, <span class="keywordtype">bool</span> assumeDynamicDimsMatchVecSizes,</div>
<div class="line"><a name="l02680"></a><span class="lineno"> 2680</span>&#160;    <span class="keywordtype">bool</span> createNamedContraction) {</div>
<div class="line"><a name="l02681"></a><span class="lineno"> 2681</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Attempting to vectorize: &quot;</span> &lt;&lt; *op;</div>
<div class="line"><a name="l02682"></a><span class="lineno"> 2682</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Input vector sizes: &quot;</span> &lt;&lt; llvm::interleaved(inputVectorSizes);</div>
<div class="line"><a name="l02683"></a><span class="lineno"> 2683</span>&#160;  LDBG() &lt;&lt; <span class="stringliteral">&quot;Input scalable vector dims: &quot;</span></div>
<div class="line"><a name="l02684"></a><span class="lineno"> 2684</span>&#160;         &lt;&lt; llvm::interleaved(inputScalableVecDims);</div>
<div class="line"><a name="l02685"></a><span class="lineno"> 2685</span>&#160; </div>
<div class="line"><a name="l02686"></a><span class="lineno"> 2686</span>&#160;  <span class="keywordflow">if</span> (failed(<a class="code" href="namespacemlir_1_1linalg.html#a8d0310adee4f127279f9147a71db0181">vectorizeOpPrecondition</a>(op, inputVectorSizes, inputScalableVecDims,</div>
<div class="line"><a name="l02687"></a><span class="lineno"> 2687</span>&#160;                                     vectorizeNDExtract,</div>
<div class="line"><a name="l02688"></a><span class="lineno"> 2688</span>&#160;                                     flatten1DDepthwiseConv))) {</div>
<div class="line"><a name="l02689"></a><span class="lineno"> 2689</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorization pre-conditions failed&quot;</span>;</div>
<div class="line"><a name="l02690"></a><span class="lineno"> 2690</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02691"></a><span class="lineno"> 2691</span>&#160;  }</div>
<div class="line"><a name="l02692"></a><span class="lineno"> 2692</span>&#160; </div>
<div class="line"><a name="l02693"></a><span class="lineno"> 2693</span>&#160;  <span class="comment">// Initialize vectorization state.</span></div>
<div class="line"><a name="l02694"></a><span class="lineno"> 2694</span>&#160;  <a class="code" href="structVectorizationState.html">VectorizationState</a> state(rewriter);</div>
<div class="line"><a name="l02695"></a><span class="lineno"> 2695</span>&#160;  <span class="keywordflow">if</span> (<span class="keyword">auto</span> linalgOp = dyn_cast&lt;linalg::LinalgOp&gt;(op)) {</div>
<div class="line"><a name="l02696"></a><span class="lineno"> 2696</span>&#160;    <span class="keywordflow">if</span> (failed(state.initState(rewriter, linalgOp, inputVectorSizes,</div>
<div class="line"><a name="l02697"></a><span class="lineno"> 2697</span>&#160;                               inputScalableVecDims,</div>
<div class="line"><a name="l02698"></a><span class="lineno"> 2698</span>&#160;                               assumeDynamicDimsMatchVecSizes))) {</div>
<div class="line"><a name="l02699"></a><span class="lineno"> 2699</span>&#160;      LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorization state couldn&#39;t be initialized&quot;</span>;</div>
<div class="line"><a name="l02700"></a><span class="lineno"> 2700</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02701"></a><span class="lineno"> 2701</span>&#160;    }</div>
<div class="line"><a name="l02702"></a><span class="lineno"> 2702</span>&#160;  }</div>
<div class="line"><a name="l02703"></a><span class="lineno"> 2703</span>&#160; </div>
<div class="line"><a name="l02704"></a><span class="lineno"> 2704</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> results;</div>
<div class="line"><a name="l02705"></a><span class="lineno"> 2705</span>&#160;  <span class="keyword">auto</span> vectorizeResult =</div>
<div class="line"><a name="l02706"></a><span class="lineno"> 2706</span>&#160;      <a class="code" href="classllvm_1_1TypeSwitch.html">TypeSwitch&lt;Operation *, LogicalResult&gt;</a>(op)</div>
<div class="line"><a name="l02707"></a><span class="lineno"> 2707</span>&#160;          .Case&lt;linalg::LinalgOp&gt;([&amp;](<span class="keyword">auto</span> linalgOp) {</div>
<div class="line"><a name="l02708"></a><span class="lineno"> 2708</span>&#160;            <span class="comment">// TODO: isaConvolutionOpInterface that can also infer from</span></div>
<div class="line"><a name="l02709"></a><span class="lineno"> 2709</span>&#160;            <span class="comment">// generic features. Will require stride/dilation attributes</span></div>
<div class="line"><a name="l02710"></a><span class="lineno"> 2710</span>&#160;            <span class="comment">// inference.</span></div>
<div class="line"><a name="l02711"></a><span class="lineno"> 2711</span>&#160;            <span class="keywordflow">if</span> (isa&lt;ConvolutionOpInterface&gt;(linalgOp.getOperation())) {</div>
<div class="line"><a name="l02712"></a><span class="lineno"> 2712</span>&#160;              FailureOr&lt;Operation *&gt; convOr = <a class="code" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a>(</div>
<div class="line"><a name="l02713"></a><span class="lineno"> 2713</span>&#160;                  rewriter, linalgOp, inputVectorSizes, inputScalableVecDims,</div>
<div class="line"><a name="l02714"></a><span class="lineno"> 2714</span>&#160;                  flatten1DDepthwiseConv);</div>
<div class="line"><a name="l02715"></a><span class="lineno"> 2715</span>&#160;              <span class="keywordflow">if</span> (succeeded(convOr)) {</div>
<div class="line"><a name="l02716"></a><span class="lineno"> 2716</span>&#160;                llvm::append_range(results, (*convOr)-&gt;getResults());</div>
<div class="line"><a name="l02717"></a><span class="lineno"> 2717</span>&#160;                <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02718"></a><span class="lineno"> 2718</span>&#160;              }</div>
<div class="line"><a name="l02719"></a><span class="lineno"> 2719</span>&#160; </div>
<div class="line"><a name="l02720"></a><span class="lineno"> 2720</span>&#160;              LDBG() &lt;&lt; <span class="stringliteral">&quot;Unsupported convolution can&#39;t be vectorized.&quot;</span>;</div>
<div class="line"><a name="l02721"></a><span class="lineno"> 2721</span>&#160;              <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02722"></a><span class="lineno"> 2722</span>&#160;            }</div>
<div class="line"><a name="l02723"></a><span class="lineno"> 2723</span>&#160; </div>
<div class="line"><a name="l02724"></a><span class="lineno"> 2724</span>&#160;            <span class="keywordflow">if</span> (createNamedContraction &amp;&amp;</div>
<div class="line"><a name="l02725"></a><span class="lineno"> 2725</span>&#160;                isa&lt;ContractionOpInterface&gt;(linalgOp.getOperation()))</div>
<div class="line"><a name="l02726"></a><span class="lineno"> 2726</span>&#160;              <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a9936412c5d68fa78d0d1998d6af2219f">vectorizeAsLinalgContraction</a>(rewriter, state, linalgOp,</div>
<div class="line"><a name="l02727"></a><span class="lineno"> 2727</span>&#160;                                                  results);</div>
<div class="line"><a name="l02728"></a><span class="lineno"> 2728</span>&#160; </div>
<div class="line"><a name="l02729"></a><span class="lineno"> 2729</span>&#160;            LDBG()</div>
<div class="line"><a name="l02730"></a><span class="lineno"> 2730</span>&#160;                &lt;&lt; <span class="stringliteral">&quot;Vectorize generic by broadcasting to the canonical vector &quot;</span></div>
<div class="line"><a name="l02731"></a><span class="lineno"> 2731</span>&#160;                   <span class="stringliteral">&quot;shape&quot;</span>;</div>
<div class="line"><a name="l02732"></a><span class="lineno"> 2732</span>&#160; </div>
<div class="line"><a name="l02733"></a><span class="lineno"> 2733</span>&#160;            <span class="comment">// Pre-process before proceeding.</span></div>
<div class="line"><a name="l02734"></a><span class="lineno"> 2734</span>&#160;            <a class="code" href="Vectorization_8cpp.html#aab700681cb96772dbfd106a67ec408af">convertAffineApply</a>(rewriter, linalgOp);</div>
<div class="line"><a name="l02735"></a><span class="lineno"> 2735</span>&#160; </div>
<div class="line"><a name="l02736"></a><span class="lineno"> 2736</span>&#160;            <span class="comment">// TODO: &#39;vectorize&#39; takes in a &#39;RewriterBase&#39; which is up-casted</span></div>
<div class="line"><a name="l02737"></a><span class="lineno"> 2737</span>&#160;            <span class="comment">// to &#39;OpBuilder&#39; when it is passed over to some methods like</span></div>
<div class="line"><a name="l02738"></a><span class="lineno"> 2738</span>&#160;            <span class="comment">// &#39;vectorizeAsLinalgGeneric&#39;. This is highly problematic: if we</span></div>
<div class="line"><a name="l02739"></a><span class="lineno"> 2739</span>&#160;            <span class="comment">// erase an op within these methods, the actual rewriter won&#39;t be</span></div>
<div class="line"><a name="l02740"></a><span class="lineno"> 2740</span>&#160;            <span class="comment">// notified and we will end up with read-after-free issues!</span></div>
<div class="line"><a name="l02741"></a><span class="lineno"> 2741</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a35e1ec347850959af0bc7cbdf61b9da3">vectorizeAsLinalgGeneric</a>(rewriter, state, linalgOp, results);</div>
<div class="line"><a name="l02742"></a><span class="lineno"> 2742</span>&#160;          })</div>
<div class="line"><a name="l02743"></a><span class="lineno"> 2743</span>&#160;          .Case&lt;tensor::PadOp&gt;([&amp;](<span class="keyword">auto</span> padOp) {</div>
<div class="line"><a name="l02744"></a><span class="lineno"> 2744</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#af8d343eff4117b4738a97dea5eb4d4bd">vectorizeAsTensorPadOp</a>(rewriter, padOp, inputVectorSizes,</div>
<div class="line"><a name="l02745"></a><span class="lineno"> 2745</span>&#160;                                          results);</div>
<div class="line"><a name="l02746"></a><span class="lineno"> 2746</span>&#160;          })</div>
<div class="line"><a name="l02747"></a><span class="lineno"> 2747</span>&#160;          .Case&lt;linalg::PackOp&gt;([&amp;](<span class="keyword">auto</span> packOp) {</div>
<div class="line"><a name="l02748"></a><span class="lineno"> 2748</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a042126c1ec44e80d376fb8e5baa1efd0">vectorizeAsTensorPackOp</a>(rewriter, packOp, inputVectorSizes,</div>
<div class="line"><a name="l02749"></a><span class="lineno"> 2749</span>&#160;                                           results);</div>
<div class="line"><a name="l02750"></a><span class="lineno"> 2750</span>&#160;          })</div>
<div class="line"><a name="l02751"></a><span class="lineno"> 2751</span>&#160;          .Case&lt;linalg::UnPackOp&gt;([&amp;](<span class="keyword">auto</span> unpackOp) {</div>
<div class="line"><a name="l02752"></a><span class="lineno"> 2752</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a026c54c12deb9d84b6fc83be82d1c183">vectorizeAsTensorUnpackOp</a>(rewriter, unpackOp,</div>
<div class="line"><a name="l02753"></a><span class="lineno"> 2753</span>&#160;                                             inputVectorSizes, results);</div>
<div class="line"><a name="l02754"></a><span class="lineno"> 2754</span>&#160;          })</div>
<div class="line"><a name="l02755"></a><span class="lineno"> 2755</span>&#160;          .Case&lt;tensor::InsertSliceOp&gt;([&amp;](<span class="keyword">auto</span> sliceOp) {</div>
<div class="line"><a name="l02756"></a><span class="lineno"> 2756</span>&#160;            <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926">vectorizeAsInsertSliceOp</a>(rewriter, sliceOp, inputVectorSizes,</div>
<div class="line"><a name="l02757"></a><span class="lineno"> 2757</span>&#160;                                            results);</div>
<div class="line"><a name="l02758"></a><span class="lineno"> 2758</span>&#160;          })</div>
<div class="line"><a name="l02759"></a><span class="lineno"> 2759</span>&#160;          .Default([](<span class="keyword">auto</span>) { <span class="keywordflow">return</span> failure(); });</div>
<div class="line"><a name="l02760"></a><span class="lineno"> 2760</span>&#160; </div>
<div class="line"><a name="l02761"></a><span class="lineno"> 2761</span>&#160;  <span class="keywordflow">if</span> (failed(vectorizeResult)) {</div>
<div class="line"><a name="l02762"></a><span class="lineno"> 2762</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorization failed&quot;</span>;</div>
<div class="line"><a name="l02763"></a><span class="lineno"> 2763</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02764"></a><span class="lineno"> 2764</span>&#160;  }</div>
<div class="line"><a name="l02765"></a><span class="lineno"> 2765</span>&#160; </div>
<div class="line"><a name="l02766"></a><span class="lineno"> 2766</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="structmlir_1_1linalg_1_1VectorizationResult.html">VectorizationResult</a>{results};</div>
<div class="line"><a name="l02767"></a><span class="lineno"> 2767</span>&#160;}</div>
<div class="line"><a name="l02768"></a><span class="lineno"> 2768</span>&#160; </div>
<div class="line"><a name="l02769"></a><span class="lineno"><a class="line" href="namespacemlir_1_1linalg.html#a8c63bc9239511b70751c238a12f5b1da"> 2769</a></span>&#160;LogicalResult <a class="code" href="namespacemlir_1_1linalg.html#a8c63bc9239511b70751c238a12f5b1da">mlir::linalg::vectorizeCopy</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a name="l02770"></a><span class="lineno"> 2770</span>&#160;                                          memref::CopyOp copyOp) {</div>
<div class="line"><a name="l02771"></a><span class="lineno"> 2771</span>&#160;  <span class="keyword">auto</span> srcType = cast&lt;MemRefType&gt;(copyOp.getSource().getType());</div>
<div class="line"><a name="l02772"></a><span class="lineno"> 2772</span>&#160;  <span class="keyword">auto</span> dstType = cast&lt;MemRefType&gt;(copyOp.getTarget().getType());</div>
<div class="line"><a name="l02773"></a><span class="lineno"> 2773</span>&#160;  <span class="keywordflow">if</span> (!srcType.hasStaticShape() || !dstType.hasStaticShape())</div>
<div class="line"><a name="l02774"></a><span class="lineno"> 2774</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02775"></a><span class="lineno"> 2775</span>&#160; </div>
<div class="line"><a name="l02776"></a><span class="lineno"> 2776</span>&#160;  <span class="keyword">auto</span> srcElementType = <a class="code" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(srcType);</div>
<div class="line"><a name="l02777"></a><span class="lineno"> 2777</span>&#160;  <span class="keyword">auto</span> dstElementType = <a class="code" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(dstType);</div>
<div class="line"><a name="l02778"></a><span class="lineno"> 2778</span>&#160;  <span class="keywordflow">if</span> (!VectorType::isValidElementType(srcElementType) ||</div>
<div class="line"><a name="l02779"></a><span class="lineno"> 2779</span>&#160;      !VectorType::isValidElementType(dstElementType))</div>
<div class="line"><a name="l02780"></a><span class="lineno"> 2780</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02781"></a><span class="lineno"> 2781</span>&#160; </div>
<div class="line"><a name="l02782"></a><span class="lineno"> 2782</span>&#160;  <span class="keyword">auto</span> readType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(srcType.getShape(), srcElementType);</div>
<div class="line"><a name="l02783"></a><span class="lineno"> 2783</span>&#160;  <span class="keyword">auto</span> writeType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(dstType.getShape(), dstElementType);</div>
<div class="line"><a name="l02784"></a><span class="lineno"> 2784</span>&#160; </div>
<div class="line"><a name="l02785"></a><span class="lineno"> 2785</span>&#160;  <a class="code" href="classmlir_1_1Location.html">Location</a> loc = copyOp-&gt;getLoc();</div>
<div class="line"><a name="l02786"></a><span class="lineno"> 2786</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> zero = <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0);</div>
<div class="line"><a name="l02787"></a><span class="lineno"> 2787</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> indices(srcType.getRank(), zero);</div>
<div class="line"><a name="l02788"></a><span class="lineno"> 2788</span>&#160; </div>
<div class="line"><a name="l02789"></a><span class="lineno"> 2789</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a> = vector::TransferReadOp::create(</div>
<div class="line"><a name="l02790"></a><span class="lineno"> 2790</span>&#160;      rewriter, loc, readType, copyOp.getSource(), indices,</div>
<div class="line"><a name="l02791"></a><span class="lineno"> 2791</span>&#160;      <span class="comment">/*padding=*/</span>std::nullopt,</div>
<div class="line"><a name="l02792"></a><span class="lineno"> 2792</span>&#160;      rewriter.<a class="code" href="classmlir_1_1Builder.html#a422a9ab33af4134efcb4044fb81deab1">getMultiDimIdentityMap</a>(srcType.getRank()));</div>
<div class="line"><a name="l02793"></a><span class="lineno"> 2793</span>&#160;  <span class="keywordflow">if</span> (cast&lt;VectorType&gt;(<a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a>.getType()).getRank() == 0) {</div>
<div class="line"><a name="l02794"></a><span class="lineno"> 2794</span>&#160;    <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a> = vector::ExtractOp::create(rewriter, loc, <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a>,</div>
<div class="line"><a name="l02795"></a><span class="lineno"> 2795</span>&#160;                                          <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>());</div>
<div class="line"><a name="l02796"></a><span class="lineno"> 2796</span>&#160;    <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a> =</div>
<div class="line"><a name="l02797"></a><span class="lineno"> 2797</span>&#160;        vector::BroadcastOp::create(rewriter, loc, writeType, <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a>);</div>
<div class="line"><a name="l02798"></a><span class="lineno"> 2798</span>&#160;  }</div>
<div class="line"><a name="l02799"></a><span class="lineno"> 2799</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *writeValue = vector::TransferWriteOp::create(</div>
<div class="line"><a name="l02800"></a><span class="lineno"> 2800</span>&#160;      rewriter, loc, <a class="code" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">readValue</a>, copyOp.getTarget(), indices,</div>
<div class="line"><a name="l02801"></a><span class="lineno"> 2801</span>&#160;      rewriter.<a class="code" href="classmlir_1_1Builder.html#a422a9ab33af4134efcb4044fb81deab1">getMultiDimIdentityMap</a>(srcType.getRank()));</div>
<div class="line"><a name="l02802"></a><span class="lineno"> 2802</span>&#160;  rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(copyOp, writeValue-&gt;<a class="code" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>());</div>
<div class="line"><a name="l02803"></a><span class="lineno"> 2803</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02804"></a><span class="lineno"> 2804</span>&#160;}</div>
<div class="line"><a name="l02805"></a><span class="lineno"> 2805</span>&#160; </div>
<div class="line"><a name="l02806"></a><span class="lineno"> 2806</span>&#160;<span class="comment">//----------------------------------------------------------------------------//</span></div>
<div class="line"><a name="l02807"></a><span class="lineno"> 2807</span>&#160;<span class="comment">// Misc. vectorization patterns.</span></div>
<div class="line"><a name="l02808"></a><span class="lineno"> 2808</span>&#160;<span class="comment">//----------------------------------------------------------------------------//</span><span class="comment"></span></div>
<div class="line"><a name="l02809"></a><span class="lineno"> 2809</span>&#160;<span class="comment">/// Base pattern for rewriting tensor::PadOps whose result is consumed by a</span></div>
<div class="line"><a name="l02810"></a><span class="lineno"> 2810</span>&#160;<span class="comment">/// given operation type OpTy.</span></div>
<div class="line"><a name="l02811"></a><span class="lineno"> 2811</span>&#160;<span class="comment"></span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> OpTy&gt;</div>
<div class="line"><a name="l02812"></a><span class="lineno"><a class="line" href="structVectorizePadOpUserPattern.html"> 2812</a></span>&#160;<span class="keyword">struct </span><a class="code" href="structVectorizePadOpUserPattern.html">VectorizePadOpUserPattern</a> : <span class="keyword">public</span> <a class="code" href="structmlir_1_1OpRewritePattern.html">OpRewritePattern</a>&lt;tensor::PadOp&gt; {</div>
<div class="line"><a name="l02813"></a><span class="lineno"> 2813</span>&#160;  <span class="keyword">using</span> <a class="code" href="structmlir_1_1OpRewritePattern.html">OpRewritePattern&lt;tensor::PadOp&gt;::OpRewritePattern</a>;</div>
<div class="line"><a name="l02814"></a><span class="lineno"> 2814</span>&#160; </div>
<div class="line"><a name="l02815"></a><span class="lineno"><a class="line" href="structVectorizePadOpUserPattern.html#af76afc4bbbe418ff35ae6074e2ced1ee"> 2815</a></span>&#160;  LogicalResult <a class="code" href="structVectorizePadOpUserPattern.html#af76afc4bbbe418ff35ae6074e2ced1ee">matchAndRewrite</a>(tensor::PadOp padOp,</div>
<div class="line"><a name="l02816"></a><span class="lineno"> 2816</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter) <span class="keyword">const</span> <span class="keyword">final</span> {</div>
<div class="line"><a name="l02817"></a><span class="lineno"> 2817</span>&#160;    <span class="keywordtype">bool</span> <a class="code" href="namespacemlir.html#a1c6ebcdda896c9a0316c2367d2843775">changed</a> = <span class="keyword">false</span>;</div>
<div class="line"><a name="l02818"></a><span class="lineno"> 2818</span>&#160;    <span class="comment">// Insert users in vector, because some users may be replaced/removed.</span></div>
<div class="line"><a name="l02819"></a><span class="lineno"> 2819</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">auto</span> *user : llvm::to_vector&lt;4&gt;(padOp-&gt;getUsers()))</div>
<div class="line"><a name="l02820"></a><span class="lineno"> 2820</span>&#160;      <span class="keywordflow">if</span> (<span class="keyword">auto</span> op = dyn_cast&lt;OpTy&gt;(user))</div>
<div class="line"><a name="l02821"></a><span class="lineno"> 2821</span>&#160;        <a class="code" href="namespacemlir.html#a1c6ebcdda896c9a0316c2367d2843775">changed</a> |= rewriteUser(rewriter, padOp, op).succeeded();</div>
<div class="line"><a name="l02822"></a><span class="lineno"> 2822</span>&#160;    <span class="keywordflow">return</span> success(<a class="code" href="namespacemlir.html#a1c6ebcdda896c9a0316c2367d2843775">changed</a>);</div>
<div class="line"><a name="l02823"></a><span class="lineno"> 2823</span>&#160;  }</div>
<div class="line"><a name="l02824"></a><span class="lineno"> 2824</span>&#160; </div>
<div class="line"><a name="l02825"></a><span class="lineno"> 2825</span>&#160;<span class="keyword">protected</span>:</div>
<div class="line"><a name="l02826"></a><span class="lineno"><a class="line" href="structVectorizePadOpUserPattern.html#a8cbfa28f3701c68839f0ca8387dea733"> 2826</a></span>&#160;  <span class="keyword">virtual</span> LogicalResult <a class="code" href="structVectorizePadOpUserPattern.html#a8cbfa28f3701c68839f0ca8387dea733">rewriteUser</a>(<a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter,</div>
<div class="line"><a name="l02827"></a><span class="lineno"> 2827</span>&#160;                                    tensor::PadOp padOp, OpTy op) <span class="keyword">const</span> = 0;</div>
<div class="line"><a name="l02828"></a><span class="lineno"> 2828</span>&#160;};</div>
<div class="line"><a name="l02829"></a><span class="lineno"> 2829</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l02830"></a><span class="lineno"> 2830</span>&#160;<span class="comment">/// Rewrite use of tensor::PadOp result in TransferReadOp. E.g.:</span></div>
<div class="line"><a name="l02831"></a><span class="lineno"> 2831</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l02832"></a><span class="lineno"> 2832</span>&#160;<span class="comment">/// %0 = tensor.pad %src ... : tensor&lt;?x?xf32&gt; to tensor&lt;17x5xf32&gt;</span></div>
<div class="line"><a name="l02833"></a><span class="lineno"> 2833</span>&#160;<span class="comment">/// %r = vector.transfer_read %0[%c0, %c0], %cst</span></div>
<div class="line"><a name="l02834"></a><span class="lineno"> 2834</span>&#160;<span class="comment">///     {in_bounds = [true, true]} : tensor&lt;17x5xf32&gt;, vector&lt;17x5xf32&gt;</span></div>
<div class="line"><a name="l02835"></a><span class="lineno"> 2835</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l02836"></a><span class="lineno"> 2836</span>&#160;<span class="comment">/// is rewritten to:</span></div>
<div class="line"><a name="l02837"></a><span class="lineno"> 2837</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l02838"></a><span class="lineno"> 2838</span>&#160;<span class="comment">/// %r = vector.transfer_read %src[%c0, %c0], %padding</span></div>
<div class="line"><a name="l02839"></a><span class="lineno"> 2839</span>&#160;<span class="comment">///     {in_bounds = [true, true]}</span></div>
<div class="line"><a name="l02840"></a><span class="lineno"> 2840</span>&#160;<span class="comment">///     : tensor&lt;?x?xf32&gt;, vector&lt;17x5xf32&gt;</span></div>
<div class="line"><a name="l02841"></a><span class="lineno"> 2841</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l02842"></a><span class="lineno"> 2842</span>&#160;<span class="comment">/// Note: By restricting this pattern to in-bounds TransferReadOps, we can be</span></div>
<div class="line"><a name="l02843"></a><span class="lineno"> 2843</span>&#160;<span class="comment">/// sure that the original padding value %cst was never used.</span></div>
<div class="line"><a name="l02844"></a><span class="lineno"> 2844</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l02845"></a><span class="lineno"> 2845</span>&#160;<span class="comment">/// This rewrite is possible if:</span></div>
<div class="line"><a name="l02846"></a><span class="lineno"> 2846</span>&#160;<span class="comment">/// - `xferOp` has no out-of-bounds dims or mask.</span></div>
<div class="line"><a name="l02847"></a><span class="lineno"> 2847</span>&#160;<span class="comment">/// - Low padding is static 0.</span></div>
<div class="line"><a name="l02848"></a><span class="lineno"> 2848</span>&#160;<span class="comment">/// - Single, scalar padding value.</span></div>
<div class="line"><a name="l02849"></a><span class="lineno"><a class="line" href="structPadOpVectorizationWithTransferReadPattern.html"> 2849</a></span>&#160;<span class="comment"></span><span class="keyword">struct </span><a class="code" href="structPadOpVectorizationWithTransferReadPattern.html">PadOpVectorizationWithTransferReadPattern</a></div>
<div class="line"><a name="l02850"></a><span class="lineno"> 2850</span>&#160;    : <span class="keyword">public</span> <a class="code" href="structVectorizePadOpUserPattern.html">VectorizePadOpUserPattern</a>&lt;vector::TransferReadOp&gt; {</div>
<div class="line"><a name="l02851"></a><span class="lineno"> 2851</span>&#160;  <span class="keyword">using</span> <a class="code" href="structVectorizePadOpUserPattern.html">VectorizePadOpUserPattern</a>&lt;</div>
<div class="line"><a name="l02852"></a><span class="lineno"> 2852</span>&#160;      vector::TransferReadOp&gt;<a class="code" href="structVectorizePadOpUserPattern.html">::VectorizePadOpUserPattern</a>;</div>
<div class="line"><a name="l02853"></a><span class="lineno"> 2853</span>&#160; </div>
<div class="line"><a name="l02854"></a><span class="lineno"><a class="line" href="structPadOpVectorizationWithTransferReadPattern.html#ada99e3114e6e559b930e1315763d0aca"> 2854</a></span>&#160;  LogicalResult <a class="code" href="structPadOpVectorizationWithTransferReadPattern.html#ada99e3114e6e559b930e1315763d0aca">rewriteUser</a>(<a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter, tensor::PadOp padOp,</div>
<div class="line"><a name="l02855"></a><span class="lineno"> 2855</span>&#160;                            vector::TransferReadOp xferOp)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l02856"></a><span class="lineno"> 2856</span>&#160;    <span class="comment">// Low padding must be static 0.</span></div>
<div class="line"><a name="l02857"></a><span class="lineno"> 2857</span>&#160;    <span class="keywordflow">if</span> (!padOp.hasZeroLowPad())</div>
<div class="line"><a name="l02858"></a><span class="lineno"> 2858</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02859"></a><span class="lineno"> 2859</span>&#160;    <span class="comment">// Pad value must be a constant.</span></div>
<div class="line"><a name="l02860"></a><span class="lineno"> 2860</span>&#160;    <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a name="l02861"></a><span class="lineno"> 2861</span>&#160;    <span class="keywordflow">if</span> (!padValue)</div>
<div class="line"><a name="l02862"></a><span class="lineno"> 2862</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02863"></a><span class="lineno"> 2863</span>&#160;    <span class="comment">// Padding value of existing `xferOp` is unused.</span></div>
<div class="line"><a name="l02864"></a><span class="lineno"> 2864</span>&#160;    <span class="keywordflow">if</span> (xferOp.hasOutOfBoundsDim() || xferOp.getMask())</div>
<div class="line"><a name="l02865"></a><span class="lineno"> 2865</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02866"></a><span class="lineno"> 2866</span>&#160; </div>
<div class="line"><a name="l02867"></a><span class="lineno"> 2867</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#abd8bae753b51386417536a36cf52d3f7">modifyOpInPlace</a>(xferOp, [&amp;]() {</div>
<div class="line"><a name="l02868"></a><span class="lineno"> 2868</span>&#160;      <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(xferOp.getVectorType().getRank(), <span class="keyword">false</span>);</div>
<div class="line"><a name="l02869"></a><span class="lineno"> 2869</span>&#160;      xferOp-&gt;setAttr(xferOp.getInBoundsAttrName(),</div>
<div class="line"><a name="l02870"></a><span class="lineno"> 2870</span>&#160;                      rewriter.<a class="code" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a name="l02871"></a><span class="lineno"> 2871</span>&#160;      xferOp.getBaseMutable().assign(padOp.getSource());</div>
<div class="line"><a name="l02872"></a><span class="lineno"> 2872</span>&#160;      xferOp.getPaddingMutable().assign(padValue);</div>
<div class="line"><a name="l02873"></a><span class="lineno"> 2873</span>&#160;    });</div>
<div class="line"><a name="l02874"></a><span class="lineno"> 2874</span>&#160; </div>
<div class="line"><a name="l02875"></a><span class="lineno"> 2875</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02876"></a><span class="lineno"> 2876</span>&#160;  }</div>
<div class="line"><a name="l02877"></a><span class="lineno"> 2877</span>&#160;};</div>
<div class="line"><a name="l02878"></a><span class="lineno"> 2878</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l02879"></a><span class="lineno"> 2879</span>&#160;<span class="comment">/// Rewrite use of tensor::PadOp result in TransferWriteOp.</span></div>
<div class="line"><a name="l02880"></a><span class="lineno"> 2880</span>&#160;<span class="comment">/// This pattern rewrites TransferWriteOps that write to a padded tensor</span></div>
<div class="line"><a name="l02881"></a><span class="lineno"> 2881</span>&#160;<span class="comment">/// value, where the same amount of padding is immediately removed again after</span></div>
<div class="line"><a name="l02882"></a><span class="lineno"> 2882</span>&#160;<span class="comment">/// the write. In such cases, the TransferWriteOp can write to the non-padded</span></div>
<div class="line"><a name="l02883"></a><span class="lineno"> 2883</span>&#160;<span class="comment">/// tensor value and apply out-of-bounds masking. E.g.:</span></div>
<div class="line"><a name="l02884"></a><span class="lineno"> 2884</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l02885"></a><span class="lineno"> 2885</span>&#160;<span class="comment">/// %0 = tensor.extract_slice ...[...] [%s0, %s1] [1, 1]</span></div>
<div class="line"><a name="l02886"></a><span class="lineno"> 2886</span>&#160;<span class="comment">///     : tensor&lt;...&gt; to tensor&lt;?x?xf32&gt;</span></div>
<div class="line"><a name="l02887"></a><span class="lineno"> 2887</span>&#160;<span class="comment">/// %1 = tensor.pad %0 ... : tensor&lt;?x?xf32&gt; to tensor&lt;17x5xf32&gt;</span></div>
<div class="line"><a name="l02888"></a><span class="lineno"> 2888</span>&#160;<span class="comment">/// %2 = vector.transfer_write %vec, %1[...]</span></div>
<div class="line"><a name="l02889"></a><span class="lineno"> 2889</span>&#160;<span class="comment">///     : vector&lt;17x5xf32&gt;, tensor&lt;17x5xf32&gt;</span></div>
<div class="line"><a name="l02890"></a><span class="lineno"> 2890</span>&#160;<span class="comment">/// %r = tensor.extract_slice %2[0, 0] [%s0, %s1] [1, 1]</span></div>
<div class="line"><a name="l02891"></a><span class="lineno"> 2891</span>&#160;<span class="comment">///     : tensor&lt;17x5xf32&gt; to tensor&lt;?x?xf32&gt;</span></div>
<div class="line"><a name="l02892"></a><span class="lineno"> 2892</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l02893"></a><span class="lineno"> 2893</span>&#160;<span class="comment">/// is rewritten to:</span></div>
<div class="line"><a name="l02894"></a><span class="lineno"> 2894</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l02895"></a><span class="lineno"> 2895</span>&#160;<span class="comment">/// %0 = tensor.extract_slice ...[...] [%s0, %s1] [1, 1]</span></div>
<div class="line"><a name="l02896"></a><span class="lineno"> 2896</span>&#160;<span class="comment">///     : tensor&lt;...&gt; to tensor&lt;?x?xf32&gt;</span></div>
<div class="line"><a name="l02897"></a><span class="lineno"> 2897</span>&#160;<span class="comment">/// %r = vector.transfer_write %vec, %0[...] : vector&lt;17x5xf32&gt;,</span></div>
<div class="line"><a name="l02898"></a><span class="lineno"> 2898</span>&#160;<span class="comment">/// tensor&lt;?x?xf32&gt;</span></div>
<div class="line"><a name="l02899"></a><span class="lineno"> 2899</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l02900"></a><span class="lineno"> 2900</span>&#160;<span class="comment">/// Note: It is important that the ExtractSliceOp %r resizes the result of the</span></div>
<div class="line"><a name="l02901"></a><span class="lineno"> 2901</span>&#160;<span class="comment">/// TransferWriteOp to the same size as the input of the TensorPadOp (or an</span></div>
<div class="line"><a name="l02902"></a><span class="lineno"> 2902</span>&#160;<span class="comment">/// even smaller size). Otherwise, %r&#39;s new (dynamic) dimensions would differ</span></div>
<div class="line"><a name="l02903"></a><span class="lineno"> 2903</span>&#160;<span class="comment">/// from %r&#39;s old dimensions.</span></div>
<div class="line"><a name="l02904"></a><span class="lineno"> 2904</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l02905"></a><span class="lineno"> 2905</span>&#160;<span class="comment">/// This rewrite is possible if:</span></div>
<div class="line"><a name="l02906"></a><span class="lineno"> 2906</span>&#160;<span class="comment">/// - Low padding is static 0.</span></div>
<div class="line"><a name="l02907"></a><span class="lineno"> 2907</span>&#160;<span class="comment">/// - `xferOp` has exactly one use, which is an ExtractSliceOp. This</span></div>
<div class="line"><a name="l02908"></a><span class="lineno"> 2908</span>&#160;<span class="comment">///   ExtractSliceOp trims the same amount of padding that was added</span></div>
<div class="line"><a name="l02909"></a><span class="lineno"> 2909</span>&#160;<span class="comment">///   beforehand.</span></div>
<div class="line"><a name="l02910"></a><span class="lineno"> 2910</span>&#160;<span class="comment">/// - Single, scalar padding value.</span></div>
<div class="line"><a name="l02911"></a><span class="lineno"><a class="line" href="structPadOpVectorizationWithTransferWritePattern.html"> 2911</a></span>&#160;<span class="comment"></span><span class="keyword">struct </span><a class="code" href="structPadOpVectorizationWithTransferWritePattern.html">PadOpVectorizationWithTransferWritePattern</a></div>
<div class="line"><a name="l02912"></a><span class="lineno"> 2912</span>&#160;    : <span class="keyword">public</span> <a class="code" href="structVectorizePadOpUserPattern.html">VectorizePadOpUserPattern</a>&lt;vector::TransferWriteOp&gt; {</div>
<div class="line"><a name="l02913"></a><span class="lineno"> 2913</span>&#160;  <span class="keyword">using</span> <a class="code" href="structVectorizePadOpUserPattern.html">VectorizePadOpUserPattern</a>&lt;</div>
<div class="line"><a name="l02914"></a><span class="lineno"> 2914</span>&#160;      vector::TransferWriteOp&gt;<a class="code" href="structVectorizePadOpUserPattern.html">::VectorizePadOpUserPattern</a>;</div>
<div class="line"><a name="l02915"></a><span class="lineno"> 2915</span>&#160; </div>
<div class="line"><a name="l02916"></a><span class="lineno"><a class="line" href="structPadOpVectorizationWithTransferWritePattern.html#a738aa18cd09d3d86a0e8763dfd8d3f2e"> 2916</a></span>&#160;  LogicalResult <a class="code" href="structPadOpVectorizationWithTransferWritePattern.html#a738aa18cd09d3d86a0e8763dfd8d3f2e">rewriteUser</a>(<a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter, tensor::PadOp padOp,</div>
<div class="line"><a name="l02917"></a><span class="lineno"> 2917</span>&#160;                            vector::TransferWriteOp xferOp)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l02918"></a><span class="lineno"> 2918</span>&#160;    <span class="comment">// TODO: support 0-d corner case.</span></div>
<div class="line"><a name="l02919"></a><span class="lineno"> 2919</span>&#160;    <span class="keywordflow">if</span> (xferOp.getTransferRank() == 0)</div>
<div class="line"><a name="l02920"></a><span class="lineno"> 2920</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02921"></a><span class="lineno"> 2921</span>&#160; </div>
<div class="line"><a name="l02922"></a><span class="lineno"> 2922</span>&#160;    <span class="comment">// Low padding must be static 0.</span></div>
<div class="line"><a name="l02923"></a><span class="lineno"> 2923</span>&#160;    <span class="keywordflow">if</span> (!padOp.hasZeroLowPad())</div>
<div class="line"><a name="l02924"></a><span class="lineno"> 2924</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02925"></a><span class="lineno"> 2925</span>&#160;    <span class="comment">// Pad value must be a constant.</span></div>
<div class="line"><a name="l02926"></a><span class="lineno"> 2926</span>&#160;    <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a name="l02927"></a><span class="lineno"> 2927</span>&#160;    <span class="keywordflow">if</span> (!padValue)</div>
<div class="line"><a name="l02928"></a><span class="lineno"> 2928</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02929"></a><span class="lineno"> 2929</span>&#160;    <span class="comment">// TransferWriteOp result must be directly consumed by an ExtractSliceOp.</span></div>
<div class="line"><a name="l02930"></a><span class="lineno"> 2930</span>&#160;    <span class="keywordflow">if</span> (!xferOp-&gt;hasOneUse())</div>
<div class="line"><a name="l02931"></a><span class="lineno"> 2931</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02932"></a><span class="lineno"> 2932</span>&#160;    <span class="keyword">auto</span> trimPadding = dyn_cast&lt;tensor::ExtractSliceOp&gt;(*xferOp-&gt;user_begin());</div>
<div class="line"><a name="l02933"></a><span class="lineno"> 2933</span>&#160;    <span class="keywordflow">if</span> (!trimPadding)</div>
<div class="line"><a name="l02934"></a><span class="lineno"> 2934</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02935"></a><span class="lineno"> 2935</span>&#160;    <span class="comment">// Only static zero offsets supported when trimming padding.</span></div>
<div class="line"><a name="l02936"></a><span class="lineno"> 2936</span>&#160;    <span class="keywordflow">if</span> (!trimPadding.hasZeroOffset())</div>
<div class="line"><a name="l02937"></a><span class="lineno"> 2937</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02938"></a><span class="lineno"> 2938</span>&#160;    <span class="comment">// trimPadding must remove the amount of padding that was added earlier.</span></div>
<div class="line"><a name="l02939"></a><span class="lineno"> 2939</span>&#160;    <span class="keywordflow">if</span> (!hasSameTensorSize(padOp.getSource(), trimPadding))</div>
<div class="line"><a name="l02940"></a><span class="lineno"> 2940</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l02941"></a><span class="lineno"> 2941</span>&#160; </div>
<div class="line"><a name="l02942"></a><span class="lineno"> 2942</span>&#160;    <span class="comment">// Insert the new TransferWriteOp at position of the old TransferWriteOp.</span></div>
<div class="line"><a name="l02943"></a><span class="lineno"> 2943</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(xferOp);</div>
<div class="line"><a name="l02944"></a><span class="lineno"> 2944</span>&#160; </div>
<div class="line"><a name="l02945"></a><span class="lineno"> 2945</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(xferOp.getVectorType().getRank(), <span class="keyword">false</span>);</div>
<div class="line"><a name="l02946"></a><span class="lineno"> 2946</span>&#160;    <span class="keyword">auto</span> newXferOp = rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#afb1c910a57707f518d2b9c903c2bb5bc">replaceOpWithNewOp</a>&lt;vector::TransferWriteOp&gt;(</div>
<div class="line"><a name="l02947"></a><span class="lineno"> 2947</span>&#160;        xferOp, padOp.getSource().getType(), xferOp.getVector(),</div>
<div class="line"><a name="l02948"></a><span class="lineno"> 2948</span>&#160;        padOp.getSource(), xferOp.getIndices(), xferOp.getPermutationMapAttr(),</div>
<div class="line"><a name="l02949"></a><span class="lineno"> 2949</span>&#160;        xferOp.getMask(), rewriter.<a class="code" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a name="l02950"></a><span class="lineno"> 2950</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(trimPadding, newXferOp-&gt;getResult(0));</div>
<div class="line"><a name="l02951"></a><span class="lineno"> 2951</span>&#160; </div>
<div class="line"><a name="l02952"></a><span class="lineno"> 2952</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l02953"></a><span class="lineno"> 2953</span>&#160;  }</div>
<div class="line"><a name="l02954"></a><span class="lineno"> 2954</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l02955"></a><span class="lineno"> 2955</span>&#160;<span class="comment">  /// Check if `beforePadding` and `afterTrimming` have the same tensor size,</span></div>
<div class="line"><a name="l02956"></a><span class="lineno"> 2956</span>&#160;<span class="comment">  /// i.e., same dimensions.</span></div>
<div class="line"><a name="l02957"></a><span class="lineno"> 2957</span>&#160;<span class="comment">  ///</span></div>
<div class="line"><a name="l02958"></a><span class="lineno"> 2958</span>&#160;<span class="comment">  /// Dimensions may be static, dynamic or mix of both. In case of dynamic</span></div>
<div class="line"><a name="l02959"></a><span class="lineno"> 2959</span>&#160;<span class="comment">  /// dimensions, this function tries to infer the (static) tensor size by</span></div>
<div class="line"><a name="l02960"></a><span class="lineno"> 2960</span>&#160;<span class="comment">  /// looking at the defining op and utilizing op-specific knowledge.</span></div>
<div class="line"><a name="l02961"></a><span class="lineno"> 2961</span>&#160;<span class="comment">  ///</span></div>
<div class="line"><a name="l02962"></a><span class="lineno"> 2962</span>&#160;<span class="comment">  /// This is a conservative analysis. In case equal tensor sizes cannot be</span></div>
<div class="line"><a name="l02963"></a><span class="lineno"> 2963</span>&#160;<span class="comment">  /// proven statically, this analysis returns `false` even though the tensor</span></div>
<div class="line"><a name="l02964"></a><span class="lineno"> 2964</span>&#160;<span class="comment">  /// sizes may turn out to be equal at runtime.</span></div>
<div class="line"><a name="l02965"></a><span class="lineno"><a class="line" href="structPadOpVectorizationWithTransferWritePattern.html#a0612efe4d3bef8d7b34dd84a0a6c927e"> 2965</a></span>&#160;<span class="comment"></span>  <span class="keywordtype">bool</span> <a class="code" href="structPadOpVectorizationWithTransferWritePattern.html#a0612efe4d3bef8d7b34dd84a0a6c927e">hasSameTensorSize</a>(<a class="code" href="classmlir_1_1Value.html">Value</a> beforePadding,</div>
<div class="line"><a name="l02966"></a><span class="lineno"> 2966</span>&#160;                         tensor::ExtractSliceOp afterTrimming)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l02967"></a><span class="lineno"> 2967</span>&#160;    <span class="comment">// If the input to tensor::PadOp is a CastOp, try with both CastOp</span></div>
<div class="line"><a name="l02968"></a><span class="lineno"> 2968</span>&#160;    <span class="comment">// result and CastOp operand.</span></div>
<div class="line"><a name="l02969"></a><span class="lineno"> 2969</span>&#160;    <span class="keywordflow">if</span> (<span class="keyword">auto</span> castOp = beforePadding.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;tensor::CastOp&gt;())</div>
<div class="line"><a name="l02970"></a><span class="lineno"> 2970</span>&#160;      <span class="keywordflow">if</span> (hasSameTensorSize(castOp.getSource(), afterTrimming))</div>
<div class="line"><a name="l02971"></a><span class="lineno"> 2971</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l02972"></a><span class="lineno"> 2972</span>&#160; </div>
<div class="line"><a name="l02973"></a><span class="lineno"> 2973</span>&#160;    <span class="keyword">auto</span> t1 = dyn_cast&lt;RankedTensorType&gt;(beforePadding.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l02974"></a><span class="lineno"> 2974</span>&#160;    <span class="keyword">auto</span> t2 = dyn_cast&lt;RankedTensorType&gt;(afterTrimming.getType());</div>
<div class="line"><a name="l02975"></a><span class="lineno"> 2975</span>&#160;    <span class="comment">// Only RankedTensorType supported.</span></div>
<div class="line"><a name="l02976"></a><span class="lineno"> 2976</span>&#160;    <span class="keywordflow">if</span> (!t1 || !t2)</div>
<div class="line"><a name="l02977"></a><span class="lineno"> 2977</span>&#160;      <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l02978"></a><span class="lineno"> 2978</span>&#160;    <span class="comment">// Rank of both values must be the same.</span></div>
<div class="line"><a name="l02979"></a><span class="lineno"> 2979</span>&#160;    <span class="keywordflow">if</span> (t1.getRank() != t2.getRank())</div>
<div class="line"><a name="l02980"></a><span class="lineno"> 2980</span>&#160;      <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l02981"></a><span class="lineno"> 2981</span>&#160; </div>
<div class="line"><a name="l02982"></a><span class="lineno"> 2982</span>&#160;    <span class="comment">// All static dimensions must be the same. Mixed cases (e.g., dimension</span></div>
<div class="line"><a name="l02983"></a><span class="lineno"> 2983</span>&#160;    <span class="comment">// static in `t1` but dynamic in `t2`) are not supported.</span></div>
<div class="line"><a name="l02984"></a><span class="lineno"> 2984</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; t1.getRank(); ++i) {</div>
<div class="line"><a name="l02985"></a><span class="lineno"> 2985</span>&#160;      <span class="keywordflow">if</span> (t1.isDynamicDim(i) != t2.isDynamicDim(i))</div>
<div class="line"><a name="l02986"></a><span class="lineno"> 2986</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l02987"></a><span class="lineno"> 2987</span>&#160;      <span class="keywordflow">if</span> (!t1.isDynamicDim(i) &amp;&amp; t1.getDimSize(i) != t2.getDimSize(i))</div>
<div class="line"><a name="l02988"></a><span class="lineno"> 2988</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l02989"></a><span class="lineno"> 2989</span>&#160;    }</div>
<div class="line"><a name="l02990"></a><span class="lineno"> 2990</span>&#160; </div>
<div class="line"><a name="l02991"></a><span class="lineno"> 2991</span>&#160;    <span class="comment">// Nothing more to check if all dimensions are static.</span></div>
<div class="line"><a name="l02992"></a><span class="lineno"> 2992</span>&#160;    <span class="keywordflow">if</span> (t1.getNumDynamicDims() == 0)</div>
<div class="line"><a name="l02993"></a><span class="lineno"> 2993</span>&#160;      <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l02994"></a><span class="lineno"> 2994</span>&#160; </div>
<div class="line"><a name="l02995"></a><span class="lineno"> 2995</span>&#160;    <span class="comment">// All dynamic sizes must be the same. The only supported case at the</span></div>
<div class="line"><a name="l02996"></a><span class="lineno"> 2996</span>&#160;    <span class="comment">// moment is when `beforePadding` is an ExtractSliceOp (or a cast</span></div>
<div class="line"><a name="l02997"></a><span class="lineno"> 2997</span>&#160;    <span class="comment">// thereof).</span></div>
<div class="line"><a name="l02998"></a><span class="lineno"> 2998</span>&#160; </div>
<div class="line"><a name="l02999"></a><span class="lineno"> 2999</span>&#160;    <span class="comment">// Apart from CastOp, only ExtractSliceOp is supported.</span></div>
<div class="line"><a name="l03000"></a><span class="lineno"> 3000</span>&#160;    <span class="keyword">auto</span> beforeSlice = beforePadding.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;tensor::ExtractSliceOp&gt;();</div>
<div class="line"><a name="l03001"></a><span class="lineno"> 3001</span>&#160;    <span class="keywordflow">if</span> (!beforeSlice)</div>
<div class="line"><a name="l03002"></a><span class="lineno"> 3002</span>&#160;      <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l03003"></a><span class="lineno"> 3003</span>&#160; </div>
<div class="line"><a name="l03004"></a><span class="lineno"> 3004</span>&#160;    assert(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(t1.getRank()) ==</div>
<div class="line"><a name="l03005"></a><span class="lineno"> 3005</span>&#160;           beforeSlice.getMixedSizes().size());</div>
<div class="line"><a name="l03006"></a><span class="lineno"> 3006</span>&#160;    assert(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(t2.getRank()) ==</div>
<div class="line"><a name="l03007"></a><span class="lineno"> 3007</span>&#160;           afterTrimming.getMixedSizes().size());</div>
<div class="line"><a name="l03008"></a><span class="lineno"> 3008</span>&#160; </div>
<div class="line"><a name="l03009"></a><span class="lineno"> 3009</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; t1.getRank(); ++i) {</div>
<div class="line"><a name="l03010"></a><span class="lineno"> 3010</span>&#160;      <span class="comment">// Skip static dimensions.</span></div>
<div class="line"><a name="l03011"></a><span class="lineno"> 3011</span>&#160;      <span class="keywordflow">if</span> (!t1.isDynamicDim(i))</div>
<div class="line"><a name="l03012"></a><span class="lineno"> 3012</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03013"></a><span class="lineno"> 3013</span>&#160;      <span class="keyword">auto</span> size1 = beforeSlice.getMixedSizes()[i];</div>
<div class="line"><a name="l03014"></a><span class="lineno"> 3014</span>&#160;      <span class="keyword">auto</span> size2 = afterTrimming.getMixedSizes()[i];</div>
<div class="line"><a name="l03015"></a><span class="lineno"> 3015</span>&#160; </div>
<div class="line"><a name="l03016"></a><span class="lineno"> 3016</span>&#160;      <span class="comment">// Case 1: Same value or same constant int.</span></div>
<div class="line"><a name="l03017"></a><span class="lineno"> 3017</span>&#160;      <span class="keywordflow">if</span> (<a class="code" href="namespacemlir.html#a2ee77c6f0feb82212b1b817785f95f48">isEqualConstantIntOrValue</a>(size1, size2))</div>
<div class="line"><a name="l03018"></a><span class="lineno"> 3018</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03019"></a><span class="lineno"> 3019</span>&#160; </div>
<div class="line"><a name="l03020"></a><span class="lineno"> 3020</span>&#160;      <span class="comment">// Other cases: Take a deeper look at defining ops of values.</span></div>
<div class="line"><a name="l03021"></a><span class="lineno"> 3021</span>&#160;      <span class="keyword">auto</span> v1 = llvm::dyn_cast_if_present&lt;Value&gt;(size1);</div>
<div class="line"><a name="l03022"></a><span class="lineno"> 3022</span>&#160;      <span class="keyword">auto</span> v2 = llvm::dyn_cast_if_present&lt;Value&gt;(size2);</div>
<div class="line"><a name="l03023"></a><span class="lineno"> 3023</span>&#160;      <span class="keywordflow">if</span> (!v1 || !v2)</div>
<div class="line"><a name="l03024"></a><span class="lineno"> 3024</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l03025"></a><span class="lineno"> 3025</span>&#160; </div>
<div class="line"><a name="l03026"></a><span class="lineno"> 3026</span>&#160;      <span class="comment">// Case 2: Both values are identical AffineMinOps. (Should not happen if</span></div>
<div class="line"><a name="l03027"></a><span class="lineno"> 3027</span>&#160;      <span class="comment">// CSE is run.)</span></div>
<div class="line"><a name="l03028"></a><span class="lineno"> 3028</span>&#160;      <span class="keyword">auto</span> minOp1 = v1.getDefiningOp&lt;affine::AffineMinOp&gt;();</div>
<div class="line"><a name="l03029"></a><span class="lineno"> 3029</span>&#160;      <span class="keyword">auto</span> minOp2 = v2.getDefiningOp&lt;affine::AffineMinOp&gt;();</div>
<div class="line"><a name="l03030"></a><span class="lineno"> 3030</span>&#160;      <span class="keywordflow">if</span> (minOp1 &amp;&amp; minOp2 &amp;&amp; minOp1.getAffineMap() == minOp2.getAffineMap() &amp;&amp;</div>
<div class="line"><a name="l03031"></a><span class="lineno"> 3031</span>&#160;          minOp1.getOperands() == minOp2.getOperands())</div>
<div class="line"><a name="l03032"></a><span class="lineno"> 3032</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03033"></a><span class="lineno"> 3033</span>&#160; </div>
<div class="line"><a name="l03034"></a><span class="lineno"> 3034</span>&#160;      <span class="comment">// Add additional cases as needed.</span></div>
<div class="line"><a name="l03035"></a><span class="lineno"> 3035</span>&#160;    }</div>
<div class="line"><a name="l03036"></a><span class="lineno"> 3036</span>&#160; </div>
<div class="line"><a name="l03037"></a><span class="lineno"> 3037</span>&#160;    <span class="comment">// All tests passed.</span></div>
<div class="line"><a name="l03038"></a><span class="lineno"> 3038</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l03039"></a><span class="lineno"> 3039</span>&#160;  }</div>
<div class="line"><a name="l03040"></a><span class="lineno"> 3040</span>&#160;};</div>
<div class="line"><a name="l03041"></a><span class="lineno"> 3041</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l03042"></a><span class="lineno"> 3042</span>&#160;<span class="comment">/// Returns the effective Pad value for the input op, provided it&#39;s a scalar.</span></div>
<div class="line"><a name="l03043"></a><span class="lineno"> 3043</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l03044"></a><span class="lineno"> 3044</span>&#160;<span class="comment">/// Many Ops exhibit pad-like behaviour, but this isn&#39;t always explicit. If</span></div>
<div class="line"><a name="l03045"></a><span class="lineno"> 3045</span>&#160;<span class="comment">/// this Op performs padding, retrieve the padding value provided that it&#39;s</span></div>
<div class="line"><a name="l03046"></a><span class="lineno"> 3046</span>&#160;<span class="comment">/// a scalar and static/fixed for all the padded values. Returns an empty value</span></div>
<div class="line"><a name="l03047"></a><span class="lineno"> 3047</span>&#160;<span class="comment">/// otherwise.</span></div>
<div class="line"><a name="l03048"></a><span class="lineno"> 3048</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l03049"></a><span class="lineno"> 3049</span>&#160;<span class="comment">/// TODO: This is used twice (when checking vectorization pre-conditions and</span></div>
<div class="line"><a name="l03050"></a><span class="lineno"> 3050</span>&#160;<span class="comment">/// when vectorizing). Cache results instead of re-running.</span></div>
<div class="line"><a name="l03051"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec"> 3051</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <a class="code" href="classmlir_1_1Value.html">Value</a> <a class="code" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op) {</div>
<div class="line"><a name="l03052"></a><span class="lineno"> 3052</span>&#160;  <span class="keywordflow">if</span> (!op)</div>
<div class="line"><a name="l03053"></a><span class="lineno"> 3053</span>&#160;    <span class="keywordflow">return</span> {};</div>
<div class="line"><a name="l03054"></a><span class="lineno"> 3054</span>&#160; </div>
<div class="line"><a name="l03055"></a><span class="lineno"> 3055</span>&#160;  <span class="comment">// 1. vector.broadcast (f32 -&gt; vector &lt;...xf32&gt;) - return the value that&#39;s</span></div>
<div class="line"><a name="l03056"></a><span class="lineno"> 3056</span>&#160;  <span class="comment">// being broadcast, provided that it&#39;s a scalar.</span></div>
<div class="line"><a name="l03057"></a><span class="lineno"> 3057</span>&#160;  <span class="keywordflow">if</span> (<span class="keyword">auto</span> bcast = llvm::dyn_cast&lt;vector::BroadcastOp&gt;(op)) {</div>
<div class="line"><a name="l03058"></a><span class="lineno"> 3058</span>&#160;    <span class="keyword">auto</span> source = bcast.getSource();</div>
<div class="line"><a name="l03059"></a><span class="lineno"> 3059</span>&#160;    <span class="keywordflow">if</span> (llvm::dyn_cast&lt;VectorType&gt;(source.getType()))</div>
<div class="line"><a name="l03060"></a><span class="lineno"> 3060</span>&#160;      <span class="keywordflow">return</span> {};</div>
<div class="line"><a name="l03061"></a><span class="lineno"> 3061</span>&#160; </div>
<div class="line"><a name="l03062"></a><span class="lineno"> 3062</span>&#160;    <span class="keywordflow">return</span> source;</div>
<div class="line"><a name="l03063"></a><span class="lineno"> 3063</span>&#160;  }</div>
<div class="line"><a name="l03064"></a><span class="lineno"> 3064</span>&#160; </div>
<div class="line"><a name="l03065"></a><span class="lineno"> 3065</span>&#160;  <span class="comment">// 2. linalg.fill - use the scalar input value that used to fill the output</span></div>
<div class="line"><a name="l03066"></a><span class="lineno"> 3066</span>&#160;  <span class="comment">// tensor.</span></div>
<div class="line"><a name="l03067"></a><span class="lineno"> 3067</span>&#160;  <span class="keywordflow">if</span> (<span class="keyword">auto</span> fill = llvm::dyn_cast&lt;linalg::FillOp&gt;(op)) {</div>
<div class="line"><a name="l03068"></a><span class="lineno"> 3068</span>&#160;    <span class="keywordflow">return</span> fill.getInputs()[0];</div>
<div class="line"><a name="l03069"></a><span class="lineno"> 3069</span>&#160;  }</div>
<div class="line"><a name="l03070"></a><span class="lineno"> 3070</span>&#160; </div>
<div class="line"><a name="l03071"></a><span class="lineno"> 3071</span>&#160;  <span class="comment">// 3. tensor.generateOp - can&#39;t guarantee the value is fixed without</span></div>
<div class="line"><a name="l03072"></a><span class="lineno"> 3072</span>&#160;  <span class="comment">// analysing, bail out.</span></div>
<div class="line"><a name="l03073"></a><span class="lineno"> 3073</span>&#160;  <span class="keywordflow">if</span> (<span class="keyword">auto</span> generate = llvm::dyn_cast&lt;tensor::GenerateOp&gt;(op)) {</div>
<div class="line"><a name="l03074"></a><span class="lineno"> 3074</span>&#160;    <span class="keywordflow">return</span> {};</div>
<div class="line"><a name="l03075"></a><span class="lineno"> 3075</span>&#160;  }</div>
<div class="line"><a name="l03076"></a><span class="lineno"> 3076</span>&#160; </div>
<div class="line"><a name="l03077"></a><span class="lineno"> 3077</span>&#160;  <span class="comment">// 4. vector.transfer_write - inspect the input vector that&#39;s written from. If</span></div>
<div class="line"><a name="l03078"></a><span class="lineno"> 3078</span>&#160;  <span class="comment">// if contains a single value that has been broadcast (e.g. via</span></div>
<div class="line"><a name="l03079"></a><span class="lineno"> 3079</span>&#160;  <span class="comment">// vector.broadcast), extract it, fail otherwise.</span></div>
<div class="line"><a name="l03080"></a><span class="lineno"> 3080</span>&#160;  <span class="keywordflow">if</span> (<span class="keyword">auto</span> xferWrite = llvm::dyn_cast&lt;vector::TransferWriteOp&gt;(op))</div>
<div class="line"><a name="l03081"></a><span class="lineno"> 3081</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(xferWrite.getVector().getDefiningOp());</div>
<div class="line"><a name="l03082"></a><span class="lineno"> 3082</span>&#160; </div>
<div class="line"><a name="l03083"></a><span class="lineno"> 3083</span>&#160;  <span class="comment">// 5. tensor.insert_slice - inspect the destination tensor. If it&#39;s larger</span></div>
<div class="line"><a name="l03084"></a><span class="lineno"> 3084</span>&#160;  <span class="comment">// than the input tensor, then, provided it&#39;s constant, we&#39;ll extract the</span></div>
<div class="line"><a name="l03085"></a><span class="lineno"> 3085</span>&#160;  <span class="comment">// value that was used to generate it (via e.g. linalg.fill), fail otherwise.</span></div>
<div class="line"><a name="l03086"></a><span class="lineno"> 3086</span>&#160;  <span class="comment">// TODO: Clarify the semantics when the input tensor is larger than the</span></div>
<div class="line"><a name="l03087"></a><span class="lineno"> 3087</span>&#160;  <span class="comment">// destination.</span></div>
<div class="line"><a name="l03088"></a><span class="lineno"> 3088</span>&#160;  <span class="keywordflow">if</span> (<span class="keyword">auto</span> slice = llvm::dyn_cast&lt;tensor::InsertSliceOp&gt;(op))</div>
<div class="line"><a name="l03089"></a><span class="lineno"> 3089</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(slice.getDest().getDefiningOp());</div>
<div class="line"><a name="l03090"></a><span class="lineno"> 3090</span>&#160; </div>
<div class="line"><a name="l03091"></a><span class="lineno"> 3091</span>&#160;  <span class="keywordflow">return</span> {};</div>
<div class="line"><a name="l03092"></a><span class="lineno"> 3092</span>&#160;}</div>
<div class="line"><a name="l03093"></a><span class="lineno"> 3093</span>&#160; </div>
<div class="line"><a name="l03094"></a><span class="lineno"> 3094</span>&#160;<span class="keyword">static</span> LogicalResult</div>
<div class="line"><a name="l03095"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926"> 3095</a></span>&#160;<a class="code" href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926">vectorizeAsInsertSliceOp</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, tensor::InsertSliceOp sliceOp,</div>
<div class="line"><a name="l03096"></a><span class="lineno"> 3096</span>&#160;                         <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a name="l03097"></a><span class="lineno"> 3097</span>&#160;                         <a class="code" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults) {</div>
<div class="line"><a name="l03098"></a><span class="lineno"> 3098</span>&#160;  <span class="comment">// TODO: Introduce a parent class that will handle the insertion point update.</span></div>
<div class="line"><a name="l03099"></a><span class="lineno"> 3099</span>&#160;  <a class="code" href="classmlir_1_1OpBuilder_1_1InsertionGuard.html">OpBuilder::InsertionGuard</a> g(rewriter);</div>
<div class="line"><a name="l03100"></a><span class="lineno"> 3100</span>&#160;  rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(sliceOp);</div>
<div class="line"><a name="l03101"></a><span class="lineno"> 3101</span>&#160; </div>
<div class="line"><a name="l03102"></a><span class="lineno"> 3102</span>&#160;  <a class="code" href="namespacemlir.html#a39768b5816332d4970911da09de5cec4">TypedValue&lt;RankedTensorType&gt;</a> source = sliceOp.getSource();</div>
<div class="line"><a name="l03103"></a><span class="lineno"> 3103</span>&#160;  <span class="keyword">auto</span> sourceType = source.getType();</div>
<div class="line"><a name="l03104"></a><span class="lineno"> 3104</span>&#160;  <span class="keyword">auto</span> resultType = sliceOp.getResultType();</div>
<div class="line"><a name="l03105"></a><span class="lineno"> 3105</span>&#160; </div>
<div class="line"><a name="l03106"></a><span class="lineno"> 3106</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> padValue = <a class="code" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(sliceOp);</div>
<div class="line"><a name="l03107"></a><span class="lineno"> 3107</span>&#160; </div>
<div class="line"><a name="l03108"></a><span class="lineno"> 3108</span>&#160;  <span class="keywordflow">if</span> (!padValue) {</div>
<div class="line"><a name="l03109"></a><span class="lineno"> 3109</span>&#160;    <span class="keyword">auto</span> elemType = sourceType.getElementType();</div>
<div class="line"><a name="l03110"></a><span class="lineno"> 3110</span>&#160;    padValue = arith::ConstantOp::create(rewriter, sliceOp.getLoc(), elemType,</div>
<div class="line"><a name="l03111"></a><span class="lineno"> 3111</span>&#160;                                         rewriter.<a class="code" href="classmlir_1_1Builder.html#a8e943986e58a8b0c88fcd51b0f0afafb">getZeroAttr</a>(elemType));</div>
<div class="line"><a name="l03112"></a><span class="lineno"> 3112</span>&#160;  }</div>
<div class="line"><a name="l03113"></a><span class="lineno"> 3113</span>&#160; </div>
<div class="line"><a name="l03114"></a><span class="lineno"> 3114</span>&#160;  <span class="comment">// 2. Get the vector shape</span></div>
<div class="line"><a name="l03115"></a><span class="lineno"> 3115</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> vecShape;</div>
<div class="line"><a name="l03116"></a><span class="lineno"> 3116</span>&#160;  <span class="keywordtype">size_t</span> rankDiff = resultType.getRank() - sourceType.getRank();</div>
<div class="line"><a name="l03117"></a><span class="lineno"> 3117</span>&#160;  <span class="keywordflow">for</span> (int64_t i = 0, end = sourceType.getRank(); i &lt; end; ++i) {</div>
<div class="line"><a name="l03118"></a><span class="lineno"> 3118</span>&#160;    <span class="keywordflow">if</span> (!inputVectorSizes.empty()) {</div>
<div class="line"><a name="l03119"></a><span class="lineno"> 3119</span>&#160;      vecShape.push_back(inputVectorSizes[i]);</div>
<div class="line"><a name="l03120"></a><span class="lineno"> 3120</span>&#160;    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!sourceType.isDynamicDim(i)) {</div>
<div class="line"><a name="l03121"></a><span class="lineno"> 3121</span>&#160;      vecShape.push_back(sourceType.getDimSize(i));</div>
<div class="line"><a name="l03122"></a><span class="lineno"> 3122</span>&#160;    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!resultType.isDynamicDim(i)) {</div>
<div class="line"><a name="l03123"></a><span class="lineno"> 3123</span>&#160;      <span class="comment">// Source shape is not statically known, but result shape is.</span></div>
<div class="line"><a name="l03124"></a><span class="lineno"> 3124</span>&#160;      <span class="comment">// Vectorize with size of result shape. This may be larger than the</span></div>
<div class="line"><a name="l03125"></a><span class="lineno"> 3125</span>&#160;      <span class="comment">// source size.</span></div>
<div class="line"><a name="l03126"></a><span class="lineno"> 3126</span>&#160;      <span class="comment">// FIXME: Using rankDiff implies that the source tensor is inserted at</span></div>
<div class="line"><a name="l03127"></a><span class="lineno"> 3127</span>&#160;      <span class="comment">// the end of the destination tensor. However, that&#39;s not required.</span></div>
<div class="line"><a name="l03128"></a><span class="lineno"> 3128</span>&#160;      vecShape.push_back(resultType.getDimSize(rankDiff + i));</div>
<div class="line"><a name="l03129"></a><span class="lineno"> 3129</span>&#160;    } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l03130"></a><span class="lineno"> 3130</span>&#160;      <span class="comment">// Neither source nor result dim of padOp is static. Cannot vectorize</span></div>
<div class="line"><a name="l03131"></a><span class="lineno"> 3131</span>&#160;      <span class="comment">// the copy.</span></div>
<div class="line"><a name="l03132"></a><span class="lineno"> 3132</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l03133"></a><span class="lineno"> 3133</span>&#160;    }</div>
<div class="line"><a name="l03134"></a><span class="lineno"> 3134</span>&#160;  }</div>
<div class="line"><a name="l03135"></a><span class="lineno"> 3135</span>&#160;  <span class="keyword">auto</span> vecType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(vecShape, sourceType.getElementType());</div>
<div class="line"><a name="l03136"></a><span class="lineno"> 3136</span>&#160; </div>
<div class="line"><a name="l03137"></a><span class="lineno"> 3137</span>&#160;  <span class="comment">// 3. Generate TransferReadOp + TransferWriteOp</span></div>
<div class="line"><a name="l03138"></a><span class="lineno"> 3138</span>&#160;  <span class="keyword">auto</span> loc = sliceOp.getLoc();</div>
<div class="line"><a name="l03139"></a><span class="lineno"> 3139</span>&#160; </div>
<div class="line"><a name="l03140"></a><span class="lineno"> 3140</span>&#160;  <span class="comment">// Create read</span></div>
<div class="line"><a name="l03141"></a><span class="lineno"> 3141</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> readIndices(</div>
<div class="line"><a name="l03142"></a><span class="lineno"> 3142</span>&#160;      vecType.getRank(), <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0));</div>
<div class="line"><a name="l03143"></a><span class="lineno"> 3143</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> read = <a class="code" href="namespacemlir_1_1vector.html#ab9c7ed08068bf03fb4bd625cd3bbd98c">mlir::vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a name="l03144"></a><span class="lineno"> 3144</span>&#160;      rewriter, loc, source, vecType.getShape(), padValue,</div>
<div class="line"><a name="l03145"></a><span class="lineno"> 3145</span>&#160;      <span class="comment">/*useInBoundsInsteadOfMasking=*/</span>inputVectorSizes.empty());</div>
<div class="line"><a name="l03146"></a><span class="lineno"> 3146</span>&#160; </div>
<div class="line"><a name="l03147"></a><span class="lineno"> 3147</span>&#160;  <span class="comment">// Create write</span></div>
<div class="line"><a name="l03148"></a><span class="lineno"> 3148</span>&#160;  <span class="keyword">auto</span> writeIndices =</div>
<div class="line"><a name="l03149"></a><span class="lineno"> 3149</span>&#160;      <a class="code" href="namespacemlir.html#aa058eb9c12d3b97deb073543c1372195">getValueOrCreateConstantIndexOp</a>(rewriter, loc, sliceOp.getMixedOffsets());</div>
<div class="line"><a name="l03150"></a><span class="lineno"> 3150</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *write =</div>
<div class="line"><a name="l03151"></a><span class="lineno"> 3151</span>&#160;      <a class="code" href="Vectorization_8cpp.html#a4cc023e06de6664a1cd635d77118db19">createWriteOrMaskedWrite</a>(rewriter, loc, read, sliceOp.getDest(),</div>
<div class="line"><a name="l03152"></a><span class="lineno"> 3152</span>&#160;                               writeIndices, inputVectorSizes.empty());</div>
<div class="line"><a name="l03153"></a><span class="lineno"> 3153</span>&#160; </div>
<div class="line"><a name="l03154"></a><span class="lineno"> 3154</span>&#160;  <span class="comment">// 4. Finalize</span></div>
<div class="line"><a name="l03155"></a><span class="lineno"> 3155</span>&#160;  newResults.push_back(write-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a name="l03156"></a><span class="lineno"> 3156</span>&#160; </div>
<div class="line"><a name="l03157"></a><span class="lineno"> 3157</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l03158"></a><span class="lineno"> 3158</span>&#160;}</div>
<div class="line"><a name="l03159"></a><span class="lineno"> 3159</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l03160"></a><span class="lineno"> 3160</span>&#160;<span class="comment">/// Rewrite use of tensor::PadOp result in InsertSliceOp. E.g.:</span></div>
<div class="line"><a name="l03161"></a><span class="lineno"> 3161</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03162"></a><span class="lineno"> 3162</span>&#160;<span class="comment">/// %0 = tensor.pad %src ... : tensor&lt;?x?xf32&gt; to tensor&lt;17x5xf32&gt;</span></div>
<div class="line"><a name="l03163"></a><span class="lineno"> 3163</span>&#160;<span class="comment">/// %r = tensor.insert_slice %0</span></div>
<div class="line"><a name="l03164"></a><span class="lineno"> 3164</span>&#160;<span class="comment">///     into %dest[%a, %b, 0, 0] [1, 1, 17, 5] [1, 1, 1, 1]</span></div>
<div class="line"><a name="l03165"></a><span class="lineno"> 3165</span>&#160;<span class="comment">///     : tensor&lt;17x5xf32&gt; into tensor&lt;?x?x17x5xf32&gt;</span></div>
<div class="line"><a name="l03166"></a><span class="lineno"> 3166</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03167"></a><span class="lineno"> 3167</span>&#160;<span class="comment">/// is rewritten to:</span></div>
<div class="line"><a name="l03168"></a><span class="lineno"> 3168</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03169"></a><span class="lineno"> 3169</span>&#160;<span class="comment">/// %0 = vector.transfer_read %src[%c0, %c0], %padding</span></div>
<div class="line"><a name="l03170"></a><span class="lineno"> 3170</span>&#160;<span class="comment">///     : tensor&lt;?x?xf32&gt;, vector&lt;17x5xf32&gt;</span></div>
<div class="line"><a name="l03171"></a><span class="lineno"> 3171</span>&#160;<span class="comment">/// %r = vector.transfer_write %0, %dest[%a, %b, %c0, %c0]</span></div>
<div class="line"><a name="l03172"></a><span class="lineno"> 3172</span>&#160;<span class="comment">///     {in_bounds = [true, true]} : vector&lt;17x5xf32&gt;, tensor&lt;?x?x17x5xf32&gt;</span></div>
<div class="line"><a name="l03173"></a><span class="lineno"> 3173</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03174"></a><span class="lineno"> 3174</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l03175"></a><span class="lineno"> 3175</span>&#160;<span class="comment">/// This rewrite is possible if:</span></div>
<div class="line"><a name="l03176"></a><span class="lineno"> 3176</span>&#160;<span class="comment">/// - Low padding is static 0.</span></div>
<div class="line"><a name="l03177"></a><span class="lineno"> 3177</span>&#160;<span class="comment">/// - `padOp` result shape is static.</span></div>
<div class="line"><a name="l03178"></a><span class="lineno"> 3178</span>&#160;<span class="comment">/// - The entire padded tensor is inserted.</span></div>
<div class="line"><a name="l03179"></a><span class="lineno"> 3179</span>&#160;<span class="comment">///   (Implies that sizes of `insertOp` are all static.)</span></div>
<div class="line"><a name="l03180"></a><span class="lineno"> 3180</span>&#160;<span class="comment">/// - Only unit strides in `insertOp`.</span></div>
<div class="line"><a name="l03181"></a><span class="lineno"> 3181</span>&#160;<span class="comment">/// - Single, scalar padding value.</span></div>
<div class="line"><a name="l03182"></a><span class="lineno"> 3182</span>&#160;<span class="comment">/// - `padOp` result not used as destination.</span></div>
<div class="line"><a name="l03183"></a><span class="lineno"><a class="line" href="structPadOpVectorizationWithInsertSlicePattern.html"> 3183</a></span>&#160;<span class="comment"></span><span class="keyword">struct </span><a class="code" href="structPadOpVectorizationWithInsertSlicePattern.html">PadOpVectorizationWithInsertSlicePattern</a></div>
<div class="line"><a name="l03184"></a><span class="lineno"> 3184</span>&#160;    : <span class="keyword">public</span> <a class="code" href="structVectorizePadOpUserPattern.html">VectorizePadOpUserPattern</a>&lt;tensor::InsertSliceOp&gt; {</div>
<div class="line"><a name="l03185"></a><span class="lineno"> 3185</span>&#160;  <span class="keyword">using</span> <a class="code" href="structVectorizePadOpUserPattern.html">VectorizePadOpUserPattern</a>&lt;</div>
<div class="line"><a name="l03186"></a><span class="lineno"> 3186</span>&#160;      tensor::InsertSliceOp&gt;<a class="code" href="structVectorizePadOpUserPattern.html">::VectorizePadOpUserPattern</a>;</div>
<div class="line"><a name="l03187"></a><span class="lineno"> 3187</span>&#160; </div>
<div class="line"><a name="l03188"></a><span class="lineno"><a class="line" href="structPadOpVectorizationWithInsertSlicePattern.html#a9ead6c8bbb0241d7c9c0a7214fe1b827"> 3188</a></span>&#160;  LogicalResult <a class="code" href="structPadOpVectorizationWithInsertSlicePattern.html#a9ead6c8bbb0241d7c9c0a7214fe1b827">rewriteUser</a>(<a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter, tensor::PadOp padOp,</div>
<div class="line"><a name="l03189"></a><span class="lineno"> 3189</span>&#160;                            tensor::InsertSliceOp insertOp)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l03190"></a><span class="lineno"> 3190</span>&#160;    <span class="comment">// Low padding must be static 0.</span></div>
<div class="line"><a name="l03191"></a><span class="lineno"> 3191</span>&#160;    <span class="keywordflow">if</span> (!padOp.hasZeroLowPad())</div>
<div class="line"><a name="l03192"></a><span class="lineno"> 3192</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l03193"></a><span class="lineno"> 3193</span>&#160;    <span class="comment">// Only unit stride supported.</span></div>
<div class="line"><a name="l03194"></a><span class="lineno"> 3194</span>&#160;    <span class="keywordflow">if</span> (!insertOp.hasUnitStride())</div>
<div class="line"><a name="l03195"></a><span class="lineno"> 3195</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l03196"></a><span class="lineno"> 3196</span>&#160;    <span class="comment">// Pad value must be a constant.</span></div>
<div class="line"><a name="l03197"></a><span class="lineno"> 3197</span>&#160;    <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a name="l03198"></a><span class="lineno"> 3198</span>&#160;    <span class="keywordflow">if</span> (!padValue)</div>
<div class="line"><a name="l03199"></a><span class="lineno"> 3199</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l03200"></a><span class="lineno"> 3200</span>&#160;    <span class="comment">// Dynamic shapes not supported.</span></div>
<div class="line"><a name="l03201"></a><span class="lineno"> 3201</span>&#160;    <span class="keywordflow">if</span> (!cast&lt;ShapedType&gt;(padOp.getResult().getType()).hasStaticShape())</div>
<div class="line"><a name="l03202"></a><span class="lineno"> 3202</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l03203"></a><span class="lineno"> 3203</span>&#160;    <span class="comment">// Pad result not used as destination.</span></div>
<div class="line"><a name="l03204"></a><span class="lineno"> 3204</span>&#160;    <span class="keywordflow">if</span> (insertOp.getDest() == padOp.getResult())</div>
<div class="line"><a name="l03205"></a><span class="lineno"> 3205</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l03206"></a><span class="lineno"> 3206</span>&#160; </div>
<div class="line"><a name="l03207"></a><span class="lineno"> 3207</span>&#160;    <span class="keyword">auto</span> vecType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(padOp.getType().getShape(),</div>
<div class="line"><a name="l03208"></a><span class="lineno"> 3208</span>&#160;                                   padOp.getType().getElementType());</div>
<div class="line"><a name="l03209"></a><span class="lineno"> 3209</span>&#160;    <span class="keywordtype">unsigned</span> vecRank = vecType.getRank();</div>
<div class="line"><a name="l03210"></a><span class="lineno"> 3210</span>&#160;    <span class="keywordtype">unsigned</span> tensorRank = insertOp.getType().getRank();</div>
<div class="line"><a name="l03211"></a><span class="lineno"> 3211</span>&#160; </div>
<div class="line"><a name="l03212"></a><span class="lineno"> 3212</span>&#160;    <span class="comment">// Check if sizes match: Insert the entire tensor into most minor dims.</span></div>
<div class="line"><a name="l03213"></a><span class="lineno"> 3213</span>&#160;    <span class="comment">// (No permutations allowed.)</span></div>
<div class="line"><a name="l03214"></a><span class="lineno"> 3214</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> expectedSizes(tensorRank - vecRank, 1);</div>
<div class="line"><a name="l03215"></a><span class="lineno"> 3215</span>&#160;    expectedSizes.append(vecType.getShape().begin(), vecType.getShape().end());</div>
<div class="line"><a name="l03216"></a><span class="lineno"> 3216</span>&#160;    <span class="keywordflow">if</span> (!llvm::all_of(</div>
<div class="line"><a name="l03217"></a><span class="lineno"> 3217</span>&#160;            llvm::zip(insertOp.getMixedSizes(), expectedSizes), [](<span class="keyword">auto</span> it) {</div>
<div class="line"><a name="l03218"></a><span class="lineno"> 3218</span>&#160;              return getConstantIntValue(std::get&lt;0&gt;(it)) == std::get&lt;1&gt;(it);</div>
<div class="line"><a name="l03219"></a><span class="lineno"> 3219</span>&#160;            }))</div>
<div class="line"><a name="l03220"></a><span class="lineno"> 3220</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l03221"></a><span class="lineno"> 3221</span>&#160; </div>
<div class="line"><a name="l03222"></a><span class="lineno"> 3222</span>&#160;    <span class="comment">// Insert the TransferReadOp and TransferWriteOp at the position of the</span></div>
<div class="line"><a name="l03223"></a><span class="lineno"> 3223</span>&#160;    <span class="comment">// InsertSliceOp.</span></div>
<div class="line"><a name="l03224"></a><span class="lineno"> 3224</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(insertOp);</div>
<div class="line"><a name="l03225"></a><span class="lineno"> 3225</span>&#160; </div>
<div class="line"><a name="l03226"></a><span class="lineno"> 3226</span>&#160;    <span class="comment">// Generate TransferReadOp: Read entire source tensor and add high</span></div>
<div class="line"><a name="l03227"></a><span class="lineno"> 3227</span>&#160;    <span class="comment">// padding.</span></div>
<div class="line"><a name="l03228"></a><span class="lineno"> 3228</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> readIndices(</div>
<div class="line"><a name="l03229"></a><span class="lineno"> 3229</span>&#160;        vecRank, <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, padOp.getLoc(), 0));</div>
<div class="line"><a name="l03230"></a><span class="lineno"> 3230</span>&#160;    <span class="keyword">auto</span> read = vector::TransferReadOp::create(rewriter, padOp.getLoc(),</div>
<div class="line"><a name="l03231"></a><span class="lineno"> 3231</span>&#160;                                               vecType, padOp.getSource(),</div>
<div class="line"><a name="l03232"></a><span class="lineno"> 3232</span>&#160;                                               readIndices, padValue);</div>
<div class="line"><a name="l03233"></a><span class="lineno"> 3233</span>&#160; </div>
<div class="line"><a name="l03234"></a><span class="lineno"> 3234</span>&#160;    <span class="comment">// Generate TransferWriteOp: Write to InsertSliceOp&#39;s dest tensor at</span></div>
<div class="line"><a name="l03235"></a><span class="lineno"> 3235</span>&#160;    <span class="comment">// specified offsets. Write is fully in-bounds because a InsertSliceOp&#39;s</span></div>
<div class="line"><a name="l03236"></a><span class="lineno"> 3236</span>&#160;    <span class="comment">// source must fit into the destination at the specified offsets.</span></div>
<div class="line"><a name="l03237"></a><span class="lineno"> 3237</span>&#160;    <span class="keyword">auto</span> writeIndices = <a class="code" href="namespacemlir.html#aa058eb9c12d3b97deb073543c1372195">getValueOrCreateConstantIndexOp</a>(</div>
<div class="line"><a name="l03238"></a><span class="lineno"> 3238</span>&#160;        rewriter, padOp.getLoc(), insertOp.getMixedOffsets());</div>
<div class="line"><a name="l03239"></a><span class="lineno"> 3239</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(vecRank, <span class="keyword">true</span>);</div>
<div class="line"><a name="l03240"></a><span class="lineno"> 3240</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#afb1c910a57707f518d2b9c903c2bb5bc">replaceOpWithNewOp</a>&lt;vector::TransferWriteOp&gt;(</div>
<div class="line"><a name="l03241"></a><span class="lineno"> 3241</span>&#160;        insertOp, read, insertOp.getDest(), writeIndices,</div>
<div class="line"><a name="l03242"></a><span class="lineno"> 3242</span>&#160;        <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a>{inBounds});</div>
<div class="line"><a name="l03243"></a><span class="lineno"> 3243</span>&#160; </div>
<div class="line"><a name="l03244"></a><span class="lineno"> 3244</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l03245"></a><span class="lineno"> 3245</span>&#160;  }</div>
<div class="line"><a name="l03246"></a><span class="lineno"> 3246</span>&#160;};</div>
<div class="line"><a name="l03247"></a><span class="lineno"> 3247</span>&#160; </div>
<div class="line"><a name="l03248"></a><span class="lineno"><a class="line" href="namespacemlir_1_1linalg.html#a43c2ef8a778a33a17885475c11b50bdd"> 3248</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="namespacemlir_1_1linalg.html#a43c2ef8a778a33a17885475c11b50bdd">mlir::linalg::populatePadOpVectorizationPatterns</a>(</div>
<div class="line"><a name="l03249"></a><span class="lineno"> 3249</span>&#160;    <a class="code" href="classmlir_1_1RewritePatternSet.html">RewritePatternSet</a> &amp;<a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>, <a class="code" href="classmlir_1_1PatternBenefit.html">PatternBenefit</a> baseBenefit) {</div>
<div class="line"><a name="l03250"></a><span class="lineno"> 3250</span>&#160;  <a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.add&lt;<a class="code" href="structPadOpVectorizationWithTransferReadPattern.html">PadOpVectorizationWithTransferReadPattern</a>,</div>
<div class="line"><a name="l03251"></a><span class="lineno"> 3251</span>&#160;               <a class="code" href="structPadOpVectorizationWithTransferWritePattern.html">PadOpVectorizationWithTransferWritePattern</a>,</div>
<div class="line"><a name="l03252"></a><span class="lineno"> 3252</span>&#160;               <a class="code" href="structPadOpVectorizationWithInsertSlicePattern.html">PadOpVectorizationWithInsertSlicePattern</a>&gt;(</div>
<div class="line"><a name="l03253"></a><span class="lineno"> 3253</span>&#160;      <a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.getContext(), baseBenefit.<a class="code" href="classmlir_1_1PatternBenefit.html#af19d7a934078c6de5512543eea299579">getBenefit</a>() + 1);</div>
<div class="line"><a name="l03254"></a><span class="lineno"> 3254</span>&#160;}</div>
<div class="line"><a name="l03255"></a><span class="lineno"> 3255</span>&#160; </div>
<div class="line"><a name="l03256"></a><span class="lineno"> 3256</span>&#160;<span class="comment">//----------------------------------------------------------------------------//</span></div>
<div class="line"><a name="l03257"></a><span class="lineno"> 3257</span>&#160;<span class="comment">// Forwarding patterns</span></div>
<div class="line"><a name="l03258"></a><span class="lineno"> 3258</span>&#160;<span class="comment">//----------------------------------------------------------------------------//</span></div>
<div class="line"><a name="l03259"></a><span class="lineno"> 3259</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l03260"></a><span class="lineno"> 3260</span>&#160;<span class="comment">/// Check whether there is any interleaved use of any `values` between</span></div>
<div class="line"><a name="l03261"></a><span class="lineno"> 3261</span>&#160;<span class="comment">/// `firstOp` and `secondOp`. Conservatively return `true` if any op or value</span></div>
<div class="line"><a name="l03262"></a><span class="lineno"> 3262</span>&#160;<span class="comment">/// is in a different block.</span></div>
<div class="line"><a name="l03263"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a69be050ec61bb7c731b8666ca80f832f"> 3263</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code" href="Vectorization_8cpp.html#a69be050ec61bb7c731b8666ca80f832f">mayExistInterleavedUses</a>(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *firstOp, <a class="code" href="classmlir_1_1Operation.html">Operation</a> *secondOp,</div>
<div class="line"><a name="l03264"></a><span class="lineno"> 3264</span>&#160;                                    <a class="code" href="classmlir_1_1ValueRange.html">ValueRange</a> values) {</div>
<div class="line"><a name="l03265"></a><span class="lineno"> 3265</span>&#160;  <span class="keywordflow">if</span> (firstOp-&gt;<a class="code" href="classmlir_1_1Operation.html#a95e463348b9127104d0f8e9bfe413eeb">getBlock</a>() != secondOp-&gt;<a class="code" href="classmlir_1_1Operation.html#a95e463348b9127104d0f8e9bfe413eeb">getBlock</a>() ||</div>
<div class="line"><a name="l03266"></a><span class="lineno"> 3266</span>&#160;      !firstOp-&gt;<a class="code" href="classmlir_1_1Operation.html#a3cfc1046bad9638cf68c7add9efa6c33">isBeforeInBlock</a>(secondOp)) {</div>
<div class="line"><a name="l03267"></a><span class="lineno"> 3267</span>&#160;    LDBG() &lt;&lt; <span class="stringliteral">&quot;interleavedUses precondition failed, firstOp: &quot;</span> &lt;&lt; *firstOp</div>
<div class="line"><a name="l03268"></a><span class="lineno"> 3268</span>&#160;           &lt;&lt; <span class="stringliteral">&quot;, second op: &quot;</span> &lt;&lt; *secondOp;</div>
<div class="line"><a name="l03269"></a><span class="lineno"> 3269</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l03270"></a><span class="lineno"> 3270</span>&#160;  }</div>
<div class="line"><a name="l03271"></a><span class="lineno"> 3271</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> v : values) {</div>
<div class="line"><a name="l03272"></a><span class="lineno"> 3272</span>&#160;    <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : v.getUses()) {</div>
<div class="line"><a name="l03273"></a><span class="lineno"> 3273</span>&#160;      <a class="code" href="classmlir_1_1Operation.html">Operation</a> *owner = u.getOwner();</div>
<div class="line"><a name="l03274"></a><span class="lineno"> 3274</span>&#160;      <span class="keywordflow">if</span> (owner == firstOp || owner == secondOp)</div>
<div class="line"><a name="l03275"></a><span class="lineno"> 3275</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03276"></a><span class="lineno"> 3276</span>&#160;      <span class="comment">// TODO: this is too conservative, use dominance info in the future.</span></div>
<div class="line"><a name="l03277"></a><span class="lineno"> 3277</span>&#160;      <span class="keywordflow">if</span> (owner-&gt;<a class="code" href="classmlir_1_1Operation.html#a95e463348b9127104d0f8e9bfe413eeb">getBlock</a>() == firstOp-&gt;<a class="code" href="classmlir_1_1Operation.html#a95e463348b9127104d0f8e9bfe413eeb">getBlock</a>() &amp;&amp;</div>
<div class="line"><a name="l03278"></a><span class="lineno"> 3278</span>&#160;          (owner-&gt;<a class="code" href="classmlir_1_1Operation.html#a3cfc1046bad9638cf68c7add9efa6c33">isBeforeInBlock</a>(firstOp) || secondOp-&gt;<a class="code" href="classmlir_1_1Operation.html#a3cfc1046bad9638cf68c7add9efa6c33">isBeforeInBlock</a>(owner)))</div>
<div class="line"><a name="l03279"></a><span class="lineno"> 3279</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03280"></a><span class="lineno"> 3280</span>&#160;      LDBG() &lt;&lt; <span class="stringliteral">&quot; found interleaved op &quot;</span> &lt;&lt; *owner &lt;&lt; <span class="stringliteral">&quot;, firstOp: &quot;</span> &lt;&lt; *firstOp</div>
<div class="line"><a name="l03281"></a><span class="lineno"> 3281</span>&#160;             &lt;&lt; <span class="stringliteral">&quot;, second op: &quot;</span> &lt;&lt; *secondOp;</div>
<div class="line"><a name="l03282"></a><span class="lineno"> 3282</span>&#160;      <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a name="l03283"></a><span class="lineno"> 3283</span>&#160;    }</div>
<div class="line"><a name="l03284"></a><span class="lineno"> 3284</span>&#160;  }</div>
<div class="line"><a name="l03285"></a><span class="lineno"> 3285</span>&#160;  <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l03286"></a><span class="lineno"> 3286</span>&#160;}</div>
<div class="line"><a name="l03287"></a><span class="lineno"> 3287</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l03288"></a><span class="lineno"> 3288</span>&#160;<span class="comment">/// Return the unique subview use of `v` if it is indeed unique, null</span></div>
<div class="line"><a name="l03289"></a><span class="lineno"> 3289</span>&#160;<span class="comment">/// otherwise.</span></div>
<div class="line"><a name="l03290"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a035a7bd3b44d215db6d50b32318822c0"> 3290</a></span>&#160;<span class="comment"></span><span class="keyword">static</span> memref::SubViewOp <a class="code" href="Vectorization_8cpp.html#a035a7bd3b44d215db6d50b32318822c0">getSubViewUseIfUnique</a>(<a class="code" href="classmlir_1_1Value.html">Value</a> v) {</div>
<div class="line"><a name="l03291"></a><span class="lineno"> 3291</span>&#160;  memref::SubViewOp subViewOp;</div>
<div class="line"><a name="l03292"></a><span class="lineno"> 3292</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : v.<a class="code" href="classmlir_1_1Value.html#a5adc50e42183f2f503143918a296da9d">getUses</a>()) {</div>
<div class="line"><a name="l03293"></a><span class="lineno"> 3293</span>&#160;    <span class="keywordflow">if</span> (<span class="keyword">auto</span> newSubViewOp = dyn_cast&lt;memref::SubViewOp&gt;(u.getOwner())) {</div>
<div class="line"><a name="l03294"></a><span class="lineno"> 3294</span>&#160;      <span class="keywordflow">if</span> (subViewOp)</div>
<div class="line"><a name="l03295"></a><span class="lineno"> 3295</span>&#160;        <span class="keywordflow">return</span> memref::SubViewOp();</div>
<div class="line"><a name="l03296"></a><span class="lineno"> 3296</span>&#160;      subViewOp = newSubViewOp;</div>
<div class="line"><a name="l03297"></a><span class="lineno"> 3297</span>&#160;    }</div>
<div class="line"><a name="l03298"></a><span class="lineno"> 3298</span>&#160;  }</div>
<div class="line"><a name="l03299"></a><span class="lineno"> 3299</span>&#160;  <span class="keywordflow">return</span> subViewOp;</div>
<div class="line"><a name="l03300"></a><span class="lineno"> 3300</span>&#160;}</div>
<div class="line"><a name="l03301"></a><span class="lineno"> 3301</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l03302"></a><span class="lineno"> 3302</span>&#160;<span class="comment">/// TODO: use interfaces, side-effects and aliasing analysis as appropriate,</span></div>
<div class="line"><a name="l03303"></a><span class="lineno"> 3303</span>&#160;<span class="comment">/// when available.</span></div>
<div class="line"><a name="l03304"></a><span class="lineno"><a class="line" href="structmlir_1_1linalg_1_1LinalgCopyVTRForwardingPattern.html#aa21d069f8a683b84f4e81366691cb9aa"> 3304</a></span>&#160;<span class="comment"></span>LogicalResult <a class="code" href="structmlir_1_1linalg_1_1LinalgCopyVTRForwardingPattern.html#aa21d069f8a683b84f4e81366691cb9aa">LinalgCopyVTRForwardingPattern::matchAndRewrite</a>(</div>
<div class="line"><a name="l03305"></a><span class="lineno"> 3305</span>&#160;    vector::TransferReadOp xferOp, <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l03306"></a><span class="lineno"> 3306</span>&#160; </div>
<div class="line"><a name="l03307"></a><span class="lineno"> 3307</span>&#160;  <span class="comment">// TODO: support mask.</span></div>
<div class="line"><a name="l03308"></a><span class="lineno"> 3308</span>&#160;  <span class="keywordflow">if</span> (xferOp.getMask())</div>
<div class="line"><a name="l03309"></a><span class="lineno"> 3309</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;unsupported mask&quot;</span>);</div>
<div class="line"><a name="l03310"></a><span class="lineno"> 3310</span>&#160; </div>
<div class="line"><a name="l03311"></a><span class="lineno"> 3311</span>&#160;  <span class="comment">// Transfer into `view`.</span></div>
<div class="line"><a name="l03312"></a><span class="lineno"> 3312</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> viewOrAlloc = xferOp.getBase();</div>
<div class="line"><a name="l03313"></a><span class="lineno"> 3313</span>&#160;  <span class="keywordflow">if</span> (!viewOrAlloc.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;memref::ViewOp&gt;() &amp;&amp;</div>
<div class="line"><a name="l03314"></a><span class="lineno"> 3314</span>&#160;      !viewOrAlloc.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;memref::AllocOp&gt;())</div>
<div class="line"><a name="l03315"></a><span class="lineno"> 3315</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;source not a view or alloc&quot;</span>);</div>
<div class="line"><a name="l03316"></a><span class="lineno"> 3316</span>&#160; </div>
<div class="line"><a name="l03317"></a><span class="lineno"> 3317</span>&#160;  <span class="comment">// Ensure there is exactly one subview of `viewOrAlloc` defining `subView`.</span></div>
<div class="line"><a name="l03318"></a><span class="lineno"> 3318</span>&#160;  memref::SubViewOp subViewOp = <a class="code" href="Vectorization_8cpp.html#a035a7bd3b44d215db6d50b32318822c0">getSubViewUseIfUnique</a>(viewOrAlloc);</div>
<div class="line"><a name="l03319"></a><span class="lineno"> 3319</span>&#160;  <span class="keywordflow">if</span> (!subViewOp)</div>
<div class="line"><a name="l03320"></a><span class="lineno"> 3320</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;no subview found&quot;</span>);</div>
<div class="line"><a name="l03321"></a><span class="lineno"> 3321</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> subView = subViewOp.getResult();</div>
<div class="line"><a name="l03322"></a><span class="lineno"> 3322</span>&#160; </div>
<div class="line"><a name="l03323"></a><span class="lineno"> 3323</span>&#160;  <span class="comment">// Find the copy into `subView` without interleaved uses.</span></div>
<div class="line"><a name="l03324"></a><span class="lineno"> 3324</span>&#160;  memref::CopyOp copyOp;</div>
<div class="line"><a name="l03325"></a><span class="lineno"> 3325</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : subView.<a class="code" href="classmlir_1_1Value.html#a5adc50e42183f2f503143918a296da9d">getUses</a>()) {</div>
<div class="line"><a name="l03326"></a><span class="lineno"> 3326</span>&#160;    <span class="keywordflow">if</span> (<span class="keyword">auto</span> newCopyOp = dyn_cast&lt;memref::CopyOp&gt;(u.getOwner())) {</div>
<div class="line"><a name="l03327"></a><span class="lineno"> 3327</span>&#160;      assert(isa&lt;MemRefType&gt;(newCopyOp.getTarget().getType()));</div>
<div class="line"><a name="l03328"></a><span class="lineno"> 3328</span>&#160;      <span class="keywordflow">if</span> (newCopyOp.getTarget() != subView)</div>
<div class="line"><a name="l03329"></a><span class="lineno"> 3329</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03330"></a><span class="lineno"> 3330</span>&#160;      <span class="keywordflow">if</span> (<a class="code" href="Vectorization_8cpp.html#a69be050ec61bb7c731b8666ca80f832f">mayExistInterleavedUses</a>(newCopyOp, xferOp, {viewOrAlloc, subView}))</div>
<div class="line"><a name="l03331"></a><span class="lineno"> 3331</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03332"></a><span class="lineno"> 3332</span>&#160;      copyOp = newCopyOp;</div>
<div class="line"><a name="l03333"></a><span class="lineno"> 3333</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03334"></a><span class="lineno"> 3334</span>&#160;    }</div>
<div class="line"><a name="l03335"></a><span class="lineno"> 3335</span>&#160;  }</div>
<div class="line"><a name="l03336"></a><span class="lineno"> 3336</span>&#160;  <span class="keywordflow">if</span> (!copyOp)</div>
<div class="line"><a name="l03337"></a><span class="lineno"> 3337</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;no copy found&quot;</span>);</div>
<div class="line"><a name="l03338"></a><span class="lineno"> 3338</span>&#160; </div>
<div class="line"><a name="l03339"></a><span class="lineno"> 3339</span>&#160;  <span class="comment">// Find the fill into `viewOrAlloc` without interleaved uses before the</span></div>
<div class="line"><a name="l03340"></a><span class="lineno"> 3340</span>&#160;  <span class="comment">// copy.</span></div>
<div class="line"><a name="l03341"></a><span class="lineno"> 3341</span>&#160;  FillOp maybeFillOp;</div>
<div class="line"><a name="l03342"></a><span class="lineno"> 3342</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : viewOrAlloc.<a class="code" href="classmlir_1_1Value.html#a5adc50e42183f2f503143918a296da9d">getUses</a>()) {</div>
<div class="line"><a name="l03343"></a><span class="lineno"> 3343</span>&#160;    <span class="keywordflow">if</span> (<span class="keyword">auto</span> newFillOp = dyn_cast&lt;FillOp&gt;(u.getOwner())) {</div>
<div class="line"><a name="l03344"></a><span class="lineno"> 3344</span>&#160;      assert(isa&lt;MemRefType&gt;(newFillOp.output().getType()));</div>
<div class="line"><a name="l03345"></a><span class="lineno"> 3345</span>&#160;      <span class="keywordflow">if</span> (newFillOp.output() != viewOrAlloc)</div>
<div class="line"><a name="l03346"></a><span class="lineno"> 3346</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03347"></a><span class="lineno"> 3347</span>&#160;      <span class="keywordflow">if</span> (<a class="code" href="Vectorization_8cpp.html#a69be050ec61bb7c731b8666ca80f832f">mayExistInterleavedUses</a>(newFillOp, copyOp, {viewOrAlloc, subView}))</div>
<div class="line"><a name="l03348"></a><span class="lineno"> 3348</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03349"></a><span class="lineno"> 3349</span>&#160;      maybeFillOp = newFillOp;</div>
<div class="line"><a name="l03350"></a><span class="lineno"> 3350</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03351"></a><span class="lineno"> 3351</span>&#160;    }</div>
<div class="line"><a name="l03352"></a><span class="lineno"> 3352</span>&#160;  }</div>
<div class="line"><a name="l03353"></a><span class="lineno"> 3353</span>&#160;  <span class="comment">// Ensure padding matches.</span></div>
<div class="line"><a name="l03354"></a><span class="lineno"> 3354</span>&#160;  <span class="keywordflow">if</span> (maybeFillOp &amp;&amp; xferOp.getPadding() != maybeFillOp.value())</div>
<div class="line"><a name="l03355"></a><span class="lineno"> 3355</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(xferOp,</div>
<div class="line"><a name="l03356"></a><span class="lineno"> 3356</span>&#160;                                       <span class="stringliteral">&quot;padding value does not match fill&quot;</span>);</div>
<div class="line"><a name="l03357"></a><span class="lineno"> 3357</span>&#160; </div>
<div class="line"><a name="l03358"></a><span class="lineno"> 3358</span>&#160;  <span class="comment">// `in` is the subview that memref.copy reads. Replace it.</span></div>
<div class="line"><a name="l03359"></a><span class="lineno"> 3359</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> in = copyOp.getSource();</div>
<div class="line"><a name="l03360"></a><span class="lineno"> 3360</span>&#160; </div>
<div class="line"><a name="l03361"></a><span class="lineno"> 3361</span>&#160;  <span class="comment">// memref.copy + linalg.fill can be used to create a padded local buffer.</span></div>
<div class="line"><a name="l03362"></a><span class="lineno"> 3362</span>&#160;  <span class="comment">// The `masked` attribute is only valid on this padded buffer.</span></div>
<div class="line"><a name="l03363"></a><span class="lineno"> 3363</span>&#160;  <span class="comment">// When forwarding to vector.transfer_read, the attribute must be reset</span></div>
<div class="line"><a name="l03364"></a><span class="lineno"> 3364</span>&#160;  <span class="comment">// conservatively.</span></div>
<div class="line"><a name="l03365"></a><span class="lineno"> 3365</span>&#160;  <span class="keyword">auto</span> vectorType = xferOp.getVectorType();</div>
<div class="line"><a name="l03366"></a><span class="lineno"> 3366</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> res = vector::TransferReadOp::create(</div>
<div class="line"><a name="l03367"></a><span class="lineno"> 3367</span>&#160;      rewriter, xferOp.getLoc(), vectorType, in, xferOp.getIndices(),</div>
<div class="line"><a name="l03368"></a><span class="lineno"> 3368</span>&#160;      xferOp.getPermutationMapAttr(), xferOp.getPadding(), xferOp.getMask(),</div>
<div class="line"><a name="l03369"></a><span class="lineno"> 3369</span>&#160;      rewriter.<a class="code" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(</div>
<div class="line"><a name="l03370"></a><span class="lineno"> 3370</span>&#160;          <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a>(vectorType.getRank(), <span class="keyword">false</span>)));</div>
<div class="line"><a name="l03371"></a><span class="lineno"> 3371</span>&#160; </div>
<div class="line"><a name="l03372"></a><span class="lineno"> 3372</span>&#160;  <span class="keywordflow">if</span> (maybeFillOp)</div>
<div class="line"><a name="l03373"></a><span class="lineno"> 3373</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(maybeFillOp);</div>
<div class="line"><a name="l03374"></a><span class="lineno"> 3374</span>&#160;  rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(copyOp);</div>
<div class="line"><a name="l03375"></a><span class="lineno"> 3375</span>&#160;  rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(xferOp, res);</div>
<div class="line"><a name="l03376"></a><span class="lineno"> 3376</span>&#160; </div>
<div class="line"><a name="l03377"></a><span class="lineno"> 3377</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l03378"></a><span class="lineno"> 3378</span>&#160;}</div>
<div class="line"><a name="l03379"></a><span class="lineno"> 3379</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l03380"></a><span class="lineno"> 3380</span>&#160;<span class="comment">/// TODO: use interfaces, side-effects and aliasing analysis as appropriate,</span></div>
<div class="line"><a name="l03381"></a><span class="lineno"> 3381</span>&#160;<span class="comment">/// when available.</span></div>
<div class="line"><a name="l03382"></a><span class="lineno"><a class="line" href="structmlir_1_1linalg_1_1LinalgCopyVTWForwardingPattern.html#ad61b7c343105b1b58fd0b591d39f97c8"> 3382</a></span>&#160;<span class="comment"></span>LogicalResult <a class="code" href="structmlir_1_1linalg_1_1LinalgCopyVTWForwardingPattern.html#ad61b7c343105b1b58fd0b591d39f97c8">LinalgCopyVTWForwardingPattern::matchAndRewrite</a>(</div>
<div class="line"><a name="l03383"></a><span class="lineno"> 3383</span>&#160;    vector::TransferWriteOp xferOp, <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const </span>{</div>
<div class="line"><a name="l03384"></a><span class="lineno"> 3384</span>&#160;  <span class="comment">// TODO: support mask.</span></div>
<div class="line"><a name="l03385"></a><span class="lineno"> 3385</span>&#160;  <span class="keywordflow">if</span> (xferOp.getMask())</div>
<div class="line"><a name="l03386"></a><span class="lineno"> 3386</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;unsupported mask&quot;</span>);</div>
<div class="line"><a name="l03387"></a><span class="lineno"> 3387</span>&#160; </div>
<div class="line"><a name="l03388"></a><span class="lineno"> 3388</span>&#160;  <span class="comment">// Transfer into `viewOrAlloc`.</span></div>
<div class="line"><a name="l03389"></a><span class="lineno"> 3389</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> viewOrAlloc = xferOp.getBase();</div>
<div class="line"><a name="l03390"></a><span class="lineno"> 3390</span>&#160;  <span class="keywordflow">if</span> (!viewOrAlloc.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;memref::ViewOp&gt;() &amp;&amp;</div>
<div class="line"><a name="l03391"></a><span class="lineno"> 3391</span>&#160;      !viewOrAlloc.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;memref::AllocOp&gt;())</div>
<div class="line"><a name="l03392"></a><span class="lineno"> 3392</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;source not a view or alloc&quot;</span>);</div>
<div class="line"><a name="l03393"></a><span class="lineno"> 3393</span>&#160; </div>
<div class="line"><a name="l03394"></a><span class="lineno"> 3394</span>&#160;  <span class="comment">// Ensure there is exactly one subview of `viewOrAlloc` defining `subView`.</span></div>
<div class="line"><a name="l03395"></a><span class="lineno"> 3395</span>&#160;  memref::SubViewOp subViewOp = <a class="code" href="Vectorization_8cpp.html#a035a7bd3b44d215db6d50b32318822c0">getSubViewUseIfUnique</a>(viewOrAlloc);</div>
<div class="line"><a name="l03396"></a><span class="lineno"> 3396</span>&#160;  <span class="keywordflow">if</span> (!subViewOp)</div>
<div class="line"><a name="l03397"></a><span class="lineno"> 3397</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;no subview found&quot;</span>);</div>
<div class="line"><a name="l03398"></a><span class="lineno"> 3398</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> subView = subViewOp.getResult();</div>
<div class="line"><a name="l03399"></a><span class="lineno"> 3399</span>&#160; </div>
<div class="line"><a name="l03400"></a><span class="lineno"> 3400</span>&#160;  <span class="comment">// Find the copy from `subView` without interleaved uses.</span></div>
<div class="line"><a name="l03401"></a><span class="lineno"> 3401</span>&#160;  memref::CopyOp copyOp;</div>
<div class="line"><a name="l03402"></a><span class="lineno"> 3402</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : subViewOp.getResult().getUses()) {</div>
<div class="line"><a name="l03403"></a><span class="lineno"> 3403</span>&#160;    <span class="keywordflow">if</span> (<span class="keyword">auto</span> newCopyOp = dyn_cast&lt;memref::CopyOp&gt;(u.getOwner())) {</div>
<div class="line"><a name="l03404"></a><span class="lineno"> 3404</span>&#160;      <span class="keywordflow">if</span> (newCopyOp.getSource() != subView)</div>
<div class="line"><a name="l03405"></a><span class="lineno"> 3405</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03406"></a><span class="lineno"> 3406</span>&#160;      <span class="keywordflow">if</span> (<a class="code" href="Vectorization_8cpp.html#a69be050ec61bb7c731b8666ca80f832f">mayExistInterleavedUses</a>(xferOp, newCopyOp, {viewOrAlloc, subView}))</div>
<div class="line"><a name="l03407"></a><span class="lineno"> 3407</span>&#160;        <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l03408"></a><span class="lineno"> 3408</span>&#160;      copyOp = newCopyOp;</div>
<div class="line"><a name="l03409"></a><span class="lineno"> 3409</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03410"></a><span class="lineno"> 3410</span>&#160;    }</div>
<div class="line"><a name="l03411"></a><span class="lineno"> 3411</span>&#160;  }</div>
<div class="line"><a name="l03412"></a><span class="lineno"> 3412</span>&#160;  <span class="keywordflow">if</span> (!copyOp)</div>
<div class="line"><a name="l03413"></a><span class="lineno"> 3413</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;no copy found&quot;</span>);</div>
<div class="line"><a name="l03414"></a><span class="lineno"> 3414</span>&#160; </div>
<div class="line"><a name="l03415"></a><span class="lineno"> 3415</span>&#160;  <span class="comment">// `out` is the subview copied into that we replace.</span></div>
<div class="line"><a name="l03416"></a><span class="lineno"> 3416</span>&#160;  assert(isa&lt;MemRefType&gt;(copyOp.getTarget().getType()));</div>
<div class="line"><a name="l03417"></a><span class="lineno"> 3417</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> out = copyOp.getTarget();</div>
<div class="line"><a name="l03418"></a><span class="lineno"> 3418</span>&#160; </div>
<div class="line"><a name="l03419"></a><span class="lineno"> 3419</span>&#160;  <span class="comment">// Forward vector.transfer into copy.</span></div>
<div class="line"><a name="l03420"></a><span class="lineno"> 3420</span>&#160;  <span class="comment">// memref.copy + linalg.fill can be used to create a padded local buffer.</span></div>
<div class="line"><a name="l03421"></a><span class="lineno"> 3421</span>&#160;  <span class="comment">// The `masked` attribute is only valid on this padded buffer.</span></div>
<div class="line"><a name="l03422"></a><span class="lineno"> 3422</span>&#160;  <span class="comment">// When forwarding to vector.transfer_write, the attribute must be reset</span></div>
<div class="line"><a name="l03423"></a><span class="lineno"> 3423</span>&#160;  <span class="comment">// conservatively.</span></div>
<div class="line"><a name="l03424"></a><span class="lineno"> 3424</span>&#160;  <span class="keyword">auto</span> vector = xferOp.getVector();</div>
<div class="line"><a name="l03425"></a><span class="lineno"> 3425</span>&#160;  vector::TransferWriteOp::create(</div>
<div class="line"><a name="l03426"></a><span class="lineno"> 3426</span>&#160;      rewriter, xferOp.getLoc(), vector, out, xferOp.getIndices(),</div>
<div class="line"><a name="l03427"></a><span class="lineno"> 3427</span>&#160;      xferOp.getPermutationMapAttr(), xferOp.getMask(),</div>
<div class="line"><a name="l03428"></a><span class="lineno"> 3428</span>&#160;      rewriter.<a class="code" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(<a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a>(</div>
<div class="line"><a name="l03429"></a><span class="lineno"> 3429</span>&#160;          dyn_cast&lt;VectorType&gt;(vector.getType()).getRank(), <span class="keyword">false</span>)));</div>
<div class="line"><a name="l03430"></a><span class="lineno"> 3430</span>&#160; </div>
<div class="line"><a name="l03431"></a><span class="lineno"> 3431</span>&#160;  rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(copyOp);</div>
<div class="line"><a name="l03432"></a><span class="lineno"> 3432</span>&#160;  rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(xferOp);</div>
<div class="line"><a name="l03433"></a><span class="lineno"> 3433</span>&#160; </div>
<div class="line"><a name="l03434"></a><span class="lineno"> 3434</span>&#160;  <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l03435"></a><span class="lineno"> 3435</span>&#160;}</div>
<div class="line"><a name="l03436"></a><span class="lineno"> 3436</span>&#160; </div>
<div class="line"><a name="l03437"></a><span class="lineno"> 3437</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l03438"></a><span class="lineno"> 3438</span>&#160;<span class="comment">// Convolution vectorization patterns</span></div>
<div class="line"><a name="l03439"></a><span class="lineno"> 3439</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l03440"></a><span class="lineno"> 3440</span>&#160; </div>
<div class="line"><a name="l03441"></a><span class="lineno"> 3441</span>&#160;<span class="keyword">template</span> &lt;<span class="keywordtype">int</span> N&gt;</div>
<div class="line"><a name="l03442"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266"> 3442</a></span>&#160;<span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(ShapedType shapedType) {}</div>
<div class="line"><a name="l03443"></a><span class="lineno"> 3443</span>&#160; </div>
<div class="line"><a name="l03444"></a><span class="lineno"> 3444</span>&#160;<span class="keyword">template</span> &lt;<span class="keywordtype">int</span> N, <span class="keyword">typename</span> IntTy, <span class="keyword">typename</span>... IntTy2&gt;</div>
<div class="line"><a name="l03445"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a733cad761b049560f9c8e85ff51e722e"> 3445</a></span>&#160;<span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(ShapedType shapedType, IntTy &amp;val, IntTy2 &amp;...vals) {</div>
<div class="line"><a name="l03446"></a><span class="lineno"> 3446</span>&#160;  val = shapedType.getShape()[N];</div>
<div class="line"><a name="l03447"></a><span class="lineno"> 3447</span>&#160;  <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>&lt;N + 1, IntTy2 &amp;...&gt;(shapedType, vals...);</div>
<div class="line"><a name="l03448"></a><span class="lineno"> 3448</span>&#160;}</div>
<div class="line"><a name="l03449"></a><span class="lineno"> 3449</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l03450"></a><span class="lineno"> 3450</span>&#160;<span class="comment">/// Bind a pack of int&amp; to the leading dimensions of shapedType.getShape().</span></div>
<div class="line"><a name="l03451"></a><span class="lineno"> 3451</span>&#160;<span class="comment"></span><span class="keyword">template</span> &lt;<span class="keyword">typename</span>... IntTy&gt;</div>
<div class="line"><a name="l03452"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a3dc8c9f4f7a24f5ad59b3df2eaf2b949"> 3452</a></span>&#160;<span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(ShapedType shapedType, IntTy &amp;...vals) {</div>
<div class="line"><a name="l03453"></a><span class="lineno"> 3453</span>&#160;  bindShapeDims&lt;0&gt;(shapedType, vals...);</div>
<div class="line"><a name="l03454"></a><span class="lineno"> 3454</span>&#160;}</div>
<div class="line"><a name="l03455"></a><span class="lineno"> 3455</span>&#160; </div>
<div class="line"><a name="l03456"></a><span class="lineno"> 3456</span>&#160;<span class="keyword">namespace </span>{<span class="comment"></span></div>
<div class="line"><a name="l03457"></a><span class="lineno"> 3457</span>&#160;<span class="comment">/// Generate a vector implementation for either:</span></div>
<div class="line"><a name="l03458"></a><span class="lineno"> 3458</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03459"></a><span class="lineno"> 3459</span>&#160;<span class="comment">///   Op def: (     w,     kw  )</span></div>
<div class="line"><a name="l03460"></a><span class="lineno"> 3460</span>&#160;<span class="comment">///    Iters: ({Par(), Red()})</span></div>
<div class="line"><a name="l03461"></a><span class="lineno"> 3461</span>&#160;<span class="comment">///   Layout: {{w + kw}, {kw}, {w}}</span></div>
<div class="line"><a name="l03462"></a><span class="lineno"> 3462</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03463"></a><span class="lineno"> 3463</span>&#160;<span class="comment">/// kw is unrolled.</span></div>
<div class="line"><a name="l03464"></a><span class="lineno"> 3464</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l03465"></a><span class="lineno"> 3465</span>&#160;<span class="comment">/// or</span></div>
<div class="line"><a name="l03466"></a><span class="lineno"> 3466</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l03467"></a><span class="lineno"> 3467</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03468"></a><span class="lineno"> 3468</span>&#160;<span class="comment">///   Op def: (     n,     w,     c,    kw,    f  )</span></div>
<div class="line"><a name="l03469"></a><span class="lineno"> 3469</span>&#160;<span class="comment">///    Iters: ({Par(), Par(), Par(), Red(), Red()})</span></div>
<div class="line"><a name="l03470"></a><span class="lineno"> 3470</span>&#160;<span class="comment">///   Layout: {{n, strideW * w + dilationW * kw, c}, {kw, c, f}, {n, w, f}}</span></div>
<div class="line"><a name="l03471"></a><span class="lineno"> 3471</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03472"></a><span class="lineno"> 3472</span>&#160;<span class="comment">/// kw is unrolled, w is unrolled iff dilationW &gt; 1.</span></div>
<div class="line"><a name="l03473"></a><span class="lineno"> 3473</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l03474"></a><span class="lineno"> 3474</span>&#160;<span class="comment">/// or</span></div>
<div class="line"><a name="l03475"></a><span class="lineno"> 3475</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l03476"></a><span class="lineno"> 3476</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03477"></a><span class="lineno"> 3477</span>&#160;<span class="comment">///   Op def: (     n,     c,     w,    f,    kw )</span></div>
<div class="line"><a name="l03478"></a><span class="lineno"> 3478</span>&#160;<span class="comment">///    Iters: ({Par(), Par(), Par(), Red(), Red()})</span></div>
<div class="line"><a name="l03479"></a><span class="lineno"> 3479</span>&#160;<span class="comment">///   Layout: {{n, c, strideW * w + dilationW * kw}, {f, c, kw}, {n, f, w}}</span></div>
<div class="line"><a name="l03480"></a><span class="lineno"> 3480</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03481"></a><span class="lineno"> 3481</span>&#160;<span class="comment">/// kw is unrolled, w is unrolled iff dilationW &gt; 1.</span></div>
<div class="line"><a name="l03482"></a><span class="lineno"> 3482</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l03483"></a><span class="lineno"> 3483</span>&#160;<span class="comment">/// or</span></div>
<div class="line"><a name="l03484"></a><span class="lineno"> 3484</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l03485"></a><span class="lineno"> 3485</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03486"></a><span class="lineno"> 3486</span>&#160;<span class="comment">///   Op def: (     n,     w,     c,    kw )</span></div>
<div class="line"><a name="l03487"></a><span class="lineno"> 3487</span>&#160;<span class="comment">///    Iters: ({Par(), Par(), Par(), Red()})</span></div>
<div class="line"><a name="l03488"></a><span class="lineno"> 3488</span>&#160;<span class="comment">///   Layout: {{n, strideW * w + dilationW * kw, c}, {kw, c}, {n, w, c}}</span></div>
<div class="line"><a name="l03489"></a><span class="lineno"> 3489</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l03490"></a><span class="lineno"> 3490</span>&#160;<span class="comment">/// kw is unrolled, w is unrolled iff dilationW &gt; 1.</span></div>
<div class="line"><a name="l03491"></a><span class="lineno"> 3491</span>&#160;<span class="comment"></span><span class="keyword">struct </span>Conv1DGenerator</div>
<div class="line"><a name="l03492"></a><span class="lineno"> 3492</span>&#160;    : <span class="keyword">public</span> <a class="code" href="classmlir_1_1StructuredGenerator.html">StructuredGenerator</a>&lt;LinalgOp, utils::IteratorType&gt; {</div>
<div class="line"><a name="l03493"></a><span class="lineno"> 3493</span>&#160;  Conv1DGenerator(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, LinalgOp linalgOp)</div>
<div class="line"><a name="l03494"></a><span class="lineno"> 3494</span>&#160;      : <a class="code" href="classmlir_1_1StructuredGenerator.html">StructuredGenerator</a>&lt;LinalgOp, utils::IteratorType&gt;(rewriter, linalgOp) {</div>
<div class="line"><a name="l03495"></a><span class="lineno"> 3495</span>&#160; </div>
<div class="line"><a name="l03496"></a><span class="lineno"> 3496</span>&#160;    lhsShaped = linalgOp.getDpsInputOperand(0)-&gt;get();</div>
<div class="line"><a name="l03497"></a><span class="lineno"> 3497</span>&#160;    rhsShaped = linalgOp.getDpsInputOperand(1)-&gt;get();</div>
<div class="line"><a name="l03498"></a><span class="lineno"> 3498</span>&#160;    resShaped = linalgOp.getDpsInitOperand(0)-&gt;get();</div>
<div class="line"><a name="l03499"></a><span class="lineno"> 3499</span>&#160;    lhsShapedType = dyn_cast&lt;ShapedType&gt;(lhsShaped.getType());</div>
<div class="line"><a name="l03500"></a><span class="lineno"> 3500</span>&#160;    rhsShapedType = dyn_cast&lt;ShapedType&gt;(rhsShaped.getType());</div>
<div class="line"><a name="l03501"></a><span class="lineno"> 3501</span>&#160;    resShapedType = dyn_cast&lt;ShapedType&gt;(resShaped.getType());</div>
<div class="line"><a name="l03502"></a><span class="lineno"> 3502</span>&#160; </div>
<div class="line"><a name="l03503"></a><span class="lineno"> 3503</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *reduceOp = <a class="code" href="Vectorization_8cpp.html#a69cbb7a1a1669d28a2e2f4b221a2132f">matchLinalgReduction</a>(linalgOp.getDpsInitOperand(0));</div>
<div class="line"><a name="l03504"></a><span class="lineno"> 3504</span>&#160;    redOp = reduceOp-&gt;<a class="code" href="classmlir_1_1Operation.html#ab2e11ba83ff765eb7595554f97aaaa75">getName</a>().<a class="code" href="classmlir_1_1OperationName.html#a2c83cffa9a4c4fb68436d9ee3497c226">getIdentifier</a>();</div>
<div class="line"><a name="l03505"></a><span class="lineno"> 3505</span>&#160; </div>
<div class="line"><a name="l03506"></a><span class="lineno"> 3506</span>&#160;    setConvOperationKind(reduceOp);</div>
<div class="line"><a name="l03507"></a><span class="lineno"> 3507</span>&#160; </div>
<div class="line"><a name="l03508"></a><span class="lineno"> 3508</span>&#160;    <span class="keyword">auto</span> maybeKind = <a class="code" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp);</div>
<div class="line"><a name="l03509"></a><span class="lineno"> 3509</span>&#160;    reductionKind = maybeKind.value();</div>
<div class="line"><a name="l03510"></a><span class="lineno"> 3510</span>&#160; </div>
<div class="line"><a name="l03511"></a><span class="lineno"> 3511</span>&#160;    <span class="comment">// The ConvolutionOpInterface gives us guarantees of existence for</span></div>
<div class="line"><a name="l03512"></a><span class="lineno"> 3512</span>&#160;    <span class="comment">// strides/dilations. However, we do not need to rely on those, we can</span></div>
<div class="line"><a name="l03513"></a><span class="lineno"> 3513</span>&#160;    <span class="comment">// simply use them if present, otherwise use the default and let the generic</span></div>
<div class="line"><a name="l03514"></a><span class="lineno"> 3514</span>&#160;    <span class="comment">// conv. matcher in the ConvGenerator succeed or fail.</span></div>
<div class="line"><a name="l03515"></a><span class="lineno"> 3515</span>&#160;    <span class="keyword">auto</span> strides = linalgOp-&gt;getAttrOfType&lt;<a class="code" href="classmlir_1_1DenseIntElementsAttr.html">DenseIntElementsAttr</a>&gt;(<span class="stringliteral">&quot;strides&quot;</span>);</div>
<div class="line"><a name="l03516"></a><span class="lineno"> 3516</span>&#160;    <span class="keyword">auto</span> dilations = linalgOp-&gt;getAttrOfType&lt;<a class="code" href="classmlir_1_1DenseIntElementsAttr.html">DenseIntElementsAttr</a>&gt;(<span class="stringliteral">&quot;dilations&quot;</span>);</div>
<div class="line"><a name="l03517"></a><span class="lineno"> 3517</span>&#160;    strideW = strides ? *strides.getValues&lt;uint64_t&gt;().begin() : 1;</div>
<div class="line"><a name="l03518"></a><span class="lineno"> 3518</span>&#160;    dilationW = dilations ? *dilations.getValues&lt;uint64_t&gt;().begin() : 1;</div>
<div class="line"><a name="l03519"></a><span class="lineno"> 3519</span>&#160;  }</div>
<div class="line"><a name="l03520"></a><span class="lineno"> 3520</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l03521"></a><span class="lineno"> 3521</span>&#160;<span class="comment">  /// Generate a vector implementation for:</span></div>
<div class="line"><a name="l03522"></a><span class="lineno"> 3522</span>&#160;<span class="comment">  /// ```</span></div>
<div class="line"><a name="l03523"></a><span class="lineno"> 3523</span>&#160;<span class="comment">  ///   Op def: (     w,     kw  )</span></div>
<div class="line"><a name="l03524"></a><span class="lineno"> 3524</span>&#160;<span class="comment">  ///    Iters: ({Par(), Red()})</span></div>
<div class="line"><a name="l03525"></a><span class="lineno"> 3525</span>&#160;<span class="comment">  ///   Layout: {{w + kw}, {kw}, {w}}</span></div>
<div class="line"><a name="l03526"></a><span class="lineno"> 3526</span>&#160;<span class="comment">  /// ```</span></div>
<div class="line"><a name="l03527"></a><span class="lineno"> 3527</span>&#160;<span class="comment">  /// kw is always unrolled.</span></div>
<div class="line"><a name="l03528"></a><span class="lineno"> 3528</span>&#160;<span class="comment">  ///</span></div>
<div class="line"><a name="l03529"></a><span class="lineno"> 3529</span>&#160;<span class="comment">  /// or</span></div>
<div class="line"><a name="l03530"></a><span class="lineno"> 3530</span>&#160;<span class="comment">  ///</span></div>
<div class="line"><a name="l03531"></a><span class="lineno"> 3531</span>&#160;<span class="comment">  /// ```</span></div>
<div class="line"><a name="l03532"></a><span class="lineno"> 3532</span>&#160;<span class="comment">  ///   Op def: (     n,     w,     c,    kw,    f  )</span></div>
<div class="line"><a name="l03533"></a><span class="lineno"> 3533</span>&#160;<span class="comment">  ///    Iters: ({Par(), Par(), Par(), Red(), Red()})</span></div>
<div class="line"><a name="l03534"></a><span class="lineno"> 3534</span>&#160;<span class="comment">  ///   Layout: {{n, strideW * w + dilationW * kw, c}, {kw, c, f}, {n, w, f}}</span></div>
<div class="line"><a name="l03535"></a><span class="lineno"> 3535</span>&#160;<span class="comment">  /// ```</span></div>
<div class="line"><a name="l03536"></a><span class="lineno"> 3536</span>&#160;<span class="comment">  /// kw is always unrolled.</span></div>
<div class="line"><a name="l03537"></a><span class="lineno"> 3537</span>&#160;<span class="comment">  /// TODO: w (resp. kw) is unrolled when the strideW ( resp. dilationW) is</span></div>
<div class="line"><a name="l03538"></a><span class="lineno"> 3538</span>&#160;<span class="comment">  /// &gt; 1.</span></div>
<div class="line"><a name="l03539"></a><span class="lineno"> 3539</span>&#160;<span class="comment"></span>  FailureOr&lt;Operation *&gt; conv(<a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fec">Conv1DOpOrder</a> conv1DOpOrder) {</div>
<div class="line"><a name="l03540"></a><span class="lineno"> 3540</span>&#160;    int64_t nSize, wSize, cSize, kwSize, fSize;</div>
<div class="line"><a name="l03541"></a><span class="lineno"> 3541</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t, 3&gt;</a> lhsShape, rhsShape, resShape;</div>
<div class="line"><a name="l03542"></a><span class="lineno"> 3542</span>&#160;    <span class="keywordtype">bool</span> isSingleChanneled = (conv1DOpOrder == <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>);</div>
<div class="line"><a name="l03543"></a><span class="lineno"> 3543</span>&#160;    <span class="keywordflow">switch</span> (conv1DOpOrder) {</div>
<div class="line"><a name="l03544"></a><span class="lineno"> 3544</span>&#160;    <span class="keywordflow">case</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>:</div>
<div class="line"><a name="l03545"></a><span class="lineno"> 3545</span>&#160;      <span class="comment">// Initialize unused dimensions</span></div>
<div class="line"><a name="l03546"></a><span class="lineno"> 3546</span>&#160;      nSize = fSize = cSize = 0;</div>
<div class="line"><a name="l03547"></a><span class="lineno"> 3547</span>&#160;      <span class="comment">// out{W}</span></div>
<div class="line"><a name="l03548"></a><span class="lineno"> 3548</span>&#160;      <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(resShapedType, wSize);</div>
<div class="line"><a name="l03549"></a><span class="lineno"> 3549</span>&#160;      <span class="comment">// kernel{kw}</span></div>
<div class="line"><a name="l03550"></a><span class="lineno"> 3550</span>&#160;      <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(rhsShapedType, kwSize);</div>
<div class="line"><a name="l03551"></a><span class="lineno"> 3551</span>&#160;      lhsShape = {<span class="comment">// iw = ow + kw - 1</span></div>
<div class="line"><a name="l03552"></a><span class="lineno"> 3552</span>&#160;                  <span class="comment">//   (i.e. 16 convolved with 3 -&gt; 14)</span></div>
<div class="line"><a name="l03553"></a><span class="lineno"> 3553</span>&#160;                  (wSize + kwSize - 1)};</div>
<div class="line"><a name="l03554"></a><span class="lineno"> 3554</span>&#160;      rhsShape = {kwSize};</div>
<div class="line"><a name="l03555"></a><span class="lineno"> 3555</span>&#160;      resShape = {wSize};</div>
<div class="line"><a name="l03556"></a><span class="lineno"> 3556</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03557"></a><span class="lineno"> 3557</span>&#160;    <span class="keywordflow">case</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>:</div>
<div class="line"><a name="l03558"></a><span class="lineno"> 3558</span>&#160;      <span class="comment">// out{n, w, f}</span></div>
<div class="line"><a name="l03559"></a><span class="lineno"> 3559</span>&#160;      <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(resShapedType, nSize, wSize, fSize);</div>
<div class="line"><a name="l03560"></a><span class="lineno"> 3560</span>&#160;      <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a name="l03561"></a><span class="lineno"> 3561</span>&#160;      <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a name="l03562"></a><span class="lineno"> 3562</span>&#160;        <span class="comment">// kernel{kw, c, f}</span></div>
<div class="line"><a name="l03563"></a><span class="lineno"> 3563</span>&#160;        <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(rhsShapedType, kwSize, cSize);</div>
<div class="line"><a name="l03564"></a><span class="lineno"> 3564</span>&#160;        <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03565"></a><span class="lineno"> 3565</span>&#160;      <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a name="l03566"></a><span class="lineno"> 3566</span>&#160;        <span class="comment">// kernel{kw}</span></div>
<div class="line"><a name="l03567"></a><span class="lineno"> 3567</span>&#160;        <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(rhsShapedType, kwSize);</div>
<div class="line"><a name="l03568"></a><span class="lineno"> 3568</span>&#160;        cSize = fSize;</div>
<div class="line"><a name="l03569"></a><span class="lineno"> 3569</span>&#160;        <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03570"></a><span class="lineno"> 3570</span>&#160;      }</div>
<div class="line"><a name="l03571"></a><span class="lineno"> 3571</span>&#160;      lhsShape = {nSize,</div>
<div class="line"><a name="l03572"></a><span class="lineno"> 3572</span>&#160;                  <span class="comment">// iw = ow * sw + kw *  dw - 1</span></div>
<div class="line"><a name="l03573"></a><span class="lineno"> 3573</span>&#160;                  <span class="comment">//   (i.e. 16 convolved with 3 (@stride 1 dilation 1) -&gt; 14)</span></div>
<div class="line"><a name="l03574"></a><span class="lineno"> 3574</span>&#160;                  <span class="comment">// Perform the proper inclusive -&gt; exclusive -&gt; inclusive.</span></div>
<div class="line"><a name="l03575"></a><span class="lineno"> 3575</span>&#160;                  ((wSize - 1) * strideW + 1) + ((kwSize - 1) * dilationW + 1) -</div>
<div class="line"><a name="l03576"></a><span class="lineno"> 3576</span>&#160;                      1,</div>
<div class="line"><a name="l03577"></a><span class="lineno"> 3577</span>&#160;                  cSize};</div>
<div class="line"><a name="l03578"></a><span class="lineno"> 3578</span>&#160;      <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a name="l03579"></a><span class="lineno"> 3579</span>&#160;      <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a name="l03580"></a><span class="lineno"> 3580</span>&#160;        rhsShape = {kwSize, cSize, fSize};</div>
<div class="line"><a name="l03581"></a><span class="lineno"> 3581</span>&#160;        <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03582"></a><span class="lineno"> 3582</span>&#160;      <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a name="l03583"></a><span class="lineno"> 3583</span>&#160;        rhsShape = {kwSize};</div>
<div class="line"><a name="l03584"></a><span class="lineno"> 3584</span>&#160;        <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03585"></a><span class="lineno"> 3585</span>&#160;      }</div>
<div class="line"><a name="l03586"></a><span class="lineno"> 3586</span>&#160;      resShape = {nSize, wSize, fSize};</div>
<div class="line"><a name="l03587"></a><span class="lineno"> 3587</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03588"></a><span class="lineno"> 3588</span>&#160;    <span class="keywordflow">case</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>:</div>
<div class="line"><a name="l03589"></a><span class="lineno"> 3589</span>&#160;      <span class="comment">// out{n, f, w}</span></div>
<div class="line"><a name="l03590"></a><span class="lineno"> 3590</span>&#160;      <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(resShapedType, nSize, fSize, wSize);</div>
<div class="line"><a name="l03591"></a><span class="lineno"> 3591</span>&#160;      <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a name="l03592"></a><span class="lineno"> 3592</span>&#160;      <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a name="l03593"></a><span class="lineno"> 3593</span>&#160;        <span class="comment">// kernel{f, c, kw}</span></div>
<div class="line"><a name="l03594"></a><span class="lineno"> 3594</span>&#160;        <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(rhsShapedType, fSize, cSize, kwSize);</div>
<div class="line"><a name="l03595"></a><span class="lineno"> 3595</span>&#160;        <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03596"></a><span class="lineno"> 3596</span>&#160;      <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a name="l03597"></a><span class="lineno"> 3597</span>&#160;        <span class="comment">// kernel{kw}</span></div>
<div class="line"><a name="l03598"></a><span class="lineno"> 3598</span>&#160;        <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(rhsShapedType, kwSize);</div>
<div class="line"><a name="l03599"></a><span class="lineno"> 3599</span>&#160;        cSize = fSize;</div>
<div class="line"><a name="l03600"></a><span class="lineno"> 3600</span>&#160;        <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03601"></a><span class="lineno"> 3601</span>&#160;      }</div>
<div class="line"><a name="l03602"></a><span class="lineno"> 3602</span>&#160;      lhsShape = {nSize, cSize,</div>
<div class="line"><a name="l03603"></a><span class="lineno"> 3603</span>&#160;                  <span class="comment">// iw = ow * sw + kw *  dw - 1</span></div>
<div class="line"><a name="l03604"></a><span class="lineno"> 3604</span>&#160;                  <span class="comment">//   (i.e. 16 convolved with 3 (@stride 1 dilation 1) -&gt; 14)</span></div>
<div class="line"><a name="l03605"></a><span class="lineno"> 3605</span>&#160;                  <span class="comment">// Perform the proper inclusive -&gt; exclusive -&gt; inclusive.</span></div>
<div class="line"><a name="l03606"></a><span class="lineno"> 3606</span>&#160;                  ((wSize - 1) * strideW + 1) + ((kwSize - 1) * dilationW + 1) -</div>
<div class="line"><a name="l03607"></a><span class="lineno"> 3607</span>&#160;                      1};</div>
<div class="line"><a name="l03608"></a><span class="lineno"> 3608</span>&#160;      <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a name="l03609"></a><span class="lineno"> 3609</span>&#160;      <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a name="l03610"></a><span class="lineno"> 3610</span>&#160;        rhsShape = {fSize, cSize, kwSize};</div>
<div class="line"><a name="l03611"></a><span class="lineno"> 3611</span>&#160;        <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03612"></a><span class="lineno"> 3612</span>&#160;      <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a name="l03613"></a><span class="lineno"> 3613</span>&#160;        rhsShape = {kwSize};</div>
<div class="line"><a name="l03614"></a><span class="lineno"> 3614</span>&#160;        <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03615"></a><span class="lineno"> 3615</span>&#160;      }</div>
<div class="line"><a name="l03616"></a><span class="lineno"> 3616</span>&#160;      resShape = {nSize, fSize, wSize};</div>
<div class="line"><a name="l03617"></a><span class="lineno"> 3617</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03618"></a><span class="lineno"> 3618</span>&#160;    }</div>
<div class="line"><a name="l03619"></a><span class="lineno"> 3619</span>&#160; </div>
<div class="line"><a name="l03620"></a><span class="lineno"> 3620</span>&#160;    vector::TransferWriteOp write;</div>
<div class="line"><a name="l03621"></a><span class="lineno"> 3621</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> zero = <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0);</div>
<div class="line"><a name="l03622"></a><span class="lineno"> 3622</span>&#160; </div>
<div class="line"><a name="l03623"></a><span class="lineno"> 3623</span>&#160;    <span class="comment">// w is unrolled (i.e. wSizeStep == 1) iff strideW &gt; 1.</span></div>
<div class="line"><a name="l03624"></a><span class="lineno"> 3624</span>&#160;    <span class="comment">// When strideW == 1, we can batch the contiguous loads and avoid</span></div>
<div class="line"><a name="l03625"></a><span class="lineno"> 3625</span>&#160;    <span class="comment">// unrolling</span></div>
<div class="line"><a name="l03626"></a><span class="lineno"> 3626</span>&#160;    int64_t wSizeStep = strideW == 1 ? wSize : 1;</div>
<div class="line"><a name="l03627"></a><span class="lineno"> 3627</span>&#160; </div>
<div class="line"><a name="l03628"></a><span class="lineno"> 3628</span>&#160;    <a class="code" href="classmlir_1_1Type.html">Type</a> lhsEltType = lhsShapedType.getElementType();</div>
<div class="line"><a name="l03629"></a><span class="lineno"> 3629</span>&#160;    <a class="code" href="classmlir_1_1Type.html">Type</a> rhsEltType = rhsShapedType.getElementType();</div>
<div class="line"><a name="l03630"></a><span class="lineno"> 3630</span>&#160;    <a class="code" href="classmlir_1_1Type.html">Type</a> resEltType = resShapedType.getElementType();</div>
<div class="line"><a name="l03631"></a><span class="lineno"> 3631</span>&#160;    <span class="keyword">auto</span> lhsType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(lhsShape, lhsEltType);</div>
<div class="line"><a name="l03632"></a><span class="lineno"> 3632</span>&#160;    <span class="keyword">auto</span> rhsType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(rhsShape, rhsEltType);</div>
<div class="line"><a name="l03633"></a><span class="lineno"> 3633</span>&#160;    <span class="keyword">auto</span> resType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(resShape, resEltType);</div>
<div class="line"><a name="l03634"></a><span class="lineno"> 3634</span>&#160;    <span class="comment">// Zero padding with the corresponding dimensions for lhs, rhs and res.</span></div>
<div class="line"><a name="l03635"></a><span class="lineno"> 3635</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> lhsPadding(lhsShape.size(), zero);</div>
<div class="line"><a name="l03636"></a><span class="lineno"> 3636</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> rhsPadding(rhsShape.size(), zero);</div>
<div class="line"><a name="l03637"></a><span class="lineno"> 3637</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> resPadding(resShape.size(), zero);</div>
<div class="line"><a name="l03638"></a><span class="lineno"> 3638</span>&#160; </div>
<div class="line"><a name="l03639"></a><span class="lineno"> 3639</span>&#160;    <span class="comment">// Read the whole lhs, rhs and res in one shot (with zero padding).</span></div>
<div class="line"><a name="l03640"></a><span class="lineno"> 3640</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> lhs = vector::TransferReadOp::create(</div>
<div class="line"><a name="l03641"></a><span class="lineno"> 3641</span>&#160;        rewriter, loc, lhsType, lhsShaped, lhsPadding,</div>
<div class="line"><a name="l03642"></a><span class="lineno"> 3642</span>&#160;        <span class="comment">/*padding=*/</span><a class="code" href="namespacemlir_1_1arith.html#af73ab4d70d330c6212d9ccd87a38056b">arith::getZeroConstant</a>(rewriter, loc, lhsEltType));</div>
<div class="line"><a name="l03643"></a><span class="lineno"> 3643</span>&#160;    <span class="comment">// This is needed only for Conv.</span></div>
<div class="line"><a name="l03644"></a><span class="lineno"> 3644</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> rhs = <span class="keyword">nullptr</span>;</div>
<div class="line"><a name="l03645"></a><span class="lineno"> 3645</span>&#160;    <span class="keywordflow">if</span> (oper == ConvOperationKind::Conv)</div>
<div class="line"><a name="l03646"></a><span class="lineno"> 3646</span>&#160;      rhs = vector::TransferReadOp::create(</div>
<div class="line"><a name="l03647"></a><span class="lineno"> 3647</span>&#160;          rewriter, loc, rhsType, rhsShaped, rhsPadding,</div>
<div class="line"><a name="l03648"></a><span class="lineno"> 3648</span>&#160;          <span class="comment">/*padding=*/</span><a class="code" href="namespacemlir_1_1arith.html#af73ab4d70d330c6212d9ccd87a38056b">arith::getZeroConstant</a>(rewriter, loc, rhsEltType));</div>
<div class="line"><a name="l03649"></a><span class="lineno"> 3649</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> res = vector::TransferReadOp::create(</div>
<div class="line"><a name="l03650"></a><span class="lineno"> 3650</span>&#160;        rewriter, loc, resType, resShaped, resPadding,</div>
<div class="line"><a name="l03651"></a><span class="lineno"> 3651</span>&#160;        <span class="comment">/*padding=*/</span><a class="code" href="namespacemlir_1_1arith.html#af73ab4d70d330c6212d9ccd87a38056b">arith::getZeroConstant</a>(rewriter, loc, resEltType));</div>
<div class="line"><a name="l03652"></a><span class="lineno"> 3652</span>&#160; </div>
<div class="line"><a name="l03653"></a><span class="lineno"> 3653</span>&#160;    <span class="comment">// The base vectorization case for channeled convolution is input:</span></div>
<div class="line"><a name="l03654"></a><span class="lineno"> 3654</span>&#160;    <span class="comment">// {n,w,c}, weight: {kw,c,f}, output: {n,w,f}. To reuse the base pattern</span></div>
<div class="line"><a name="l03655"></a><span class="lineno"> 3655</span>&#160;    <span class="comment">// vectorization case, we do pre transpose on input, weight, and output.</span></div>
<div class="line"><a name="l03656"></a><span class="lineno"> 3656</span>&#160;    <span class="keywordflow">switch</span> (conv1DOpOrder) {</div>
<div class="line"><a name="l03657"></a><span class="lineno"> 3657</span>&#160;    <span class="keywordflow">case</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>:</div>
<div class="line"><a name="l03658"></a><span class="lineno"> 3658</span>&#160;    <span class="keywordflow">case</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>:</div>
<div class="line"><a name="l03659"></a><span class="lineno"> 3659</span>&#160;      <span class="comment">// Base case, so no transposes necessary.</span></div>
<div class="line"><a name="l03660"></a><span class="lineno"> 3660</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03661"></a><span class="lineno"> 3661</span>&#160;    <span class="keywordflow">case</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>: {</div>
<div class="line"><a name="l03662"></a><span class="lineno"> 3662</span>&#160;      <span class="comment">// To match base vectorization case, we pre-transpose current case.</span></div>
<div class="line"><a name="l03663"></a><span class="lineno"> 3663</span>&#160;      <span class="comment">// ncw -&gt; nwc</span></div>
<div class="line"><a name="l03664"></a><span class="lineno"> 3664</span>&#160;      <span class="keyword">static</span> constexpr std::array&lt;int64_t, 3&gt; permLhs = {0, 2, 1};</div>
<div class="line"><a name="l03665"></a><span class="lineno"> 3665</span>&#160;      lhs = vector::TransposeOp::create(rewriter, loc, lhs, permLhs);</div>
<div class="line"><a name="l03666"></a><span class="lineno"> 3666</span>&#160;      <span class="comment">// fcw -&gt; wcf</span></div>
<div class="line"><a name="l03667"></a><span class="lineno"> 3667</span>&#160;      <span class="keyword">static</span> constexpr std::array&lt;int64_t, 3&gt; permRhs = {2, 1, 0};</div>
<div class="line"><a name="l03668"></a><span class="lineno"> 3668</span>&#160; </div>
<div class="line"><a name="l03669"></a><span class="lineno"> 3669</span>&#160;      <span class="comment">// This is needed only for Conv.</span></div>
<div class="line"><a name="l03670"></a><span class="lineno"> 3670</span>&#160;      <span class="keywordflow">if</span> (oper == ConvOperationKind::Conv)</div>
<div class="line"><a name="l03671"></a><span class="lineno"> 3671</span>&#160;        rhs = vector::TransposeOp::create(rewriter, loc, rhs, permRhs);</div>
<div class="line"><a name="l03672"></a><span class="lineno"> 3672</span>&#160;      <span class="comment">// nfw -&gt; nwf</span></div>
<div class="line"><a name="l03673"></a><span class="lineno"> 3673</span>&#160;      <span class="keyword">static</span> constexpr std::array&lt;int64_t, 3&gt; permRes = {0, 2, 1};</div>
<div class="line"><a name="l03674"></a><span class="lineno"> 3674</span>&#160;      res = vector::TransposeOp::create(rewriter, loc, res, permRes);</div>
<div class="line"><a name="l03675"></a><span class="lineno"> 3675</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03676"></a><span class="lineno"> 3676</span>&#160;    }</div>
<div class="line"><a name="l03677"></a><span class="lineno"> 3677</span>&#160;    }</div>
<div class="line"><a name="l03678"></a><span class="lineno"> 3678</span>&#160; </div>
<div class="line"><a name="l03679"></a><span class="lineno"> 3679</span>&#160;    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l03680"></a><span class="lineno"> 3680</span>&#160;    <span class="comment">// Begin vector-only rewrite part</span></div>
<div class="line"><a name="l03681"></a><span class="lineno"> 3681</span>&#160;    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l03682"></a><span class="lineno"> 3682</span>&#160;    <span class="comment">// Unroll along kw and read slices of lhs and rhs.</span></div>
<div class="line"><a name="l03683"></a><span class="lineno"> 3683</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> lhsVals, rhsVals, resVals;</div>
<div class="line"><a name="l03684"></a><span class="lineno"> 3684</span>&#160;    lhsVals = <a class="code" href="Vectorization_8cpp.html#a41a2f2306467feacee5865c5be9c0401">extractConvInputSlices</a>(rewriter, loc, lhs, nSize, wSize, cSize,</div>
<div class="line"><a name="l03685"></a><span class="lineno"> 3685</span>&#160;                                     kwSize, strideW, dilationW, wSizeStep,</div>
<div class="line"><a name="l03686"></a><span class="lineno"> 3686</span>&#160;                                     isSingleChanneled);</div>
<div class="line"><a name="l03687"></a><span class="lineno"> 3687</span>&#160;    <span class="comment">// Do not do for pooling.</span></div>
<div class="line"><a name="l03688"></a><span class="lineno"> 3688</span>&#160;    <span class="keywordflow">if</span> (oper == ConvOperationKind::Conv)</div>
<div class="line"><a name="l03689"></a><span class="lineno"> 3689</span>&#160;      rhsVals = <a class="code" href="Vectorization_8cpp.html#a313dd728e35dcd639ff665bcc97d81ad">extractConvFilterSlices</a>(rewriter, loc, rhs, kwSize);</div>
<div class="line"><a name="l03690"></a><span class="lineno"> 3690</span>&#160;    resVals = <a class="code" href="Vectorization_8cpp.html#abe4a6208d725462b6ab07ee8310da2f1">extractConvResultSlices</a>(rewriter, loc, res, nSize, wSize, fSize,</div>
<div class="line"><a name="l03691"></a><span class="lineno"> 3691</span>&#160;                                      wSizeStep, isSingleChanneled);</div>
<div class="line"><a name="l03692"></a><span class="lineno"> 3692</span>&#160; </div>
<div class="line"><a name="l03693"></a><span class="lineno"> 3693</span>&#160;    <span class="keyword">auto</span> linearIndex = [&amp;](int64_t kw, int64_t w) {</div>
<div class="line"><a name="l03694"></a><span class="lineno"> 3694</span>&#160;      <span class="keywordflow">return</span> kw * (wSize / wSizeStep) + w;</div>
<div class="line"><a name="l03695"></a><span class="lineno"> 3695</span>&#160;    };</div>
<div class="line"><a name="l03696"></a><span class="lineno"> 3696</span>&#160; </div>
<div class="line"><a name="l03697"></a><span class="lineno"> 3697</span>&#160;    <span class="comment">// Compute contraction: O{n, w, f} += I{n, sw * w + dw * kw, c} * F{c, f}</span></div>
<div class="line"><a name="l03698"></a><span class="lineno"> 3698</span>&#160;    <span class="comment">// or perform outerproduct for non-channeled convolution or perform simple</span></div>
<div class="line"><a name="l03699"></a><span class="lineno"> 3699</span>&#160;    <span class="comment">// arith operation for pooling</span></div>
<div class="line"><a name="l03700"></a><span class="lineno"> 3700</span>&#160;    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a name="l03701"></a><span class="lineno"> 3701</span>&#160;      <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l03702"></a><span class="lineno"> 3702</span>&#160;        <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a name="l03703"></a><span class="lineno"> 3703</span>&#160;        <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a name="l03704"></a><span class="lineno"> 3704</span>&#160;          <span class="keywordflow">if</span> (isSingleChanneled) {</div>
<div class="line"><a name="l03705"></a><span class="lineno"> 3705</span>&#160;            resVals[w] = conv1dSliceAsOuterProduct(rewriter, loc,</div>
<div class="line"><a name="l03706"></a><span class="lineno"> 3706</span>&#160;                                                   lhsVals[linearIndex(kw, w)],</div>
<div class="line"><a name="l03707"></a><span class="lineno"> 3707</span>&#160;                                                   rhsVals[kw], resVals[w]);</div>
<div class="line"><a name="l03708"></a><span class="lineno"> 3708</span>&#160;          } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l03709"></a><span class="lineno"> 3709</span>&#160;            resVals[w] = conv1dSliceAsContraction(rewriter, loc,</div>
<div class="line"><a name="l03710"></a><span class="lineno"> 3710</span>&#160;                                                  lhsVals[linearIndex(kw, w)],</div>
<div class="line"><a name="l03711"></a><span class="lineno"> 3711</span>&#160;                                                  rhsVals[kw], resVals[w]);</div>
<div class="line"><a name="l03712"></a><span class="lineno"> 3712</span>&#160;          }</div>
<div class="line"><a name="l03713"></a><span class="lineno"> 3713</span>&#160;          <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03714"></a><span class="lineno"> 3714</span>&#160;        <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a name="l03715"></a><span class="lineno"> 3715</span>&#160;          resVals[w] = pool1dSlice(rewriter, loc, lhsVals[linearIndex(kw, w)],</div>
<div class="line"><a name="l03716"></a><span class="lineno"> 3716</span>&#160;                                   resVals[w]);</div>
<div class="line"><a name="l03717"></a><span class="lineno"> 3717</span>&#160;          <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03718"></a><span class="lineno"> 3718</span>&#160;        }</div>
<div class="line"><a name="l03719"></a><span class="lineno"> 3719</span>&#160;      }</div>
<div class="line"><a name="l03720"></a><span class="lineno"> 3720</span>&#160;    }</div>
<div class="line"><a name="l03721"></a><span class="lineno"> 3721</span>&#160; </div>
<div class="line"><a name="l03722"></a><span class="lineno"> 3722</span>&#160;    res = <a class="code" href="Vectorization_8cpp.html#a110d1ed6891097419f0358bd63e974c8">insertConvResultSlices</a>(rewriter, loc, res, wSize, wSizeStep, resVals,</div>
<div class="line"><a name="l03723"></a><span class="lineno"> 3723</span>&#160;                                 isSingleChanneled);</div>
<div class="line"><a name="l03724"></a><span class="lineno"> 3724</span>&#160;    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l03725"></a><span class="lineno"> 3725</span>&#160;    <span class="comment">// End vector-only rewrite part</span></div>
<div class="line"><a name="l03726"></a><span class="lineno"> 3726</span>&#160;    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l03727"></a><span class="lineno"> 3727</span>&#160; </div>
<div class="line"><a name="l03728"></a><span class="lineno"> 3728</span>&#160;    <span class="comment">// The base vectorization case for channeled convolution is output:</span></div>
<div class="line"><a name="l03729"></a><span class="lineno"> 3729</span>&#160;    <span class="comment">// {n,w,f} To reuse the result from base pattern vectorization case, we</span></div>
<div class="line"><a name="l03730"></a><span class="lineno"> 3730</span>&#160;    <span class="comment">// post transpose the base case result.</span></div>
<div class="line"><a name="l03731"></a><span class="lineno"> 3731</span>&#160;    <span class="keywordflow">switch</span> (conv1DOpOrder) {</div>
<div class="line"><a name="l03732"></a><span class="lineno"> 3732</span>&#160;    <span class="keywordflow">case</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>:</div>
<div class="line"><a name="l03733"></a><span class="lineno"> 3733</span>&#160;    <span class="keywordflow">case</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>:</div>
<div class="line"><a name="l03734"></a><span class="lineno"> 3734</span>&#160;      <span class="comment">// Base case, so no transposes necessary.</span></div>
<div class="line"><a name="l03735"></a><span class="lineno"> 3735</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03736"></a><span class="lineno"> 3736</span>&#160;    <span class="keywordflow">case</span> <a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>: {</div>
<div class="line"><a name="l03737"></a><span class="lineno"> 3737</span>&#160;      <span class="comment">// nwf -&gt; nfw</span></div>
<div class="line"><a name="l03738"></a><span class="lineno"> 3738</span>&#160;      <span class="keyword">static</span> constexpr std::array&lt;int64_t, 3&gt; perm = {0, 2, 1};</div>
<div class="line"><a name="l03739"></a><span class="lineno"> 3739</span>&#160;      res = vector::TransposeOp::create(rewriter, loc, res, perm);</div>
<div class="line"><a name="l03740"></a><span class="lineno"> 3740</span>&#160;      <span class="keywordflow">break</span>;</div>
<div class="line"><a name="l03741"></a><span class="lineno"> 3741</span>&#160;    }</div>
<div class="line"><a name="l03742"></a><span class="lineno"> 3742</span>&#160;    }</div>
<div class="line"><a name="l03743"></a><span class="lineno"> 3743</span>&#160; </div>
<div class="line"><a name="l03744"></a><span class="lineno"> 3744</span>&#160;    <span class="keywordflow">return</span> vector::TransferWriteOp::create(rewriter, loc, res, resShaped,</div>
<div class="line"><a name="l03745"></a><span class="lineno"> 3745</span>&#160;                                           resPadding)</div>
<div class="line"><a name="l03746"></a><span class="lineno"> 3746</span>&#160;        .getOperation();</div>
<div class="line"><a name="l03747"></a><span class="lineno"> 3747</span>&#160;  }</div>
<div class="line"><a name="l03748"></a><span class="lineno"> 3748</span>&#160; </div>
<div class="line"><a name="l03749"></a><span class="lineno"> 3749</span>&#160;  <span class="comment">// Take a value and widen to have the same element type as `ty`.</span></div>
<div class="line"><a name="l03750"></a><span class="lineno"> 3750</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> <a class="code" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Location.html">Location</a> loc, <a class="code" href="classmlir_1_1Value.html">Value</a> val, <a class="code" href="classmlir_1_1Type.html">Type</a> ty) {</div>
<div class="line"><a name="l03751"></a><span class="lineno"> 3751</span>&#160;    <span class="keyword">const</span> <a class="code" href="classmlir_1_1Type.html">Type</a> srcElementType = <a class="code" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(val.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l03752"></a><span class="lineno"> 3752</span>&#160;    <span class="keyword">const</span> <a class="code" href="classmlir_1_1Type.html">Type</a> dstElementType = <a class="code" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(ty);</div>
<div class="line"><a name="l03753"></a><span class="lineno"> 3753</span>&#160;    assert(isa&lt;IntegerType&gt;(dstElementType) || isa&lt;FloatType&gt;(dstElementType));</div>
<div class="line"><a name="l03754"></a><span class="lineno"> 3754</span>&#160;    <span class="keywordflow">if</span> (srcElementType == dstElementType)</div>
<div class="line"><a name="l03755"></a><span class="lineno"> 3755</span>&#160;      <span class="keywordflow">return</span> val;</div>
<div class="line"><a name="l03756"></a><span class="lineno"> 3756</span>&#160; </div>
<div class="line"><a name="l03757"></a><span class="lineno"> 3757</span>&#160;    <span class="keyword">const</span> int64_t srcWidth = srcElementType.<a class="code" href="classmlir_1_1Type.html#aeb142623709910125e07ecf1f9f2cdd5">getIntOrFloatBitWidth</a>();</div>
<div class="line"><a name="l03758"></a><span class="lineno"> 3758</span>&#160;    <span class="keyword">const</span> int64_t dstWidth = dstElementType.<a class="code" href="classmlir_1_1Type.html#aeb142623709910125e07ecf1f9f2cdd5">getIntOrFloatBitWidth</a>();</div>
<div class="line"><a name="l03759"></a><span class="lineno"> 3759</span>&#160;    <span class="keyword">const</span> <a class="code" href="classmlir_1_1Type.html">Type</a> dstType =</div>
<div class="line"><a name="l03760"></a><span class="lineno"> 3760</span>&#160;        cast&lt;ShapedType&gt;(val.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()).cloneWith(std::nullopt, dstElementType);</div>
<div class="line"><a name="l03761"></a><span class="lineno"> 3761</span>&#160; </div>
<div class="line"><a name="l03762"></a><span class="lineno"> 3762</span>&#160;    <span class="keywordflow">if</span> (isa&lt;IntegerType&gt;(srcElementType) &amp;&amp; isa&lt;FloatType&gt;(dstElementType)) {</div>
<div class="line"><a name="l03763"></a><span class="lineno"> 3763</span>&#160;      <span class="keywordflow">return</span> arith::SIToFPOp::create(rewriter, loc, dstType, val);</div>
<div class="line"><a name="l03764"></a><span class="lineno"> 3764</span>&#160;    }</div>
<div class="line"><a name="l03765"></a><span class="lineno"> 3765</span>&#160; </div>
<div class="line"><a name="l03766"></a><span class="lineno"> 3766</span>&#160;    <span class="keywordflow">if</span> (isa&lt;FloatType&gt;(srcElementType) &amp;&amp; isa&lt;FloatType&gt;(dstElementType) &amp;&amp;</div>
<div class="line"><a name="l03767"></a><span class="lineno"> 3767</span>&#160;        srcWidth &lt; dstWidth)</div>
<div class="line"><a name="l03768"></a><span class="lineno"> 3768</span>&#160;      <span class="keywordflow">return</span> arith::ExtFOp::create(rewriter, loc, dstType, val);</div>
<div class="line"><a name="l03769"></a><span class="lineno"> 3769</span>&#160; </div>
<div class="line"><a name="l03770"></a><span class="lineno"> 3770</span>&#160;    <span class="keywordflow">if</span> (isa&lt;IntegerType&gt;(srcElementType) &amp;&amp; isa&lt;IntegerType&gt;(dstElementType) &amp;&amp;</div>
<div class="line"><a name="l03771"></a><span class="lineno"> 3771</span>&#160;        srcWidth &lt; dstWidth)</div>
<div class="line"><a name="l03772"></a><span class="lineno"> 3772</span>&#160;      <span class="keywordflow">return</span> arith::ExtSIOp::create(rewriter, loc, dstType, val);</div>
<div class="line"><a name="l03773"></a><span class="lineno"> 3773</span>&#160; </div>
<div class="line"><a name="l03774"></a><span class="lineno"> 3774</span>&#160;    assert(<span class="keyword">false</span> &amp;&amp; <span class="stringliteral">&quot;unhandled promotion case&quot;</span>);</div>
<div class="line"><a name="l03775"></a><span class="lineno"> 3775</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">nullptr</span>;</div>
<div class="line"><a name="l03776"></a><span class="lineno"> 3776</span>&#160;  }</div>
<div class="line"><a name="l03777"></a><span class="lineno"> 3777</span>&#160; </div>
<div class="line"><a name="l03778"></a><span class="lineno"> 3778</span>&#160;  <span class="comment">// Create a contraction: lhs{n, w, c} * rhs{c, f} -&gt; res{n, w, f}</span></div>
<div class="line"><a name="l03779"></a><span class="lineno"> 3779</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> conv1dSliceAsContraction(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Location.html">Location</a> loc,</div>
<div class="line"><a name="l03780"></a><span class="lineno"> 3780</span>&#160;                                 <a class="code" href="classmlir_1_1Value.html">Value</a> lhs, <a class="code" href="classmlir_1_1Value.html">Value</a> rhs, <a class="code" href="classmlir_1_1Value.html">Value</a> res) {</div>
<div class="line"><a name="l03781"></a><span class="lineno"> 3781</span>&#160;    vector::IteratorType par = vector::IteratorType::parallel;</div>
<div class="line"><a name="l03782"></a><span class="lineno"> 3782</span>&#160;    vector::IteratorType red = vector::IteratorType::reduction;</div>
<div class="line"><a name="l03783"></a><span class="lineno"> 3783</span>&#160;    <a class="code" href="classmlir_1_1AffineExpr.html">AffineExpr</a> n, w, f, c;</div>
<div class="line"><a name="l03784"></a><span class="lineno"> 3784</span>&#160;    <a class="code" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, w, f, c);</div>
<div class="line"><a name="l03785"></a><span class="lineno"> 3785</span>&#160;    lhs = <a class="code" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(rewriter, loc, lhs, res.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l03786"></a><span class="lineno"> 3786</span>&#160;    rhs = <a class="code" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(rewriter, loc, rhs, res.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l03787"></a><span class="lineno"> 3787</span>&#160;    <span class="keyword">auto</span> contrationOp = vector::ContractionOp::create(</div>
<div class="line"><a name="l03788"></a><span class="lineno"> 3788</span>&#160;        rewriter, loc, lhs, rhs, res,</div>
<div class="line"><a name="l03789"></a><span class="lineno"> 3789</span>&#160;        <span class="comment">/*indexingMaps=*/</span>MapList{{n, w, c}, {c, f}, {n, w, f}},</div>
<div class="line"><a name="l03790"></a><span class="lineno"> 3790</span>&#160;        <span class="comment">/*iteratorTypes=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;vector::IteratorType&gt;</a>{par, par, par, red});</div>
<div class="line"><a name="l03791"></a><span class="lineno"> 3791</span>&#160;    contrationOp.setKind(reductionKind);</div>
<div class="line"><a name="l03792"></a><span class="lineno"> 3792</span>&#160;    <span class="keywordflow">return</span> contrationOp;</div>
<div class="line"><a name="l03793"></a><span class="lineno"> 3793</span>&#160;  }</div>
<div class="line"><a name="l03794"></a><span class="lineno"> 3794</span>&#160; </div>
<div class="line"><a name="l03795"></a><span class="lineno"> 3795</span>&#160;  <span class="comment">// Create an outerproduct: lhs{w} * rhs{1} -&gt; res{w} for single channel</span></div>
<div class="line"><a name="l03796"></a><span class="lineno"> 3796</span>&#160;  <span class="comment">// convolution.</span></div>
<div class="line"><a name="l03797"></a><span class="lineno"> 3797</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> conv1dSliceAsOuterProduct(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Location.html">Location</a> loc,</div>
<div class="line"><a name="l03798"></a><span class="lineno"> 3798</span>&#160;                                  <a class="code" href="classmlir_1_1Value.html">Value</a> lhs, <a class="code" href="classmlir_1_1Value.html">Value</a> rhs, <a class="code" href="classmlir_1_1Value.html">Value</a> res) {</div>
<div class="line"><a name="l03799"></a><span class="lineno"> 3799</span>&#160;    <span class="keywordflow">return</span> vector::OuterProductOp::create(rewriter, loc, res.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>(), lhs,</div>
<div class="line"><a name="l03800"></a><span class="lineno"> 3800</span>&#160;                                          rhs, res, vector::CombiningKind::ADD);</div>
<div class="line"><a name="l03801"></a><span class="lineno"> 3801</span>&#160;  }</div>
<div class="line"><a name="l03802"></a><span class="lineno"> 3802</span>&#160; </div>
<div class="line"><a name="l03803"></a><span class="lineno"> 3803</span>&#160;  <span class="comment">// Create a reduction: lhs{n, w, c} -&gt; res{n, w, c}</span></div>
<div class="line"><a name="l03804"></a><span class="lineno"> 3804</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> pool1dSlice(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Location.html">Location</a> loc, <a class="code" href="classmlir_1_1Value.html">Value</a> lhs,</div>
<div class="line"><a name="l03805"></a><span class="lineno"> 3805</span>&#160;                    <a class="code" href="classmlir_1_1Value.html">Value</a> res) {</div>
<div class="line"><a name="l03806"></a><span class="lineno"> 3806</span>&#160;    <span class="keywordflow">if</span> (isPoolExt)</div>
<div class="line"><a name="l03807"></a><span class="lineno"> 3807</span>&#160;      lhs = rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#ac6a6edadd39800db410864ef06a004b2">create</a>(loc, poolExtOp, lhs, res.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>())-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0);</div>
<div class="line"><a name="l03808"></a><span class="lineno"> 3808</span>&#160;    <span class="keywordflow">return</span> rewriter</div>
<div class="line"><a name="l03809"></a><span class="lineno"> 3809</span>&#160;        .<a class="code" href="classmlir_1_1OpBuilder.html#ac6a6edadd39800db410864ef06a004b2">create</a>(loc, redOp, <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;Value&gt;</a>{lhs, res}, res.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>())</div>
<div class="line"><a name="l03810"></a><span class="lineno"> 3810</span>&#160;        -&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0);</div>
<div class="line"><a name="l03811"></a><span class="lineno"> 3811</span>&#160;  }</div>
<div class="line"><a name="l03812"></a><span class="lineno"> 3812</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l03813"></a><span class="lineno"> 3813</span>&#160;<span class="comment">  /// Generate a vector implementation for:</span></div>
<div class="line"><a name="l03814"></a><span class="lineno"> 3814</span>&#160;<span class="comment">  /// ```</span></div>
<div class="line"><a name="l03815"></a><span class="lineno"> 3815</span>&#160;<span class="comment">  ///   Op def: (     n,     w,     c,    kw)</span></div>
<div class="line"><a name="l03816"></a><span class="lineno"> 3816</span>&#160;<span class="comment">  ///    Iters: ({Par(), Par(), Par(), Red()})</span></div>
<div class="line"><a name="l03817"></a><span class="lineno"> 3817</span>&#160;<span class="comment">  ///   Layout: {{n, strideW * w + dilationW * kw, c}, {kw, c}, {n, w, c}}</span></div>
<div class="line"><a name="l03818"></a><span class="lineno"> 3818</span>&#160;<span class="comment">  /// ```</span></div>
<div class="line"><a name="l03819"></a><span class="lineno"> 3819</span>&#160;<span class="comment">  /// kw is always unrolled.</span></div>
<div class="line"><a name="l03820"></a><span class="lineno"> 3820</span>&#160;<span class="comment">  /// TODO: w (resp. kw) is unrolled when the strideW ( resp. dilationW) is</span></div>
<div class="line"><a name="l03821"></a><span class="lineno"> 3821</span>&#160;<span class="comment">  /// &gt; 1.</span></div>
<div class="line"><a name="l03822"></a><span class="lineno"> 3822</span>&#160;<span class="comment"></span>  FailureOr&lt;Operation *&gt; depthwiseConv(uint64_t channelDimVecSize,</div>
<div class="line"><a name="l03823"></a><span class="lineno"> 3823</span>&#160;                                       <span class="keywordtype">bool</span> channelDimScalableFlag,</div>
<div class="line"><a name="l03824"></a><span class="lineno"> 3824</span>&#160;                                       <span class="keywordtype">bool</span> flatten) {</div>
<div class="line"><a name="l03825"></a><span class="lineno"> 3825</span>&#160;    <span class="keywordtype">bool</span> scalableChDim = <span class="keyword">false</span>;</div>
<div class="line"><a name="l03826"></a><span class="lineno"> 3826</span>&#160;    <span class="keywordtype">bool</span> useMasking = <span class="keyword">false</span>;</div>
<div class="line"><a name="l03827"></a><span class="lineno"> 3827</span>&#160;    int64_t nSize, wSize, cSize, kwSize;</div>
<div class="line"><a name="l03828"></a><span class="lineno"> 3828</span>&#160;    <span class="comment">// kernel{kw, c}</span></div>
<div class="line"><a name="l03829"></a><span class="lineno"> 3829</span>&#160;    <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(rhsShapedType, kwSize, cSize);</div>
<div class="line"><a name="l03830"></a><span class="lineno"> 3830</span>&#160;    <span class="keywordflow">if</span> (ShapedType::isDynamic(cSize)) {</div>
<div class="line"><a name="l03831"></a><span class="lineno"> 3831</span>&#160;      assert(channelDimVecSize != 0 &amp;&amp; <span class="stringliteral">&quot;Channel dim vec size must be &gt; 0&quot;</span>);</div>
<div class="line"><a name="l03832"></a><span class="lineno"> 3832</span>&#160;      cSize = channelDimVecSize;</div>
<div class="line"><a name="l03833"></a><span class="lineno"> 3833</span>&#160;      <span class="comment">// Scalable vectors are only used when both conditions are met:</span></div>
<div class="line"><a name="l03834"></a><span class="lineno"> 3834</span>&#160;      <span class="comment">//  1. channel dim is dynamic</span></div>
<div class="line"><a name="l03835"></a><span class="lineno"> 3835</span>&#160;      <span class="comment">//  2. channelDimScalableFlag is set</span></div>
<div class="line"><a name="l03836"></a><span class="lineno"> 3836</span>&#160;      scalableChDim = channelDimScalableFlag;</div>
<div class="line"><a name="l03837"></a><span class="lineno"> 3837</span>&#160;      useMasking = <span class="keyword">true</span>;</div>
<div class="line"><a name="l03838"></a><span class="lineno"> 3838</span>&#160;    }</div>
<div class="line"><a name="l03839"></a><span class="lineno"> 3839</span>&#160; </div>
<div class="line"><a name="l03840"></a><span class="lineno"> 3840</span>&#160;    assert(!(useMasking &amp;&amp; flatten) &amp;&amp;</div>
<div class="line"><a name="l03841"></a><span class="lineno"> 3841</span>&#160;           <span class="stringliteral">&quot;Unsupported flattened conv with dynamic shapes&quot;</span>);</div>
<div class="line"><a name="l03842"></a><span class="lineno"> 3842</span>&#160; </div>
<div class="line"><a name="l03843"></a><span class="lineno"> 3843</span>&#160;    <span class="comment">// out{n, w, c}</span></div>
<div class="line"><a name="l03844"></a><span class="lineno"> 3844</span>&#160;    <a class="code" href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a>(resShapedType, nSize, wSize);</div>
<div class="line"><a name="l03845"></a><span class="lineno"> 3845</span>&#160; </div>
<div class="line"><a name="l03846"></a><span class="lineno"> 3846</span>&#160;    vector::TransferWriteOp write;</div>
<div class="line"><a name="l03847"></a><span class="lineno"> 3847</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> zero = <a class="code" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0);</div>
<div class="line"><a name="l03848"></a><span class="lineno"> 3848</span>&#160; </div>
<div class="line"><a name="l03849"></a><span class="lineno"> 3849</span>&#160;    <span class="comment">// w is unrolled (i.e. wSizeStep == 1) iff strideW &gt; 1.</span></div>
<div class="line"><a name="l03850"></a><span class="lineno"> 3850</span>&#160;    <span class="comment">// When strideW == 1, we can batch the contiguous loads and avoid</span></div>
<div class="line"><a name="l03851"></a><span class="lineno"> 3851</span>&#160;    <span class="comment">// unrolling</span></div>
<div class="line"><a name="l03852"></a><span class="lineno"> 3852</span>&#160;    int64_t wSizeStep = strideW == 1 ? wSize : 1;</div>
<div class="line"><a name="l03853"></a><span class="lineno"> 3853</span>&#160; </div>
<div class="line"><a name="l03854"></a><span class="lineno"> 3854</span>&#160;    <a class="code" href="classmlir_1_1Type.html">Type</a> lhsEltType = lhsShapedType.getElementType();</div>
<div class="line"><a name="l03855"></a><span class="lineno"> 3855</span>&#160;    <a class="code" href="classmlir_1_1Type.html">Type</a> rhsEltType = rhsShapedType.getElementType();</div>
<div class="line"><a name="l03856"></a><span class="lineno"> 3856</span>&#160;    <a class="code" href="classmlir_1_1Type.html">Type</a> resEltType = resShapedType.getElementType();</div>
<div class="line"><a name="l03857"></a><span class="lineno"> 3857</span>&#160;    VectorType lhsType = <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(</div>
<div class="line"><a name="l03858"></a><span class="lineno"> 3858</span>&#160;        {nSize,</div>
<div class="line"><a name="l03859"></a><span class="lineno"> 3859</span>&#160;         <span class="comment">// iw = ow * sw + kw *  dw - 1</span></div>
<div class="line"><a name="l03860"></a><span class="lineno"> 3860</span>&#160;         <span class="comment">//   (i.e. 16 convolved with 3 (@stride 1 dilation 1) -&gt; 14)</span></div>
<div class="line"><a name="l03861"></a><span class="lineno"> 3861</span>&#160;         ((wSize - 1) * strideW + 1) + ((kwSize - 1) * dilationW + 1) - 1,</div>
<div class="line"><a name="l03862"></a><span class="lineno"> 3862</span>&#160;         cSize},</div>
<div class="line"><a name="l03863"></a><span class="lineno"> 3863</span>&#160;        lhsEltType, <span class="comment">/*scalableDims=*/</span>{<span class="keyword">false</span>, <span class="keyword">false</span>, scalableChDim});</div>
<div class="line"><a name="l03864"></a><span class="lineno"> 3864</span>&#160;    VectorType rhsType =</div>
<div class="line"><a name="l03865"></a><span class="lineno"> 3865</span>&#160;        <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>({kwSize, cSize}, rhsEltType,</div>
<div class="line"><a name="l03866"></a><span class="lineno"> 3866</span>&#160;                        <span class="comment">/*scalableDims=*/</span>{<span class="keyword">false</span>, scalableChDim});</div>
<div class="line"><a name="l03867"></a><span class="lineno"> 3867</span>&#160;    VectorType resType =</div>
<div class="line"><a name="l03868"></a><span class="lineno"> 3868</span>&#160;        <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>({nSize, wSize, cSize}, resEltType,</div>
<div class="line"><a name="l03869"></a><span class="lineno"> 3869</span>&#160;                        <span class="comment">/*scalableDims=*/</span>{<span class="keyword">false</span>, <span class="keyword">false</span>, scalableChDim});</div>
<div class="line"><a name="l03870"></a><span class="lineno"> 3870</span>&#160; </div>
<div class="line"><a name="l03871"></a><span class="lineno"> 3871</span>&#160;    <span class="comment">// Masks the input xfer Op along the channel dim, iff the corresponding</span></div>
<div class="line"><a name="l03872"></a><span class="lineno"> 3872</span>&#160;    <span class="comment">// scalable flag is set.</span></div>
<div class="line"><a name="l03873"></a><span class="lineno"> 3873</span>&#160;    <span class="keyword">auto</span> maybeMaskXferOp = [&amp;](<a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> maskShape,</div>
<div class="line"><a name="l03874"></a><span class="lineno"> 3874</span>&#160;                               <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> scalableDims,</div>
<div class="line"><a name="l03875"></a><span class="lineno"> 3875</span>&#160;                               <a class="code" href="classmlir_1_1Operation.html">Operation</a> *opToMask) {</div>
<div class="line"><a name="l03876"></a><span class="lineno"> 3876</span>&#160;      <span class="keywordflow">if</span> (!useMasking)</div>
<div class="line"><a name="l03877"></a><span class="lineno"> 3877</span>&#160;        <span class="keywordflow">return</span> opToMask;</div>
<div class="line"><a name="l03878"></a><span class="lineno"> 3878</span>&#160;      <span class="keyword">auto</span> maskType =</div>
<div class="line"><a name="l03879"></a><span class="lineno"> 3879</span>&#160;          <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(maskShape, rewriter.<a class="code" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>(), scalableDims);</div>
<div class="line"><a name="l03880"></a><span class="lineno"> 3880</span>&#160; </div>
<div class="line"><a name="l03881"></a><span class="lineno"> 3881</span>&#160;      <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(maskShape.size(), <span class="keyword">true</span>);</div>
<div class="line"><a name="l03882"></a><span class="lineno"> 3882</span>&#160;      <span class="keyword">auto</span> xferOp = cast&lt;VectorTransferOpInterface&gt;(opToMask);</div>
<div class="line"><a name="l03883"></a><span class="lineno"> 3883</span>&#160;      xferOp-&gt;setAttr(xferOp.getInBoundsAttrName(),</div>
<div class="line"><a name="l03884"></a><span class="lineno"> 3884</span>&#160;                      rewriter.<a class="code" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a name="l03885"></a><span class="lineno"> 3885</span>&#160; </div>
<div class="line"><a name="l03886"></a><span class="lineno"> 3886</span>&#160;      <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;OpFoldResult&gt;</a> mixedDims = <a class="code" href="namespacemlir_1_1vector.html#ad910c130857e946d9d30b58ffb708f3a">vector::getMixedSizesXfer</a>(</div>
<div class="line"><a name="l03887"></a><span class="lineno"> 3887</span>&#160;          cast&lt;LinalgOp&gt;(op).hasPureTensorSemantics(), opToMask, rewriter);</div>
<div class="line"><a name="l03888"></a><span class="lineno"> 3888</span>&#160; </div>
<div class="line"><a name="l03889"></a><span class="lineno"> 3889</span>&#160;      <a class="code" href="classmlir_1_1Value.html">Value</a> maskOp =</div>
<div class="line"><a name="l03890"></a><span class="lineno"> 3890</span>&#160;          vector::CreateMaskOp::create(rewriter, loc, maskType, mixedDims);</div>
<div class="line"><a name="l03891"></a><span class="lineno"> 3891</span>&#160; </div>
<div class="line"><a name="l03892"></a><span class="lineno"> 3892</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacemlir_1_1vector.html#a4f68d86708480673ecc59b2714973a65">mlir::vector::maskOperation</a>(rewriter, opToMask, maskOp);</div>
<div class="line"><a name="l03893"></a><span class="lineno"> 3893</span>&#160;    };</div>
<div class="line"><a name="l03894"></a><span class="lineno"> 3894</span>&#160; </div>
<div class="line"><a name="l03895"></a><span class="lineno"> 3895</span>&#160;    <span class="comment">// Read lhs slice of size {n, w * strideW + kw * dilationW, c} @ [0, 0,</span></div>
<div class="line"><a name="l03896"></a><span class="lineno"> 3896</span>&#160;    <span class="comment">// 0].</span></div>
<div class="line"><a name="l03897"></a><span class="lineno"> 3897</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> lhs = vector::TransferReadOp::create(</div>
<div class="line"><a name="l03898"></a><span class="lineno"> 3898</span>&#160;        rewriter, loc, lhsType, lhsShaped, <a class="code" href="classmlir_1_1ValueRange.html">ValueRange</a>{zero, zero, zero},</div>
<div class="line"><a name="l03899"></a><span class="lineno"> 3899</span>&#160;        <span class="comment">/*padding=*/</span><a class="code" href="namespacemlir_1_1arith.html#af73ab4d70d330c6212d9ccd87a38056b">arith::getZeroConstant</a>(rewriter, loc, lhsEltType));</div>
<div class="line"><a name="l03900"></a><span class="lineno"> 3900</span>&#160;    <span class="keyword">auto</span> maybeMaskedLhs = maybeMaskXferOp(</div>
<div class="line"><a name="l03901"></a><span class="lineno"> 3901</span>&#160;        lhsType.getShape(), lhsType.getScalableDims(), lhs.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>());</div>
<div class="line"><a name="l03902"></a><span class="lineno"> 3902</span>&#160; </div>
<div class="line"><a name="l03903"></a><span class="lineno"> 3903</span>&#160;    <span class="comment">// Read rhs slice of size {kw, c} @ [0, 0].</span></div>
<div class="line"><a name="l03904"></a><span class="lineno"> 3904</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> rhs = vector::TransferReadOp::create(</div>
<div class="line"><a name="l03905"></a><span class="lineno"> 3905</span>&#160;        rewriter, loc, rhsType, rhsShaped, <a class="code" href="classmlir_1_1ValueRange.html">ValueRange</a>{zero, zero},</div>
<div class="line"><a name="l03906"></a><span class="lineno"> 3906</span>&#160;        <span class="comment">/*padding=*/</span><a class="code" href="namespacemlir_1_1arith.html#af73ab4d70d330c6212d9ccd87a38056b">arith::getZeroConstant</a>(rewriter, loc, rhsEltType));</div>
<div class="line"><a name="l03907"></a><span class="lineno"> 3907</span>&#160;    <span class="keyword">auto</span> maybeMaskedRhs = maybeMaskXferOp(</div>
<div class="line"><a name="l03908"></a><span class="lineno"> 3908</span>&#160;        rhsType.getShape(), rhsType.getScalableDims(), rhs.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>());</div>
<div class="line"><a name="l03909"></a><span class="lineno"> 3909</span>&#160; </div>
<div class="line"><a name="l03910"></a><span class="lineno"> 3910</span>&#160;    <span class="comment">// Read res slice of size {n, w, c} @ [0, 0, 0].</span></div>
<div class="line"><a name="l03911"></a><span class="lineno"> 3911</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> res = vector::TransferReadOp::create(</div>
<div class="line"><a name="l03912"></a><span class="lineno"> 3912</span>&#160;        rewriter, loc, resType, resShaped, <a class="code" href="classmlir_1_1ValueRange.html">ValueRange</a>{zero, zero, zero},</div>
<div class="line"><a name="l03913"></a><span class="lineno"> 3913</span>&#160;        <span class="comment">/*padding=*/</span><a class="code" href="namespacemlir_1_1arith.html#af73ab4d70d330c6212d9ccd87a38056b">arith::getZeroConstant</a>(rewriter, loc, resEltType));</div>
<div class="line"><a name="l03914"></a><span class="lineno"> 3914</span>&#160;    <span class="keyword">auto</span> maybeMaskedRes = maybeMaskXferOp(</div>
<div class="line"><a name="l03915"></a><span class="lineno"> 3915</span>&#160;        resType.getShape(), resType.getScalableDims(), res.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>());</div>
<div class="line"><a name="l03916"></a><span class="lineno"> 3916</span>&#160; </div>
<div class="line"><a name="l03917"></a><span class="lineno"> 3917</span>&#160;    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l03918"></a><span class="lineno"> 3918</span>&#160;    <span class="comment">// Begin vector-only rewrite part</span></div>
<div class="line"><a name="l03919"></a><span class="lineno"> 3919</span>&#160;    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l03920"></a><span class="lineno"> 3920</span>&#160;    <span class="comment">// Unroll along kw and read slices of lhs and rhs.</span></div>
<div class="line"><a name="l03921"></a><span class="lineno"> 3921</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> lhsVals, rhsVals, resVals;</div>
<div class="line"><a name="l03922"></a><span class="lineno"> 3922</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> inOutSliceSizes = {nSize, wSizeStep, cSize};</div>
<div class="line"><a name="l03923"></a><span class="lineno"> 3923</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> inOutStrides = {1, 1, 1};</div>
<div class="line"><a name="l03924"></a><span class="lineno"> 3924</span>&#160; </div>
<div class="line"><a name="l03925"></a><span class="lineno"> 3925</span>&#160;    <span class="comment">// Extract lhs slice of size {n, wSizeStep, c}</span></div>
<div class="line"><a name="l03926"></a><span class="lineno"> 3926</span>&#160;    <span class="comment">//   @ [0, sw * w + dw * kw, 0].</span></div>
<div class="line"><a name="l03927"></a><span class="lineno"> 3927</span>&#160;    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a name="l03928"></a><span class="lineno"> 3928</span>&#160;      <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l03929"></a><span class="lineno"> 3929</span>&#160;        lhsVals.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a name="l03930"></a><span class="lineno"> 3930</span>&#160;            rewriter, loc, maybeMaskedLhs-&gt;getResult(0),</div>
<div class="line"><a name="l03931"></a><span class="lineno"> 3931</span>&#160;            <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{0, w * strideW + kw * dilationW, 0},</div>
<div class="line"><a name="l03932"></a><span class="lineno"> 3932</span>&#160;            inOutSliceSizes, inOutStrides));</div>
<div class="line"><a name="l03933"></a><span class="lineno"> 3933</span>&#160;      }</div>
<div class="line"><a name="l03934"></a><span class="lineno"> 3934</span>&#160;    }</div>
<div class="line"><a name="l03935"></a><span class="lineno"> 3935</span>&#160;    <span class="comment">// Extract rhs slice of size {c} @ [kw].</span></div>
<div class="line"><a name="l03936"></a><span class="lineno"> 3936</span>&#160;    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a name="l03937"></a><span class="lineno"> 3937</span>&#160;      rhsVals.push_back(</div>
<div class="line"><a name="l03938"></a><span class="lineno"> 3938</span>&#160;          vector::ExtractOp::create(rewriter, loc, maybeMaskedRhs-&gt;getResult(0),</div>
<div class="line"><a name="l03939"></a><span class="lineno"> 3939</span>&#160;                                    <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{kw}));</div>
<div class="line"><a name="l03940"></a><span class="lineno"> 3940</span>&#160;    }</div>
<div class="line"><a name="l03941"></a><span class="lineno"> 3941</span>&#160;    <span class="comment">// Extract res slice: {n, wSizeStep, c} @ [0, w, 0].</span></div>
<div class="line"><a name="l03942"></a><span class="lineno"> 3942</span>&#160;    <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l03943"></a><span class="lineno"> 3943</span>&#160;      resVals.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a name="l03944"></a><span class="lineno"> 3944</span>&#160;          rewriter, loc, maybeMaskedRes-&gt;getResult(0),</div>
<div class="line"><a name="l03945"></a><span class="lineno"> 3945</span>&#160;          <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{0, w, 0}, inOutSliceSizes,</div>
<div class="line"><a name="l03946"></a><span class="lineno"> 3946</span>&#160;          inOutStrides));</div>
<div class="line"><a name="l03947"></a><span class="lineno"> 3947</span>&#160;    }</div>
<div class="line"><a name="l03948"></a><span class="lineno"> 3948</span>&#160; </div>
<div class="line"><a name="l03949"></a><span class="lineno"> 3949</span>&#160;    <span class="keyword">auto</span> linearIndex = [&amp;](int64_t kw, int64_t w) {</div>
<div class="line"><a name="l03950"></a><span class="lineno"> 3950</span>&#160;      <span class="keywordflow">return</span> kw * (wSize / wSizeStep) + w;</div>
<div class="line"><a name="l03951"></a><span class="lineno"> 3951</span>&#160;    };</div>
<div class="line"><a name="l03952"></a><span class="lineno"> 3952</span>&#160; </div>
<div class="line"><a name="l03953"></a><span class="lineno"> 3953</span>&#160;    <span class="comment">// Note - the scalable flags are ignored as flattening combined with</span></div>
<div class="line"><a name="l03954"></a><span class="lineno"> 3954</span>&#160;    <span class="comment">// scalable vectorization is not supported.</span></div>
<div class="line"><a name="l03955"></a><span class="lineno"> 3955</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> inOutFlattenSliceSizes = {nSize, wSizeStep * cSize};</div>
<div class="line"><a name="l03956"></a><span class="lineno"> 3956</span>&#160;    <span class="keyword">auto</span> lhsTypeAfterFlattening =</div>
<div class="line"><a name="l03957"></a><span class="lineno"> 3957</span>&#160;        <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(inOutFlattenSliceSizes, lhsEltType);</div>
<div class="line"><a name="l03958"></a><span class="lineno"> 3958</span>&#160;    <span class="keyword">auto</span> resTypeAfterFlattening =</div>
<div class="line"><a name="l03959"></a><span class="lineno"> 3959</span>&#160;        <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(inOutFlattenSliceSizes, resEltType);</div>
<div class="line"><a name="l03960"></a><span class="lineno"> 3960</span>&#160; </div>
<div class="line"><a name="l03961"></a><span class="lineno"> 3961</span>&#160;    <span class="comment">// Compute contraction: O{n, w, c} += I{n, sw * w + dw * kw, c} * F{c}</span></div>
<div class="line"><a name="l03962"></a><span class="lineno"> 3962</span>&#160;    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a name="l03963"></a><span class="lineno"> 3963</span>&#160;      <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l03964"></a><span class="lineno"> 3964</span>&#160;        <a class="code" href="classmlir_1_1Value.html">Value</a> lhsVal = lhsVals[linearIndex(kw, w)];</div>
<div class="line"><a name="l03965"></a><span class="lineno"> 3965</span>&#160;        <a class="code" href="classmlir_1_1Value.html">Value</a> resVal = resVals[w];</div>
<div class="line"><a name="l03966"></a><span class="lineno"> 3966</span>&#160;        <span class="keywordflow">if</span> (flatten) {</div>
<div class="line"><a name="l03967"></a><span class="lineno"> 3967</span>&#160;          <span class="comment">// Flatten the input and output vectors (collapse the channel</span></div>
<div class="line"><a name="l03968"></a><span class="lineno"> 3968</span>&#160;          <span class="comment">// dimension)</span></div>
<div class="line"><a name="l03969"></a><span class="lineno"> 3969</span>&#160;          lhsVal =</div>
<div class="line"><a name="l03970"></a><span class="lineno"> 3970</span>&#160;              vector::ShapeCastOp::create(rewriter, loc, lhsTypeAfterFlattening,</div>
<div class="line"><a name="l03971"></a><span class="lineno"> 3971</span>&#160;                                          lhsVals[linearIndex(kw, w)]);</div>
<div class="line"><a name="l03972"></a><span class="lineno"> 3972</span>&#160;          resVal = vector::ShapeCastOp::create(</div>
<div class="line"><a name="l03973"></a><span class="lineno"> 3973</span>&#160;              rewriter, loc, resTypeAfterFlattening, resVals[w]);</div>
<div class="line"><a name="l03974"></a><span class="lineno"> 3974</span>&#160;        }</div>
<div class="line"><a name="l03975"></a><span class="lineno"> 3975</span>&#160;        resVals[w] = depthwiseConv1dSliceAsMulAcc(rewriter, loc, lhsVal,</div>
<div class="line"><a name="l03976"></a><span class="lineno"> 3976</span>&#160;                                                  rhsVals[kw], resVal, flatten);</div>
<div class="line"><a name="l03977"></a><span class="lineno"> 3977</span>&#160;        <span class="keywordflow">if</span> (flatten) {</div>
<div class="line"><a name="l03978"></a><span class="lineno"> 3978</span>&#160;          <span class="comment">// Un-flatten the output vector (restore the channel dimension)</span></div>
<div class="line"><a name="l03979"></a><span class="lineno"> 3979</span>&#160;          resVals[w] = vector::ShapeCastOp::create(</div>
<div class="line"><a name="l03980"></a><span class="lineno"> 3980</span>&#160;              rewriter, loc, <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(inOutSliceSizes, resEltType),</div>
<div class="line"><a name="l03981"></a><span class="lineno"> 3981</span>&#160;              resVals[w]);</div>
<div class="line"><a name="l03982"></a><span class="lineno"> 3982</span>&#160;        }</div>
<div class="line"><a name="l03983"></a><span class="lineno"> 3983</span>&#160;      }</div>
<div class="line"><a name="l03984"></a><span class="lineno"> 3984</span>&#160;    }</div>
<div class="line"><a name="l03985"></a><span class="lineno"> 3985</span>&#160; </div>
<div class="line"><a name="l03986"></a><span class="lineno"> 3986</span>&#160;    <span class="comment">// Its possible we failed to create the Fma.</span></div>
<div class="line"><a name="l03987"></a><span class="lineno"> 3987</span>&#160;    <span class="keywordflow">if</span> (!llvm::all_of(resVals, [](<a class="code" href="classmlir_1_1Value.html">Value</a> v) { <span class="keywordflow">return</span> v; })) {</div>
<div class="line"><a name="l03988"></a><span class="lineno"> 3988</span>&#160;      <span class="comment">// Manually revert (in reverse order) to avoid leaving a bad IR state.</span></div>
<div class="line"><a name="l03989"></a><span class="lineno"> 3989</span>&#160;      <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;collection :</div>
<div class="line"><a name="l03990"></a><span class="lineno"> 3990</span>&#160;           {resVals, rhsVals, lhsVals, {res, rhs, lhs, zero}})</div>
<div class="line"><a name="l03991"></a><span class="lineno"> 3991</span>&#160;        <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1Value.html">Value</a> v : collection)</div>
<div class="line"><a name="l03992"></a><span class="lineno"> 3992</span>&#160;          rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(v.<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>());</div>
<div class="line"><a name="l03993"></a><span class="lineno"> 3993</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;failed to create FMA&quot;</span>);</div>
<div class="line"><a name="l03994"></a><span class="lineno"> 3994</span>&#160;    }</div>
<div class="line"><a name="l03995"></a><span class="lineno"> 3995</span>&#160; </div>
<div class="line"><a name="l03996"></a><span class="lineno"> 3996</span>&#160;    <span class="comment">// Write back res slice: {n, wSizeStep, c} @ [0, w, 0].</span></div>
<div class="line"><a name="l03997"></a><span class="lineno"> 3997</span>&#160;    <span class="comment">// This does not depend on kw.</span></div>
<div class="line"><a name="l03998"></a><span class="lineno"> 3998</span>&#160;    <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a name="l03999"></a><span class="lineno"> 3999</span>&#160;      maybeMaskedRes = vector::InsertStridedSliceOp::create(</div>
<div class="line"><a name="l04000"></a><span class="lineno"> 4000</span>&#160;          rewriter, loc, resVals[w], maybeMaskedRes-&gt;getResult(0),</div>
<div class="line"><a name="l04001"></a><span class="lineno"> 4001</span>&#160;          <span class="comment">/*offsets=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{0, w, 0},</div>
<div class="line"><a name="l04002"></a><span class="lineno"> 4002</span>&#160;          <span class="comment">/*strides=*/</span><a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{1, 1, 1});</div>
<div class="line"><a name="l04003"></a><span class="lineno"> 4003</span>&#160;    }</div>
<div class="line"><a name="l04004"></a><span class="lineno"> 4004</span>&#160;    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l04005"></a><span class="lineno"> 4005</span>&#160;    <span class="comment">// End vector-only rewrite part</span></div>
<div class="line"><a name="l04006"></a><span class="lineno"> 4006</span>&#160;    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l04007"></a><span class="lineno"> 4007</span>&#160; </div>
<div class="line"><a name="l04008"></a><span class="lineno"> 4008</span>&#160;    <span class="comment">// Write back res slice of size {n, w, c} @ [0, 0, 0].</span></div>
<div class="line"><a name="l04009"></a><span class="lineno"> 4009</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *resOut = vector::TransferWriteOp::create(</div>
<div class="line"><a name="l04010"></a><span class="lineno"> 4010</span>&#160;        rewriter, loc, maybeMaskedRes-&gt;getResult(0), resShaped,</div>
<div class="line"><a name="l04011"></a><span class="lineno"> 4011</span>&#160;        <a class="code" href="classmlir_1_1ValueRange.html">ValueRange</a>{zero, zero, zero});</div>
<div class="line"><a name="l04012"></a><span class="lineno"> 4012</span>&#160;    <span class="keywordflow">return</span> maybeMaskXferOp(resType.getShape(), resType.getScalableDims(),</div>
<div class="line"><a name="l04013"></a><span class="lineno"> 4013</span>&#160;                           resOut);</div>
<div class="line"><a name="l04014"></a><span class="lineno"> 4014</span>&#160;  }</div>
<div class="line"><a name="l04015"></a><span class="lineno"> 4015</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l04016"></a><span class="lineno"> 4016</span>&#160;<span class="comment">  /// Lower:</span></div>
<div class="line"><a name="l04017"></a><span class="lineno"> 4017</span>&#160;<span class="comment">  ///   *  lhs{n, w, c} * rhs{c} -&gt; res{n, w, c} (flatten = false)</span></div>
<div class="line"><a name="l04018"></a><span class="lineno"> 4018</span>&#160;<span class="comment">  ///   *  lhs{n, w * c} * rhs{c} -&gt; res{n, w * c} (flatten = true)</span></div>
<div class="line"><a name="l04019"></a><span class="lineno"> 4019</span>&#160;<span class="comment">  /// to MulAcc.</span></div>
<div class="line"><a name="l04020"></a><span class="lineno"> 4020</span>&#160;<span class="comment"></span>  <a class="code" href="classmlir_1_1Value.html">Value</a> depthwiseConv1dSliceAsMulAcc(<a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code" href="classmlir_1_1Location.html">Location</a> loc,</div>
<div class="line"><a name="l04021"></a><span class="lineno"> 4021</span>&#160;                                     <a class="code" href="classmlir_1_1Value.html">Value</a> lhs, <a class="code" href="classmlir_1_1Value.html">Value</a> rhs, <a class="code" href="classmlir_1_1Value.html">Value</a> res,</div>
<div class="line"><a name="l04022"></a><span class="lineno"> 4022</span>&#160;                                     <span class="keywordtype">bool</span> flatten) {</div>
<div class="line"><a name="l04023"></a><span class="lineno"> 4023</span>&#160;    <span class="keyword">auto</span> rhsTy = cast&lt;ShapedType&gt;(rhs.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l04024"></a><span class="lineno"> 4024</span>&#160;    <span class="keyword">auto</span> resTy = cast&lt;ShapedType&gt;(res.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a name="l04025"></a><span class="lineno"> 4025</span>&#160; </div>
<div class="line"><a name="l04026"></a><span class="lineno"> 4026</span>&#160;    <span class="comment">// TODO(suderman): Change this to use a vector.ima intrinsic.</span></div>
<div class="line"><a name="l04027"></a><span class="lineno"> 4027</span>&#160;    lhs = <a class="code" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(rewriter, loc, lhs, resTy);</div>
<div class="line"><a name="l04028"></a><span class="lineno"> 4028</span>&#160; </div>
<div class="line"><a name="l04029"></a><span class="lineno"> 4029</span>&#160;    <span class="keywordflow">if</span> (flatten) {</div>
<div class="line"><a name="l04030"></a><span class="lineno"> 4030</span>&#160;      <span class="comment">// NOTE: This following logic won&#39;t work for scalable vectors. For this</span></div>
<div class="line"><a name="l04031"></a><span class="lineno"> 4031</span>&#160;      <span class="comment">// reason, &quot;flattening&quot; is not supported when shapes are dynamic (this</span></div>
<div class="line"><a name="l04032"></a><span class="lineno"> 4032</span>&#160;      <span class="comment">// should be captured by one of the pre-conditions).</span></div>
<div class="line"><a name="l04033"></a><span class="lineno"> 4033</span>&#160; </div>
<div class="line"><a name="l04034"></a><span class="lineno"> 4034</span>&#160;      <span class="comment">// There are two options for handling the filter:</span></div>
<div class="line"><a name="l04035"></a><span class="lineno"> 4035</span>&#160;      <span class="comment">//  * shape_cast(broadcast(filter))</span></div>
<div class="line"><a name="l04036"></a><span class="lineno"> 4036</span>&#160;      <span class="comment">//  * broadcast(shuffle(filter))</span></div>
<div class="line"><a name="l04037"></a><span class="lineno"> 4037</span>&#160;      <span class="comment">// Opt for the option without shape_cast to simplify the codegen.</span></div>
<div class="line"><a name="l04038"></a><span class="lineno"> 4038</span>&#160;      <span class="keyword">auto</span> rhsSize = cast&lt;VectorType&gt;(rhs.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()).getShape()[0];</div>
<div class="line"><a name="l04039"></a><span class="lineno"> 4039</span>&#160;      <span class="keyword">auto</span> resSize = cast&lt;VectorType&gt;(res.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()).getShape()[1];</div>
<div class="line"><a name="l04040"></a><span class="lineno"> 4040</span>&#160; </div>
<div class="line"><a name="l04041"></a><span class="lineno"> 4041</span>&#160;      <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t, 16&gt;</a> indices;</div>
<div class="line"><a name="l04042"></a><span class="lineno"> 4042</span>&#160;      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; resSize / rhsSize; ++i) {</div>
<div class="line"><a name="l04043"></a><span class="lineno"> 4043</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> <a class="code" href="unionj.html">j</a> = 0; <a class="code" href="unionj.html">j</a> &lt; rhsSize; ++<a class="code" href="unionj.html">j</a>)</div>
<div class="line"><a name="l04044"></a><span class="lineno"> 4044</span>&#160;          indices.push_back(<a class="code" href="unionj.html">j</a>);</div>
<div class="line"><a name="l04045"></a><span class="lineno"> 4045</span>&#160;      }</div>
<div class="line"><a name="l04046"></a><span class="lineno"> 4046</span>&#160; </div>
<div class="line"><a name="l04047"></a><span class="lineno"> 4047</span>&#160;      rhs = vector::ShuffleOp::create(rewriter, loc, rhs, rhs, indices);</div>
<div class="line"><a name="l04048"></a><span class="lineno"> 4048</span>&#160;    }</div>
<div class="line"><a name="l04049"></a><span class="lineno"> 4049</span>&#160;    <span class="comment">// Broadcast the filter to match the output vector</span></div>
<div class="line"><a name="l04050"></a><span class="lineno"> 4050</span>&#160;    rhs = vector::BroadcastOp::create(rewriter, loc,</div>
<div class="line"><a name="l04051"></a><span class="lineno"> 4051</span>&#160;                                      resTy.clone(rhsTy.getElementType()), rhs);</div>
<div class="line"><a name="l04052"></a><span class="lineno"> 4052</span>&#160; </div>
<div class="line"><a name="l04053"></a><span class="lineno"> 4053</span>&#160;    rhs = <a class="code" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(rewriter, loc, rhs, resTy);</div>
<div class="line"><a name="l04054"></a><span class="lineno"> 4054</span>&#160; </div>
<div class="line"><a name="l04055"></a><span class="lineno"> 4055</span>&#160;    <span class="keywordflow">if</span> (!lhs || !rhs)</div>
<div class="line"><a name="l04056"></a><span class="lineno"> 4056</span>&#160;      <span class="keywordflow">return</span> <span class="keyword">nullptr</span>;</div>
<div class="line"><a name="l04057"></a><span class="lineno"> 4057</span>&#160; </div>
<div class="line"><a name="l04058"></a><span class="lineno"> 4058</span>&#160;    <span class="keywordflow">if</span> (isa&lt;FloatType&gt;(resTy.getElementType()))</div>
<div class="line"><a name="l04059"></a><span class="lineno"> 4059</span>&#160;      <span class="keywordflow">return</span> vector::FMAOp::create(rewriter, loc, lhs, rhs, res);</div>
<div class="line"><a name="l04060"></a><span class="lineno"> 4060</span>&#160; </div>
<div class="line"><a name="l04061"></a><span class="lineno"> 4061</span>&#160;    <span class="keyword">auto</span> mul = arith::MulIOp::create(rewriter, loc, lhs, rhs);</div>
<div class="line"><a name="l04062"></a><span class="lineno"> 4062</span>&#160;    <span class="keywordflow">return</span> arith::AddIOp::create(rewriter, loc, mul, res);</div>
<div class="line"><a name="l04063"></a><span class="lineno"> 4063</span>&#160;  }</div>
<div class="line"><a name="l04064"></a><span class="lineno"> 4064</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l04065"></a><span class="lineno"> 4065</span>&#160;<span class="comment">  /// Entry point for non-channeled convolution:</span></div>
<div class="line"><a name="l04066"></a><span class="lineno"> 4066</span>&#160;<span class="comment">  ///   {{w + kw}, {kw}, {w}}</span></div>
<div class="line"><a name="l04067"></a><span class="lineno"> 4067</span>&#160;<span class="comment"></span>  FailureOr&lt;Operation *&gt; generateNonChanneledConv() {</div>
<div class="line"><a name="l04068"></a><span class="lineno"> 4068</span>&#160;    <a class="code" href="classmlir_1_1AffineExpr.html">AffineExpr</a> w, kw;</div>
<div class="line"><a name="l04069"></a><span class="lineno"> 4069</span>&#160;    <a class="code" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, w, kw);</div>
<div class="line"><a name="l04070"></a><span class="lineno"> 4070</span>&#160;    <span class="keywordflow">if</span> (!iters({Par(), Red()}))</div>
<div class="line"><a name="l04071"></a><span class="lineno"> 4071</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op,</div>
<div class="line"><a name="l04072"></a><span class="lineno"> 4072</span>&#160;                                         <span class="stringliteral">&quot;failed to match conv::W 1-par 1-red&quot;</span>);</div>
<div class="line"><a name="l04073"></a><span class="lineno"> 4073</span>&#160; </div>
<div class="line"><a name="l04074"></a><span class="lineno"> 4074</span>&#160;    <span class="comment">// No transposition needed.</span></div>
<div class="line"><a name="l04075"></a><span class="lineno"> 4075</span>&#160;    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {w + kw},</div>
<div class="line"><a name="l04076"></a><span class="lineno"> 4076</span>&#160;                <span class="comment">/*rhsIndex*/</span> {kw},</div>
<div class="line"><a name="l04077"></a><span class="lineno"> 4077</span>&#160;                <span class="comment">/*resIndex*/</span> {w}}))</div>
<div class="line"><a name="l04078"></a><span class="lineno"> 4078</span>&#160;      <span class="keywordflow">return</span> conv(<a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>);</div>
<div class="line"><a name="l04079"></a><span class="lineno"> 4079</span>&#160; </div>
<div class="line"><a name="l04080"></a><span class="lineno"> 4080</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a conv::W layout&quot;</span>);</div>
<div class="line"><a name="l04081"></a><span class="lineno"> 4081</span>&#160;  }</div>
<div class="line"><a name="l04082"></a><span class="lineno"> 4082</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l04083"></a><span class="lineno"> 4083</span>&#160;<span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a name="l04084"></a><span class="lineno"> 4084</span>&#160;<span class="comment">  ///   {{n, strideW * w + dilationW * kw, c}, {kw, c, f}, {n, w, f}}</span></div>
<div class="line"><a name="l04085"></a><span class="lineno"> 4085</span>&#160;<span class="comment"></span>  FailureOr&lt;Operation *&gt; generateNwcConv() {</div>
<div class="line"><a name="l04086"></a><span class="lineno"> 4086</span>&#160;    <a class="code" href="classmlir_1_1AffineExpr.html">AffineExpr</a> n, w, f, kw, c;</div>
<div class="line"><a name="l04087"></a><span class="lineno"> 4087</span>&#160;    <a class="code" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, w, f, kw, c);</div>
<div class="line"><a name="l04088"></a><span class="lineno"> 4088</span>&#160;    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red(), Red()}))</div>
<div class="line"><a name="l04089"></a><span class="lineno"> 4089</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l04090"></a><span class="lineno"> 4090</span>&#160;          op, <span class="stringliteral">&quot;failed to match conv::Nwc 3-par 2-red&quot;</span>);</div>
<div class="line"><a name="l04091"></a><span class="lineno"> 4091</span>&#160; </div>
<div class="line"><a name="l04092"></a><span class="lineno"> 4092</span>&#160;    <span class="comment">// No transposition needed.</span></div>
<div class="line"><a name="l04093"></a><span class="lineno"> 4093</span>&#160;    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, strideW * w + dilationW * kw, c},</div>
<div class="line"><a name="l04094"></a><span class="lineno"> 4094</span>&#160;                <span class="comment">/*rhsIndex*/</span> {kw, c, f},</div>
<div class="line"><a name="l04095"></a><span class="lineno"> 4095</span>&#160;                <span class="comment">/*resIndex*/</span> {n, w, f}}))</div>
<div class="line"><a name="l04096"></a><span class="lineno"> 4096</span>&#160;      <span class="keywordflow">return</span> conv(<a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>);</div>
<div class="line"><a name="l04097"></a><span class="lineno"> 4097</span>&#160; </div>
<div class="line"><a name="l04098"></a><span class="lineno"> 4098</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a conv::Nwc layout&quot;</span>);</div>
<div class="line"><a name="l04099"></a><span class="lineno"> 4099</span>&#160;  }</div>
<div class="line"><a name="l04100"></a><span class="lineno"> 4100</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l04101"></a><span class="lineno"> 4101</span>&#160;<span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a name="l04102"></a><span class="lineno"> 4102</span>&#160;<span class="comment">  ///   {{n, c, strideW * w + dilationW * kw}, {f, c, kw}, {n, f, w}}</span></div>
<div class="line"><a name="l04103"></a><span class="lineno"> 4103</span>&#160;<span class="comment"></span>  FailureOr&lt;Operation *&gt; generateNcwConv() {</div>
<div class="line"><a name="l04104"></a><span class="lineno"> 4104</span>&#160;    <a class="code" href="classmlir_1_1AffineExpr.html">AffineExpr</a> n, w, f, kw, c;</div>
<div class="line"><a name="l04105"></a><span class="lineno"> 4105</span>&#160;    <a class="code" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, f, w, c, kw);</div>
<div class="line"><a name="l04106"></a><span class="lineno"> 4106</span>&#160;    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red(), Red()}))</div>
<div class="line"><a name="l04107"></a><span class="lineno"> 4107</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l04108"></a><span class="lineno"> 4108</span>&#160;          op, <span class="stringliteral">&quot;failed to match conv::Ncw 3-par 2-red&quot;</span>);</div>
<div class="line"><a name="l04109"></a><span class="lineno"> 4109</span>&#160; </div>
<div class="line"><a name="l04110"></a><span class="lineno"> 4110</span>&#160;    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, c, strideW * w + dilationW * kw},</div>
<div class="line"><a name="l04111"></a><span class="lineno"> 4111</span>&#160;                <span class="comment">/*rhsIndex*/</span> {f, c, kw},</div>
<div class="line"><a name="l04112"></a><span class="lineno"> 4112</span>&#160;                <span class="comment">/*resIndex*/</span> {n, f, w}}))</div>
<div class="line"><a name="l04113"></a><span class="lineno"> 4113</span>&#160;      <span class="keywordflow">return</span> conv(<a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>);</div>
<div class="line"><a name="l04114"></a><span class="lineno"> 4114</span>&#160; </div>
<div class="line"><a name="l04115"></a><span class="lineno"> 4115</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a conv::Ncw layout&quot;</span>);</div>
<div class="line"><a name="l04116"></a><span class="lineno"> 4116</span>&#160;  }</div>
<div class="line"><a name="l04117"></a><span class="lineno"> 4117</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l04118"></a><span class="lineno"> 4118</span>&#160;<span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a name="l04119"></a><span class="lineno"> 4119</span>&#160;<span class="comment">  ///   {{n, strideW * w + dilationW * kw, c}, {kw}, {n, w, c}} for pooling</span></div>
<div class="line"><a name="l04120"></a><span class="lineno"> 4120</span>&#160;<span class="comment"></span>  FailureOr&lt;Operation *&gt; generateNwcPooling() {</div>
<div class="line"><a name="l04121"></a><span class="lineno"> 4121</span>&#160;    <a class="code" href="classmlir_1_1AffineExpr.html">AffineExpr</a> n, w, c, kw;</div>
<div class="line"><a name="l04122"></a><span class="lineno"> 4122</span>&#160;    <a class="code" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, w, c, kw);</div>
<div class="line"><a name="l04123"></a><span class="lineno"> 4123</span>&#160;    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red()}))</div>
<div class="line"><a name="l04124"></a><span class="lineno"> 4124</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op,</div>
<div class="line"><a name="l04125"></a><span class="lineno"> 4125</span>&#160;                                         <span class="stringliteral">&quot;failed to match pooling 3-par 1-red&quot;</span>);</div>
<div class="line"><a name="l04126"></a><span class="lineno"> 4126</span>&#160; </div>
<div class="line"><a name="l04127"></a><span class="lineno"> 4127</span>&#160;    <span class="comment">// No transposition needed.</span></div>
<div class="line"><a name="l04128"></a><span class="lineno"> 4128</span>&#160;    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, strideW * w + dilationW * kw, c},</div>
<div class="line"><a name="l04129"></a><span class="lineno"> 4129</span>&#160;                <span class="comment">/*rhsIndex*/</span> {kw},</div>
<div class="line"><a name="l04130"></a><span class="lineno"> 4130</span>&#160;                <span class="comment">/*resIndex*/</span> {n, w, c}}))</div>
<div class="line"><a name="l04131"></a><span class="lineno"> 4131</span>&#160;      <span class="keywordflow">return</span> conv(<a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>);</div>
<div class="line"><a name="l04132"></a><span class="lineno"> 4132</span>&#160; </div>
<div class="line"><a name="l04133"></a><span class="lineno"> 4133</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a pooling::Nwc layout&quot;</span>);</div>
<div class="line"><a name="l04134"></a><span class="lineno"> 4134</span>&#160;  }</div>
<div class="line"><a name="l04135"></a><span class="lineno"> 4135</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l04136"></a><span class="lineno"> 4136</span>&#160;<span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a name="l04137"></a><span class="lineno"> 4137</span>&#160;<span class="comment">  ///   {{n, c, strideW * w + dilationW * kw}, {kw}, {n, c, w}} for pooling</span></div>
<div class="line"><a name="l04138"></a><span class="lineno"> 4138</span>&#160;<span class="comment"></span>  FailureOr&lt;Operation *&gt; generateNcwPooling() {</div>
<div class="line"><a name="l04139"></a><span class="lineno"> 4139</span>&#160;    <a class="code" href="classmlir_1_1AffineExpr.html">AffineExpr</a> n, w, c, kw;</div>
<div class="line"><a name="l04140"></a><span class="lineno"> 4140</span>&#160;    <a class="code" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, c, w, kw);</div>
<div class="line"><a name="l04141"></a><span class="lineno"> 4141</span>&#160;    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red()}))</div>
<div class="line"><a name="l04142"></a><span class="lineno"> 4142</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op,</div>
<div class="line"><a name="l04143"></a><span class="lineno"> 4143</span>&#160;                                         <span class="stringliteral">&quot;failed to match pooling 3-par 1-red&quot;</span>);</div>
<div class="line"><a name="l04144"></a><span class="lineno"> 4144</span>&#160; </div>
<div class="line"><a name="l04145"></a><span class="lineno"> 4145</span>&#160;    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, c, strideW * w + dilationW * kw},</div>
<div class="line"><a name="l04146"></a><span class="lineno"> 4146</span>&#160;                <span class="comment">/*rhsIndex*/</span> {kw},</div>
<div class="line"><a name="l04147"></a><span class="lineno"> 4147</span>&#160;                <span class="comment">/*resIndex*/</span> {n, c, w}}))</div>
<div class="line"><a name="l04148"></a><span class="lineno"> 4148</span>&#160;      <span class="keywordflow">return</span> conv(<a class="code" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>);</div>
<div class="line"><a name="l04149"></a><span class="lineno"> 4149</span>&#160; </div>
<div class="line"><a name="l04150"></a><span class="lineno"> 4150</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a pooling::Ncw layout&quot;</span>);</div>
<div class="line"><a name="l04151"></a><span class="lineno"> 4151</span>&#160;  }</div>
<div class="line"><a name="l04152"></a><span class="lineno"> 4152</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l04153"></a><span class="lineno"> 4153</span>&#160;<span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a name="l04154"></a><span class="lineno"> 4154</span>&#160;<span class="comment">  ///   {{n, strideW * w + dilationW * kw, c}, {kw, c}, {n, w, c}}</span></div>
<div class="line"><a name="l04155"></a><span class="lineno"> 4155</span>&#160;<span class="comment"></span>  FailureOr&lt;Operation *&gt; generateDilatedConv(uint64_t vecChDimSize = 0,</div>
<div class="line"><a name="l04156"></a><span class="lineno"> 4156</span>&#160;                                             <span class="keywordtype">bool</span> vecChDimScalableFlag = <span class="keyword">false</span>,</div>
<div class="line"><a name="l04157"></a><span class="lineno"> 4157</span>&#160;                                             <span class="keywordtype">bool</span> flatten = <span class="keyword">false</span>) {</div>
<div class="line"><a name="l04158"></a><span class="lineno"> 4158</span>&#160;    <a class="code" href="classmlir_1_1AffineExpr.html">AffineExpr</a> n, w, c, kw;</div>
<div class="line"><a name="l04159"></a><span class="lineno"> 4159</span>&#160;    <a class="code" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, w, c, kw);</div>
<div class="line"><a name="l04160"></a><span class="lineno"> 4160</span>&#160;    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red()}))</div>
<div class="line"><a name="l04161"></a><span class="lineno"> 4161</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l04162"></a><span class="lineno"> 4162</span>&#160;          op, <span class="stringliteral">&quot;failed to match depthwise::Nwc conv 3-par 1-red&quot;</span>);</div>
<div class="line"><a name="l04163"></a><span class="lineno"> 4163</span>&#160; </div>
<div class="line"><a name="l04164"></a><span class="lineno"> 4164</span>&#160;    <span class="comment">// No transposition needed.</span></div>
<div class="line"><a name="l04165"></a><span class="lineno"> 4165</span>&#160;    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, strideW * w + dilationW * kw, c},</div>
<div class="line"><a name="l04166"></a><span class="lineno"> 4166</span>&#160;                <span class="comment">/*rhsIndex*/</span> {kw, c},</div>
<div class="line"><a name="l04167"></a><span class="lineno"> 4167</span>&#160;                <span class="comment">/*resIndex*/</span> {n, w, c}}))</div>
<div class="line"><a name="l04168"></a><span class="lineno"> 4168</span>&#160;      <span class="keywordflow">return</span> depthwiseConv(vecChDimSize, vecChDimScalableFlag, flatten);</div>
<div class="line"><a name="l04169"></a><span class="lineno"> 4169</span>&#160; </div>
<div class="line"><a name="l04170"></a><span class="lineno"> 4170</span>&#160;    <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a depthwise::Nwc layout&quot;</span>);</div>
<div class="line"><a name="l04171"></a><span class="lineno"> 4171</span>&#160;  }</div>
<div class="line"><a name="l04172"></a><span class="lineno"> 4172</span>&#160; </div>
<div class="line"><a name="l04173"></a><span class="lineno"> 4173</span>&#160;<span class="keyword">private</span>:</div>
<div class="line"><a name="l04174"></a><span class="lineno"> 4174</span>&#160;  ConvOperationKind oper = ConvOperationKind::Conv;</div>
<div class="line"><a name="l04175"></a><span class="lineno"> 4175</span>&#160;  StringAttr redOp;</div>
<div class="line"><a name="l04176"></a><span class="lineno"> 4176</span>&#160;  StringAttr poolExtOp;</div>
<div class="line"><a name="l04177"></a><span class="lineno"> 4177</span>&#160;  <span class="keywordtype">bool</span> isPoolExt = <span class="keyword">false</span>;</div>
<div class="line"><a name="l04178"></a><span class="lineno"> 4178</span>&#160;  <span class="keywordtype">int</span> strideW, dilationW;</div>
<div class="line"><a name="l04179"></a><span class="lineno"> 4179</span>&#160;  <a class="code" href="classmlir_1_1Value.html">Value</a> lhsShaped, rhsShaped, resShaped;</div>
<div class="line"><a name="l04180"></a><span class="lineno"> 4180</span>&#160;  ShapedType lhsShapedType, rhsShapedType, resShapedType;</div>
<div class="line"><a name="l04181"></a><span class="lineno"> 4181</span>&#160;  vector::CombiningKind reductionKind;</div>
<div class="line"><a name="l04182"></a><span class="lineno"> 4182</span>&#160; </div>
<div class="line"><a name="l04183"></a><span class="lineno"> 4183</span>&#160;  <span class="comment">// Sets oper, poolExtOp and isPoolExt for valid conv/pooling ops.</span></div>
<div class="line"><a name="l04184"></a><span class="lineno"> 4184</span>&#160;  <span class="keywordtype">void</span> setConvOperationKind(<a class="code" href="classmlir_1_1Operation.html">Operation</a> *reduceOp) {</div>
<div class="line"><a name="l04185"></a><span class="lineno"> 4185</span>&#160;    <span class="keywordtype">int</span> numBlockArguments =</div>
<div class="line"><a name="l04186"></a><span class="lineno"> 4186</span>&#160;        llvm::count_if(reduceOp-&gt;<a class="code" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(), llvm::IsaPred&lt;BlockArgument&gt;);</div>
<div class="line"><a name="l04187"></a><span class="lineno"> 4187</span>&#160;    <span class="keywordflow">if</span> (numBlockArguments == 1) {</div>
<div class="line"><a name="l04188"></a><span class="lineno"> 4188</span>&#160;      <span class="comment">// Will be convolution if feeder is a MulOp.</span></div>
<div class="line"><a name="l04189"></a><span class="lineno"> 4189</span>&#160;      <span class="comment">// A strength reduced version of MulOp for i1 type is AndOp which is also</span></div>
<div class="line"><a name="l04190"></a><span class="lineno"> 4190</span>&#160;      <span class="comment">// supported. Otherwise, it can be pooling. This strength reduction logic</span></div>
<div class="line"><a name="l04191"></a><span class="lineno"> 4191</span>&#160;      <span class="comment">// is in `buildBinaryFn` helper in the Linalg dialect.</span></div>
<div class="line"><a name="l04192"></a><span class="lineno"> 4192</span>&#160;      <span class="keyword">auto</span> feedValIt = llvm::find_if_not(reduceOp-&gt;<a class="code" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(),</div>
<div class="line"><a name="l04193"></a><span class="lineno"> 4193</span>&#160;                                         llvm::IsaPred&lt;BlockArgument&gt;);</div>
<div class="line"><a name="l04194"></a><span class="lineno"> 4194</span>&#160;      <a class="code" href="classmlir_1_1Operation.html">Operation</a> *feedOp = (*feedValIt).getDefiningOp();</div>
<div class="line"><a name="l04195"></a><span class="lineno"> 4195</span>&#160;      <span class="keywordflow">if</span> (<a class="code" href="Vectorization_8cpp.html#a33cb68fa87ea3bda8e98058b464af807">isCastOfBlockArgument</a>(feedOp)) {</div>
<div class="line"><a name="l04196"></a><span class="lineno"> 4196</span>&#160;        oper = ConvOperationKind::Pool;</div>
<div class="line"><a name="l04197"></a><span class="lineno"> 4197</span>&#160;        isPoolExt = <span class="keyword">true</span>;</div>
<div class="line"><a name="l04198"></a><span class="lineno"> 4198</span>&#160;        poolExtOp = feedOp-&gt;<a class="code" href="classmlir_1_1Operation.html#ab2e11ba83ff765eb7595554f97aaaa75">getName</a>().<a class="code" href="classmlir_1_1OperationName.html#a2c83cffa9a4c4fb68436d9ee3497c226">getIdentifier</a>();</div>
<div class="line"><a name="l04199"></a><span class="lineno"> 4199</span>&#160;        <span class="keywordflow">return</span>;</div>
<div class="line"><a name="l04200"></a><span class="lineno"> 4200</span>&#160;      }</div>
<div class="line"><a name="l04201"></a><span class="lineno"> 4201</span>&#160;      oper = ConvOperationKind::Conv;</div>
<div class="line"><a name="l04202"></a><span class="lineno"> 4202</span>&#160;      <span class="keywordflow">return</span>;</div>
<div class="line"><a name="l04203"></a><span class="lineno"> 4203</span>&#160;    }</div>
<div class="line"><a name="l04204"></a><span class="lineno"> 4204</span>&#160;    <span class="comment">// numBlockArugments == 2 and this is a pooling op.</span></div>
<div class="line"><a name="l04205"></a><span class="lineno"> 4205</span>&#160;    oper = ConvOperationKind::Pool;</div>
<div class="line"><a name="l04206"></a><span class="lineno"> 4206</span>&#160;    isPoolExt = <span class="keyword">false</span>;</div>
<div class="line"><a name="l04207"></a><span class="lineno"> 4207</span>&#160;  }</div>
<div class="line"><a name="l04208"></a><span class="lineno"> 4208</span>&#160;};</div>
<div class="line"><a name="l04209"></a><span class="lineno"> 4209</span>&#160;} <span class="comment">// namespace</span></div>
<div class="line"><a name="l04210"></a><span class="lineno"> 4210</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l04211"></a><span class="lineno"> 4211</span>&#160;<span class="comment">/// Helper function to vectorize a LinalgOp with convolution semantics.</span></div>
<div class="line"><a name="l04212"></a><span class="lineno"> 4212</span>&#160;<span class="comment"></span><span class="comment">// TODO: extend the generic vectorization to support windows and drop this.</span></div>
<div class="line"><a name="l04213"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea"> 4213</a></span>&#160;<span class="keyword">static</span> FailureOr&lt;Operation *&gt; <a class="code" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a>(</div>
<div class="line"><a name="l04214"></a><span class="lineno"> 4214</span>&#160;    <a class="code" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, LinalgOp op, <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVecSizes,</div>
<div class="line"><a name="l04215"></a><span class="lineno"> 4215</span>&#160;    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputScalableVecDims, <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a name="l04216"></a><span class="lineno"> 4216</span>&#160;  Conv1DGenerator conv1dGen(rewriter, op);</div>
<div class="line"><a name="l04217"></a><span class="lineno"> 4217</span>&#160;  <span class="keyword">auto</span> res = conv1dGen.generateNonChanneledConv();</div>
<div class="line"><a name="l04218"></a><span class="lineno"> 4218</span>&#160;  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a name="l04219"></a><span class="lineno"> 4219</span>&#160;    <span class="keywordflow">return</span> res;</div>
<div class="line"><a name="l04220"></a><span class="lineno"> 4220</span>&#160;  res = conv1dGen.generateNwcConv();</div>
<div class="line"><a name="l04221"></a><span class="lineno"> 4221</span>&#160;  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a name="l04222"></a><span class="lineno"> 4222</span>&#160;    <span class="keywordflow">return</span> res;</div>
<div class="line"><a name="l04223"></a><span class="lineno"> 4223</span>&#160;  res = conv1dGen.generateNcwConv();</div>
<div class="line"><a name="l04224"></a><span class="lineno"> 4224</span>&#160;  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a name="l04225"></a><span class="lineno"> 4225</span>&#160;    <span class="keywordflow">return</span> res;</div>
<div class="line"><a name="l04226"></a><span class="lineno"> 4226</span>&#160;  res = conv1dGen.generateNwcPooling();</div>
<div class="line"><a name="l04227"></a><span class="lineno"> 4227</span>&#160;  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a name="l04228"></a><span class="lineno"> 4228</span>&#160;    <span class="keywordflow">return</span> res;</div>
<div class="line"><a name="l04229"></a><span class="lineno"> 4229</span>&#160;  res = conv1dGen.generateNcwPooling();</div>
<div class="line"><a name="l04230"></a><span class="lineno"> 4230</span>&#160;  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a name="l04231"></a><span class="lineno"> 4231</span>&#160;    <span class="keywordflow">return</span> res;</div>
<div class="line"><a name="l04232"></a><span class="lineno"> 4232</span>&#160; </div>
<div class="line"><a name="l04233"></a><span class="lineno"> 4233</span>&#160;  <span class="comment">// Only depthwise 1D NWC convs are left - these can be vectorized using masks</span></div>
<div class="line"><a name="l04234"></a><span class="lineno"> 4234</span>&#160;  <span class="comment">// and scalable vectors. Note that ATM the only dim that can be dynamic (i.e.</span></div>
<div class="line"><a name="l04235"></a><span class="lineno"> 4235</span>&#160;  <span class="comment">// masked/scalable) is the channel dim (i.e. the trailing dim).</span></div>
<div class="line"><a name="l04236"></a><span class="lineno"> 4236</span>&#160;  uint64_t vecChDimSize = ShapedType::kDynamic;</div>
<div class="line"><a name="l04237"></a><span class="lineno"> 4237</span>&#160;  <span class="keywordtype">bool</span> vecChDimScalableFlag = <span class="keyword">false</span>;</div>
<div class="line"><a name="l04238"></a><span class="lineno"> 4238</span>&#160;  <span class="keywordflow">if</span> (!inputVecSizes.empty()) {</div>
<div class="line"><a name="l04239"></a><span class="lineno"> 4239</span>&#160;    <span class="comment">// Only use the input vector size corresponding to the channel dim. Other</span></div>
<div class="line"><a name="l04240"></a><span class="lineno"> 4240</span>&#160;    <span class="comment">// vector dims will be inferred from the Ops.</span></div>
<div class="line"><a name="l04241"></a><span class="lineno"> 4241</span>&#160;    assert((isa&lt;linalg::DepthwiseConv1DNwcWcOp&gt;(*op) ||</div>
<div class="line"><a name="l04242"></a><span class="lineno"> 4242</span>&#160;            isa&lt;linalg::DepthwiseConv1DNcwCwOp&gt;(*op)) &amp;&amp;</div>
<div class="line"><a name="l04243"></a><span class="lineno"> 4243</span>&#160;           <span class="stringliteral">&quot;Not a 1D depthwise conv!&quot;</span>);</div>
<div class="line"><a name="l04244"></a><span class="lineno"> 4244</span>&#160;    <span class="keywordtype">size_t</span> chDimIdx =</div>
<div class="line"><a name="l04245"></a><span class="lineno"> 4245</span>&#160;        <a class="code" href="classllvm_1_1TypeSwitch.html">TypeSwitch&lt;Operation *, size_t&gt;</a>(op)</div>
<div class="line"><a name="l04246"></a><span class="lineno"> 4246</span>&#160;            .Case&lt;linalg::DepthwiseConv1DNwcWcOp&gt;([](<span class="keyword">auto</span> conv) { <span class="keywordflow">return</span> 2; })</div>
<div class="line"><a name="l04247"></a><span class="lineno"> 4247</span>&#160;            .Case&lt;linalg::DepthwiseConv1DNcwCwOp&gt;([](<span class="keyword">auto</span> conv) { <span class="keywordflow">return</span> 1; });</div>
<div class="line"><a name="l04248"></a><span class="lineno"> 4248</span>&#160; </div>
<div class="line"><a name="l04249"></a><span class="lineno"> 4249</span>&#160;    vecChDimSize = inputVecSizes[chDimIdx];</div>
<div class="line"><a name="l04250"></a><span class="lineno"> 4250</span>&#160;    vecChDimScalableFlag = inputScalableVecDims[chDimIdx];</div>
<div class="line"><a name="l04251"></a><span class="lineno"> 4251</span>&#160;  }</div>
<div class="line"><a name="l04252"></a><span class="lineno"> 4252</span>&#160;  <span class="keywordflow">return</span> conv1dGen.generateDilatedConv(vecChDimSize, vecChDimScalableFlag,</div>
<div class="line"><a name="l04253"></a><span class="lineno"> 4253</span>&#160;                                       flatten1DDepthwiseConv);</div>
<div class="line"><a name="l04254"></a><span class="lineno"> 4254</span>&#160;}</div>
<div class="line"><a name="l04255"></a><span class="lineno"> 4255</span>&#160; </div>
<div class="line"><a name="l04256"></a><span class="lineno"><a class="line" href="structVectorizeConvolution.html"> 4256</a></span>&#160;<span class="keyword">struct </span><a class="code" href="structVectorizeConvolution.html">VectorizeConvolution</a> : <span class="keyword">public</span> <a class="code" href="structmlir_1_1OpInterfaceRewritePattern.html">OpInterfaceRewritePattern</a>&lt;LinalgOp&gt; {</div>
<div class="line"><a name="l04257"></a><span class="lineno"> 4257</span>&#160;  <span class="keyword">using</span> <a class="code" href="structmlir_1_1OpInterfaceRewritePattern.html#a723a250f581dc2a0758fbe6b7c55f1c9">OpInterfaceRewritePattern::OpInterfaceRewritePattern</a>;</div>
<div class="line"><a name="l04258"></a><span class="lineno"> 4258</span>&#160; </div>
<div class="line"><a name="l04259"></a><span class="lineno"><a class="line" href="structVectorizeConvolution.html#a443953ce53e5f5038608ab46597ebbaf"> 4259</a></span>&#160;  LogicalResult <a class="code" href="structVectorizeConvolution.html#a443953ce53e5f5038608ab46597ebbaf">matchAndRewrite</a>(LinalgOp op,</div>
<div class="line"><a name="l04260"></a><span class="lineno"> 4260</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l04261"></a><span class="lineno"> 4261</span>&#160;    FailureOr&lt;Operation *&gt; resultOrFail = <a class="code" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a>(rewriter, op);</div>
<div class="line"><a name="l04262"></a><span class="lineno"> 4262</span>&#160;    <span class="keywordflow">if</span> (failed(resultOrFail))</div>
<div class="line"><a name="l04263"></a><span class="lineno"> 4263</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l04264"></a><span class="lineno"> 4264</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *newOp = *resultOrFail;</div>
<div class="line"><a name="l04265"></a><span class="lineno"> 4265</span>&#160;    <span class="keywordflow">if</span> (newOp-&gt;<a class="code" href="classmlir_1_1Operation.html#afeb237ab61bc6c18e133da3060a7fbfb">getNumResults</a>() == 0) {</div>
<div class="line"><a name="l04266"></a><span class="lineno"> 4266</span>&#160;      rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(op.getOperation());</div>
<div class="line"><a name="l04267"></a><span class="lineno"> 4267</span>&#160;      <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l04268"></a><span class="lineno"> 4268</span>&#160;    }</div>
<div class="line"><a name="l04269"></a><span class="lineno"> 4269</span>&#160;    assert(newOp-&gt;<a class="code" href="classmlir_1_1Operation.html#afeb237ab61bc6c18e133da3060a7fbfb">getNumResults</a>() == 1 &amp;&amp; <span class="stringliteral">&quot;expected single result&quot;</span>);</div>
<div class="line"><a name="l04270"></a><span class="lineno"> 4270</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(op.getOperation(), newOp-&gt;<a class="code" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a name="l04271"></a><span class="lineno"> 4271</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l04272"></a><span class="lineno"> 4272</span>&#160;  }</div>
<div class="line"><a name="l04273"></a><span class="lineno"> 4273</span>&#160;};</div>
<div class="line"><a name="l04274"></a><span class="lineno"> 4274</span>&#160; </div>
<div class="line"><a name="l04275"></a><span class="lineno"><a class="line" href="namespacemlir_1_1linalg.html#a891b8f2d145dcc3327ba55c7a49d44e4"> 4275</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="namespacemlir_1_1linalg.html#a891b8f2d145dcc3327ba55c7a49d44e4">mlir::linalg::populateConvolutionVectorizationPatterns</a>(</div>
<div class="line"><a name="l04276"></a><span class="lineno"> 4276</span>&#160;    <a class="code" href="classmlir_1_1RewritePatternSet.html">RewritePatternSet</a> &amp;<a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>, <a class="code" href="classmlir_1_1PatternBenefit.html">PatternBenefit</a> benefit) {</div>
<div class="line"><a name="l04277"></a><span class="lineno"> 4277</span>&#160;  <a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.add&lt;<a class="code" href="structVectorizeConvolution.html">VectorizeConvolution</a>&gt;(<a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.getContext(), benefit);</div>
<div class="line"><a name="l04278"></a><span class="lineno"> 4278</span>&#160;}</div>
<div class="ttc" id="aAffineOps_8h_html"><div class="ttname"><a href="AffineOps_8h.html">AffineOps.h</a></div></div>
<div class="ttc" id="aBuilders_8h_html"><div class="ttname"><a href="Builders_8h.html">Builders.h</a></div></div>
<div class="ttc" id="aBuiltinTypeInterfaces_8h_html"><div class="ttname"><a href="BuiltinTypeInterfaces_8h.html">BuiltinTypeInterfaces.h</a></div></div>
<div class="ttc" id="aDialect_2Affine_2Utils_8h_html"><div class="ttname"><a href="Dialect_2Affine_2Utils_8h.html">Utils.h</a></div></div>
<div class="ttc" id="aDialect_2Linalg_2Utils_2Utils_8h_html"><div class="ttname"><a href="Dialect_2Linalg_2Utils_2Utils_8h.html">Utils.h</a></div></div>
<div class="ttc" id="aFuncOps_8h_html"><div class="ttname"><a href="FuncOps_8h.html">FuncOps.h</a></div></div>
<div class="ttc" id="aIndexingUtils_8h_html"><div class="ttname"><a href="IndexingUtils_8h.html">IndexingUtils.h</a></div></div>
<div class="ttc" id="aLinalgOps_8cpp_html_a28955b1aca39affb65f8316b45796bfa"><div class="ttname"><a href="LinalgOps_8cpp.html#a28955b1aca39affb65f8316b45796bfa">kind</a></div><div class="ttdeci">union mlir::linalg::@1225::ArityGroupAndKind::Kind kind</div></div>
<div class="ttc" id="aLinalgOps_8cpp_html_a2f749fca1dfad319b229d0c4884bf113"><div class="ttname"><a href="LinalgOps_8cpp.html#a2f749fca1dfad319b229d0c4884bf113">outerDimsPerm</a></div><div class="ttdeci">SmallVector&lt; int64_t &gt; outerDimsPerm</div><div class="ttdef"><b>Definition:</b> <a href="LinalgOps_8cpp_source.html#l04749">LinalgOps.cpp:4749</a></div></div>
<div class="ttc" id="aLinalgOps_8cpp_html_a4e9957a01583cd463e0cb458fc18013c"><div class="ttname"><a href="LinalgOps_8cpp.html#a4e9957a01583cd463e0cb458fc18013c">innerTiles</a></div><div class="ttdeci">SmallVector&lt; OpFoldResult &gt; innerTiles</div><div class="ttdef"><b>Definition:</b> <a href="LinalgOps_8cpp_source.html#l04748">LinalgOps.cpp:4748</a></div></div>
<div class="ttc" id="aLinalgOps_8cpp_html_aa7b25f95711cd673d4f468989b6fbad1"><div class="ttname"><a href="LinalgOps_8cpp.html#aa7b25f95711cd673d4f468989b6fbad1">innerDimsPos</a></div><div class="ttdeci">SmallVector&lt; int64_t &gt; innerDimsPos</div><div class="ttdef"><b>Definition:</b> <a href="LinalgOps_8cpp_source.html#l04747">LinalgOps.cpp:4747</a></div></div>
<div class="ttc" id="aMaskableOpInterface_8h_html"><div class="ttname"><a href="MaskableOpInterface_8h.html">MaskableOpInterface.h</a></div></div>
<div class="ttc" id="aOpDefinition_8h_html"><div class="ttname"><a href="OpDefinition_8h.html">OpDefinition.h</a></div></div>
<div class="ttc" id="aPatternMatch_8h_html"><div class="ttname"><a href="PatternMatch_8h.html">PatternMatch.h</a></div></div>
<div class="ttc" id="aPolynomialApproximation_8cpp_html_a42d8a93cefd0d3e87b43de975bfd31bc"><div class="ttname"><a href="PolynomialApproximation_8cpp.html#a42d8a93cefd0d3e87b43de975bfd31bc">vectorShape</a></div><div class="ttdeci">static std::optional&lt; VectorShape &gt; vectorShape(Type type)</div><div class="ttdef"><b>Definition:</b> <a href="PolynomialApproximation_8cpp_source.html#l00047">PolynomialApproximation.cpp:47</a></div></div>
<div class="ttc" id="aPolynomialApproximation_8cpp_html_aaf0f5c82a4c61c0e930f33c21058f82e"><div class="ttname"><a href="PolynomialApproximation_8cpp.html#aaf0f5c82a4c61c0e930f33c21058f82e">clamp</a></div><div class="ttdeci">static Value clamp(ImplicitLocOpBuilder &amp;builder, Value value, Value lowerBound, Value upperBound)</div><div class="ttdef"><b>Definition:</b> <a href="PolynomialApproximation_8cpp_source.html#l00220">PolynomialApproximation.cpp:220</a></div></div>
<div class="ttc" id="aPolynomialApproximation_8cpp_html_af7cb11d1121f694b53c0981dc5e8ba9a"><div class="ttname"><a href="PolynomialApproximation_8cpp.html#af7cb11d1121f694b53c0981dc5e8ba9a">min</a></div><div class="ttdeci">static Value min(ImplicitLocOpBuilder &amp;builder, Value value, Value bound)</div><div class="ttdef"><b>Definition:</b> <a href="PolynomialApproximation_8cpp_source.html#l00204">PolynomialApproximation.cpp:204</a></div></div>
<div class="ttc" id="aRegionUtils_8h_html"><div class="ttname"><a href="RegionUtils_8h.html">RegionUtils.h</a></div></div>
<div class="ttc" id="aSliceAnalysis_8h_html"><div class="ttname"><a href="SliceAnalysis_8h.html">SliceAnalysis.h</a></div></div>
<div class="ttc" id="aSparseTensorIterator_8cpp_html_ace3cf96892ab9fd15d9e7b6b35044b43"><div class="ttname"><a href="SparseTensorIterator_8cpp.html#ace3cf96892ab9fd15d9e7b6b35044b43">MINUI</a></div><div class="ttdeci">#define MINUI(lhs, rhs)</div><div class="ttdef"><b>Definition:</b> <a href="SparseTensorIterator_8cpp_source.html#l00037">SparseTensorIterator.cpp:37</a></div></div>
<div class="ttc" id="aStructuredOpsUtils_8h_html"><div class="ttname"><a href="StructuredOpsUtils_8h.html">StructuredOpsUtils.h</a></div></div>
<div class="ttc" id="aValue_8h_html"><div class="ttname"><a href="Value_8h.html">Value.h</a></div></div>
<div class="ttc" id="aVectorOps_8h_html"><div class="ttname"><a href="VectorOps_8h.html">VectorOps.h</a></div></div>
<div class="ttc" id="aVectorUtils_8h_html"><div class="ttname"><a href="VectorUtils_8h.html">VectorUtils.h</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a007245f85f137cf2008229e2a4932915"><div class="ttname"><a href="Vectorization_8cpp.html#a007245f85f137cf2008229e2a4932915">getConvOperationKind</a></div><div class="ttdeci">static std::optional&lt; ConvOperationKind &gt; getConvOperationKind(Operation *reduceOp)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02258">Vectorization.cpp:2258</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a026c54c12deb9d84b6fc83be82d1c183"><div class="ttname"><a href="Vectorization_8cpp.html#a026c54c12deb9d84b6fc83be82d1c183">vectorizeAsTensorUnpackOp</a></div><div class="ttdeci">static LogicalResult vectorizeAsTensorUnpackOp(RewriterBase &amp;rewriter, linalg::UnPackOp unpackOp, ArrayRef&lt; int64_t &gt; inputVectorSizes, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Vectorize a linalg::UnPackOp to these 4 Ops: Vector::TransferReadOp - Reads a vector from the source ...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01891">Vectorization.cpp:1891</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a035a7bd3b44d215db6d50b32318822c0"><div class="ttname"><a href="Vectorization_8cpp.html#a035a7bd3b44d215db6d50b32318822c0">getSubViewUseIfUnique</a></div><div class="ttdeci">static memref::SubViewOp getSubViewUseIfUnique(Value v)</div><div class="ttdoc">Return the unique subview use of v if it is indeed unique, null otherwise.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03290">Vectorization.cpp:3290</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a042126c1ec44e80d376fb8e5baa1efd0"><div class="ttname"><a href="Vectorization_8cpp.html#a042126c1ec44e80d376fb8e5baa1efd0">vectorizeAsTensorPackOp</a></div><div class="ttdeci">static LogicalResult vectorizeAsTensorPackOp(RewriterBase &amp;rewriter, linalg::PackOp packOp, ArrayRef&lt; int64_t &gt; inputVectorSizes, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Vectorize linalg::PackOp with (1) static inner_tiles (2) constant padding value and (3) input vector ...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01765">Vectorization.cpp:1765</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a0bcdc4b64d42010b23b271435831cb39"><div class="ttname"><a href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a></div><div class="ttdeci">static bool isLoopInvariantIdx(LinalgOp &amp;linalgOp, Value &amp;val, VectorType resType)</div><div class="ttdoc">Checks whether val can be used for calculating a loop invariant index.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00937">Vectorization.cpp:937</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a110d1ed6891097419f0358bd63e974c8"><div class="ttname"><a href="Vectorization_8cpp.html#a110d1ed6891097419f0358bd63e974c8">insertConvResultSlices</a></div><div class="ttdeci">static Value insertConvResultSlices(RewriterBase &amp;rewriter, Location loc, Value res, int64_t wSize, int64_t wSizeStep, SmallVectorImpl&lt; Value &gt; &amp;resVals, bool isSingleChanneled)</div><div class="ttdoc">Helper function to insert the computed result slices.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00189">Vectorization.cpp:189</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a172594be3a7384cb03a833aed99dc03c"><div class="ttname"><a href="Vectorization_8cpp.html#a172594be3a7384cb03a833aed99dc03c">getTensorExtractMemoryAccessPattern</a></div><div class="ttdeci">static VectorMemoryAccessKind getTensorExtractMemoryAccessPattern(tensor::ExtractOp extractOp, LinalgOp &amp;linalgOp, VectorType resType)</div><div class="ttdoc">Infer the memory access pattern for the input ExtractOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01051">Vectorization.cpp:1051</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a1bedce144a30ca3ef5eac6628b35d4a9"><div class="ttname"><a href="Vectorization_8cpp.html#a1bedce144a30ca3ef5eac6628b35d4a9">isMaskTriviallyFoldable</a></div><div class="ttdeci">static bool isMaskTriviallyFoldable(SmallVector&lt; OpFoldResult &gt; &amp;maskSizes, SmallVector&lt; Value &gt; &amp;writeIdxs, ArrayRef&lt; int64_t &gt; destShape, ArrayRef&lt; int64_t &gt; maskShape)</div><div class="ttdoc">Determines whether a mask for xfer_write is trivially &quot;all true&quot;.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01586">Vectorization.cpp:1586</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a1ee50532663d56946548afe0ff92509c"><div class="ttname"><a href="Vectorization_8cpp.html#a1ee50532663d56946548afe0ff92509c">reductionPreconditions</a></div><div class="ttdeci">static LogicalResult reductionPreconditions(LinalgOp op)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02031">Vectorization.cpp:2031</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a224b215237fb8401f7031f2991266dcc"><div class="ttname"><a href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcc">VectorMemoryAccessKind</a></div><div class="ttdeci">VectorMemoryAccessKind</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00902">Vectorization.cpp:902</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea"><div class="ttname"><a href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea">Contiguous</a></div><div class="ttdeci">@ Contiguous</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00902">Vectorization.cpp:902</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d"><div class="ttname"><a href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">Gather</a></div><div class="ttdeci">@ Gather</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00902">Vectorization.cpp:902</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca"><div class="ttname"><a href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">ScalarBroadcast</a></div><div class="ttdeci">@ ScalarBroadcast</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00902">Vectorization.cpp:902</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a26cb5e24425fdce30baaba6f7c0f5c84"><div class="ttname"><a href="Vectorization_8cpp.html#a26cb5e24425fdce30baaba6f7c0f5c84">vectorizeTensorExtract</a></div><div class="ttdeci">static VectorizationHookResult vectorizeTensorExtract(RewriterBase &amp;rewriter, VectorizationState &amp;state, Operation *op, LinalgOp linalgOp, const IRMapping &amp;bvm)</div><div class="ttdoc">Helper function to vectorize the tensor.extract operations.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01132">Vectorization.cpp:1132</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a280bd1ab81d418cd32713eeb0a2dfffd"><div class="ttname"><a href="Vectorization_8cpp.html#a280bd1ab81d418cd32713eeb0a2dfffd">vectorizeLinalgIndex</a></div><div class="ttdeci">static VectorizationHookResult vectorizeLinalgIndex(RewriterBase &amp;rewriter, VectorizationState &amp;state, Operation *op, LinalgOp linalgOp)</div><div class="ttdoc">Helper function to vectorize the index operations of a linalgOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00794">Vectorization.cpp:794</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a298ab89fe37b4d0e351c2d1619476926"><div class="ttname"><a href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926">vectorizeAsInsertSliceOp</a></div><div class="ttdeci">static LogicalResult vectorizeAsInsertSliceOp(RewriterBase &amp;rewriter, tensor::InsertSliceOp sliceOp, ArrayRef&lt; int64_t &gt; inputVectorSizes, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Vectorize tensor::InsertSliceOp with:</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03095">Vectorization.cpp:3095</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a2d2260cd7405010dc09da594212af829"><div class="ttname"><a href="Vectorization_8cpp.html#a2d2260cd7405010dc09da594212af829">vectorizePadOpPrecondition</a></div><div class="ttdeci">static LogicalResult vectorizePadOpPrecondition(tensor::PadOp padOp, ArrayRef&lt; int64_t &gt; inputVectorSizes)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02464">Vectorization.cpp:2464</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a313dd728e35dcd639ff665bcc97d81ad"><div class="ttname"><a href="Vectorization_8cpp.html#a313dd728e35dcd639ff665bcc97d81ad">extractConvFilterSlices</a></div><div class="ttdeci">static SmallVector&lt; Value &gt; extractConvFilterSlices(RewriterBase &amp;rewriter, Location loc, Value filter, int64_t kwSize)</div><div class="ttdoc">Helper function to extract the filter slices after filter is unrolled along kw.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00145">Vectorization.cpp:145</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a320b06f6c6f3905541d59f2c33ce5aea"><div class="ttname"><a href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a></div><div class="ttdeci">static FailureOr&lt; Operation * &gt; vectorizeConvolution(RewriterBase &amp;rewriter, LinalgOp convOp, ArrayRef&lt; int64_t &gt; inputVecSizes={}, ArrayRef&lt; bool &gt; inputVecScalableFlags={}, bool flatten1DDepthwiseConv=false)</div><div class="ttdoc">Try to vectorize convOp as a convolution.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l04213">Vectorization.cpp:4213</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a33cb68fa87ea3bda8e98058b464af807"><div class="ttname"><a href="Vectorization_8cpp.html#a33cb68fa87ea3bda8e98058b464af807">isCastOfBlockArgument</a></div><div class="ttdeci">static bool isCastOfBlockArgument(Operation *op)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02242">Vectorization.cpp:2242</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a35e1ec347850959af0bc7cbdf61b9da3"><div class="ttname"><a href="Vectorization_8cpp.html#a35e1ec347850959af0bc7cbdf61b9da3">vectorizeAsLinalgGeneric</a></div><div class="ttdeci">static LogicalResult vectorizeAsLinalgGeneric(RewriterBase &amp;rewriter, VectorizationState &amp;state, LinalgOp linalgOp, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Generic vectorization function that rewrites the body of a linalgOp into vector form.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01418">Vectorization.cpp:1418</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a41a2f2306467feacee5865c5be9c0401"><div class="ttname"><a href="Vectorization_8cpp.html#a41a2f2306467feacee5865c5be9c0401">extractConvInputSlices</a></div><div class="ttdeci">static SmallVector&lt; Value &gt; extractConvInputSlices(RewriterBase &amp;rewriter, Location loc, Value input, int64_t nSize, int64_t wSize, int64_t cSize, int64_t kwSize, int strideW, int dilationW, int64_t wSizeStep, bool isSingleChanneled)</div><div class="ttdoc">Helper function to extract the input slices after filter is unrolled along kw.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00109">Vectorization.cpp:109</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a455f83de6534e53da06be057973f7e38"><div class="ttname"><a href="Vectorization_8cpp.html#a455f83de6534e53da06be057973f7e38">vectorizeOneOp</a></div><div class="ttdeci">static VectorizationHookResult vectorizeOneOp(RewriterBase &amp;rewriter, VectorizationState &amp;state, LinalgOp linalgOp, Operation *op, const IRMapping &amp;bvm, ArrayRef&lt; CustomVectorizationHook &gt; customVectorizationHooks)</div><div class="ttdoc">Generic vectorization for a single operation op, given already vectorized operands carried by bvm.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01303">Vectorization.cpp:1303</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a4cc023e06de6664a1cd635d77118db19"><div class="ttname"><a href="Vectorization_8cpp.html#a4cc023e06de6664a1cd635d77118db19">createWriteOrMaskedWrite</a></div><div class="ttdeci">static Operation * createWriteOrMaskedWrite(OpBuilder &amp;builder, Location loc, Value vecToStore, Value dest, SmallVector&lt; Value &gt; writeIndices={}, bool useInBoundsInsteadOfMasking=false)</div><div class="ttdoc">Creates an optionally masked TransferWriteOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01663">Vectorization.cpp:1663</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a4ffeefd6b3cba67afe11ecdc2b48fcef"><div class="ttname"><a href="Vectorization_8cpp.html#a4ffeefd6b3cba67afe11ecdc2b48fcef">buildVectorWrite</a></div><div class="ttdeci">static Value buildVectorWrite(RewriterBase &amp;rewriter, Value value, OpOperand *outputOperand, VectorizationState &amp;state)</div><div class="ttdoc">Build a vector.transfer_write of value into outputOperand at indices set to all 0; where outputOperan...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00696">Vectorization.cpp:696</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a51c7625311de4f665ab3c2cde71709ec"><div class="ttname"><a href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a></div><div class="ttdeci">static Value getStaticPadVal(Operation *op)</div><div class="ttdoc">Returns the effective Pad value for the input op, provided it's a scalar.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03051">Vectorization.cpp:3051</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a53b9b71ed8f443a028671c1eb661054d"><div class="ttname"><a href="Vectorization_8cpp.html#a53b9b71ed8f443a028671c1eb661054d">reduceIfNeeded</a></div><div class="ttdeci">static Operation * reduceIfNeeded(OpBuilder &amp;b, LinalgOp linalgOp, Operation *op, Value reduceValue, Value initialValue, const IRMapping &amp;bvm)</div><div class="ttdoc">Emit reduction operations if the shapes of the value to reduce is different that the result shape.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01267">Vectorization.cpp:1267</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a5445f8ed0f258de115f0d82727780cb3"><div class="ttname"><a href="Vectorization_8cpp.html#a5445f8ed0f258de115f0d82727780cb3">vectorizePackOpPrecondition</a></div><div class="ttdeci">static LogicalResult vectorizePackOpPrecondition(linalg::PackOp packOp, ArrayRef&lt; int64_t &gt; inputVectorSizes)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02431">Vectorization.cpp:2431</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a5d1d008a71edcf988a6fa4575a1c0266"><div class="ttname"><a href="Vectorization_8cpp.html#a5d1d008a71edcf988a6fa4575a1c0266">bindShapeDims</a></div><div class="ttdeci">static void bindShapeDims(ShapedType shapedType)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03442">Vectorization.cpp:3442</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a66021212cd375df8f87b79b0f01b7e19"><div class="ttname"><a href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">hasReductionIterator</a></div><div class="ttdeci">static bool hasReductionIterator(LinalgOp &amp;op)</div><div class="ttdoc">Check if op is a linalg.reduce or a linalg.generic that has at least one reduction iterator.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00684">Vectorization.cpp:684</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a69be050ec61bb7c731b8666ca80f832f"><div class="ttname"><a href="Vectorization_8cpp.html#a69be050ec61bb7c731b8666ca80f832f">mayExistInterleavedUses</a></div><div class="ttdeci">static bool mayExistInterleavedUses(Operation *firstOp, Operation *secondOp, ValueRange values)</div><div class="ttdoc">Check whether there is any interleaved use of any values between firstOp and secondOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03263">Vectorization.cpp:3263</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a69cbb7a1a1669d28a2e2f4b221a2132f"><div class="ttname"><a href="Vectorization_8cpp.html#a69cbb7a1a1669d28a2e2f4b221a2132f">matchLinalgReduction</a></div><div class="ttdeci">static Operation * matchLinalgReduction(OpOperand *outputOperand)</div><div class="ttdoc">Check whether outputOperand is a reduction with a single combiner operation.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00635">Vectorization.cpp:635</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a786634b3fadeefcfe74e0c22f18312f1"><div class="ttname"><a href="Vectorization_8cpp.html#a786634b3fadeefcfe74e0c22f18312f1">buildMultiDimReduce</a></div><div class="ttdeci">static Operation * buildMultiDimReduce(OpBuilder &amp;b, Operation *reduceOp, Value valueToReduce, Value acc, ArrayRef&lt; bool &gt; dimsToMask)</div><div class="ttdoc">Create MultiDimReductionOp to compute the reduction for reductionOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00668">Vectorization.cpp:668</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a7e9ce28bca426dd4de93ad09392b4ec1"><div class="ttname"><a href="Vectorization_8cpp.html#a7e9ce28bca426dd4de93ad09392b4ec1">getTrailingNonUnitLoopDimIdx</a></div><div class="ttdeci">static uint64_t getTrailingNonUnitLoopDimIdx(LinalgOp linalgOp)</div><div class="ttdoc">Find the index of the trailing non-unit dim in linalgOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00919">Vectorization.cpp:919</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a8019302085ef04a05864f2bb3f198f5c"><div class="ttname"><a href="Vectorization_8cpp.html#a8019302085ef04a05864f2bb3f198f5c">getCollapsedVecType</a></div><div class="ttdeci">static VectorType getCollapsedVecType(VectorType type, ArrayRef&lt; AffineMap &gt; reassociation)</div><div class="ttdoc">Given the re-associations, &quot;collapses&quot; the input Vector type.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01850">Vectorization.cpp:1850</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a88081210ed22e2f80c50dd07348f3fec"><div class="ttname"><a href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fec">Conv1DOpOrder</a></div><div class="ttdeci">Conv1DOpOrder</div><div class="ttdoc">Helper enum to represent conv1d input traversal order.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00572">Vectorization.cpp:572</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276"><div class="ttname"><a href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a></div><div class="ttdeci">@ W</div></div>
<div class="ttc" id="aVectorization_8cpp_html_a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741"><div class="ttname"><a href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a></div><div class="ttdeci">@ Ncw</div></div>
<div class="ttc" id="aVectorization_8cpp_html_a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3"><div class="ttname"><a href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a></div><div class="ttdeci">@ Nwc</div></div>
<div class="ttc" id="aVectorization_8cpp_html_a894a3a33f4cfc348a3aced8a058b550a"><div class="ttname"><a href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550a">VectorizationHookStatus</a></div><div class="ttdeci">VectorizationHookStatus</div><div class="ttdoc">Helper data structure to represent the result of vectorization for a single operation.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00581">Vectorization.cpp:581</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661"><div class="ttname"><a href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">Failure</a></div><div class="ttdeci">@ Failure</div><div class="ttdoc">Op failed to vectorize.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00583">Vectorization.cpp:583</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6"><div class="ttname"><a href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">NewOp</a></div><div class="ttdeci">@ NewOp</div><div class="ttdoc">Op vectorized into a new Op whose results will replace original Op's results.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00591">Vectorization.cpp:588</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f"><div class="ttname"><a href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f">NoReplace</a></div><div class="ttdeci">@ NoReplace</div><div class="ttdoc">Op vectorized and custom function took care of replacement logic.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00585">Vectorization.cpp:585</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a8a252028bd6c5a6051cc0e8a48c72afb"><div class="ttname"><a href="Vectorization_8cpp.html#a8a252028bd6c5a6051cc0e8a48c72afb">CustomVectorizationHook</a></div><div class="ttdeci">std::function&lt; VectorizationHookResult(Operation *, const IRMapping &amp;)&gt; CustomVectorizationHook</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00759">Vectorization.cpp:760</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a8c5b389af0339b5680716058382108fc"><div class="ttname"><a href="Vectorization_8cpp.html#a8c5b389af0339b5680716058382108fc">vectorizeConvOpPrecondition</a></div><div class="ttdeci">static LogicalResult vectorizeConvOpPrecondition(linalg::LinalgOp convOp)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02317">Vectorization.cpp:2317</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a9361ccf3f87080ceace5da1af0d2e522"><div class="ttname"><a href="Vectorization_8cpp.html#a9361ccf3f87080ceace5da1af0d2e522">vectorizeDynamicLinalgOpPrecondition</a></div><div class="ttdeci">static LogicalResult vectorizeDynamicLinalgOpPrecondition(linalg::LinalgOp op, bool flatten1DDepthwiseConv)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02079">Vectorization.cpp:2079</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a9936412c5d68fa78d0d1998d6af2219f"><div class="ttname"><a href="Vectorization_8cpp.html#a9936412c5d68fa78d0d1998d6af2219f">vectorizeAsLinalgContraction</a></div><div class="ttdeci">static LogicalResult vectorizeAsLinalgContraction(RewriterBase &amp;rewriter, VectorizationState &amp;state, LinalgOp linalgOp, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Vectorize a named linalg contraction op into: vector::TransferReadOp - Reads vectors from the operand...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02160">Vectorization.cpp:2160</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a9b7d2592a2bad4ef2be89bf0d7efd19a"><div class="ttname"><a href="Vectorization_8cpp.html#a9b7d2592a2bad4ef2be89bf0d7efd19a">CustomVectorizationPrecondition</a></div><div class="ttdeci">std::function&lt; LogicalResult(Operation *, bool)&gt; CustomVectorizationPrecondition</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00753">Vectorization.cpp:754</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a9f962c6d10f2f4f71699143aa472289f"><div class="ttname"><a href="Vectorization_8cpp.html#a9f962c6d10f2f4f71699143aa472289f">isSupportedPoolKind</a></div><div class="ttdeci">static bool isSupportedPoolKind(vector::CombiningKind kind)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02300">Vectorization.cpp:2300</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_aab700681cb96772dbfd106a67ec408af"><div class="ttname"><a href="Vectorization_8cpp.html#aab700681cb96772dbfd106a67ec408af">convertAffineApply</a></div><div class="ttdeci">static void convertAffineApply(RewriterBase &amp;rewriter, LinalgOp linalgOp)</div><div class="ttdoc">Converts affine.apply Ops to arithmetic operations.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02657">Vectorization.cpp:2657</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ab37ae3178304b744d6b0249a60a6e7a3"><div class="ttname"><a href="Vectorization_8cpp.html#ab37ae3178304b744d6b0249a60a6e7a3">getSingleOpOfType</a></div><div class="ttdeci">static OpType getSingleOpOfType(Block &amp;block)</div><div class="ttdoc">Return the unique instance of OpType in block if it is indeed unique.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00093">Vectorization.cpp:93</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ab6ce64f69fae16d29646e68dab583d58"><div class="ttname"><a href="Vectorization_8cpp.html#ab6ce64f69fae16d29646e68dab583d58">vectorizeInsertSliceOpPrecondition</a></div><div class="ttdeci">static LogicalResult vectorizeInsertSliceOpPrecondition(tensor::InsertSliceOp sliceOp, ArrayRef&lt; int64_t &gt; inputVectorSizes)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02121">Vectorization.cpp:2121</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_abe4a6208d725462b6ab07ee8310da2f1"><div class="ttname"><a href="Vectorization_8cpp.html#abe4a6208d725462b6ab07ee8310da2f1">extractConvResultSlices</a></div><div class="ttdeci">static SmallVector&lt; Value &gt; extractConvResultSlices(RewriterBase &amp;rewriter, Location loc, Value res, int64_t nSize, int64_t wSize, int64_t fSize, int64_t wSizeStep, bool isSingleChanneled)</div><div class="ttdoc">Helper function to extract the result slices after filter is unrolled along kw.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00161">Vectorization.cpp:161</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_abea66cfdf6b9e3285381e7d3543c894c"><div class="ttname"><a href="Vectorization_8cpp.html#abea66cfdf6b9e3285381e7d3543c894c">getTiledPackShape</a></div><div class="ttdeci">static SmallVector&lt; int64_t &gt; getTiledPackShape(linalg::PackOp packOp, ArrayRef&lt; int64_t &gt; destShape)</div><div class="ttdoc">Given a linalg::PackOp, return the dest shape before any packing permutations.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l01535">Vectorization.cpp:1535</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_acdd38e6c601b328398794c7d9d092b43"><div class="ttname"><a href="Vectorization_8cpp.html#acdd38e6c601b328398794c7d9d092b43">vectorizeLinalgOpPrecondition</a></div><div class="ttdeci">static LogicalResult vectorizeLinalgOpPrecondition(LinalgOp linalgOp, ArrayRef&lt; int64_t &gt; inputVectorSizes, bool vectorizeNDExtract, bool flatten1DDepthwiseConv)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02362">Vectorization.cpp:2362</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ace2ca9537983c711e37b040688830950"><div class="ttname"><a href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">reindexIndexingMap</a></div><div class="ttdeci">static AffineMap reindexIndexingMap(AffineMap map)</div><div class="ttdoc">Given an indexing map coming from a LinalgOp indexing, restricted to a projectedPermutation,...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00561">Vectorization.cpp:561</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ad09df73d48432e3de8291c7076164ba7"><div class="ttname"><a href="Vectorization_8cpp.html#ad09df73d48432e3de8291c7076164ba7">tensorExtractVectorizationPrecondition</a></div><div class="ttdeci">static LogicalResult tensorExtractVectorizationPrecondition(Operation *op, bool vectorizeNDExtract)</div><div class="ttdoc">Helper function to check if the tensor.extract can be vectorized by the custom hook vectorizeTensorEx...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00838">Vectorization.cpp:838</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ad6ef02407dc9f6a46da43369638fbbe8"><div class="ttname"><a href="Vectorization_8cpp.html#ad6ef02407dc9f6a46da43369638fbbe8">vectorizeDynamicConvOpPrecondition</a></div><div class="ttdeci">static LogicalResult vectorizeDynamicConvOpPrecondition(linalg::LinalgOp conv, bool flatten1DDepthwiseConv)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02051">Vectorization.cpp:2051</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ae26a024dfac331ddb29bc4a78271b9d0"><div class="ttname"><a href="Vectorization_8cpp.html#ae26a024dfac331ddb29bc4a78271b9d0">getDimsToReduce</a></div><div class="ttdeci">static SmallVector&lt; bool &gt; getDimsToReduce(LinalgOp linalgOp)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00677">Vectorization.cpp:677</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ae3a45e985a37cbb4db1c7c23ce0d9e9f"><div class="ttname"><a href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a></div><div class="ttdeci">static Value broadcastIfNeeded(OpBuilder &amp;b, Value value, Type dstType)</div><div class="ttdoc">Broadcast value to a vector of shape if possible.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00651">Vectorization.cpp:651</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ae4411a5d89520c86474035493a7da7c1"><div class="ttname"><a href="Vectorization_8cpp.html#ae4411a5d89520c86474035493a7da7c1">calculateGatherOffset</a></div><div class="ttdeci">static Value calculateGatherOffset(RewriterBase &amp;rewriter, VectorizationState &amp;state, tensor::ExtractOp extractOp, const IRMapping &amp;bvm)</div><div class="ttdoc">Calculates the offsets ($index_vec) for vector.gather operations generated from tensor....</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00871">Vectorization.cpp:871</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_aed76d5bbb8b5413dcba7a1b210d50f7c"><div class="ttname"><a href="Vectorization_8cpp.html#aed76d5bbb8b5413dcba7a1b210d50f7c">vectorizeScalableVectorPrecondition</a></div><div class="ttdeci">static LogicalResult vectorizeScalableVectorPrecondition(Operation *op, ArrayRef&lt; int64_t &gt; inputVectorSizes, ArrayRef&lt; bool &gt; inputScalableVecDims)</div><div class="ttdoc">Preconditions for scalable vectors.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02505">Vectorization.cpp:2505</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_af2f7690c564bae0d01129c661bfcb1f3"><div class="ttname"><a href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3">isContiguousLoadIdx</a></div><div class="ttdeci">static bool isContiguousLoadIdx(LinalgOp &amp;linalgOp, Value &amp;val, bool &amp;foundIndexOp, VectorType resType)</div><div class="ttdoc">Check whether val could be used for calculating the trailing index for a contiguous load operation.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00996">Vectorization.cpp:996</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_af7adb8d1e2203f372dfc75ab40903520"><div class="ttname"><a href="Vectorization_8cpp.html#af7adb8d1e2203f372dfc75ab40903520">vectorizeUnPackOpPrecondition</a></div><div class="ttdeci">static LogicalResult vectorizeUnPackOpPrecondition(linalg::UnPackOp unpackOp, ArrayRef&lt; int64_t &gt; inputVectorSizes)</div><div class="ttdoc">Need to check if the inner-tiles are static/constant.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02100">Vectorization.cpp:2100</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_af85a26f7c1860388d0e83d22745a27aa"><div class="ttname"><a href="Vectorization_8cpp.html#af85a26f7c1860388d0e83d22745a27aa">vectorizeLinalgYield</a></div><div class="ttdeci">static VectorizationHookResult vectorizeLinalgYield(RewriterBase &amp;rewriter, Operation *op, const IRMapping &amp;bvm, VectorizationState &amp;state, LinalgOp linalgOp, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Helper function to vectorize the terminator of a linalgOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00770">Vectorization.cpp:770</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_af8d343eff4117b4738a97dea5eb4d4bd"><div class="ttname"><a href="Vectorization_8cpp.html#af8d343eff4117b4738a97dea5eb4d4bd">vectorizeAsTensorPadOp</a></div><div class="ttdeci">static LogicalResult vectorizeAsTensorPadOp(RewriterBase &amp;rewriter, tensor::PadOp padOp, ArrayRef&lt; int64_t &gt; inputVectorSizes, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Vectorize a padOp with (1) static result type, (2) constant padding value and (3) all-zero lowPad to ...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02001">Vectorization.cpp:2001</a></div></div>
<div class="ttc" id="aclassllvm_1_1ArrayRef_html"><div class="ttname"><a href="classllvm_1_1ArrayRef.html">llvm::ArrayRef</a></div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00048">LLVM.h:48</a></div></div>
<div class="ttc" id="aclassllvm_1_1DenseMap_html"><div class="ttname"><a href="classllvm_1_1DenseMap.html">llvm::DenseMap</a></div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00055">LLVM.h:55</a></div></div>
<div class="ttc" id="aclassllvm_1_1SetVector_html"><div class="ttname"><a href="classllvm_1_1SetVector.html">llvm::SetVector</a></div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00066">LLVM.h:66</a></div></div>
<div class="ttc" id="aclassllvm_1_1SmallVectorImpl_html"><div class="ttname"><a href="classllvm_1_1SmallVectorImpl.html">llvm::SmallVectorImpl</a></div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00074">LLVM.h:74</a></div></div>
<div class="ttc" id="aclassllvm_1_1SmallVector_html"><div class="ttname"><a href="classllvm_1_1SmallVector.html">llvm::SmallVector</a></div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00072">LLVM.h:72</a></div></div>
<div class="ttc" id="aclassllvm_1_1TypeSwitch_html"><div class="ttname"><a href="classllvm_1_1TypeSwitch.html">llvm::TypeSwitch</a></div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00082">LLVM.h:82</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineDimExpr_html"><div class="ttname"><a href="classmlir_1_1AffineDimExpr.html">mlir::AffineDimExpr</a></div><div class="ttdoc">A dimensional identifier appearing in an affine expression.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2IR_2AffineExpr_8h_source.html#l00223">AffineExpr.h:223</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineExpr_html"><div class="ttname"><a href="classmlir_1_1AffineExpr.html">mlir::AffineExpr</a></div><div class="ttdoc">Base type for affine expression.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2IR_2AffineExpr_8h_source.html#l00068">AffineExpr.h:68</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html"><div class="ttname"><a href="classmlir_1_1AffineMap.html">mlir::AffineMap</a></div><div class="ttdoc">A multi-dimensional affine map Affine map's are immutable like Type's, and they are uniqued.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2IR_2AffineMap_8h_source.html#l00046">AffineMap.h:46</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a035fc7c93286e3aa0354f522f2cd885a"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a035fc7c93286e3aa0354f522f2cd885a">mlir::AffineMap::getMinorIdentityMap</a></div><div class="ttdeci">static AffineMap getMinorIdentityMap(unsigned dims, unsigned results, MLIRContext *context)</div><div class="ttdoc">Returns an identity affine map (d0, ..., dn) -&gt; (dp, ..., dn) on the most minor dimensions.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00131">AffineMap.cpp:131</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a07ce6ee55edc21c008a3bf8d10a2d726"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a07ce6ee55edc21c008a3bf8d10a2d726">mlir::AffineMap::getContext</a></div><div class="ttdeci">MLIRContext * getContext() const</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00339">AffineMap.cpp:339</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a39ed2c2a4c743450a4a999fa6db1bf84"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a39ed2c2a4c743450a4a999fa6db1bf84">mlir::AffineMap::getMultiDimIdentityMap</a></div><div class="ttdeci">static AffineMap getMultiDimIdentityMap(unsigned numDims, MLIRContext *context)</div><div class="ttdoc">Returns an AffineMap with 'numDims' identity result dim exprs.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00330">AffineMap.cpp:330</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a3cfca2eb29fddf3c4bda714cccaa53f9"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a3cfca2eb29fddf3c4bda714cccaa53f9">mlir::AffineMap::get</a></div><div class="ttdeci">static AffineMap get(MLIRContext *context)</div><div class="ttdoc">Returns a zero result affine map with no dimensions or symbols: () -&gt; ().</div><div class="ttdef"><b>Definition:</b> <a href="MLIRContext_8cpp_source.html#l01203">MLIRContext.cpp:1203</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a457a8530ceb03d15e3b171ea3a9fc4a6"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a457a8530ceb03d15e3b171ea3a9fc4a6">mlir::AffineMap::isProjectedPermutation</a></div><div class="ttdeci">bool isProjectedPermutation(bool allowZeroInResults=false) const</div><div class="ttdoc">Returns true if the AffineMap represents a subset (i.e.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00611">AffineMap.cpp:611</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a96f194ae3b4baf33c67b10c9f795b564"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a96f194ae3b4baf33c67b10c9f795b564">mlir::AffineMap::getNumResults</a></div><div class="ttdeci">unsigned getNumResults() const</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00398">AffineMap.cpp:398</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_aa821f07143bcad97d6df532c232129a3"><div class="ttname"><a href="classmlir_1_1AffineMap.html#aa821f07143bcad97d6df532c232129a3">mlir::AffineMap::getNumInputs</a></div><div class="ttdeci">unsigned getNumInputs() const</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00399">AffineMap.cpp:399</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_ac64464574634cca5ffcd023227260414"><div class="ttname"><a href="classmlir_1_1AffineMap.html#ac64464574634cca5ffcd023227260414">mlir::AffineMap::getFilteredIdentityMap</a></div><div class="ttdeci">static AffineMap getFilteredIdentityMap(MLIRContext *ctx, unsigned numDims, llvm::function_ref&lt; bool(AffineDimExpr)&gt; keepDimFilter)</div><div class="ttdoc">Returns an identity affine map with numDims input dimensions and filtered results using keepDimFilter...</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00138">AffineMap.cpp:138</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_ac8532830efc67348905fd1e414beaebb"><div class="ttname"><a href="classmlir_1_1AffineMap.html#ac8532830efc67348905fd1e414beaebb">mlir::AffineMap::dropZeroResults</a></div><div class="ttdeci">AffineMap dropZeroResults()</div><div class="ttdoc">Returns the AffineMap resulting from removing &quot;zero&quot; results (constant values == 0) from this map.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00600">AffineMap.cpp:600</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_acd08312b1039c20f008d2f6785c47816"><div class="ttname"><a href="classmlir_1_1AffineMap.html#acd08312b1039c20f008d2f6785c47816">mlir::AffineMap::getPermutationMap</a></div><div class="ttdeci">static AffineMap getPermutationMap(ArrayRef&lt; unsigned &gt; permutation, MLIRContext *context)</div><div class="ttdoc">Returns an AffineMap representing a permutation.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00260">AffineMap.cpp:260</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_acf141c61521d9a40ba68c0b350a31836"><div class="ttname"><a href="classmlir_1_1AffineMap.html#acf141c61521d9a40ba68c0b350a31836">mlir::AffineMap::getBroadcastDims</a></div><div class="ttdeci">SmallVector&lt; unsigned &gt; getBroadcastDims() const</div><div class="ttdoc">Returns the list of broadcast dimensions (i.e.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00157">AffineMap.cpp:157</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_af2baf4561cf7d74a9959fd9e875c9a82"><div class="ttname"><a href="classmlir_1_1AffineMap.html#af2baf4561cf7d74a9959fd9e875c9a82">mlir::AffineMap::compose</a></div><div class="ttdeci">AffineMap compose(AffineMap map) const</div><div class="ttdoc">Returns the AffineMap resulting from composing this with map.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00552">AffineMap.cpp:552</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_af6e665372add0df0668e1ebd231488b4"><div class="ttname"><a href="classmlir_1_1AffineMap.html#af6e665372add0df0668e1ebd231488b4">mlir::AffineMap::isPermutation</a></div><div class="ttdeci">bool isPermutation() const</div><div class="ttdoc">Returns true if the AffineMap represents a symbol-less permutation map.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00641">AffineMap.cpp:641</a></div></div>
<div class="ttc" id="aclassmlir_1_1Attribute_html"><div class="ttname"><a href="classmlir_1_1Attribute.html">mlir::Attribute</a></div><div class="ttdoc">Attributes are known-constant values of operations.</div><div class="ttdef"><b>Definition:</b> <a href="Attributes_8h_source.html#l00025">Attributes.h:25</a></div></div>
<div class="ttc" id="aclassmlir_1_1BlockArgument_html"><div class="ttname"><a href="classmlir_1_1BlockArgument.html">mlir::BlockArgument</a></div><div class="ttdoc">This class represents an argument of a Block.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00309">Value.h:309</a></div></div>
<div class="ttc" id="aclassmlir_1_1BlockArgument_html_a5396ce59c00cd3ef7a8a500c59af295c"><div class="ttname"><a href="classmlir_1_1BlockArgument.html#a5396ce59c00cd3ef7a8a500c59af295c">mlir::BlockArgument::getArgNumber</a></div><div class="ttdeci">unsigned getArgNumber() const</div><div class="ttdoc">Returns the number of this argument.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00321">Value.h:321</a></div></div>
<div class="ttc" id="aclassmlir_1_1Block_html"><div class="ttname"><a href="classmlir_1_1Block.html">mlir::Block</a></div><div class="ttdoc">Block represents an ordered list of Operations.</div><div class="ttdef"><b>Definition:</b> <a href="Block_8h_source.html#l00032">Block.h:33</a></div></div>
<div class="ttc" id="aclassmlir_1_1Block_html_a790af2827870ed217e85447b8ed8559c"><div class="ttname"><a href="classmlir_1_1Block.html#a790af2827870ed217e85447b8ed8559c">mlir::Block::walk</a></div><div class="ttdeci">RetT walk(FnT &amp;&amp;callback)</div><div class="ttdoc">Walk all nested operations, blocks (including this block) or regions, depending on the type of callba...</div><div class="ttdef"><b>Definition:</b> <a href="Block_8h_source.html#l00305">Block.h:305</a></div></div>
<div class="ttc" id="aclassmlir_1_1Block_html_a983ab2de9394598ad42fea4d142f5d8b"><div class="ttname"><a href="classmlir_1_1Block.html#a983ab2de9394598ad42fea4d142f5d8b">mlir::Block::getOperations</a></div><div class="ttdeci">OpListType &amp; getOperations()</div><div class="ttdef"><b>Definition:</b> <a href="Block_8h_source.html#l00137">Block.h:137</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_a422a9ab33af4134efcb4044fb81deab1"><div class="ttname"><a href="classmlir_1_1Builder.html#a422a9ab33af4134efcb4044fb81deab1">mlir::Builder::getMultiDimIdentityMap</a></div><div class="ttdeci">AffineMap getMultiDimIdentityMap(unsigned rank)</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00382">Builders.cpp:382</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_a8e943986e58a8b0c88fcd51b0f0afafb"><div class="ttname"><a href="classmlir_1_1Builder.html#a8e943986e58a8b0c88fcd51b0f0afafb">mlir::Builder::getZeroAttr</a></div><div class="ttdeci">TypedAttr getZeroAttr(Type type)</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00319">Builders.cpp:319</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_aa6d1e114c8047cad1b014b504688a868"><div class="ttname"><a href="classmlir_1_1Builder.html#aa6d1e114c8047cad1b014b504688a868">mlir::Builder::getContext</a></div><div class="ttdeci">MLIRContext * getContext() const</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00055">Builders.h:55</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_ac68228481d9deafab913889e4fb01886"><div class="ttname"><a href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">mlir::Builder::getI1Type</a></div><div class="ttdeci">IntegerType getI1Type()</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00052">Builders.cpp:52</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_ac9e0170e1b16f9c7464823b7b2fcb042"><div class="ttname"><a href="classmlir_1_1Builder.html#ac9e0170e1b16f9c7464823b7b2fcb042">mlir::Builder::getArrayAttr</a></div><div class="ttdeci">ArrayAttr getArrayAttr(ArrayRef&lt; Attribute &gt; value)</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00261">Builders.cpp:261</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_ace585fd315aa2ebcc7bb87e18483f5b4"><div class="ttname"><a href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">mlir::Builder::getIndexType</a></div><div class="ttdeci">IndexType getIndexType()</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00050">Builders.cpp:50</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_af40fe132a1059a68679775fa4c06666b"><div class="ttname"><a href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">mlir::Builder::getBoolArrayAttr</a></div><div class="ttdeci">ArrayAttr getBoolArrayAttr(ArrayRef&lt; bool &gt; values)</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00265">Builders.cpp:265</a></div></div>
<div class="ttc" id="aclassmlir_1_1DenseIntElementsAttr_html"><div class="ttname"><a href="classmlir_1_1DenseIntElementsAttr.html">mlir::DenseIntElementsAttr</a></div><div class="ttdoc">An attribute that represents a reference to a dense integer vector or tensor object.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2IR_2BuiltinAttributes_8h_source.html#l00952">BuiltinAttributes.h:952</a></div></div>
<div class="ttc" id="aclassmlir_1_1DenseIntElementsAttr_html_a9db4e0b61c851fb050659e8a3cd4f4a0"><div class="ttname"><a href="classmlir_1_1DenseIntElementsAttr.html#a9db4e0b61c851fb050659e8a3cd4f4a0">mlir::DenseIntElementsAttr::get</a></div><div class="ttdeci">static DenseIntElementsAttr get(const ShapedType &amp;type, Arg &amp;&amp;arg)</div><div class="ttdoc">Get an instance of a DenseIntElementsAttr with the given arguments.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2IR_2BuiltinAttributes_8h_source.html#l00963">BuiltinAttributes.h:963</a></div></div>
<div class="ttc" id="aclassmlir_1_1IRMapping_html"><div class="ttname"><a href="classmlir_1_1IRMapping.html">mlir::IRMapping</a></div><div class="ttdoc">This is a utility class for mapping one set of IR entities to another.</div><div class="ttdef"><b>Definition:</b> <a href="IRMapping_8h_source.html#l00026">IRMapping.h:26</a></div></div>
<div class="ttc" id="aclassmlir_1_1IRMapping_html_a3c0a75333d64669ef09490fc43218569"><div class="ttname"><a href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">mlir::IRMapping::lookup</a></div><div class="ttdeci">auto lookup(T from) const</div><div class="ttdoc">Lookup a mapped value within the map.</div><div class="ttdef"><b>Definition:</b> <a href="IRMapping_8h_source.html#l00072">IRMapping.h:72</a></div></div>
<div class="ttc" id="aclassmlir_1_1IRMapping_html_a9e4259707f73d5c85210c6c076a782bd"><div class="ttname"><a href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">mlir::IRMapping::map</a></div><div class="ttdeci">void map(Value from, Value to)</div><div class="ttdoc">Inserts a new mapping for 'from' to 'to'.</div><div class="ttdef"><b>Definition:</b> <a href="IRMapping_8h_source.html#l00030">IRMapping.h:30</a></div></div>
<div class="ttc" id="aclassmlir_1_1IROperand_html_a015cbc633653c0c763dca72a22b0e087"><div class="ttname"><a href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">mlir::IROperand::get</a></div><div class="ttdeci">IRValueT get() const</div><div class="ttdoc">Return the current value being used by this operand.</div><div class="ttdef"><b>Definition:</b> <a href="UseDefLists_8h_source.html#l00160">UseDefLists.h:160</a></div></div>
<div class="ttc" id="aclassmlir_1_1Location_html"><div class="ttname"><a href="classmlir_1_1Location.html">mlir::Location</a></div><div class="ttdoc">This class defines the main interface for locations in MLIR and acts as a non-nullable wrapper around...</div><div class="ttdef"><b>Definition:</b> <a href="Location_8h_source.html#l00076">Location.h:76</a></div></div>
<div class="ttc" id="aclassmlir_1_1MLIRContext_html"><div class="ttname"><a href="classmlir_1_1MLIRContext.html">mlir::MLIRContext</a></div><div class="ttdoc">MLIRContext is the top-level object for a collection of MLIR operations.</div><div class="ttdef"><b>Definition:</b> <a href="MLIRContext_8h_source.html#l00060">MLIRContext.h:60</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_1_1InsertionGuard_html"><div class="ttname"><a href="classmlir_1_1OpBuilder_1_1InsertionGuard.html">mlir::OpBuilder::InsertionGuard</a></div><div class="ttdoc">RAII guard to reset the insertion point of the builder when destroyed.</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00346">Builders.h:346</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html"><div class="ttname"><a href="classmlir_1_1OpBuilder.html">mlir::OpBuilder</a></div><div class="ttdoc">This class helps build Operations.</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00205">Builders.h:205</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_a10fe4674bc755659cb9d09131c713ebc"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#a10fe4674bc755659cb9d09131c713ebc">mlir::OpBuilder::getInsertionPoint</a></div><div class="ttdeci">Block::iterator getInsertionPoint() const</div><div class="ttdoc">Returns the current insertion point of the builder.</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00443">Builders.h:443</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_a394cad81296b42a24e1c37b045e15359"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#a394cad81296b42a24e1c37b045e15359">mlir::OpBuilder::clone</a></div><div class="ttdeci">Operation * clone(Operation &amp;op, IRMapping &amp;mapper)</div><div class="ttdoc">Creates a deep copy of the specified operation, remapping any operands that use values outside of the...</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00548">Builders.cpp:548</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_a4853433035d219e56febdb51d1b531cd"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">mlir::OpBuilder::setInsertionPoint</a></div><div class="ttdeci">void setInsertionPoint(Block *block, Block::iterator insertPoint)</div><div class="ttdoc">Set the insertion point to the specified location.</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00396">Builders.h:396</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_a9bfa9ca1c08777d5eba6276c24c0cf9a"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#a9bfa9ca1c08777d5eba6276c24c0cf9a">mlir::OpBuilder::createOrFold</a></div><div class="ttdeci">void createOrFold(SmallVectorImpl&lt; Value &gt; &amp;results, Location location, Args &amp;&amp;...args)</div><div class="ttdoc">Create an operation of specific op type at the current insertion point, and immediately try to fold i...</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00517">Builders.h:517</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_ac6a6edadd39800db410864ef06a004b2"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#ac6a6edadd39800db410864ef06a004b2">mlir::OpBuilder::create</a></div><div class="ttdeci">Operation * create(const OperationState &amp;state)</div><div class="ttdoc">Creates an operation given the fields represented as an OperationState.</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00452">Builders.cpp:452</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpFoldResult_html"><div class="ttname"><a href="classmlir_1_1OpFoldResult.html">mlir::OpFoldResult</a></div><div class="ttdoc">This class represents a single result from folding an operation.</div><div class="ttdef"><b>Definition:</b> <a href="OpDefinition_8h_source.html#l00272">OpDefinition.h:272</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpOperand_html"><div class="ttname"><a href="classmlir_1_1OpOperand.html">mlir::OpOperand</a></div><div class="ttdoc">This class represents an operand of an operation.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00257">Value.h:257</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpOperand_html_a097f9026defd8afd19ab06b21aa11bdf"><div class="ttname"><a href="classmlir_1_1OpOperand.html#a097f9026defd8afd19ab06b21aa11bdf">mlir::OpOperand::getOperandNumber</a></div><div class="ttdeci">unsigned getOperandNumber()</div><div class="ttdoc">Return which operand this is in the OpOperand list of the Operation.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8cpp_source.html#l00226">Value.cpp:226</a></div></div>
<div class="ttc" id="aclassmlir_1_1OperationName_html_a2c83cffa9a4c4fb68436d9ee3497c226"><div class="ttname"><a href="classmlir_1_1OperationName.html#a2c83cffa9a4c4fb68436d9ee3497c226">mlir::OperationName::getIdentifier</a></div><div class="ttdeci">StringAttr getIdentifier() const</div><div class="ttdoc">Return the name of this operation as a StringAttr.</div><div class="ttdef"><b>Definition:</b> <a href="OperationSupport_8h_source.html#l00476">OperationSupport.h:476</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html"><div class="ttname"><a href="classmlir_1_1Operation.html">mlir::Operation</a></div><div class="ttdoc">Operation is the basic unit of execution within MLIR.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00084">Operation.h:88</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a1eecfffb7445e24f9fbdec2d619251ff"><div class="ttname"><a href="classmlir_1_1Operation.html#a1eecfffb7445e24f9fbdec2d619251ff">mlir::Operation::getOperand</a></div><div class="ttdeci">Value getOperand(unsigned idx)</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00350">Operation.h:350</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a3cfc1046bad9638cf68c7add9efa6c33"><div class="ttname"><a href="classmlir_1_1Operation.html#a3cfc1046bad9638cf68c7add9efa6c33">mlir::Operation::isBeforeInBlock</a></div><div class="ttdeci">bool isBeforeInBlock(Operation *other)</div><div class="ttdoc">Given an operation 'other' that is within the same parent block, return whether the current operation...</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8cpp_source.html#l00385">Operation.cpp:385</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a56f58b55c803b3313da7b4a04a3d542d"><div class="ttname"><a href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">mlir::Operation::getResult</a></div><div class="ttdeci">OpResult getResult(unsigned idx)</div><div class="ttdoc">Get the 'idx'th result of this operation.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00407">Operation.h:407</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a6c0b8ce5ff714a34f0192f3aa60dc7ea"><div class="ttname"><a href="classmlir_1_1Operation.html#a6c0b8ce5ff714a34f0192f3aa60dc7ea">mlir::Operation::getLoc</a></div><div class="ttdeci">Location getLoc()</div><div class="ttdoc">The source location the operation was defined or derived from.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00223">Operation.h:223</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a80db2165a86e0837b30f5f3e0dc899df"><div class="ttname"><a href="classmlir_1_1Operation.html#a80db2165a86e0837b30f5f3e0dc899df">mlir::Operation::getNumOperands</a></div><div class="ttdeci">unsigned getNumOperands()</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00346">Operation.h:346</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a8ec626dafc87ed8fb20d8323017dec72"><div class="ttname"><a href="classmlir_1_1Operation.html#a8ec626dafc87ed8fb20d8323017dec72">mlir::Operation::getAttrs</a></div><div class="ttdeci">ArrayRef&lt; NamedAttribute &gt; getAttrs()</div><div class="ttdoc">Return all of the attributes on this operation.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00512">Operation.h:512</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a95e463348b9127104d0f8e9bfe413eeb"><div class="ttname"><a href="classmlir_1_1Operation.html#a95e463348b9127104d0f8e9bfe413eeb">mlir::Operation::getBlock</a></div><div class="ttdeci">Block * getBlock()</div><div class="ttdoc">Returns the operation block that contains this operation.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00213">Operation.h:213</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a9d3b09f8e60b126070e82957d78d9fd0"><div class="ttname"><a href="classmlir_1_1Operation.html#a9d3b09f8e60b126070e82957d78d9fd0">mlir::Operation::operand_end</a></div><div class="ttdeci">operand_iterator operand_end()</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00375">Operation.h:375</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_aa01ae296df28a63def56ea015dea9929"><div class="ttname"><a href="classmlir_1_1Operation.html#aa01ae296df28a63def56ea015dea9929">mlir::Operation::getRegion</a></div><div class="ttdeci">Region &amp; getRegion(unsigned index)</div><div class="ttdoc">Returns the region held by this operation at position 'index'.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00686">Operation.h:686</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_ab2e11ba83ff765eb7595554f97aaaa75"><div class="ttname"><a href="classmlir_1_1Operation.html#ab2e11ba83ff765eb7595554f97aaaa75">mlir::Operation::getName</a></div><div class="ttdeci">OperationName getName()</div><div class="ttdoc">The name of an operation is the key identifier for it.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00119">Operation.h:119</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_ac3095b4b7756a4974ba1c21b0e8ed762"><div class="ttname"><a href="classmlir_1_1Operation.html#ac3095b4b7756a4974ba1c21b0e8ed762">mlir::Operation::getResultTypes</a></div><div class="ttdeci">result_type_range getResultTypes()</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00428">Operation.h:428</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_ac632a7783f8ec353f79c4f17cb188454"><div class="ttname"><a href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">mlir::Operation::getOperands</a></div><div class="ttdeci">operand_range getOperands()</div><div class="ttdoc">Returns an iterator on the underlying Value's.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00378">Operation.h:378</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_ad79736dd29f14a220af56d7fb37d4bc3"><div class="ttname"><a href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">mlir::Operation::getResults</a></div><div class="ttdeci">result_range getResults()</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00415">Operation.h:415</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_afeb237ab61bc6c18e133da3060a7fbfb"><div class="ttname"><a href="classmlir_1_1Operation.html#afeb237ab61bc6c18e133da3060a7fbfb">mlir::Operation::getNumResults</a></div><div class="ttdeci">unsigned getNumResults()</div><div class="ttdoc">Return the number of results held by this operation.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00404">Operation.h:404</a></div></div>
<div class="ttc" id="aclassmlir_1_1PatternBenefit_html"><div class="ttname"><a href="classmlir_1_1PatternBenefit.html">mlir::PatternBenefit</a></div><div class="ttdoc">This class represents the benefit of a pattern match in a unitless scheme that ranges from 0 (very li...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00034">PatternMatch.h:34</a></div></div>
<div class="ttc" id="aclassmlir_1_1PatternBenefit_html_af19d7a934078c6de5512543eea299579"><div class="ttname"><a href="classmlir_1_1PatternBenefit.html#af19d7a934078c6de5512543eea299579">mlir::PatternBenefit::getBenefit</a></div><div class="ttdeci">unsigned short getBenefit() const</div><div class="ttdoc">If the corresponding pattern can match, return its benefit. If the.</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8cpp_source.html#l00025">PatternMatch.cpp:25</a></div></div>
<div class="ttc" id="aclassmlir_1_1PatternRewriter_html"><div class="ttname"><a href="classmlir_1_1PatternRewriter.html">mlir::PatternRewriter</a></div><div class="ttdoc">A special type of RewriterBase that coordinates the application of a rewrite pattern on the current I...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00783">PatternMatch.h:783</a></div></div>
<div class="ttc" id="aclassmlir_1_1Region_html_ac5f83e51909b69039a7506737b458452"><div class="ttname"><a href="classmlir_1_1Region.html#ac5f83e51909b69039a7506737b458452">mlir::Region::front</a></div><div class="ttdeci">Block &amp; front()</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Region_8h_source.html#l00065">Region.h:65</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewritePatternSet_html"><div class="ttname"><a href="classmlir_1_1RewritePatternSet.html">mlir::RewritePatternSet</a></div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00806">PatternMatch.h:806</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html"><div class="ttname"><a href="classmlir_1_1RewriterBase.html">mlir::RewriterBase</a></div><div class="ttdoc">This class coordinates the application of a rewrite on a set of IR, providing a way for clients to tr...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00358">PatternMatch.h:358</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a032aa8fe5345a286681688ef10f5cb84"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">mlir::RewriterBase::notifyMatchFailure</a></div><div class="ttdeci">std::enable_if_t&lt;!std::is_convertible&lt; CallbackT, Twine &gt;::value, LogicalResult &gt; notifyMatchFailure(Location loc, CallbackT &amp;&amp;reasonCallback)</div><div class="ttdoc">Used to notify the listener that the IR failed to be rewritten because of a match failure,...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00716">PatternMatch.h:716</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a53c88f3ce889be590b3801b4ddee627f"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">mlir::RewriterBase::replaceOp</a></div><div class="ttdeci">virtual void replaceOp(Operation *op, ValueRange newValues)</div><div class="ttdoc">Replace the results of the given (original) operation with the specified list of values (replacements...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8cpp_source.html#l00127">PatternMatch.cpp:127</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a786138ac6a91e0932da343ef5c6f1e70"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">mlir::RewriterBase::eraseOp</a></div><div class="ttdeci">virtual void eraseOp(Operation *op)</div><div class="ttdoc">This method erases an operation that is known to have no uses.</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8cpp_source.html#l00155">PatternMatch.cpp:155</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a9bc0bf42591d2bf716733ed23bb8b6e6"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a9bc0bf42591d2bf716733ed23bb8b6e6">mlir::RewriterBase::replaceAllUsesExcept</a></div><div class="ttdeci">void replaceAllUsesExcept(Value from, Value to, Operation *exceptedUser)</div><div class="ttdoc">Find uses of from and replace them with to except if the user is exceptedUser.</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00700">PatternMatch.h:700</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_abd8bae753b51386417536a36cf52d3f7"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#abd8bae753b51386417536a36cf52d3f7">mlir::RewriterBase::modifyOpInPlace</a></div><div class="ttdeci">void modifyOpInPlace(Operation *root, CallableT &amp;&amp;callable)</div><div class="ttdoc">This method is a utility wrapper around an in-place modification of an operation.</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00628">PatternMatch.h:628</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_afb1c910a57707f518d2b9c903c2bb5bc"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#afb1c910a57707f518d2b9c903c2bb5bc">mlir::RewriterBase::replaceOpWithNewOp</a></div><div class="ttdeci">OpTy replaceOpWithNewOp(Operation *op, Args &amp;&amp;...args)</div><div class="ttdoc">Replace the results of the given (original) op with a new op that is created without verification (re...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00519">PatternMatch.h:519</a></div></div>
<div class="ttc" id="aclassmlir_1_1StructuredGenerator_html"><div class="ttname"><a href="classmlir_1_1StructuredGenerator.html">mlir::StructuredGenerator</a></div><div class="ttdoc">Helper StructuredGenerator class to manipulate and rewrite ops with StructuredOpInterface.</div><div class="ttdef"><b>Definition:</b> <a href="StructuredOpsUtils_8h_source.html#l00090">StructuredOpsUtils.h:90</a></div></div>
<div class="ttc" id="aclassmlir_1_1Type_html"><div class="ttname"><a href="classmlir_1_1Type.html">mlir::Type</a></div><div class="ttdoc">Instances of the Type class are uniqued, have an immutable identifier and an optional mutable compone...</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Types_8h_source.html#l00074">Types.h:74</a></div></div>
<div class="ttc" id="aclassmlir_1_1Type_html_a5d5d5335ce4fc906636a2690155a7d72"><div class="ttname"><a href="classmlir_1_1Type.html#a5d5d5335ce4fc906636a2690155a7d72">mlir::Type::isIndex</a></div><div class="ttdeci">bool isIndex() const</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Types_8cpp_source.html#l00054">Types.cpp:54</a></div></div>
<div class="ttc" id="aclassmlir_1_1Type_html_aeb142623709910125e07ecf1f9f2cdd5"><div class="ttname"><a href="classmlir_1_1Type.html#aeb142623709910125e07ecf1f9f2cdd5">mlir::Type::getIntOrFloatBitWidth</a></div><div class="ttdeci">unsigned getIntOrFloatBitWidth() const</div><div class="ttdoc">Return the bit width of an integer or a float type, assert failure on other types.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Types_8cpp_source.html#l00122">Types.cpp:122</a></div></div>
<div class="ttc" id="aclassmlir_1_1ValueRange_html"><div class="ttname"><a href="classmlir_1_1ValueRange.html">mlir::ValueRange</a></div><div class="ttdoc">This class provides an abstraction over the different types of ranges over Values.</div><div class="ttdef"><b>Definition:</b> <a href="ValueRange_8h_source.html#l00383">ValueRange.h:387</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html"><div class="ttname"><a href="classmlir_1_1Value.html">mlir::Value</a></div><div class="ttdoc">This class represents an instance of an SSA value in the MLIR system, representing a computable value...</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00096">Value.h:96</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_a5348fc13d5201e2adf7ded6b4b2fb1ad"><div class="ttname"><a href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">mlir::Value::getType</a></div><div class="ttdeci">Type getType() const</div><div class="ttdoc">Return the type of this value.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00105">Value.h:105</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_a5adc50e42183f2f503143918a296da9d"><div class="ttname"><a href="classmlir_1_1Value.html#a5adc50e42183f2f503143918a296da9d">mlir::Value::getUses</a></div><div class="ttdeci">use_range getUses() const</div><div class="ttdoc">Returns a range of all uses, which is useful for iterating over all uses.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00188">Value.h:188</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_ae9df8c75072dbaab98cd4b7cd82b6ebc"><div class="ttname"><a href="classmlir_1_1Value.html#ae9df8c75072dbaab98cd4b7cd82b6ebc">mlir::Value::getLoc</a></div><div class="ttdeci">Location getLoc() const</div><div class="ttdoc">Return the location of this value.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8cpp_source.html#l00024">Value.cpp:24</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_aed80a742a36c5b3298467ce5d01738c8"><div class="ttname"><a href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">mlir::Value::getDefiningOp</a></div><div class="ttdeci">Operation * getDefiningOp() const</div><div class="ttdoc">If this value is the result of an operation, return the operation that defines it.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8cpp_source.html#l00018">Value.cpp:18</a></div></div>
<div class="ttc" id="aclassmlir_1_1WalkResult_html_a97a7015a793bb5d2a97f08e358f42797"><div class="ttname"><a href="classmlir_1_1WalkResult.html#a97a7015a793bb5d2a97f08e358f42797">mlir::WalkResult::advance</a></div><div class="ttdeci">static WalkResult advance()</div><div class="ttdef"><b>Definition:</b> <a href="WalkResult_8h_source.html#l00047">WalkResult.h:47</a></div></div>
<div class="ttc" id="aclassmlir_1_1WalkResult_html_abab80dca5987e18f9abf08162cd3faaa"><div class="ttname"><a href="classmlir_1_1WalkResult.html#abab80dca5987e18f9abf08162cd3faaa">mlir::WalkResult::interrupt</a></div><div class="ttdeci">static WalkResult interrupt()</div><div class="ttdef"><b>Definition:</b> <a href="WalkResult_8h_source.html#l00046">WalkResult.h:46</a></div></div>
<div class="ttc" id="aclassmlir_1_1arith_1_1ConstantIndexOp_html_af8e9cba912ba269664b71b920ba30e6d"><div class="ttname"><a href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">mlir::arith::ConstantIndexOp::create</a></div><div class="ttdeci">static ConstantIndexOp create(OpBuilder &amp;builder, Location location, int64_t value)</div><div class="ttdef"><b>Definition:</b> <a href="ArithOps_8cpp_source.html#l00359">ArithOps.cpp:359</a></div></div>
<div class="ttc" id="aclassmlir_1_1detail_1_1IROperandBase_html_ac5a818295c7c908f8015c93181239769"><div class="ttname"><a href="classmlir_1_1detail_1_1IROperandBase.html#ac5a818295c7c908f8015c93181239769">mlir::detail::IROperandBase::getOwner</a></div><div class="ttdeci">Operation * getOwner() const</div><div class="ttdoc">Return the owner of this operand.</div><div class="ttdef"><b>Definition:</b> <a href="UseDefLists_8h_source.html#l00038">UseDefLists.h:38</a></div></div>
<div class="ttc" id="amlir_2Dialect_2Arith_2IR_2Arith_8h_html"><div class="ttname"><a href="mlir_2Dialect_2Arith_2IR_2Arith_8h.html">Arith.h</a></div></div>
<div class="ttc" id="amlir_2Dialect_2Linalg_2IR_2Linalg_8h_html"><div class="ttname"><a href="mlir_2Dialect_2Linalg_2IR_2Linalg_8h.html">Linalg.h</a></div></div>
<div class="ttc" id="amlir_2Dialect_2Linalg_2Transforms_2Transforms_8h_html"><div class="ttname"><a href="mlir_2Dialect_2Linalg_2Transforms_2Transforms_8h.html">Transforms.h</a></div></div>
<div class="ttc" id="amlir_2Dialect_2Tensor_2IR_2Tensor_8h_html"><div class="ttname"><a href="mlir_2Dialect_2Tensor_2IR_2Tensor_8h.html">Tensor.h</a></div></div>
<div class="ttc" id="amlir_2IR_2AffineExpr_8h_html"><div class="ttname"><a href="mlir_2IR_2AffineExpr_8h.html">AffineExpr.h</a></div></div>
<div class="ttc" id="amlir_2IR_2AffineMap_8h_html"><div class="ttname"><a href="mlir_2IR_2AffineMap_8h.html">AffineMap.h</a></div></div>
<div class="ttc" id="amlir_2IR_2BuiltinTypes_8h_html"><div class="ttname"><a href="mlir_2IR_2BuiltinTypes_8h.html">BuiltinTypes.h</a></div></div>
<div class="ttc" id="amlir_2Support_2LLVM_8h_html"><div class="ttname"><a href="mlir_2Support_2LLVM_8h.html">LLVM.h</a></div></div>
<div class="ttc" id="anamespacemlir_1_1OpTrait_html_a0c5480822c4898f287f588dfe98d1c85"><div class="ttname"><a href="namespacemlir_1_1OpTrait.html#a0c5480822c4898f287f588dfe98d1c85">mlir::OpTrait::hasElementwiseMappableTraits</a></div><div class="ttdeci">bool hasElementwiseMappableTraits(Operation *op)</div><div class="ttdoc">Together, Elementwise, Scalarizable, Vectorizable, and Tensorizable provide an easy way for scalar op...</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8cpp_source.html#l01397">Operation.cpp:1397</a></div></div>
<div class="ttc" id="anamespacemlir_1_1affine_html_a39d426a50bbe0eea58b951870ad90c2c"><div class="ttname"><a href="namespacemlir_1_1affine.html#a39d426a50bbe0eea58b951870ad90c2c">mlir::affine::expandAffineExpr</a></div><div class="ttdeci">Value expandAffineExpr(OpBuilder &amp;builder, Location loc, AffineExpr expr, ValueRange dimValues, ValueRange symbolValues)</div><div class="ttdoc">Emit code that computes the given affine expression using standard arithmetic operations applied to t...</div><div class="ttdef"><b>Definition:</b> <a href="Dialect_2Affine_2Utils_2Utils_8cpp_source.html#l00218">Utils.cpp:218</a></div></div>
<div class="ttc" id="anamespacemlir_1_1arith_html_af73ab4d70d330c6212d9ccd87a38056b"><div class="ttname"><a href="namespacemlir_1_1arith.html#af73ab4d70d330c6212d9ccd87a38056b">mlir::arith::getZeroConstant</a></div><div class="ttdeci">Value getZeroConstant(OpBuilder &amp;builder, Location loc, Type type)</div><div class="ttdoc">Creates an arith.constant operation with a zero value of type type.</div><div class="ttdef"><b>Definition:</b> <a href="ArithOps_8cpp_source.html#l00380">ArithOps.cpp:380</a></div></div>
<div class="ttc" id="anamespacemlir_1_1detail_html_a7146031ab7f6bb4cdacc53c4f1e96aac"><div class="ttname"><a href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">mlir::detail::enumerate</a></div><div class="ttdeci">constexpr void enumerate(std::tuple&lt; Tys... &gt; &amp;tuple, CallbackT &amp;&amp;callback)</div><div class="ttdef"><b>Definition:</b> <a href="Matchers_8h_source.html#l00344">Matchers.h:344</a></div></div>
<div class="ttc" id="anamespacemlir_1_1detail_html_a98a07efa628a8720c45b577162e4fe66"><div class="ttname"><a href="namespacemlir_1_1detail.html#a98a07efa628a8720c45b577162e4fe66">mlir::detail::divideCeil</a></div><div class="ttdeci">llvm::TypeSize divideCeil(llvm::TypeSize numerator, uint64_t denominator)</div><div class="ttdoc">Divides the known min value of the numerator by the denominator and rounds the result up to the next ...</div><div class="ttdef"><b>Definition:</b> <a href="DataLayoutInterfaces_8cpp_source.html#l00468">DataLayoutInterfaces.cpp:468</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html"><div class="ttname"><a href="namespacemlir_1_1linalg.html">mlir::linalg</a></div><div class="ttdef"><b>Definition:</b> <a href="LinalgToStandard_8h_source.html#l00024">LinalgToStandard.h:24</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a142a09c03dbaa0d795e44f62d4b6b395"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a142a09c03dbaa0d795e44f62d4b6b395">mlir::linalg::hasVectorizationImpl</a></div><div class="ttdeci">bool hasVectorizationImpl(Operation *)</div><div class="ttdoc">Return true if there's dedicated logic in the Linalg Vectorizer to vectorize this Op,...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02671">Vectorization.cpp:2671</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a1eda2843cbf0dc5507bc64ec67f46f22"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a1eda2843cbf0dc5507bc64ec67f46f22">mlir::linalg::allIndexingsAreProjectedPermutation</a></div><div class="ttdeci">bool allIndexingsAreProjectedPermutation(LinalgOp op)</div><div class="ttdoc">Check if all indexing maps are projected permutations.</div><div class="ttdef"><b>Definition:</b> <a href="Dialect_2Linalg_2Utils_2Utils_8cpp_source.html#l00200">Utils.cpp:200</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a303bb59c046a82276569e6b906002997"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a303bb59c046a82276569e6b906002997">mlir::linalg::vectorize</a></div><div class="ttdeci">FailureOr&lt; VectorizationResult &gt; vectorize(RewriterBase &amp;rewriter, Operation *op, ArrayRef&lt; int64_t &gt; inputVectorSizes={}, ArrayRef&lt; bool &gt; inputScalableVecDims={}, bool vectorizeNDExtract=false, bool flatten1DDepthwiseConv=false, bool assumeDynamicDimsMatchVecSizes=false, bool createNamedContraction=false)</div><div class="ttdoc">Returns a VectorizationResult containing the results of the vectorized op, or failure if the transfor...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02676">Vectorization.cpp:2676</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a43c2ef8a778a33a17885475c11b50bdd"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a43c2ef8a778a33a17885475c11b50bdd">mlir::linalg::populatePadOpVectorizationPatterns</a></div><div class="ttdeci">void populatePadOpVectorizationPatterns(RewritePatternSet &amp;patterns, PatternBenefit baseBenefit=1)</div><div class="ttdoc">Populates patterns with patterns that vectorize tensor.pad.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03248">Vectorization.cpp:3248</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a5377722f56e02541897c157260bd1eee"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a5377722f56e02541897c157260bd1eee">mlir::linalg::isReductionIterator</a></div><div class="ttdeci">bool isReductionIterator(utils::IteratorType iteratorType)</div><div class="ttdoc">Check if iterator type has &quot;reduction&quot; semantics.</div><div class="ttdef"><b>Definition:</b> <a href="Dialect_2Linalg_2Utils_2Utils_8cpp_source.html#l00239">Utils.cpp:239</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a5c34dd63bd77acc711bdf98d6e2c7b75"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a5c34dd63bd77acc711bdf98d6e2c7b75">mlir::linalg::getPackInverseDestPerm</a></div><div class="ttdeci">SmallVector&lt; int64_t &gt; getPackInverseDestPerm(linalg::PackOp packOp)</div><div class="ttdoc">Shell function to compute the Destination Permutation of PackOp This function uses the helper functio...</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a891b8f2d145dcc3327ba55c7a49d44e4"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a891b8f2d145dcc3327ba55c7a49d44e4">mlir::linalg::populateConvolutionVectorizationPatterns</a></div><div class="ttdeci">void populateConvolutionVectorizationPatterns(RewritePatternSet &amp;patterns, PatternBenefit benefit=1)</div><div class="ttdoc">Populate patterns for vectorizing low-D convolution ops.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l04275">Vectorization.cpp:4275</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a8b1c347bc995910212c197f9f8728b12"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a8b1c347bc995910212c197f9f8728b12">mlir::linalg::isElementwise</a></div><div class="ttdeci">bool isElementwise(LinalgOp op)</div><div class="ttdoc">Check if a LinalgOp is an element-wise operation.</div><div class="ttdef"><b>Definition:</b> <a href="Dialect_2Linalg_2Utils_2Utils_8cpp_source.html#l00220">Utils.cpp:220</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a8c63bc9239511b70751c238a12f5b1da"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a8c63bc9239511b70751c238a12f5b1da">mlir::linalg::vectorizeCopy</a></div><div class="ttdeci">LogicalResult vectorizeCopy(RewriterBase &amp;builder, memref::CopyOp copyOp)</div><div class="ttdoc">Emit a suitable vector form for a Copy op with fully static shape.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02769">Vectorization.cpp:2769</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a8d0310adee4f127279f9147a71db0181"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a8d0310adee4f127279f9147a71db0181">mlir::linalg::vectorizeOpPrecondition</a></div><div class="ttdeci">LogicalResult vectorizeOpPrecondition(Operation *op, ArrayRef&lt; int64_t &gt; inputVectorSizes={}, ArrayRef&lt; bool &gt; inputScalableVecDims={}, bool vectorizeNDExtract=false, bool flatten1DDepthwiseConv=false)</div><div class="ttdoc">Return success if the operation can be vectorized.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02623">Vectorization.cpp:2623</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_aa9d51592527f88974d4540b6dd73a59d"><div class="ttname"><a href="namespacemlir_1_1linalg.html#aa9d51592527f88974d4540b6dd73a59d">mlir::linalg::getUnPackInverseSrcPerm</a></div><div class="ttdeci">SmallVector&lt; int64_t &gt; getUnPackInverseSrcPerm(linalg::UnPackOp unpackOp)</div><div class="ttdoc">Shell function to compute the Source Permutation of unPackOp.</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_ae27267a4634c46beba8c9f55c14cdfa1"><div class="ttname"><a href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">mlir::linalg::getCombinerOpKind</a></div><div class="ttdeci">enum WinogradConv2DFmr uint32_t std::optional&lt; vector::CombiningKind &gt; getCombinerOpKind(Operation *combinerOp)</div><div class="ttdoc">Return vector::CombiningKind for the given op.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00604">Vectorization.cpp:604</a></div></div>
<div class="ttc" id="anamespacemlir_1_1memref_html_ab0c13e32e47a301b4ccac4b27404de51"><div class="ttname"><a href="namespacemlir_1_1memref.html#ab0c13e32e47a301b4ccac4b27404de51">mlir::memref::getMixedSizes</a></div><div class="ttdeci">SmallVector&lt; OpFoldResult &gt; getMixedSizes(OpBuilder &amp;builder, Location loc, Value value)</div><div class="ttdoc">Return the dimensions of the given memref value.</div><div class="ttdef"><b>Definition:</b> <a href="MemRefOps_8cpp_source.html#l00077">MemRefOps.cpp:77</a></div></div>
<div class="ttc" id="anamespacemlir_1_1scf_html_a797e5365dbe74c07bf61e43ff8e6a796"><div class="ttname"><a href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">mlir::scf::promote</a></div><div class="ttdeci">void promote(RewriterBase &amp;rewriter, scf::ForallOp forallOp)</div><div class="ttdoc">Promotes the loop body of a scf::ForallOp to its containing block.</div><div class="ttdef"><b>Definition:</b> <a href="Dialect_2SCF_2IR_2SCF_8cpp_source.html#l00654">SCF.cpp:654</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_1_1detail_html_a492fbad8ce09b07f0fcdaa6deeaf0242"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor_1_1detail.html#a492fbad8ce09b07f0fcdaa6deeaf0242">mlir::sparse_tensor::detail::readValue</a></div><div class="ttdeci">std::enable_if_t&lt;!is_complex&lt; V &gt;::value, V &gt; readValue(char **linePtr)</div><div class="ttdoc">Returns an element-value of non-complex type.</div><div class="ttdef"><b>Definition:</b> <a href="File_8h_source.html#l00043">File.h:43</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_a341516a4c95139534df7b424b2de2598"><div class="ttname"><a href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">mlir::vector::isValidMaskedInputVector</a></div><div class="ttdeci">LogicalResult isValidMaskedInputVector(ArrayRef&lt; int64_t &gt; shape, ArrayRef&lt; int64_t &gt; inputVectorSizes)</div><div class="ttdoc">Returns success if inputVectorSizes is a valid masking configuraion for given shape,...</div><div class="ttdef"><b>Definition:</b> <a href="VectorUtils_8cpp_source.html#l00368">VectorUtils.cpp:368</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_a4ba6d4a825dbd36205be5322733056efa822b19813c2556c566eec6864da1319f"><div class="ttname"><a href="namespacemlir_1_1vector.html#a4ba6d4a825dbd36205be5322733056efa822b19813c2556c566eec6864da1319f">mlir::vector::ConstantMaskKind::AllTrue</a></div><div class="ttdeci">@ AllTrue</div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_a4f68d86708480673ecc59b2714973a65"><div class="ttname"><a href="namespacemlir_1_1vector.html#a4f68d86708480673ecc59b2714973a65">mlir::vector::maskOperation</a></div><div class="ttdeci">Operation * maskOperation(OpBuilder &amp;builder, Operation *maskableOp, Value mask, Value passthru=Value())</div><div class="ttdoc">Creates a vector.mask operation around a maskable operation.</div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_a5150a3f7aa4857a1863bd10fb551442a"><div class="ttname"><a href="namespacemlir_1_1vector.html#a5150a3f7aa4857a1863bd10fb551442a">mlir::vector::isBroadcastableTo</a></div><div class="ttdeci">BroadcastableToResult isBroadcastableTo(Type srcType, VectorType dstVectorType, std::pair&lt; VectorDim, VectorDim &gt; *mismatchingDims=nullptr)</div><div class="ttdef"><b>Definition:</b> <a href="VectorOps_8cpp_source.html#l02767">VectorOps.cpp:2767</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_ab9c7ed08068bf03fb4bd625cd3bbd98c"><div class="ttname"><a href="namespacemlir_1_1vector.html#ab9c7ed08068bf03fb4bd625cd3bbd98c">mlir::vector::createReadOrMaskedRead</a></div><div class="ttdeci">Value createReadOrMaskedRead(OpBuilder &amp;builder, Location loc, Value source, ArrayRef&lt; int64_t &gt; inputVectorSizes, Value padValue, bool useInBoundsInsteadOfMasking=false, ArrayRef&lt; bool &gt; scalableDims={})</div><div class="ttdoc">Creates a TransferReadOp from source.</div><div class="ttdef"><b>Definition:</b> <a href="VectorUtils_8cpp_source.html#l00317">VectorUtils.cpp:317</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_acfee45e655b185bd625e2f7994dc2c50a505a83f220c02df2f85c3810cd9ceb38"><div class="ttname"><a href="namespacemlir_1_1vector.html#acfee45e655b185bd625e2f7994dc2c50a505a83f220c02df2f85c3810cd9ceb38">mlir::vector::BroadcastableToResult::Success</a></div><div class="ttdeci">@ Success</div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_ad910c130857e946d9d30b58ffb708f3a"><div class="ttname"><a href="namespacemlir_1_1vector.html#ad910c130857e946d9d30b58ffb708f3a">mlir::vector::getMixedSizesXfer</a></div><div class="ttdeci">SmallVector&lt; OpFoldResult &gt; getMixedSizesXfer(bool hasTensorSemantics, Operation *xfer, RewriterBase &amp;rewriter)</div><div class="ttdoc">A wrapper for getMixedSizes for vector.transfer_read and vector.transfer_write Ops (for source and de...</div><div class="ttdef"><b>Definition:</b> <a href="VectorUtils_8cpp_source.html#l00296">VectorUtils.cpp:296</a></div></div>
<div class="ttc" id="anamespacemlir_html"><div class="ttname"><a href="namespacemlir.html">mlir</a></div><div class="ttdoc">Include the generated interface declarations.</div><div class="ttdef"><b>Definition:</b> <a href="LocalAliasAnalysis_8h_source.html#l00020">LocalAliasAnalysis.h:20</a></div></div>
<div class="ttc" id="anamespacemlir_html_a0190228b09e7b51a4bc1e013c01d404c"><div class="ttname"><a href="namespacemlir.html#a0190228b09e7b51a4bc1e013c01d404c">mlir::matchPattern</a></div><div class="ttdeci">bool matchPattern(Value value, const Pattern &amp;pattern)</div><div class="ttdoc">Entry point for matching a pattern over a Value.</div><div class="ttdef"><b>Definition:</b> <a href="Matchers_8h_source.html#l00490">Matchers.h:490</a></div></div>
<div class="ttc" id="anamespacemlir_html_a091c0686ba6d6f3ad4af9db1aea8063f"><div class="ttname"><a href="namespacemlir.html#a091c0686ba6d6f3ad4af9db1aea8063f">mlir::m_ConstantInt</a></div><div class="ttdeci">detail::constant_int_value_binder m_ConstantInt(IntegerAttr::ValueType *bind_value)</div><div class="ttdoc">Matches a constant holding a scalar/vector/tensor integer (splat) and writes the integer value to bin...</div><div class="ttdef"><b>Definition:</b> <a href="Matchers_8h_source.html#l00527">Matchers.h:527</a></div></div>
<div class="ttc" id="anamespacemlir_html_a1c6ebcdda896c9a0316c2367d2843775"><div class="ttname"><a href="namespacemlir.html#a1c6ebcdda896c9a0316c2367d2843775">mlir::changed</a></div><div class="ttdeci">const FrozenRewritePatternSet GreedyRewriteConfig bool * changed</div><div class="ttdef"><b>Definition:</b> <a href="GreedyPatternRewriteDriver_8h_source.html#l00285">GreedyPatternRewriteDriver.h:285</a></div></div>
<div class="ttc" id="anamespacemlir_html_a22bfcc5fa9deffb32e7c39183f732c90"><div class="ttname"><a href="namespacemlir.html#a22bfcc5fa9deffb32e7c39183f732c90">mlir::getConstantIntValue</a></div><div class="ttdeci">std::optional&lt; int64_t &gt; getConstantIntValue(OpFoldResult ofr)</div><div class="ttdoc">If ofr is a constant integer or an IntegerAttr, return the integer.</div><div class="ttdef"><b>Definition:</b> <a href="StaticValueUtils_8cpp_source.html#l00115">StaticValueUtils.cpp:115</a></div></div>
<div class="ttc" id="anamespacemlir_html_a2b76f177cd65bd4fd394f9dc65d20be2"><div class="ttname"><a href="namespacemlir.html#a2b76f177cd65bd4fd394f9dc65d20be2">mlir::applyPermutationMap</a></div><div class="ttdeci">SmallVector&lt; T &gt; applyPermutationMap(AffineMap map, llvm::ArrayRef&lt; T &gt; source)</div><div class="ttdoc">Apply a permutation from map to source and return the result.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2IR_2AffineMap_8h_source.html#l00675">AffineMap.h:675</a></div></div>
<div class="ttc" id="anamespacemlir_html_a2ee77c6f0feb82212b1b817785f95f48"><div class="ttname"><a href="namespacemlir.html#a2ee77c6f0feb82212b1b817785f95f48">mlir::isEqualConstantIntOrValue</a></div><div class="ttdeci">bool isEqualConstantIntOrValue(OpFoldResult ofr1, OpFoldResult ofr2)</div><div class="ttdoc">Return true if ofr1 and ofr2 are the same integer constant attribute values or the same SSA value.</div><div class="ttdef"><b>Definition:</b> <a href="StaticValueUtils_8cpp_source.html#l00165">StaticValueUtils.cpp:165</a></div></div>
<div class="ttc" id="anamespacemlir_html_a39612be2ef116102866d3bb9c6a8ca88"><div class="ttname"><a href="namespacemlir.html#a39612be2ef116102866d3bb9c6a8ca88">mlir::inverseAndBroadcastProjectedPermutation</a></div><div class="ttdeci">AffineMap inverseAndBroadcastProjectedPermutation(AffineMap map)</div><div class="ttdoc">Return the reverse map of a projected permutation where the projected dimensions are transformed into...</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00808">AffineMap.cpp:808</a></div></div>
<div class="ttc" id="anamespacemlir_html_a39768b5816332d4970911da09de5cec4"><div class="ttname"><a href="namespacemlir.html#a39768b5816332d4970911da09de5cec4">mlir::TypedValue</a></div><div class="ttdeci">std::conditional_t&lt; std::is_same_v&lt; Ty, mlir::Type &gt;, mlir::Value, detail::TypedValue&lt; Ty &gt; &gt; TypedValue</div><div class="ttdoc">If Ty is mlir::Type this will select Value instead of having a wrapper around it.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00487">Value.h:488</a></div></div>
<div class="ttc" id="anamespacemlir_html_a3d147ba82716614172eb7e9b5209d3eb"><div class="ttname"><a href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">mlir::bindDims</a></div><div class="ttdeci">void bindDims(MLIRContext *ctx, AffineExprTy &amp;...exprs)</div><div class="ttdoc">Bind a list of AffineExpr references to DimExpr at positions: [0 .</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2IR_2AffineExpr_8h_source.html#l00311">AffineExpr.h:311</a></div></div>
<div class="ttc" id="anamespacemlir_html_a44886de1f618c57e6589a875d1407830"><div class="ttname"><a href="namespacemlir.html#a44886de1f618c57e6589a875d1407830">mlir::applyPermutation</a></div><div class="ttdeci">SmallVector&lt; T &gt; applyPermutation(ArrayRef&lt; T &gt; input, ArrayRef&lt; int64_t &gt; permutation)</div><div class="ttdef"><b>Definition:</b> <a href="IndexingUtils_8h_source.html#l00201">IndexingUtils.h:201</a></div></div>
<div class="ttc" id="anamespacemlir_html_a52b322818d83a2256d4e4391acbf78a2"><div class="ttname"><a href="namespacemlir.html#a52b322818d83a2256d4e4391acbf78a2">mlir::inversePermutation</a></div><div class="ttdeci">AffineMap inversePermutation(AffineMap map)</div><div class="ttdoc">Returns a map of codomain to domain dimensions such that the first codomain dimension for a particula...</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00784">AffineMap.cpp:784</a></div></div>
<div class="ttc" id="anamespacemlir_html_a561d5231fcefc471a4c9069fce2eaf87"><div class="ttname"><a href="namespacemlir.html#a561d5231fcefc471a4c9069fce2eaf87">mlir::getSymbolLessAffineMaps</a></div><div class="ttdeci">SmallVector&lt; AffineMap, 4 &gt; getSymbolLessAffineMaps(ArrayRef&lt; ReassociationExprs &gt; reassociation)</div><div class="ttdoc">Constructs affine maps out of Array&lt;Array&lt;AffineExpr&gt;&gt;.</div><div class="ttdef"><b>Definition:</b> <a href="ReshapeOpsUtils_8cpp_source.html#l00447">ReshapeOpsUtils.cpp:447</a></div></div>
<div class="ttc" id="anamespacemlir_html_a6bc751bc8f30d71ad4cb771c0fcc788b"><div class="ttname"><a href="namespacemlir.html#a6bc751bc8f30d71ad4cb771c0fcc788b">mlir::matchReduction</a></div><div class="ttdeci">Value matchReduction(ArrayRef&lt; BlockArgument &gt; iterCarriedArgs, unsigned redPos, SmallVectorImpl&lt; Operation * &gt; &amp;combinerOps)</div><div class="ttdoc">Utility to match a generic reduction given a list of iteration-carried arguments, iterCarriedArgs and...</div><div class="ttdef"><b>Definition:</b> <a href="SliceAnalysis_8cpp_source.html#l00288">SliceAnalysis.cpp:288</a></div></div>
<div class="ttc" id="anamespacemlir_html_a82686ceb29eb0f78b59e29021f1b2cdd"><div class="ttname"><a href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">mlir::getElementTypeOrSelf</a></div><div class="ttdeci">Type getElementTypeOrSelf(Type type)</div><div class="ttdoc">Return the element type or return the type itself.</div><div class="ttdef"><b>Definition:</b> <a href="TypeUtilities_8cpp_source.html#l00023">TypeUtilities.cpp:23</a></div></div>
<div class="ttc" id="anamespacemlir_html_a8789c71249b4fcc3059f4ba4a9d27f26"><div class="ttname"><a href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">mlir::patterns</a></div><div class="ttdeci">const FrozenRewritePatternSet &amp; patterns</div><div class="ttdef"><b>Definition:</b> <a href="GreedyPatternRewriteDriver_8h_source.html#l00283">GreedyPatternRewriteDriver.h:283</a></div></div>
<div class="ttc" id="anamespacemlir_html_a98f08e970a346cd42559db87f97f0b91"><div class="ttname"><a href="namespacemlir.html#a98f08e970a346cd42559db87f97f0b91">mlir::getUsedValuesDefinedAbove</a></div><div class="ttdeci">void getUsedValuesDefinedAbove(Region &amp;region, Region &amp;limit, SetVector&lt; Value &gt; &amp;values)</div><div class="ttdoc">Fill values with a list of values defined at the ancestors of the limit region and used within region...</div><div class="ttdef"><b>Definition:</b> <a href="RegionUtils_8cpp_source.html#l00067">RegionUtils.cpp:67</a></div></div>
<div class="ttc" id="anamespacemlir_html_a99f84d2ce14eec6c85a20251582e5cc1"><div class="ttname"><a href="namespacemlir.html#a99f84d2ce14eec6c85a20251582e5cc1">mlir::compressUnusedDims</a></div><div class="ttdeci">AffineMap compressUnusedDims(AffineMap map)</div><div class="ttdoc">Drop the dims that are not used.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00715">AffineMap.cpp:715</a></div></div>
<div class="ttc" id="anamespacemlir_html_a9b2799e8f52860dadc460b88a8f2df32"><div class="ttname"><a href="namespacemlir.html#a9b2799e8f52860dadc460b88a8f2df32">mlir::convertReassociationIndicesToExprs</a></div><div class="ttdeci">SmallVector&lt; SmallVector&lt; AffineExpr, 2 &gt;, 2 &gt; convertReassociationIndicesToExprs(MLIRContext *context, ArrayRef&lt; ReassociationIndices &gt; reassociationIndices)</div><div class="ttdoc">Convert reassociation indices to affine expressions.</div><div class="ttdef"><b>Definition:</b> <a href="ReshapeOpsUtils_8cpp_source.html#l00396">ReshapeOpsUtils.cpp:396</a></div></div>
<div class="ttc" id="anamespacemlir_html_a9e3d6f94b6a941066c3e7e5535817a9b"><div class="ttname"><a href="namespacemlir.html#a9e3d6f94b6a941066c3e7e5535817a9b">mlir::isReassociationValid</a></div><div class="ttdeci">bool isReassociationValid(ArrayRef&lt; AffineMap &gt; reassociation, int *invalidIndex=nullptr)</div><div class="ttdoc">Return true if the reassociation specification is valid, false otherwise.</div><div class="ttdef"><b>Definition:</b> <a href="ReshapeOpsUtils_8cpp_source.html#l00460">ReshapeOpsUtils.cpp:460</a></div></div>
<div class="ttc" id="anamespacemlir_html_aa058eb9c12d3b97deb073543c1372195"><div class="ttname"><a href="namespacemlir.html#aa058eb9c12d3b97deb073543c1372195">mlir::getValueOrCreateConstantIndexOp</a></div><div class="ttdeci">Value getValueOrCreateConstantIndexOp(OpBuilder &amp;b, Location loc, OpFoldResult ofr)</div><div class="ttdoc">Converts an OpFoldResult to a Value.</div><div class="ttdef"><b>Definition:</b> <a href="Dialect_2Arith_2Utils_2Utils_8cpp_source.html#l00111">Utils.cpp:111</a></div></div>
<div class="ttc" id="anamespacemlir_html_ab26cdced424aa629fde4150cc8674d50"><div class="ttname"><a href="namespacemlir.html#ab26cdced424aa629fde4150cc8674d50">mlir::getAffineConstantExpr</a></div><div class="ttdeci">AffineExpr getAffineConstantExpr(int64_t constant, MLIRContext *context)</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineExpr_8cpp_source.html#l00643">AffineExpr.cpp:643</a></div></div>
<div class="ttc" id="anamespacemlir_html_ab4871db68c59a176135e0e35a3625e73"><div class="ttname"><a href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">mlir::get</a></div><div class="ttdeci">auto get(MLIRContext *context, Ts &amp;&amp;...params)</div><div class="ttdoc">Helper method that injects context only if needed, this helps unify some of the attribute constructio...</div><div class="ttdef"><b>Definition:</b> <a href="BytecodeImplementation_8h_source.html#l00509">BytecodeImplementation.h:509</a></div></div>
<div class="ttc" id="anamespacemlir_html_ac61c6bb6068af953a0711cf404a99645"><div class="ttname"><a href="namespacemlir.html#ac61c6bb6068af953a0711cf404a99645">mlir::getUnusedDimsBitVector</a></div><div class="ttdeci">llvm::SmallBitVector getUnusedDimsBitVector(ArrayRef&lt; AffineMap &gt; maps)</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00923">AffineMap.cpp:923</a></div></div>
<div class="ttc" id="anamespacemlir_html_ad402a86ee4c9000c6fa1fceaddab560b"><div class="ttname"><a href="namespacemlir.html#ad402a86ee4c9000c6fa1fceaddab560b">mlir::m_Constant</a></div><div class="ttdeci">detail::constant_op_matcher m_Constant()</div><div class="ttdoc">Matches a constant foldable operation.</div><div class="ttdef"><b>Definition:</b> <a href="Matchers_8h_source.html#l00369">Matchers.h:369</a></div></div>
<div class="ttc" id="anamespacemlir_html_adbcff71555e8c1965e508f324f43a55a"><div class="ttname"><a href="namespacemlir.html#adbcff71555e8c1965e508f324f43a55a">mlir::applyPermutationToVector</a></div><div class="ttdeci">void applyPermutationToVector(SmallVector&lt; T, N &gt; &amp;inVec, ArrayRef&lt; int64_t &gt; permutation)</div><div class="ttdoc">Apply the permutation defined by permutation to inVec.</div><div class="ttdef"><b>Definition:</b> <a href="IndexingUtils_8h_source.html#l00226">IndexingUtils.h:226</a></div></div>
<div class="ttc" id="anamespacemlir_html_afc254f56cba37671e1e5b2b933c6a090"><div class="ttname"><a href="namespacemlir.html#afc254f56cba37671e1e5b2b933c6a090">mlir::invertPermutationVector</a></div><div class="ttdeci">SmallVector&lt; int64_t &gt; invertPermutationVector(ArrayRef&lt; int64_t &gt; permutation)</div><div class="ttdoc">Helper method to apply to inverse a permutation.</div><div class="ttdef"><b>Definition:</b> <a href="IndexingUtils_8cpp_source.html#l00206">IndexingUtils.cpp:206</a></div></div>
<div class="ttc" id="astructPadOpVectorizationWithInsertSlicePattern_html"><div class="ttname"><a href="structPadOpVectorizationWithInsertSlicePattern.html">PadOpVectorizationWithInsertSlicePattern</a></div><div class="ttdoc">Rewrite use of tensor::PadOp result in InsertSliceOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03183">Vectorization.cpp:3184</a></div></div>
<div class="ttc" id="astructPadOpVectorizationWithInsertSlicePattern_html_a9ead6c8bbb0241d7c9c0a7214fe1b827"><div class="ttname"><a href="structPadOpVectorizationWithInsertSlicePattern.html#a9ead6c8bbb0241d7c9c0a7214fe1b827">PadOpVectorizationWithInsertSlicePattern::rewriteUser</a></div><div class="ttdeci">LogicalResult rewriteUser(PatternRewriter &amp;rewriter, tensor::PadOp padOp, tensor::InsertSliceOp insertOp) const override</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03188">Vectorization.cpp:3188</a></div></div>
<div class="ttc" id="astructPadOpVectorizationWithTransferReadPattern_html"><div class="ttname"><a href="structPadOpVectorizationWithTransferReadPattern.html">PadOpVectorizationWithTransferReadPattern</a></div><div class="ttdoc">Rewrite use of tensor::PadOp result in TransferReadOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02849">Vectorization.cpp:2850</a></div></div>
<div class="ttc" id="astructPadOpVectorizationWithTransferReadPattern_html_ada99e3114e6e559b930e1315763d0aca"><div class="ttname"><a href="structPadOpVectorizationWithTransferReadPattern.html#ada99e3114e6e559b930e1315763d0aca">PadOpVectorizationWithTransferReadPattern::rewriteUser</a></div><div class="ttdeci">LogicalResult rewriteUser(PatternRewriter &amp;rewriter, tensor::PadOp padOp, vector::TransferReadOp xferOp) const override</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02854">Vectorization.cpp:2854</a></div></div>
<div class="ttc" id="astructPadOpVectorizationWithTransferWritePattern_html"><div class="ttname"><a href="structPadOpVectorizationWithTransferWritePattern.html">PadOpVectorizationWithTransferWritePattern</a></div><div class="ttdoc">Rewrite use of tensor::PadOp result in TransferWriteOp.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02911">Vectorization.cpp:2912</a></div></div>
<div class="ttc" id="astructPadOpVectorizationWithTransferWritePattern_html_a0612efe4d3bef8d7b34dd84a0a6c927e"><div class="ttname"><a href="structPadOpVectorizationWithTransferWritePattern.html#a0612efe4d3bef8d7b34dd84a0a6c927e">PadOpVectorizationWithTransferWritePattern::hasSameTensorSize</a></div><div class="ttdeci">bool hasSameTensorSize(Value beforePadding, tensor::ExtractSliceOp afterTrimming) const</div><div class="ttdoc">Check if beforePadding and afterTrimming have the same tensor size, i.e., same dimensions.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02965">Vectorization.cpp:2965</a></div></div>
<div class="ttc" id="astructPadOpVectorizationWithTransferWritePattern_html_a738aa18cd09d3d86a0e8763dfd8d3f2e"><div class="ttname"><a href="structPadOpVectorizationWithTransferWritePattern.html#a738aa18cd09d3d86a0e8763dfd8d3f2e">PadOpVectorizationWithTransferWritePattern::rewriteUser</a></div><div class="ttdeci">LogicalResult rewriteUser(PatternRewriter &amp;rewriter, tensor::PadOp padOp, vector::TransferWriteOp xferOp) const override</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02916">Vectorization.cpp:2916</a></div></div>
<div class="ttc" id="astructVectorizationHookResult_html"><div class="ttname"><a href="structVectorizationHookResult.html">VectorizationHookResult</a></div><div class="ttdoc">VectorizationHookResult contains the vectorized op returned from a CustomVectorizationHook.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00595">Vectorization.cpp:595</a></div></div>
<div class="ttc" id="astructVectorizationHookResult_html_a325ec6cd37d3dcf718897f5e68a37b91"><div class="ttname"><a href="structVectorizationHookResult.html#a325ec6cd37d3dcf718897f5e68a37b91">VectorizationHookResult::status</a></div><div class="ttdeci">enum VectorizationHookStatus status</div><div class="ttdoc">Return status from vectorizing the current op.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00342">Vectorization.cpp:597</a></div></div>
<div class="ttc" id="astructVectorizationHookResult_html_ab9025f3486cb1c8f0c6461db368c1a50"><div class="ttname"><a href="structVectorizationHookResult.html#ab9025f3486cb1c8f0c6461db368c1a50">VectorizationHookResult::newOp</a></div><div class="ttdeci">Operation * newOp</div><div class="ttdoc">New vectorized operation to replace the current op.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00600">Vectorization.cpp:600</a></div></div>
<div class="ttc" id="astructVectorizationState_html"><div class="ttname"><a href="structVectorizationState.html">VectorizationState</a></div><div class="ttdoc">Contains the vectorization state and related methods used across the vectorization process of a given...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00218">Vectorization.cpp:218</a></div></div>
<div class="ttc" id="astructVectorizationState_html_a0ac270c1aef44b0633eb6a4f3e2aa071"><div class="ttname"><a href="structVectorizationState.html#a0ac270c1aef44b0633eb6a4f3e2aa071">VectorizationState::getScalableVecDims</a></div><div class="ttdeci">ArrayRef&lt; bool &gt; getScalableVecDims() const</div><div class="ttdoc">Returns the vector dimensions that are scalable in the canonical vector shape.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00233">Vectorization.cpp:233</a></div></div>
<div class="ttc" id="astructVectorizationState_html_a18a5831810f1beae1d2f37fb9f711b18"><div class="ttname"><a href="structVectorizationState.html#a18a5831810f1beae1d2f37fb9f711b18">VectorizationState::initState</a></div><div class="ttdeci">LogicalResult initState(RewriterBase &amp;rewriter, LinalgOp linalgOp, ArrayRef&lt; int64_t &gt; inputVectorSizes, ArrayRef&lt; bool &gt; inputScalableVecDims, bool assumeDynamicDimsMatchVecSizes=false)</div><div class="ttdoc">Initializes the vectorization state, including the computation of the canonical vector shape for vect...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00380">Vectorization.cpp:380</a></div></div>
<div class="ttc" id="astructVectorizationState_html_a5b0655951fd32179a5cfbd895109fd7a"><div class="ttname"><a href="structVectorizationState.html#a5b0655951fd32179a5cfbd895109fd7a">VectorizationState::getCanonicalVecType</a></div><div class="ttdeci">VectorType getCanonicalVecType(Type elementType, std::optional&lt; AffineMap &gt; dimPermutation=std::nullopt) const</div><div class="ttdoc">Returns a vector type of the provided elementType with the canonical vector shape and the correspondi...</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00239">Vectorization.cpp:239</a></div></div>
<div class="ttc" id="astructVectorizationState_html_a62f8a62afd86fa2984ca7c4ad23904b4"><div class="ttname"><a href="structVectorizationState.html#a62f8a62afd86fa2984ca7c4ad23904b4">VectorizationState::getCanonicalVecShape</a></div><div class="ttdeci">ArrayRef&lt; int64_t &gt; getCanonicalVecShape() const</div><div class="ttdoc">Returns the canonical vector shape used to vectorize the iteration space.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00229">Vectorization.cpp:229</a></div></div>
<div class="ttc" id="astructVectorizationState_html_ac46e33dfa27baf34825d041264c2fd9c"><div class="ttname"><a href="structVectorizationState.html#ac46e33dfa27baf34825d041264c2fd9c">VectorizationState::VectorizationState</a></div><div class="ttdeci">VectorizationState(RewriterBase &amp;rewriter)</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l00219">Vectorization.cpp:219</a></div></div>
<div class="ttc" id="astructVectorizeConvolution_html"><div class="ttname"><a href="structVectorizeConvolution.html">VectorizeConvolution</a></div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l04256">Vectorization.cpp:4256</a></div></div>
<div class="ttc" id="astructVectorizeConvolution_html_a443953ce53e5f5038608ab46597ebbaf"><div class="ttname"><a href="structVectorizeConvolution.html#a443953ce53e5f5038608ab46597ebbaf">VectorizeConvolution::matchAndRewrite</a></div><div class="ttdeci">LogicalResult matchAndRewrite(LinalgOp op, PatternRewriter &amp;rewriter) const override</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l04259">Vectorization.cpp:4259</a></div></div>
<div class="ttc" id="astructVectorizePadOpUserPattern_html"><div class="ttname"><a href="structVectorizePadOpUserPattern.html">VectorizePadOpUserPattern</a></div><div class="ttdoc">Base pattern for rewriting tensor::PadOps whose result is consumed by a given operation type OpTy.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02812">Vectorization.cpp:2812</a></div></div>
<div class="ttc" id="astructVectorizePadOpUserPattern_html_a8cbfa28f3701c68839f0ca8387dea733"><div class="ttname"><a href="structVectorizePadOpUserPattern.html#a8cbfa28f3701c68839f0ca8387dea733">VectorizePadOpUserPattern::rewriteUser</a></div><div class="ttdeci">virtual LogicalResult rewriteUser(PatternRewriter &amp;rewriter, tensor::PadOp padOp, OpTy op) const =0</div></div>
<div class="ttc" id="astructVectorizePadOpUserPattern_html_af76afc4bbbe418ff35ae6074e2ced1ee"><div class="ttname"><a href="structVectorizePadOpUserPattern.html#af76afc4bbbe418ff35ae6074e2ced1ee">VectorizePadOpUserPattern::matchAndRewrite</a></div><div class="ttdeci">LogicalResult matchAndRewrite(tensor::PadOp padOp, PatternRewriter &amp;rewriter) const final</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l02815">Vectorization.cpp:2815</a></div></div>
<div class="ttc" id="astructmlir_1_1OpInterfaceRewritePattern_html"><div class="ttname"><a href="structmlir_1_1OpInterfaceRewritePattern.html">mlir::OpInterfaceRewritePattern</a></div><div class="ttdoc">OpInterfaceRewritePattern is a wrapper around RewritePattern that allows for matching and rewriting a...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00329">PatternMatch.h:330</a></div></div>
<div class="ttc" id="astructmlir_1_1OpInterfaceRewritePattern_html_a723a250f581dc2a0758fbe6b7c55f1c9"><div class="ttname"><a href="structmlir_1_1OpInterfaceRewritePattern.html#a723a250f581dc2a0758fbe6b7c55f1c9">mlir::OpInterfaceRewritePattern::OpInterfaceRewritePattern</a></div><div class="ttdeci">OpInterfaceRewritePattern(MLIRContext *context, PatternBenefit benefit=1)</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00332">PatternMatch.h:332</a></div></div>
<div class="ttc" id="astructmlir_1_1OpRewritePattern_html"><div class="ttname"><a href="structmlir_1_1OpRewritePattern.html">mlir::OpRewritePattern</a></div><div class="ttdoc">OpRewritePattern is a wrapper around RewritePattern that allows for matching and rewriting against an...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00313">PatternMatch.h:314</a></div></div>
<div class="ttc" id="astructmlir_1_1linalg_1_1LinalgCopyVTRForwardingPattern_html_aa21d069f8a683b84f4e81366691cb9aa"><div class="ttname"><a href="structmlir_1_1linalg_1_1LinalgCopyVTRForwardingPattern.html#aa21d069f8a683b84f4e81366691cb9aa">mlir::linalg::LinalgCopyVTRForwardingPattern::matchAndRewrite</a></div><div class="ttdeci">LogicalResult matchAndRewrite(vector::TransferReadOp xferOp, PatternRewriter &amp;rewriter) const override</div><div class="ttdoc">TODO: use interfaces, side-effects and aliasing analysis as appropriate, when available.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03304">Vectorization.cpp:3304</a></div></div>
<div class="ttc" id="astructmlir_1_1linalg_1_1LinalgCopyVTWForwardingPattern_html_ad61b7c343105b1b58fd0b591d39f97c8"><div class="ttname"><a href="structmlir_1_1linalg_1_1LinalgCopyVTWForwardingPattern.html#ad61b7c343105b1b58fd0b591d39f97c8">mlir::linalg::LinalgCopyVTWForwardingPattern::matchAndRewrite</a></div><div class="ttdeci">LogicalResult matchAndRewrite(vector::TransferWriteOp xferOp, PatternRewriter &amp;rewriter) const override</div><div class="ttdoc">TODO: use interfaces, side-effects and aliasing analysis as appropriate, when available.</div><div class="ttdef"><b>Definition:</b> <a href="Vectorization_8cpp_source.html#l03382">Vectorization.cpp:3382</a></div></div>
<div class="ttc" id="astructmlir_1_1linalg_1_1VectorizationResult_html"><div class="ttname"><a href="structmlir_1_1linalg_1_1VectorizationResult.html">mlir::linalg::VectorizationResult</a></div><div class="ttdoc">Transformation information returned after vectorizing.</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Dialect_2Linalg_2Transforms_2Transforms_8h_source.html#l00885">Transforms.h:885</a></div></div>
<div class="ttc" id="aunionj_html"><div class="ttname"><a href="unionj.html">j</a></div><div class="ttdoc">Eliminates variable at the specified position using Fourier-Motzkin variable elimination.</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Aug 1 2025 16:33:22 for MLIR by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
