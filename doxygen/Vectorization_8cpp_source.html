<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.14.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MLIR: lib/Dialect/Linalg/Transforms/Vectorization.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">MLIR<span id="projectnumber">&#160;22.0.0git</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.14.0 -->
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search',false);
});
</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a href="dir_97aefd0d527b934f1d99a682da8fe6a9.html">lib</a></li><li class="navelem"><a href="dir_1a25ec519b6c1121408b67cc33ce3f15.html">Dialect</a></li><li class="navelem"><a href="dir_8edb792440615361a0811a7329611599.html">Linalg</a></li><li class="navelem"><a href="dir_7e2f808e77498894ca0efbd745da2201.html">Transforms</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="headertitle"><div class="title">Vectorization.cpp</div></div>
</div><!--header-->
<div class="contents">
<a href="Vectorization_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">//===- Vectorization.cpp - Implementation of linalg Vectorization ---------===//</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment">//</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment">// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment">//</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment">//</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment">// This file implements the linalg dialect Vectorization transformations.</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment">//</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="preprocessor">#include &quot;<a class="code" href="Dialect_2Affine_2Utils_8h.html">mlir/Dialect/Affine/Utils.h</a>&quot;</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span> </div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="preprocessor">#include &quot;<a class="code" href="SliceAnalysis_8h.html">mlir/Analysis/SliceAnalysis.h</a>&quot;</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="preprocessor">#include &quot;<a class="code" href="AffineOps_8h.html">mlir/Dialect/Affine/IR/AffineOps.h</a>&quot;</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2Arith_2IR_2Arith_8h.html">mlir/Dialect/Arith/IR/Arith.h</a>&quot;</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="preprocessor">#include &quot;<a class="code" href="FuncOps_8h.html">mlir/Dialect/Func/IR/FuncOps.h</a>&quot;</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2Linalg_2IR_2Linalg_8h.html">mlir/Dialect/Linalg/IR/Linalg.h</a>&quot;</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2Linalg_2Transforms_2Transforms_8h.html">mlir/Dialect/Linalg/Transforms/Transforms.h</a>&quot;</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="preprocessor">#include &quot;<a class="code" href="Dialect_2Linalg_2Utils_2Utils_8h.html">mlir/Dialect/Linalg/Utils/Utils.h</a>&quot;</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2Tensor_2IR_2Tensor_8h.html">mlir/Dialect/Tensor/IR/Tensor.h</a>&quot;</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="preprocessor">#include &quot;<a class="code" href="IndexingUtils_8h.html">mlir/Dialect/Utils/IndexingUtils.h</a>&quot;</span></div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="preprocessor">#include &quot;<a class="code" href="StructuredOpsUtils_8h.html">mlir/Dialect/Utils/StructuredOpsUtils.h</a>&quot;</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="preprocessor">#include &quot;<a class="code" href="VectorOps_8h.html">mlir/Dialect/Vector/IR/VectorOps.h</a>&quot;</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span><span class="preprocessor">#include &quot;<a class="code" href="MaskableOpInterface_8h.html">mlir/Dialect/Vector/Interfaces/MaskableOpInterface.h</a>&quot;</span></div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="preprocessor">#include &quot;<a class="code" href="VectorUtils_8h.html">mlir/Dialect/Vector/Utils/VectorUtils.h</a>&quot;</span></div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span><span class="preprocessor">#include &quot;<a class="code" href="mlir_2IR_2AffineExpr_8h.html">mlir/IR/AffineExpr.h</a>&quot;</span></div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="preprocessor">#include &quot;<a class="code" href="mlir_2IR_2AffineMap_8h.html">mlir/IR/AffineMap.h</a>&quot;</span></div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span><span class="preprocessor">#include &quot;<a class="code" href="Builders_8h.html">mlir/IR/Builders.h</a>&quot;</span></div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="preprocessor">#include &quot;<a class="code" href="BuiltinTypeInterfaces_8h.html">mlir/IR/BuiltinTypeInterfaces.h</a>&quot;</span></div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span><span class="preprocessor">#include &quot;<a class="code" href="mlir_2IR_2BuiltinTypes_8h.html">mlir/IR/BuiltinTypes.h</a>&quot;</span></div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span><span class="preprocessor">#include &quot;<a class="code" href="OpDefinition_8h.html">mlir/IR/OpDefinition.h</a>&quot;</span></div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span><span class="preprocessor">#include &quot;<a class="code" href="PatternMatch_8h.html">mlir/IR/PatternMatch.h</a>&quot;</span></div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span><span class="preprocessor">#include &quot;<a class="code" href="Value_8h.html">mlir/IR/Value.h</a>&quot;</span></div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span><span class="preprocessor">#include &quot;<a class="code" href="mlir_2Support_2LLVM_8h.html">mlir/Support/LLVM.h</a>&quot;</span></div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span><span class="preprocessor">#include &quot;<a class="code" href="RegionUtils_8h.html">mlir/Transforms/RegionUtils.h</a>&quot;</span></div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span><span class="preprocessor">#include &quot;llvm/ADT/STLExtras.h&quot;</span></div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span><span class="preprocessor">#include &quot;llvm/ADT/Sequence.h&quot;</span></div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span><span class="preprocessor">#include &quot;llvm/ADT/SmallVector.h&quot;</span></div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span><span class="preprocessor">#include &quot;llvm/ADT/TypeSwitch.h&quot;</span></div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span><span class="preprocessor">#include &quot;llvm/Support/DebugLog.h&quot;</span></div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span><span class="preprocessor">#include &quot;llvm/Support/InterleavedRange.h&quot;</span></div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span><span class="preprocessor">#include &quot;llvm/Support/MathExtras.h&quot;</span></div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno">   44</span><span class="preprocessor">#include &quot;llvm/Support/raw_ostream.h&quot;</span></div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span><span class="preprocessor">#include &lt;optional&gt;</span></div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span> </div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno">   47</span><span class="keyword">using namespace </span><a class="code hl_namespace" href="namespacemlir.html">mlir</a>;</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span><span class="keyword">using namespace </span><a class="code hl_namespace" href="namespacemlir_1_1linalg.html">mlir::linalg</a>;</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span> </div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ad78e062f62e0d6e453941fb4ca843e4d">   50</a></span><span class="preprocessor">#define DEBUG_TYPE &quot;linalg-vectorization&quot;</span></div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span><span class="comment"></span> </div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span><span class="comment">/// Try to vectorize `convOp` as a convolution.</span></div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span><span class="keyword">static</span> FailureOr&lt;Operation *&gt;</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">   54</a></span><a class="code hl_function" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, LinalgOp convOp,</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span>                     <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVecSizes = {},</div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span>                     <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputVecScalableFlags = {},</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span>                     <span class="keywordtype">bool</span> flatten1DDepthwiseConv = <span class="keyword">false</span>);</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span><span class="comment"></span> </div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span><span class="comment">/// Vectorize tensor::InsertSliceOp with:</span></div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span><span class="comment">///   * vector::TransferReadOp + vector::TransferWriteOp</span></div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span><span class="comment">/// The vector sizes are either:</span></div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span><span class="comment">///   * user-provided in `inputVectorSizes`, or</span></div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span><span class="comment">///   * inferred from the static dims in the input and output tensors.</span></div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span><span class="comment">/// Bails out if:</span></div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span><span class="comment">///   * vector sizes are not user-provided, and</span></div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span><span class="comment">///   * at least one dim is dynamic (in both the input and output tensors).</span></div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span><span class="comment">///</span></div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span><span class="comment">/// Before:</span></div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span><span class="comment">///     !t_in_type = tensor&lt;1x2x3xf32&gt;</span></div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span><span class="comment">///     !t_out_type = tensor&lt;9x8x7x1x2x3xf32&gt;</span></div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span><span class="comment">///     !v_type = vector&lt;1x2x3xf32&gt;</span></div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span><span class="comment">///     %inserted_slice = tensor.insert_slice %src into %dest ... : !t_in_type</span></div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span><span class="comment">///     into !t_out_type</span></div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span><span class="comment">/// After:</span></div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span><span class="comment">///     %read = vector.transfer_read %src[...], %pad ... : !t_in_type, !v_type</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span><span class="comment">///     %write = vector.transfer_write %read, %dest ... : !v_type, !t_out_type</span></div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926">   78</a></span><a class="code hl_function" href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926">vectorizeAsInsertSliceOp</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, tensor::InsertSliceOp sliceOp,</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>                         <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>                         <a class="code hl_class" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults);</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span><span class="comment"></span> </div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span><span class="comment">/// Returns the effective Pad value for the input op, provided it&#39;s a scalar.</span></div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span><span class="comment">///</span></div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span><span class="comment">/// Many Ops exhibit pad-like behaviour, but this isn&#39;t always explicit. If</span></div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span><span class="comment">/// this Op performs padding, retrieve the padding value provided that it&#39;s</span></div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span><span class="comment">/// a scalar and static/fixed for all the padded values. Returns an empty value</span></div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span><span class="comment">/// otherwise.</span></div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">   88</a></span><span class="keyword">static</span> <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> <a class="code hl_function" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op);</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span><span class="comment"></span> </div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span><span class="comment">/// Return the unique instance of OpType in `block` if it is indeed unique.</span></div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span><span class="comment">/// Return null if none or more than 1 instances exist.</span></div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> OpType&gt;</div>
<div class="foldopen" id="foldopen00093" data-start="{" data-end="}">
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ab37ae3178304b744d6b0249a60a6e7a3">   93</a></span><span class="keyword">static</span> OpType <a class="code hl_function" href="Vectorization_8cpp.html#ab37ae3178304b744d6b0249a60a6e7a3">getSingleOpOfType</a>(<a class="code hl_class" href="classmlir_1_1Block.html">Block</a> &amp;block) {</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>  OpType res;</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>  block.<a class="code hl_function" href="classmlir_1_1Block.html#a790af2827870ed217e85447b8ed8559c">walk</a>([&amp;](OpType op) {</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>    <span class="keywordflow">if</span> (res) {</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>      res = <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>      <span class="keywordflow">return</span> <a class="code hl_function" href="classmlir_1_1WalkResult.html#abab80dca5987e18f9abf08162cd3faaa">WalkResult::interrupt</a>();</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>    }</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>    res = op;</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="classmlir_1_1WalkResult.html#a97a7015a793bb5d2a97f08e358f42797">WalkResult::advance</a>();</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>  });</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>  <span class="keywordflow">return</span> res;</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>}</div>
</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span><span class="comment"></span> </div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span><span class="comment">/// Helper function to extract the input slices after filter is unrolled along</span></div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span><span class="comment">/// kw.</span></div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span><span class="keyword">static</span> <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a></div>
<div class="foldopen" id="foldopen00109" data-start="{" data-end="}">
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a200fa245f199890432efcd7596b5e672">  109</a></span><a class="code hl_function" href="Vectorization_8cpp.html#a200fa245f199890432efcd7596b5e672">extractConvInputSlices</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code hl_class" href="classmlir_1_1Location.html">Location</a> loc, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> input,</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>                       <a class="code hl_class" href="classint64__t.html">int64_t</a> nSize, <a class="code hl_class" href="classint64__t.html">int64_t</a> wSize, <a class="code hl_class" href="classint64__t.html">int64_t</a> cSize,</div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>                       <a class="code hl_class" href="classint64__t.html">int64_t</a> kwSize, <span class="keywordtype">int</span> strideW, <span class="keywordtype">int</span> dilationW,</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>                       <a class="code hl_class" href="classint64__t.html">int64_t</a> wSizeStep, <span class="keywordtype">bool</span> isSingleChanneled) {</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>;</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>  <span class="keywordflow">if</span> (isSingleChanneled) {</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>    <span class="comment">// Extract input slice of size {wSizeStep} @ [w + kw] for non-channeled</span></div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>    <span class="comment">// convolution.</span></div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> sizes = {wSizeStep};</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1};</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>    <span class="keywordflow">for</span> (<a class="code hl_class" href="classint64__t.html">int64_t</a> kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>      <span class="keywordflow">for</span> (<a class="code hl_class" href="classint64__t.html">int64_t</a> w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>        <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>            rewriter, loc, input, <span class="comment">/*offsets=*/</span><a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{w + kw}, sizes,</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>            strides));</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>      }</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>    }</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>    <span class="comment">// Extract lhs slice of size {n, wSizeStep, c} @ [0, sw * w + dw * kw, 0]</span></div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>    <span class="comment">// for channeled convolution.</span></div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> sizes = {nSize, wSizeStep, cSize};</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1, 1, 1};</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>    <span class="keywordflow">for</span> (<a class="code hl_class" href="classint64__t.html">int64_t</a> kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>      <span class="keywordflow">for</span> (<a class="code hl_class" href="classint64__t.html">int64_t</a> w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>        <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>            rewriter, loc, input,</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>            <span class="comment">/*offsets=*/</span><a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{0, w * strideW + kw * dilationW, 0},</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>            sizes, strides));</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>      }</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>    }</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>  }</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>  <span class="keywordflow">return</span> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>;</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>}</div>
</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span><span class="comment"></span> </div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span><span class="comment">/// Helper function to extract the filter slices after filter is unrolled along</span></div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span><span class="comment">/// kw.</span></div>
<div class="foldopen" id="foldopen00145" data-start="{" data-end="}">
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a5fd4201faa9fbc0aad08b5af06556cc8">  145</a></span><span class="keyword">static</span> <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> <a class="code hl_function" href="Vectorization_8cpp.html#a5fd4201faa9fbc0aad08b5af06556cc8">extractConvFilterSlices</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>                                                  <a class="code hl_class" href="classmlir_1_1Location.html">Location</a> loc, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> filter,</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>                                                  <a class="code hl_class" href="classint64__t.html">int64_t</a> kwSize) {</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>;</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>  <span class="comment">// Extract rhs slice of size [{c, f} for channeled convolutions and {1} for</span></div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>  <span class="comment">// non-chanelled convolution] @ [kw].</span></div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>  <span class="keywordflow">for</span> (<a class="code hl_class" href="classint64__t.html">int64_t</a> kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>    <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>.push_back(vector::ExtractOp::create(</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>        rewriter, loc, filter, <span class="comment">/*offsets=*/</span><a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{kw}));</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>  }</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>  <span class="keywordflow">return</span> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>;</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>}</div>
</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span><span class="comment"></span> </div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span><span class="comment">/// Helper function to extract the result slices after filter is unrolled along</span></div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span><span class="comment">/// kw.</span></div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span><span class="keyword">static</span> <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a></div>
<div class="foldopen" id="foldopen00161" data-start="{" data-end="}">
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#af0d6a3da24bf08205af9661c55447701">  161</a></span><a class="code hl_function" href="Vectorization_8cpp.html#af0d6a3da24bf08205af9661c55447701">extractConvResultSlices</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code hl_class" href="classmlir_1_1Location.html">Location</a> loc, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> res,</div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>                        <a class="code hl_class" href="classint64__t.html">int64_t</a> nSize, <a class="code hl_class" href="classint64__t.html">int64_t</a> wSize, <a class="code hl_class" href="classint64__t.html">int64_t</a> fSize,</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span>                        <a class="code hl_class" href="classint64__t.html">int64_t</a> wSizeStep, <span class="keywordtype">bool</span> isSingleChanneled) {</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>;</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>  <span class="keywordflow">if</span> (isSingleChanneled) {</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>    <span class="comment">// Extract res slice: {wSizeStep} @ [w] for non-channeled convolution.</span></div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> sizes = {wSizeStep};</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1};</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span>    <span class="keywordflow">for</span> (<a class="code hl_class" href="classint64__t.html">int64_t</a> w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span>      <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>          rewriter, loc, res, <span class="comment">/*offsets=*/</span><a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{w}, sizes,</div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span>          strides));</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span>    }</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>    <span class="comment">// Extract res slice: {n, wSizeStep, f} @ [0, w, 0] for channeled</span></div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>    <span class="comment">// convolution.</span></div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> sizes = {nSize, wSizeStep, fSize};</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1, 1, 1};</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>    <span class="keywordflow">for</span> (<a class="code hl_class" href="classint64__t.html">int64_t</a> w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>      <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>          rewriter, loc, res, <span class="comment">/*offsets=*/</span><a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{0, w, 0}, sizes,</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>          strides));</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>    }</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>  }</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>  <span class="keywordflow">return</span> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>;</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>}</div>
</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span><span class="comment"></span> </div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span><span class="comment">/// Helper function to insert the computed result slices.</span></div>
<div class="foldopen" id="foldopen00189" data-start="{" data-end="}">
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a110d1ed6891097419f0358bd63e974c8">  189</a></span><span class="keyword">static</span> <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> <a class="code hl_function" href="Vectorization_8cpp.html#a110d1ed6891097419f0358bd63e974c8">insertConvResultSlices</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code hl_class" href="classmlir_1_1Location.html">Location</a> loc,</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>                                    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> res, <a class="code hl_class" href="classint64__t.html">int64_t</a> wSize, <a class="code hl_class" href="classint64__t.html">int64_t</a> wSizeStep,</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>                                    <a class="code hl_class" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;resVals,</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>                                    <span class="keywordtype">bool</span> isSingleChanneled) {</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span> </div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>  <span class="keywordflow">if</span> (isSingleChanneled) {</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>    <span class="comment">// Write back res slice: {wSizeStep} @ [w] for non-channeled convolution.</span></div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>    <span class="comment">// This does not depend on kw.</span></div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1};</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>    <span class="keywordflow">for</span> (<a class="code hl_class" href="classint64__t.html">int64_t</a> w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>      res = vector::InsertStridedSliceOp::create(</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>          rewriter, loc, resVals[w], res, <span class="comment">/*offsets=*/</span><a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{w},</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>          strides);</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>    }</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>    <span class="comment">// Write back res slice: {n, wSizeStep, f} @ [0, w, 0] for channeled</span></div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>    <span class="comment">// convolution. This does not depend on kw.</span></div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> strides = {1, 1, 1};</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>    <span class="keywordflow">for</span> (<a class="code hl_class" href="classint64__t.html">int64_t</a> w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>      res = vector::InsertStridedSliceOp::create(</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>          rewriter, loc, resVals[w], res,</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>          <span class="comment">/*offsets=*/</span><a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>{0, w, 0}, strides);</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>    }</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>  }</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>  <span class="keywordflow">return</span> res;</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>}</div>
</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span><span class="comment"></span> </div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span><span class="comment">/// Contains the vectorization state and related methods used across the</span></div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span><span class="comment">/// vectorization process of a given operation.</span></div>
<div class="foldopen" id="foldopen00218" data-start="{" data-end="};">
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno"><a class="line" href="structVectorizationState.html">  218</a></span><span class="keyword">struct </span><a class="code hl_function" href="structVectorizationState.html#ac46e33dfa27baf34825d041264c2fd9c">VectorizationState</a> {</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno"><a class="line" href="structVectorizationState.html#ac46e33dfa27baf34825d041264c2fd9c">  219</a></span>  <a class="code hl_function" href="structVectorizationState.html#ac46e33dfa27baf34825d041264c2fd9c">VectorizationState</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter) : rewriterGuard(rewriter) {}</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span><span class="comment"></span> </div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span><span class="comment">  /// Initializes the vectorization state, including the computation of the</span></div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span><span class="comment">  /// canonical vector shape for vectorization.</span></div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>  LogicalResult initState(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, LinalgOp linalgOp,</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>                          <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>                          <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputScalableVecDims,</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>                          <span class="keywordtype">bool</span> assumeDynamicDimsMatchVecSizes = <span class="keyword">false</span>);</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span><span class="comment"></span> </div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span><span class="comment">  /// Returns the canonical vector shape used to vectorize the iteration space.</span></div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a01db79101b5db86d0de4c9e5d9b7e19b">  229</a></span>  <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> <a class="code hl_function" href="structVectorizationState.html#a01db79101b5db86d0de4c9e5d9b7e19b">getCanonicalVecShape</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> canonicalVecShape; }</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span><span class="comment"></span> </div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span><span class="comment">  /// Returns the vector dimensions that are scalable in the canonical vector</span></div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span><span class="comment">  /// shape.</span></div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a8eab28272149a7cac2bf97d99b199d20">  233</a></span>  <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> <a class="code hl_function" href="structVectorizationState.html#a8eab28272149a7cac2bf97d99b199d20">getScalableVecDims</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> scalableVecDims; }</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span><span class="comment"></span> </div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span><span class="comment">  /// Returns a vector type of the provided `elementType` with the canonical</span></div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span><span class="comment">  /// vector shape and the corresponding fixed/scalable dimensions bit. If</span></div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span><span class="comment">  /// `dimPermutation` is provided, the canonical vector dimensions are permuted</span></div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span><span class="comment">  /// accordingly.</span></div>
<div class="foldopen" id="foldopen00239" data-start="{" data-end="}">
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a5b0655951fd32179a5cfbd895109fd7a">  239</a></span>  VectorType <a class="code hl_function" href="structVectorizationState.html#a5b0655951fd32179a5cfbd895109fd7a">getCanonicalVecType</a>(</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>      <a class="code hl_class" href="classmlir_1_1Type.html">Type</a> elementType,</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>      std::optional&lt;AffineMap&gt; dimPermutation = std::nullopt)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> <a class="code hl_function" href="PolynomialApproximation_8cpp.html#ab923648d7590d36d942f588f686aa290">vectorShape</a>;</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> scalableDims;</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>    <span class="keywordflow">if</span> (dimPermutation.has_value()) {</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>      <a class="code hl_function" href="PolynomialApproximation_8cpp.html#ab923648d7590d36d942f588f686aa290">vectorShape</a> =</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>          <a class="code hl_function" href="namespacemlir.html#abf34b5ae79f6561558887f2dd8254f94">applyPermutationMap&lt;int64_t&gt;</a>(*dimPermutation, canonicalVecShape);</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>      scalableDims =</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>          <a class="code hl_function" href="namespacemlir.html#abf34b5ae79f6561558887f2dd8254f94">applyPermutationMap&lt;bool&gt;</a>(*dimPermutation, scalableVecDims);</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>      <a class="code hl_function" href="PolynomialApproximation_8cpp.html#ab923648d7590d36d942f588f686aa290">vectorShape</a>.append(canonicalVecShape.begin(), canonicalVecShape.end());</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>      scalableDims.append(scalableVecDims.begin(), scalableVecDims.end());</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>    }</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span> </div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>    <span class="keywordflow">return</span> VectorType::get(<a class="code hl_function" href="PolynomialApproximation_8cpp.html#ab923648d7590d36d942f588f686aa290">vectorShape</a>, elementType, scalableDims);</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>  }</div>
</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span><span class="comment"></span> </div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span><span class="comment">  /// Masks an operation with the canonical vector mask if the operation needs</span></div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span><span class="comment">  /// masking. Returns the masked operation or the original operation if masking</span></div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span><span class="comment">  /// is not needed. If provided, the canonical mask for this operation is</span></div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span><span class="comment">  /// permuted using `maybeIndexingMap`.</span></div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>  <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>  <a class="code hl_function" href="namespacemlir_1_1vector.html#a21bfcee9196fe1a2cfa548b7df8193a9">maskOperation</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *opToMask, LinalgOp linalgOp,</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>                std::optional&lt;AffineMap&gt; maybeIndexingMap = std::nullopt);</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span> </div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span><span class="keyword">private</span>:<span class="comment"></span></div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span><span class="comment">  /// Initializes the iteration space static sizes using the Linalg op</span></div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span><span class="comment">  /// information. This may become more complicated in the future.</span></div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>  <span class="keywordtype">void</span> initIterSpaceStaticSizes(LinalgOp linalgOp) {</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>    iterSpaceStaticSizes.append(linalgOp.getStaticLoopRanges());</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>  }</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span><span class="comment"></span> </div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span><span class="comment">  /// Generates &#39;arith.constant&#39; and &#39;tensor/memref.dim&#39; operations for</span></div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span><span class="comment">  /// all the static and dynamic dimensions of the iteration space to be</span></div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span><span class="comment">  /// vectorized and store them in `iterSpaceValueSizes`.</span></div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>  LogicalResult precomputeIterSpaceValueSizes(RewriterBase &amp;rewriter,</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>                                              LinalgOp linalgOp);</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span><span class="comment"></span> </div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span><span class="comment">  /// Create or retrieve an existing mask value to mask `opToMask` in the</span></div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span><span class="comment">  /// canonical vector iteration space. If `maybeMaskingMap` the mask is</span></div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span><span class="comment">  /// permuted using that permutation map. If a new mask is created, it will be</span></div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span><span class="comment">  /// cached for future users.</span></div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>  Value getOrCreateMaskFor(RewriterBase &amp;rewriter, Operation *opToMask,</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>                           LinalgOp linalgOp,</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>                           std::optional&lt;AffineMap&gt; maybeMaskingMap);</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span><span class="comment"></span> </div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span><span class="comment">  /// Check whether this permutation map can be used for masking. At the</span></div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span><span class="comment">  /// moment we only make sure that there are no broadcast dimensions, but this</span></div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span><span class="comment">  /// might change if indexing maps evolve.</span></div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>  <span class="keywordtype">bool</span> isValidMaskingMap(AffineMap maskingMap) {</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>    <span class="keywordflow">return</span> maskingMap.<a class="code hl_function" href="classmlir_1_1AffineMap.html#acf141c61521d9a40ba68c0b350a31836">getBroadcastDims</a>().empty();</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>  }</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span><span class="comment"></span> </div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span><span class="comment">  /// Turn the input indexing map into a valid masking map.</span></div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span><span class="comment">  ///</span></div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span><span class="comment">  /// The input indexing map may contain &quot;zero&quot; results, e.g.:</span></div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span><span class="comment">  ///    (d0, d1, d2, d3) -&gt; (d2, d1, d0, 0)</span></div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span><span class="comment">  /// Applying such maps to canonical vector shapes like this one:</span></div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span><span class="comment">  ///    (1, 16, 16, 4)</span></div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span><span class="comment">  /// would yield an invalid vector shape like this:</span></div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span><span class="comment">  ///    (16, 16, 1, 0)</span></div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span><span class="comment">  /// Instead, drop the broadcasting dims that make no sense for masking perm.</span></div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span><span class="comment">  /// maps:</span></div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span><span class="comment">  ///    (d0, d1, d2, d3) -&gt; (d2, d1, d0)</span></div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span><span class="comment">  /// This way, the corresponding vector/mask type will be:</span></div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span><span class="comment">  ///    vector&lt;16x16x1xty&gt;</span></div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span><span class="comment">  /// rather than this invalid Vector type:</span></div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span><span class="comment">  ///    vector&lt;16x16x1x0xty&gt;</span></div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>  AffineMap getMaskingMapFromIndexingMap(AffineMap &amp;indexingMap) {</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>    <span class="keywordflow">return</span> indexingMap.<a class="code hl_function" href="classmlir_1_1AffineMap.html#ac8532830efc67348905fd1e414beaebb">dropZeroResults</a>();</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>  }</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span> </div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>  <span class="comment">// Holds the compile-time static sizes of the iteration space to vectorize.</span></div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>  <span class="comment">// Dynamic dimensions are represented using ShapedType::kDynamic.</span></div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>  SmallVector&lt;int64_t&gt; iterSpaceStaticSizes;</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span><span class="comment"></span> </div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span><span class="comment">  /// Holds the value sizes of the iteration space to vectorize. Static</span></div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span><span class="comment">  /// dimensions are represented by &#39;arith.constant&#39; and dynamic</span></div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span><span class="comment">  /// dimensions by &#39;tensor/memref.dim&#39;.</span></div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>  SmallVector&lt;Value&gt; iterSpaceValueSizes;</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span><span class="comment"></span> </div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span><span class="comment">  /// Holds the canonical vector shape used to vectorize the iteration space.</span></div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>  SmallVector&lt;int64_t&gt; canonicalVecShape;</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span><span class="comment"></span> </div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span><span class="comment">  /// Holds the vector dimensions that are scalable in the canonical vector</span></div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span><span class="comment">  /// shape.</span></div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>  SmallVector&lt;bool&gt; scalableVecDims;</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span><span class="comment"></span> </div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span><span class="comment">  /// Holds the active masks for permutations of the canonical vector iteration</span></div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span><span class="comment">  /// space.</span></div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>  <a class="code hl_typedef" href="namespacemlir.html#abde461319ad5039ddbf5b4e70f47618b">DenseMap&lt;AffineMap, Value&gt;</a> activeMaskCache;</div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span><span class="comment"></span> </div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span><span class="comment">  /// Global vectorization guard for the incoming rewriter. It&#39;s initialized</span></div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span><span class="comment">  /// when the vectorization state is initialized.</span></div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span>  OpBuilder::InsertionGuard rewriterGuard;</div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span><span class="comment"></span> </div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span><span class="comment">  /// Do all dynamic dims match the corresponding vector sizes?</span></div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span><span class="comment">  ///</span></div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span><span class="comment">  /// When a dynamic tensor/memref dimension matches the corresponding vector</span></div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span><span class="comment">  /// dimension, masking can be safely skipped, despite the presence of dynamic</span></div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span><span class="comment">  /// shapes. Use this flag with care and only for cases where you are</span></div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span><span class="comment">  /// confident the assumption holds.</span></div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>  <span class="keywordtype">bool</span> assumeDynamicDimsMatchVecSizes = <span class="keyword">false</span>;</div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>};</div>
</div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span> </div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>LogicalResult</div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>VectorizationState::precomputeIterSpaceValueSizes(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>                                                  LinalgOp linalgOp) {</div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>  <span class="comment">// TODO: Support 0-d vectors.</span></div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> vecDim = 0, end = canonicalVecShape.size(); vecDim &lt; end; ++vecDim) {</div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>    <span class="keywordflow">if</span> (ShapedType::isStatic(iterSpaceStaticSizes[vecDim])) {</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>      <span class="comment">// Create constant index op for static dimensions.</span></div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>      iterSpaceValueSizes.push_back(<a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(</div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>          rewriter, linalgOp.getLoc(), iterSpaceStaticSizes[vecDim]));</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>      <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>    }</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span> </div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>    <span class="comment">// Find an operand defined on this dimension of the iteration space to</span></div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>    <span class="comment">// extract the runtime dimension size.</span></div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>    Value operand;</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>    <span class="keywordtype">unsigned</span> operandDimPos;</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>    <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(linalgOp.mapIterationSpaceDimToOperandDim(vecDim, operand,</div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>                                                         operandDimPos)))</div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span> </div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>    Value dynamicDim =</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>        linalgOp.hasPureTensorSemantics()</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>            ? (Value)tensor::DimOp::create(rewriter, linalgOp.getLoc(), operand,</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>                                           operandDimPos)</div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>            : (Value)memref::DimOp::create(rewriter, linalgOp.getLoc(), operand,</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>                                           operandDimPos);</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>    iterSpaceValueSizes.push_back(dynamicDim);</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>  }</div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span> </div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>}</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span><span class="comment"></span> </div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span><span class="comment">/// Initializes the vectorization state, including the computation of the</span></div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span><span class="comment">/// canonical vector shape for vectorization.</span></div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span><span class="comment">// TODO: Move this to the constructor when we can remove the failure cases.</span></div>
<div class="foldopen" id="foldopen00380" data-start="{" data-end="}">
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a18a5831810f1beae1d2f37fb9f711b18">  380</a></span>LogicalResult <a class="code hl_function" href="structVectorizationState.html#a18a5831810f1beae1d2f37fb9f711b18">VectorizationState::initState</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span>                                            LinalgOp linalgOp,</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>                                            <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> inputVectorSizes,</div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span>                                            <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> inputScalableVecDims,</div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span>                                            <span class="keywordtype">bool</span> assumeDimsMatchVec) {</div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span>  assumeDynamicDimsMatchVecSizes = assumeDimsMatchVec;</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>  <span class="comment">// Initialize the insertion point.</span></div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span>  rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(linalgOp);</div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span> </div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>  <span class="keywordflow">if</span> (!inputVectorSizes.empty()) {</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>    <span class="comment">// Get the canonical vector shape from the input vector sizes provided. This</span></div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>    <span class="comment">// path should be taken to vectorize code with dynamic shapes and when using</span></div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>    <span class="comment">// vector sizes greater than the iteration space sizes.</span></div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>    canonicalVecShape.append(inputVectorSizes.begin(), inputVectorSizes.end());</div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>    scalableVecDims.append(inputScalableVecDims.begin(),</div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>                           inputScalableVecDims.end());</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>    <span class="comment">// Compute the canonical vector shape from the operation shape. If there are</span></div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>    <span class="comment">// dynamic shapes, the operation won&#39;t be vectorized. We assume all the</span></div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>    <span class="comment">// vector dimensions are fixed.</span></div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>    canonicalVecShape = linalgOp.getStaticLoopRanges();</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>    scalableVecDims.append(linalgOp.getNumLoops(), <span class="keyword">false</span>);</div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>  }</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span> </div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Canonical vector shape: &quot;</span> &lt;&lt; llvm::interleaved(canonicalVecShape);</div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Scalable vector dims: &quot;</span> &lt;&lt; llvm::interleaved(scalableVecDims);</div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span> </div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span>  <span class="keywordflow">if</span> (ShapedType::isDynamicShape(canonicalVecShape))</div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span> </div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span>  <span class="comment">// Initialize iteration space static sizes.</span></div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>  initIterSpaceStaticSizes(linalgOp);</div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span> </div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>  <span class="comment">// Generate &#39;arith.constant&#39; and &#39;tensor/memref.dim&#39; operations for</span></div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>  <span class="comment">// all the static and dynamic dimensions of the iteration space, needed to</span></div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>  <span class="comment">// compute a mask during vectorization.</span></div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>  <span class="keywordflow">if</span> (failed(precomputeIterSpaceValueSizes(rewriter, linalgOp)))</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span> </div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>}</div>
</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span><span class="comment"></span> </div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span><span class="comment">/// Create or retrieve an existing mask value to mask `opToMask` in the</span></div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span><span class="comment">/// canonical vector iteration space. If `maybeMaskingMap` the mask is permuted</span></div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span><span class="comment">/// using that permutation map. If a new mask is created, it will be cached for</span></div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span><span class="comment">/// future users.</span></div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span><a class="code hl_class" href="classmlir_1_1Value.html">Value</a> VectorizationState::getOrCreateMaskFor(</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>    <a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *opToMask, LinalgOp linalgOp,</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>    std::optional&lt;AffineMap&gt; maybeMaskingMap) {</div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span> </div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>  assert((!maybeMaskingMap || isValidMaskingMap(*maybeMaskingMap)) &amp;&amp;</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>         <span class="stringliteral">&quot;Ill-formed masking map.&quot;</span>);</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span> </div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>  <span class="comment">// No mask is needed if the operation is not maskable.</span></div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>  <span class="keyword">auto</span> maskableOp = dyn_cast&lt;vector::MaskableOpInterface&gt;(opToMask);</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>  <span class="keywordflow">if</span> (!maskableOp)</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>    <span class="keywordflow">return</span> <a class="code hl_class" href="classmlir_1_1Value.html">Value</a>();</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span> </div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>  assert(!maskableOp.isMasked() &amp;&amp;</div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>         <span class="stringliteral">&quot;Masking an operation that is already masked&quot;</span>);</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span> </div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span>  <span class="comment">// If no masking map was provided, use an identity map with the loop dims.</span></div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>  assert((!maybeMaskingMap || *maybeMaskingMap) &amp;&amp;</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>         <span class="stringliteral">&quot;Unexpected null mask permutation map&quot;</span>);</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>  <a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> maskingMap =</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>      maybeMaskingMap ? *maybeMaskingMap</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>                      : <a class="code hl_function" href="classmlir_1_1AffineMap.html#a39ed2c2a4c743450a4a999fa6db1bf84">AffineMap::getMultiDimIdentityMap</a>(</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>                            linalgOp.getNumLoops(), rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#acbdddd0c6fa53e5605c93109ad00953b">getContext</a>());</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span> </div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Masking map: &quot;</span> &lt;&lt; maskingMap;</div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span> </div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>  <span class="comment">// Return the active mask for the masking map of this operation if it was</span></div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>  <span class="comment">// already created.</span></div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>  <span class="keyword">auto</span> activeMaskIt = activeMaskCache.find(maskingMap);</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>  <span class="keywordflow">if</span> (activeMaskIt != activeMaskCache.end()) {</div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> mask = activeMaskIt-&gt;second;</div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Reusing mask: &quot;</span> &lt;&lt; mask;</div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span>    <span class="keywordflow">return</span> mask;</div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>  }</div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span> </div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>  <span class="comment">// Compute permuted projection of the iteration space to be masked and the</span></div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>  <span class="comment">// corresponding mask shape. If the resulting iteration space dimensions are</span></div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>  <span class="comment">// static and identical to the mask shape, masking is not needed for this</span></div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>  <span class="comment">// operation.</span></div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span>  <span class="comment">// TODO: Improve this check. Only projected permutation indexing maps are</span></div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>  <span class="comment">// supported.</span></div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>  SmallVector&lt;int64_t&gt; permutedStaticSizes =</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>      <a class="code hl_function" href="namespacemlir.html#abf34b5ae79f6561558887f2dd8254f94">applyPermutationMap&lt;int64_t&gt;</a>(maskingMap, iterSpaceStaticSizes);</div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span>  <span class="keyword">auto</span> maskType = getCanonicalVecType(rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>(), maskingMap);</div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span>  <span class="keyword">auto</span> maskShape = maskType.getShape();</div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span> </div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Mask shape: &quot;</span> &lt;&lt; llvm::interleaved(maskShape);</div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span> </div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span>  <span class="keywordflow">if</span> (permutedStaticSizes == maskShape) {</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Masking is not needed for masking map: &quot;</span> &lt;&lt; maskingMap;</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span>    activeMaskCache[maskingMap] = Value();</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>    <span class="keywordflow">return</span> Value();</div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>  }</div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span> </div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>  <span class="keywordflow">if</span> (assumeDynamicDimsMatchVecSizes) {</div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>    <span class="comment">// While for _dynamic_ dim sizes we can _assume_ that the corresponding</span></div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>    <span class="comment">// vector sizes match, we still need to check the _static_ dim sizes. Only</span></div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>    <span class="comment">// then we can be 100% sure that masking is not required.</span></div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>    <span class="keywordflow">if</span> (llvm::all_of(llvm::zip(permutedStaticSizes, maskType.getShape()),</div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span>                     [](<span class="keyword">auto</span> it) {</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span>                       return std::get&lt;0&gt;(it) == ShapedType::kDynamic</div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>                                  ? true</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>                                  : std::get&lt;0&gt;(it) == std::get&lt;1&gt;(it);</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>                     })) {</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>      LDBG()</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>          &lt;&lt; <span class="stringliteral">&quot;Dynamic + static dimensions match vector sizes, masking is not &quot;</span></div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>             <span class="stringliteral">&quot;required.&quot;</span>;</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>      activeMaskCache[maskingMap] = Value();</div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>      <span class="keywordflow">return</span> Value();</div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>    }</div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span>  }</div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span> </div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span>  <span class="comment">// Permute the iteration space value sizes to compute the mask upper bounds.</span></div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>  SmallVector&lt;Value&gt; upperBounds =</div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>      <a class="code hl_function" href="namespacemlir.html#abf34b5ae79f6561558887f2dd8254f94">applyPermutationMap</a>(maskingMap, ArrayRef&lt;Value&gt;(iterSpaceValueSizes));</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>  assert(!maskShape.empty() &amp;&amp; !upperBounds.empty() &amp;&amp;</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span>         <span class="stringliteral">&quot;Masked 0-d vectors are not supported yet&quot;</span>);</div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span> </div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>  <span class="comment">// Create the mask based on the dimension values.</span></div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>  Value mask = vector::CreateMaskOp::create(rewriter, linalgOp.getLoc(),</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span>                                            maskType, upperBounds);</div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Creating new mask: &quot;</span> &lt;&lt; mask;</div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>  activeMaskCache[maskingMap] = mask;</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>  <span class="keywordflow">return</span> mask;</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>}</div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span> </div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>Operation *</div>
<div class="foldopen" id="foldopen00512" data-start="{" data-end="}">
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno"><a class="line" href="structVectorizationState.html#a37816d928cc471a94c6ec113f60969a2">  512</a></span><a class="code hl_function" href="structVectorizationState.html#a37816d928cc471a94c6ec113f60969a2">VectorizationState::maskOperation</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *opToMask,</div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>                                  LinalgOp linalgOp,</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>                                  std::optional&lt;AffineMap&gt; maybeIndexingMap) {</div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Trying to mask: &quot;</span> &lt;&lt; *opToMask;</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span> </div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>  std::optional&lt;AffineMap&gt; maybeMaskingMap = std::nullopt;</div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span>  <span class="keywordflow">if</span> (maybeIndexingMap)</div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span>    maybeMaskingMap = getMaskingMapFromIndexingMap(*maybeIndexingMap);</div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span> </div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span>  <span class="comment">// Create or retrieve mask for this operation.</span></div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>  <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> mask =</div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>      getOrCreateMaskFor(rewriter, opToMask, linalgOp, maybeMaskingMap);</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span> </div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span>  <span class="keywordflow">if</span> (!mask) {</div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;No mask required&quot;</span>;</div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span>    <span class="keywordflow">if</span> (assumeDynamicDimsMatchVecSizes) {</div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span>      <a class="code hl_class" href="classllvm_1_1TypeSwitch.html">llvm::TypeSwitch&lt;Operation *&gt;</a>(opToMask)</div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span>          .Case&lt;vector::TransferReadOp, vector::TransferWriteOp&gt;(</div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span>              [&amp;](<span class="keyword">auto</span> xferOp) {</div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span>                <span class="comment">// For vector.transfer_read and vector.transfer_write, there is</span></div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span>                <span class="comment">// also the `in-bounds` attribute that has to be set explicitly</span></div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span>                <span class="comment">// to true. Otherwise, &quot;out-of-bounds&quot; access will be assumed</span></div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span>                <span class="comment">// and masks will be generated while lowering these.</span></div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span>                LDBG() &lt;&lt; <span class="stringliteral">&quot;Assuming dynamic dimensions match vector sizes and &quot;</span></div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span>                          <span class="stringliteral">&quot;setting their in-bounds to true!&quot;</span>;</div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span>                <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBoundsMap = xferOp.getInBoundsValues();</div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span>                ShapedType xferType = xferOp.getShapedType();</div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span>                <a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> permMap = xferOp.<a class="code hl_function" href="classmlir_1_1AffineMap.html#acd08312b1039c20f008d2f6785c47816">getPermutationMap</a>();</div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span>                <span class="comment">// Only set the in-bounds values to true for dynamic dims.</span></div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span>                <span class="comment">// Different mechanisms will set these accordingly for the</span></div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span>                <span class="comment">// static dims.</span></div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span>                <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; xferOp.getTransferRank(); i++) {</div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span>                  <span class="keyword">auto</span> dimExpr = dyn_cast&lt;AffineDimExpr&gt;(permMap.<a class="code hl_function" href="classmlir_1_1AffineMap.html#ac60458b2cba87d765341cd6b2d41ed12">getResult</a>(i));</div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span>                  <span class="comment">// Skip broadcast dimensions.</span></div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span>                  <span class="keywordflow">if</span> (!dimExpr)</div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span>                    <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span>                  <span class="keywordtype">unsigned</span> pos = dimExpr.getPosition();</div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span>                  <span class="keywordflow">if</span> (xferType.isDynamicDim(pos))</div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span>                    inBoundsMap[i] = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span>                }</div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span>                rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#abd8bae753b51386417536a36cf52d3f7">modifyOpInPlace</a>(xferOp, [&amp;]() {</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span>                  xferOp.setInBoundsAttr(</div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span>                      rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBoundsMap));</div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span>                });</div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span>              })</div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>          .Default([](<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op) {</div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span>            <span class="comment">// No-op if the operation is not an xfer read or write.</span></div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span>          });</div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span>    }</div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span>    <span class="keywordflow">return</span> opToMask;</div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span>  }</div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span> </div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span>  <span class="comment">// Wrap the operation with a new `vector.mask` and update D-U chain.</span></div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span>  assert(opToMask &amp;&amp; <span class="stringliteral">&quot;Expected a valid operation to mask&quot;</span>);</div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span>  <span class="keyword">auto</span> maskOp = cast&lt;vector::MaskOp&gt;(</div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span>      <a class="code hl_function" href="namespacemlir_1_1vector.html#a21bfcee9196fe1a2cfa548b7df8193a9">mlir::vector::maskOperation</a>(rewriter, opToMask, mask));</div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span>  <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *maskOpTerminator = &amp;maskOp.getMaskRegion().front().back();</div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span> </div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [resIdx, resVal] : llvm::enumerate(opToMask-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>()))</div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span>    rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a9bc0bf42591d2bf716733ed23bb8b6e6">replaceAllUsesExcept</a>(resVal, maskOp.getResult(resIdx),</div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span>                                  maskOpTerminator);</div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span> </div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Masked operation: &quot;</span> &lt;&lt; *maskOp;</div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span>  <span class="keywordflow">return</span> maskOp;</div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span>}</div>
</div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span><span class="comment"></span> </div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span><span class="comment">/// Given an indexing `map` coming from a LinalgOp indexing, restricted to a</span></div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span><span class="comment">/// projectedPermutation, compress the unused dimensions to serve as a</span></div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span><span class="comment">/// permutation_map for a vector transfer operation.</span></div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span><span class="comment">/// For example, given a linalg op such as:</span></div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span><span class="comment">///</span></div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span><span class="comment">///   %0 = linalg.generic {</span></div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span><span class="comment">///        indexing_maps = affine_map&lt;(d0, d1, d2, d3, d4) -&gt; (d4, d0, d2)&gt;,</span></div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span><span class="comment">///        indexing_maps = affine_map&lt;(d0, d1, d2, d3, d4) -&gt; (d1, d3)&gt;</span></div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span><span class="comment">///      }</span></div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span><span class="comment">///     ins(%0 : tensor&lt;2x3x4xf32&gt;)</span></div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span><span class="comment">///    outs(%1 : tensor&lt;5x6xf32&gt;)</span></div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span><span class="comment">///</span></div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span><span class="comment">/// the iteration domain size of the linalg op is 3x5x4x6x2. The first affine</span></div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span><span class="comment">/// map is reindexed to `affine_map&lt;(d0, d1, d2) -&gt; (d2, d0, d1)&gt;`, the second</span></div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span><span class="comment">/// affine map is reindexed to `affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;`.</span></div>
<div class="foldopen" id="foldopen00595" data-start="{" data-end="}">
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">  595</a></span><span class="keyword">static</span> <a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> <a class="code hl_function" href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">reindexIndexingMap</a>(<a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> map) {</div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span>  assert(map.<a class="code hl_function" href="classmlir_1_1AffineMap.html#a457a8530ceb03d15e3b171ea3a9fc4a6">isProjectedPermutation</a>(<span class="comment">/*allowZeroInResults=*/</span><span class="keyword">true</span>) &amp;&amp;</div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span>         <span class="stringliteral">&quot;expected projected permutation&quot;</span>);</div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno">  598</span>  <span class="keyword">auto</span> res = <a class="code hl_function" href="namespacemlir.html#a99f84d2ce14eec6c85a20251582e5cc1">compressUnusedDims</a>(map);</div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span>  assert(res.getNumDims() ==</div>
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno">  600</span>             (res.getNumResults() - res.getNumOfZeroResults()) &amp;&amp;</div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span>         <span class="stringliteral">&quot;expected reindexed map with same number of dims and results&quot;</span>);</div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span>  <span class="keywordflow">return</span> res;</div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span>}</div>
</div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span><span class="comment"></span> </div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span><span class="comment">/// Helper enum to represent conv1d input traversal order.</span></div>
<div class="foldopen" id="foldopen00606" data-start="{" data-end="};">
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fec">  606</a></span><span class="keyword">enum class</span> <a class="code hl_enumeration" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fec">Conv1DOpOrder</a> {</div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">  607</a></span>  <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">W</a>,   <span class="comment">// Corresponds to non-channeled 1D convolution operation.</span></div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">  608</a></span>  <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Ncw</a>, <span class="comment">// Corresponds to operation that traverses the input in (n, c, w) order.</span></div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">  609</a></span>  <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Nwc</a>  <span class="comment">// Corresponds to operation that traverses the input in (n, w, c) order.</span></div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span>};</div>
</div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span><span class="comment"></span> </div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno">  612</span><span class="comment">/// Helper data structure to represent the result of vectorization for a single</span></div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span><span class="comment">/// operation. In certain specific cases, like terminators, we do not want to</span></div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span><span class="comment">/// propagate.</span></div>
<div class="foldopen" id="foldopen00615" data-start="{" data-end="};">
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550a">  615</a></span><span class="keyword">enum</span> <a class="code hl_enumeration" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550a">VectorizationHookStatus</a> {<span class="comment"></span></div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span><span class="comment">  /// Op failed to vectorize.</span></div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">  617</a></span>  <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">Failure</a> = 0,<span class="comment"></span></div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span><span class="comment">  /// Op vectorized and custom function took care of replacement logic</span></div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f">  619</a></span>  <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f">NoReplace</a>,<span class="comment"></span></div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span><span class="comment">  /// Op vectorized into a new Op whose results will replace original Op&#39;s</span></div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span><span class="comment">  /// results.</span></div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">  622</a></span>  <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">NewOp</a></div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno">  623</span>  <span class="comment">// TODO: support values if Op vectorized to Many-Ops whose results we need to</span></div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span>  <span class="comment">// aggregate for replacement.</span></div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span>};<span class="comment"></span></div>
</div>
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno">  626</span><span class="comment">/// VectorizationHookResult contains the vectorized op returned from a</span></div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span><span class="comment">/// CustomVectorizationHook. This is an internal implementation detail of</span></div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span><span class="comment">/// linalg vectorization, not to be confused with VectorizationResult.</span></div>
<div class="foldopen" id="foldopen00629" data-start="{" data-end="};">
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno"><a class="line" href="structVectorizationHookResult.html">  629</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a> {<span class="comment"></span></div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span><span class="comment">  /// Return status from vectorizing the current op.</span></div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno"><a class="line" href="structVectorizationHookResult.html#a325ec6cd37d3dcf718897f5e68a37b91">  631</a></span>  <span class="keyword">enum</span> <a class="code hl_enumeration" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550a">VectorizationHookStatus</a> <a class="code hl_variable" href="structVectorizationHookResult.html#a325ec6cd37d3dcf718897f5e68a37b91">status</a> = <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>;<span class="comment"></span></div>
<div class="line"><a id="l00632" name="l00632"></a><span class="lineno">  632</span><span class="comment">  /// New vectorized operation to replace the current op.</span></div>
<div class="line"><a id="l00633" name="l00633"></a><span class="lineno">  633</span><span class="comment">  /// Replacement behavior is specified by `status`.</span></div>
<div class="line"><a id="l00634" name="l00634"></a><span class="lineno"><a class="line" href="structVectorizationHookResult.html#ab9025f3486cb1c8f0c6461db368c1a50">  634</a></span>  <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *<a class="code hl_variable" href="structVectorizationHookResult.html#ab9025f3486cb1c8f0c6461db368c1a50">newOp</a>;</div>
<div class="line"><a id="l00635" name="l00635"></a><span class="lineno">  635</span>};</div>
</div>
<div class="line"><a id="l00636" name="l00636"></a><span class="lineno">  636</span> </div>
<div class="line"><a id="l00637" name="l00637"></a><span class="lineno">  637</span>std::optional&lt;vector::CombiningKind&gt;</div>
<div class="foldopen" id="foldopen00638" data-start="{" data-end="}">
<div class="line"><a id="l00638" name="l00638"></a><span class="lineno"><a class="line" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">  638</a></span><a class="code hl_function" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">mlir::linalg::getCombinerOpKind</a>(<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *combinerOp) {</div>
<div class="line"><a id="l00639" name="l00639"></a><span class="lineno">  639</span>  <span class="keyword">using </span>::mlir::vector::CombiningKind;</div>
<div class="line"><a id="l00640" name="l00640"></a><span class="lineno">  640</span> </div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span>  <span class="keywordflow">if</span> (!combinerOp)</div>
<div class="line"><a id="l00642" name="l00642"></a><span class="lineno">  642</span>    <span class="keywordflow">return</span> std::nullopt;</div>
<div class="line"><a id="l00643" name="l00643"></a><span class="lineno">  643</span>  <span class="keywordflow">return</span> <a class="code hl_class" href="classllvm_1_1TypeSwitch.html">llvm::TypeSwitch&lt;Operation *, std::optional&lt;CombiningKind&gt;</a>&gt;(combinerOp)</div>
<div class="line"><a id="l00644" name="l00644"></a><span class="lineno">  644</span>      .Case&lt;arith::AddIOp, arith::AddFOp&gt;(</div>
<div class="line"><a id="l00645" name="l00645"></a><span class="lineno">  645</span>          [&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::ADD; })</div>
<div class="line"><a id="l00646" name="l00646"></a><span class="lineno">  646</span>      .Case&lt;arith::AndIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::AND; })</div>
<div class="line"><a id="l00647" name="l00647"></a><span class="lineno">  647</span>      .Case&lt;arith::MaxSIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MAXSI; })</div>
<div class="line"><a id="l00648" name="l00648"></a><span class="lineno">  648</span>      .Case&lt;arith::MaxUIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MAXUI; })</div>
<div class="line"><a id="l00649" name="l00649"></a><span class="lineno">  649</span>      .Case&lt;arith::MaximumFOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MAXIMUMF; })</div>
<div class="line"><a id="l00650" name="l00650"></a><span class="lineno">  650</span>      .Case&lt;arith::MaxNumFOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MAXNUMF; })</div>
<div class="line"><a id="l00651" name="l00651"></a><span class="lineno">  651</span>      .Case&lt;arith::MinSIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MINSI; })</div>
<div class="line"><a id="l00652" name="l00652"></a><span class="lineno">  652</span>      .Case&lt;arith::MinUIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MINUI; })</div>
<div class="line"><a id="l00653" name="l00653"></a><span class="lineno">  653</span>      .Case&lt;arith::MinimumFOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MINIMUMF; })</div>
<div class="line"><a id="l00654" name="l00654"></a><span class="lineno">  654</span>      .Case&lt;arith::MinNumFOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MINNUMF; })</div>
<div class="line"><a id="l00655" name="l00655"></a><span class="lineno">  655</span>      .Case&lt;arith::MulIOp, arith::MulFOp&gt;(</div>
<div class="line"><a id="l00656" name="l00656"></a><span class="lineno">  656</span>          [&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::MUL; })</div>
<div class="line"><a id="l00657" name="l00657"></a><span class="lineno">  657</span>      .Case&lt;arith::OrIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::OR; })</div>
<div class="line"><a id="l00658" name="l00658"></a><span class="lineno">  658</span>      .Case&lt;arith::XOrIOp&gt;([&amp;](<span class="keyword">auto</span> op) { <span class="keywordflow">return</span> CombiningKind::XOR; })</div>
<div class="line"><a id="l00659" name="l00659"></a><span class="lineno">  659</span>      .Default(std::nullopt);</div>
<div class="line"><a id="l00660" name="l00660"></a><span class="lineno">  660</span>}</div>
</div>
<div class="line"><a id="l00661" name="l00661"></a><span class="lineno">  661</span><span class="comment"></span> </div>
<div class="line"><a id="l00662" name="l00662"></a><span class="lineno">  662</span><span class="comment">/// Check whether `outputOperand` is a reduction with a single combiner</span></div>
<div class="line"><a id="l00663" name="l00663"></a><span class="lineno">  663</span><span class="comment">/// operation. Return the combiner operation of the reduction. Return</span></div>
<div class="line"><a id="l00664" name="l00664"></a><span class="lineno">  664</span><span class="comment">/// nullptr otherwise. Multiple reduction operations would impose an</span></div>
<div class="line"><a id="l00665" name="l00665"></a><span class="lineno">  665</span><span class="comment">/// ordering between reduction dimensions and is currently unsupported in</span></div>
<div class="line"><a id="l00666" name="l00666"></a><span class="lineno">  666</span><span class="comment">/// Linalg. This limitation is motivated by the fact that e.g. min(max(X)) !=</span></div>
<div class="line"><a id="l00667" name="l00667"></a><span class="lineno">  667</span><span class="comment">/// max(min(X))</span></div>
<div class="line"><a id="l00668" name="l00668"></a><span class="lineno">  668</span><span class="comment">// TODO: use in LinalgOp verification, there is a circular dependency atm.</span></div>
<div class="foldopen" id="foldopen00669" data-start="{" data-end="}">
<div class="line"><a id="l00669" name="l00669"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a4c99d55a1274aa91b750b22a4a3c76e2">  669</a></span><span class="keyword">static</span> <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *<a class="code hl_function" href="Vectorization_8cpp.html#a4c99d55a1274aa91b750b22a4a3c76e2">matchLinalgReduction</a>(<a class="code hl_class" href="classmlir_1_1OpOperand.html">OpOperand</a> *outputOperand) {</div>
<div class="line"><a id="l00670" name="l00670"></a><span class="lineno">  670</span>  <span class="keyword">auto</span> linalgOp = cast&lt;LinalgOp&gt;(outputOperand-&gt;<a class="code hl_function" href="classmlir_1_1detail_1_1IROperandBase.html#a9ab8c68c85b92faa00c9df16a15ad1c0">getOwner</a>());</div>
<div class="line"><a id="l00671" name="l00671"></a><span class="lineno">  671</span>  <span class="keywordtype">unsigned</span> outputPos =</div>
<div class="line"><a id="l00672" name="l00672"></a><span class="lineno">  672</span>      outputOperand-&gt;<a class="code hl_function" href="classmlir_1_1OpOperand.html#a097f9026defd8afd19ab06b21aa11bdf">getOperandNumber</a>() - linalgOp.getNumDpsInputs();</div>
<div class="line"><a id="l00673" name="l00673"></a><span class="lineno">  673</span>  <span class="comment">// Only single combiner operations are supported for now.</span></div>
<div class="line"><a id="l00674" name="l00674"></a><span class="lineno">  674</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Operation *, 4&gt;</a> combinerOps;</div>
<div class="line"><a id="l00675" name="l00675"></a><span class="lineno">  675</span>  <span class="keywordflow">if</span> (!<a class="code hl_function" href="namespacemlir.html#a6bc751bc8f30d71ad4cb771c0fcc788b">matchReduction</a>(linalgOp.getRegionOutputArgs(), outputPos, combinerOps) ||</div>
<div class="line"><a id="l00676" name="l00676"></a><span class="lineno">  676</span>      combinerOps.size() != 1)</div>
<div class="line"><a id="l00677" name="l00677"></a><span class="lineno">  677</span>    <span class="keywordflow">return</span> <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l00678" name="l00678"></a><span class="lineno">  678</span> </div>
<div class="line"><a id="l00679" name="l00679"></a><span class="lineno">  679</span>  <span class="comment">// Return the combiner operation.</span></div>
<div class="line"><a id="l00680" name="l00680"></a><span class="lineno">  680</span>  <span class="keywordflow">return</span> combinerOps[0];</div>
<div class="line"><a id="l00681" name="l00681"></a><span class="lineno">  681</span>}</div>
</div>
<div class="line"><a id="l00682" name="l00682"></a><span class="lineno">  682</span><span class="comment"></span> </div>
<div class="line"><a id="l00683" name="l00683"></a><span class="lineno">  683</span><span class="comment">/// Broadcast `value` to a vector of `shape` if possible. Return value</span></div>
<div class="line"><a id="l00684" name="l00684"></a><span class="lineno">  684</span><span class="comment">/// otherwise.</span></div>
<div class="foldopen" id="foldopen00685" data-start="{" data-end="}">
<div class="line"><a id="l00685" name="l00685"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">  685</a></span><span class="keyword">static</span> <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> <a class="code hl_function" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(<a class="code hl_class" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;<a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a21ad0bd836b90d08f4cf640b4c298e7c">b</a>, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> value, <a class="code hl_class" href="classmlir_1_1Type.html">Type</a> dstType) {</div>
<div class="line"><a id="l00686" name="l00686"></a><span class="lineno">  686</span>  <span class="keyword">auto</span> dstVecType = dyn_cast&lt;VectorType&gt;(dstType);</div>
<div class="line"><a id="l00687" name="l00687"></a><span class="lineno">  687</span>  <span class="comment">// If no shape to broadcast to, just return `value`.</span></div>
<div class="line"><a id="l00688" name="l00688"></a><span class="lineno">  688</span>  <span class="keywordflow">if</span> (dstVecType.getRank() == 0)</div>
<div class="line"><a id="l00689" name="l00689"></a><span class="lineno">  689</span>    <span class="keywordflow">return</span> value;</div>
<div class="line"><a id="l00690" name="l00690"></a><span class="lineno">  690</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1vector.html#a5150a3f7aa4857a1863bd10fb551442a">vector::isBroadcastableTo</a>(value.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>(), dstVecType) !=</div>
<div class="line"><a id="l00691" name="l00691"></a><span class="lineno">  691</span>      <a class="code hl_enumvalue" href="namespacemlir_1_1vector.html#acfee45e655b185bd625e2f7994dc2c50a505a83f220c02df2f85c3810cd9ceb38">vector::BroadcastableToResult::Success</a>)</div>
<div class="line"><a id="l00692" name="l00692"></a><span class="lineno">  692</span>    <span class="keywordflow">return</span> value;</div>
<div class="line"><a id="l00693" name="l00693"></a><span class="lineno">  693</span>  <a class="code hl_class" href="classmlir_1_1Location.html">Location</a> loc = <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a21ad0bd836b90d08f4cf640b4c298e7c">b</a>.getInsertionPoint()-&gt;getLoc();</div>
<div class="line"><a id="l00694" name="l00694"></a><span class="lineno">  694</span>  <span class="keywordflow">return</span> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a21ad0bd836b90d08f4cf640b4c298e7c">b</a>.createOrFold&lt;vector::BroadcastOp&gt;(loc, dstVecType, value);</div>
<div class="line"><a id="l00695" name="l00695"></a><span class="lineno">  695</span>}</div>
</div>
<div class="line"><a id="l00696" name="l00696"></a><span class="lineno">  696</span><span class="comment"></span> </div>
<div class="line"><a id="l00697" name="l00697"></a><span class="lineno">  697</span><span class="comment">/// Create MultiDimReductionOp to compute the reduction for `reductionOp`. This</span></div>
<div class="line"><a id="l00698" name="l00698"></a><span class="lineno">  698</span><span class="comment">/// assumes that `reductionOp` has two operands and one of them is the reduction</span></div>
<div class="line"><a id="l00699" name="l00699"></a><span class="lineno">  699</span><span class="comment">/// initial value.buildMultiDimReduce</span></div>
<div class="line"><a id="l00700" name="l00700"></a><span class="lineno">  700</span><span class="comment">// Note: this is a true builder that notifies the OpBuilder listener.</span></div>
<div class="line"><a id="l00701" name="l00701"></a><span class="lineno">  701</span><span class="comment">// TODO: Consider moving as a static helper on the ReduceOp.</span></div>
<div class="foldopen" id="foldopen00702" data-start="{" data-end="}">
<div class="line"><a id="l00702" name="l00702"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#af936802591fc5ba398ba106887feac8f">  702</a></span><span class="keyword">static</span> <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *<a class="code hl_function" href="Vectorization_8cpp.html#af936802591fc5ba398ba106887feac8f">buildMultiDimReduce</a>(<a class="code hl_class" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;<a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a21ad0bd836b90d08f4cf640b4c298e7c">b</a>, <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *reduceOp,</div>
<div class="line"><a id="l00703" name="l00703"></a><span class="lineno">  703</span>                                      <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> valueToReduce, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> <a class="code hl_namespace" href="namespacemlir_1_1acc.html">acc</a>,</div>
<div class="line"><a id="l00704" name="l00704"></a><span class="lineno">  704</span>                                      <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;bool&gt;</a> dimsToMask) {</div>
<div class="line"><a id="l00705" name="l00705"></a><span class="lineno">  705</span>  <span class="keyword">auto</span> maybeKind = <a class="code hl_function" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp);</div>
<div class="line"><a id="l00706" name="l00706"></a><span class="lineno">  706</span>  assert(maybeKind &amp;&amp; <span class="stringliteral">&quot;Failed precondition: could not get reduction kind&quot;</span>);</div>
<div class="line"><a id="l00707" name="l00707"></a><span class="lineno">  707</span>  <span class="keywordflow">return</span> vector::MultiDimReductionOp::create(</div>
<div class="line"><a id="l00708" name="l00708"></a><span class="lineno">  708</span>      <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a21ad0bd836b90d08f4cf640b4c298e7c">b</a>, reduceOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a6c0b8ce5ff714a34f0192f3aa60dc7ea">getLoc</a>(), valueToReduce, <a class="code hl_namespace" href="namespacemlir_1_1acc.html">acc</a>, dimsToMask, *maybeKind);</div>
<div class="line"><a id="l00709" name="l00709"></a><span class="lineno">  709</span>}</div>
</div>
<div class="line"><a id="l00710" name="l00710"></a><span class="lineno">  710</span> </div>
<div class="foldopen" id="foldopen00711" data-start="{" data-end="}">
<div class="line"><a id="l00711" name="l00711"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a129f4ae5f0a8071a3f98c8f73ee729f9">  711</a></span><span class="keyword">static</span> <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> <a class="code hl_function" href="Vectorization_8cpp.html#a129f4ae5f0a8071a3f98c8f73ee729f9">getDimsToReduce</a>(LinalgOp linalgOp) {</div>
<div class="line"><a id="l00712" name="l00712"></a><span class="lineno">  712</span>  <span class="keywordflow">return</span> llvm::to_vector(</div>
<div class="line"><a id="l00713" name="l00713"></a><span class="lineno">  713</span>      llvm::map_range(linalgOp.getIteratorTypesArray(), <a class="code hl_function" href="namespacemlir_1_1linalg.html#a5377722f56e02541897c157260bd1eee">isReductionIterator</a>));</div>
<div class="line"><a id="l00714" name="l00714"></a><span class="lineno">  714</span>}</div>
</div>
<div class="line"><a id="l00715" name="l00715"></a><span class="lineno">  715</span><span class="comment"></span> </div>
<div class="line"><a id="l00716" name="l00716"></a><span class="lineno">  716</span><span class="comment">/// Check if `op` is a linalg.reduce or a linalg.generic that has at least one</span></div>
<div class="line"><a id="l00717" name="l00717"></a><span class="lineno">  717</span><span class="comment">/// reduction iterator.</span></div>
<div class="foldopen" id="foldopen00718" data-start="{" data-end="}">
<div class="line"><a id="l00718" name="l00718"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">  718</a></span><span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code hl_function" href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">hasReductionIterator</a>(LinalgOp &amp;op) {</div>
<div class="line"><a id="l00719" name="l00719"></a><span class="lineno">  719</span>  <span class="keywordflow">return</span> isa&lt;linalg::ReduceOp&gt;(op) ||</div>
<div class="line"><a id="l00720" name="l00720"></a><span class="lineno">  720</span>         (isa&lt;linalg::GenericOp&gt;(op) &amp;&amp;</div>
<div class="line"><a id="l00721" name="l00721"></a><span class="lineno">  721</span>          llvm::any_of(op.getIteratorTypesArray(), <a class="code hl_function" href="namespacemlir_1_1linalg.html#a5377722f56e02541897c157260bd1eee">isReductionIterator</a>));</div>
<div class="line"><a id="l00722" name="l00722"></a><span class="lineno">  722</span>}</div>
</div>
<div class="line"><a id="l00723" name="l00723"></a><span class="lineno">  723</span><span class="comment"></span> </div>
<div class="line"><a id="l00724" name="l00724"></a><span class="lineno">  724</span><span class="comment">/// Build a vector.transfer_write of `value` into `outputOperand` at indices set</span></div>
<div class="line"><a id="l00725" name="l00725"></a><span class="lineno">  725</span><span class="comment">/// to all `0`; where `outputOperand` is an output operand of the LinalgOp</span></div>
<div class="line"><a id="l00726" name="l00726"></a><span class="lineno">  726</span><span class="comment">/// currently being vectorized. If `dest` has null rank, build an memref.store.</span></div>
<div class="line"><a id="l00727" name="l00727"></a><span class="lineno">  727</span><span class="comment">/// Return the produced value or null if no value is produced.</span></div>
<div class="line"><a id="l00728" name="l00728"></a><span class="lineno">  728</span><span class="comment">// Note: this is a true builder that notifies the OpBuilder listener.</span></div>
<div class="line"><a id="l00729" name="l00729"></a><span class="lineno">  729</span><span class="comment">// TODO: Consider moving as a static helper on the ReduceOp.</span></div>
<div class="foldopen" id="foldopen00730" data-start="{" data-end="}">
<div class="line"><a id="l00730" name="l00730"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a4ffeefd6b3cba67afe11ecdc2b48fcef">  730</a></span><span class="keyword">static</span> <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> <a class="code hl_function" href="Vectorization_8cpp.html#a4ffeefd6b3cba67afe11ecdc2b48fcef">buildVectorWrite</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> value,</div>
<div class="line"><a id="l00731" name="l00731"></a><span class="lineno">  731</span>                              <a class="code hl_class" href="classmlir_1_1OpOperand.html">OpOperand</a> *outputOperand,</div>
<div class="line"><a id="l00732" name="l00732"></a><span class="lineno">  732</span>                              VectorizationState &amp;state) {</div>
<div class="line"><a id="l00733" name="l00733"></a><span class="lineno">  733</span>  <a class="code hl_class" href="classmlir_1_1Location.html">Location</a> loc = value.<a class="code hl_function" href="classmlir_1_1Value.html#ae9df8c75072dbaab98cd4b7cd82b6ebc">getLoc</a>();</div>
<div class="line"><a id="l00734" name="l00734"></a><span class="lineno">  734</span>  <span class="keyword">auto</span> linalgOp = cast&lt;LinalgOp&gt;(outputOperand-&gt;<a class="code hl_function" href="classmlir_1_1detail_1_1IROperandBase.html#a9ab8c68c85b92faa00c9df16a15ad1c0">getOwner</a>());</div>
<div class="line"><a id="l00735" name="l00735"></a><span class="lineno">  735</span>  <a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> opOperandMap = linalgOp.getMatchingIndexingMap(outputOperand);</div>
<div class="line"><a id="l00736" name="l00736"></a><span class="lineno">  736</span> </div>
<div class="line"><a id="l00737" name="l00737"></a><span class="lineno">  737</span>  <span class="comment">// Compute the vector type of the value to store. This type should be an</span></div>
<div class="line"><a id="l00738" name="l00738"></a><span class="lineno">  738</span>  <span class="comment">// identity or projection of the canonical vector type without any permutation</span></div>
<div class="line"><a id="l00739" name="l00739"></a><span class="lineno">  739</span>  <span class="comment">// applied, given that any permutation in a transfer write happens as part of</span></div>
<div class="line"><a id="l00740" name="l00740"></a><span class="lineno">  740</span>  <span class="comment">// the write itself.</span></div>
<div class="line"><a id="l00741" name="l00741"></a><span class="lineno">  741</span>  <a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> vectorTypeMap = <a class="code hl_function" href="classmlir_1_1AffineMap.html#ac64464574634cca5ffcd023227260414">AffineMap::getFilteredIdentityMap</a>(</div>
<div class="line"><a id="l00742" name="l00742"></a><span class="lineno">  742</span>      opOperandMap.<a class="code hl_function" href="classmlir_1_1AffineMap.html#a07ce6ee55edc21c008a3bf8d10a2d726">getContext</a>(), opOperandMap.<a class="code hl_function" href="classmlir_1_1AffineMap.html#aa821f07143bcad97d6df532c232129a3">getNumInputs</a>(),</div>
<div class="line"><a id="l00743" name="l00743"></a><span class="lineno">  743</span>      [&amp;](<a class="code hl_class" href="classmlir_1_1AffineDimExpr.html">AffineDimExpr</a> dimExpr) -&gt; <span class="keywordtype">bool</span> {</div>
<div class="line"><a id="l00744" name="l00744"></a><span class="lineno">  744</span>        return llvm::is_contained(opOperandMap.getResults(), dimExpr);</div>
<div class="line"><a id="l00745" name="l00745"></a><span class="lineno">  745</span>      });</div>
<div class="line"><a id="l00746" name="l00746"></a><span class="lineno">  746</span>  <span class="keyword">auto</span> vectorType = state.getCanonicalVecType(</div>
<div class="line"><a id="l00747" name="l00747"></a><span class="lineno">  747</span>      <a class="code hl_function" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(outputOperand-&gt;<a class="code hl_function" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>().<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()), vectorTypeMap);</div>
<div class="line"><a id="l00748" name="l00748"></a><span class="lineno">  748</span> </div>
<div class="line"><a id="l00749" name="l00749"></a><span class="lineno">  749</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>(linalgOp.getRank(outputOperand),</div>
<div class="line"><a id="l00750" name="l00750"></a><span class="lineno">  750</span>                             <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0));</div>
<div class="line"><a id="l00751" name="l00751"></a><span class="lineno">  751</span> </div>
<div class="line"><a id="l00752" name="l00752"></a><span class="lineno">  752</span>  <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *write;</div>
<div class="line"><a id="l00753" name="l00753"></a><span class="lineno">  753</span>  <span class="keywordflow">if</span> (vectorType.getRank() &gt; 0) {</div>
<div class="line"><a id="l00754" name="l00754"></a><span class="lineno">  754</span>    <a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> writeMap = <a class="code hl_function" href="namespacemlir.html#a52b322818d83a2256d4e4391acbf78a2">inversePermutation</a>(<a class="code hl_function" href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">reindexIndexingMap</a>(opOperandMap));</div>
<div class="line"><a id="l00755" name="l00755"></a><span class="lineno">  755</span>    value = <a class="code hl_function" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(rewriter, value, vectorType);</div>
<div class="line"><a id="l00756" name="l00756"></a><span class="lineno">  756</span>    assert(value.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>() == vectorType &amp;&amp; <span class="stringliteral">&quot;Incorrect type&quot;</span>);</div>
<div class="line"><a id="l00757" name="l00757"></a><span class="lineno">  757</span>    write = vector::TransferWriteOp::create(</div>
<div class="line"><a id="l00758" name="l00758"></a><span class="lineno">  758</span>        rewriter, loc, value, outputOperand-&gt;<a class="code hl_function" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>(), <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>, writeMap);</div>
<div class="line"><a id="l00759" name="l00759"></a><span class="lineno">  759</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00760" name="l00760"></a><span class="lineno">  760</span>    <span class="comment">// 0-d case is still special: do not invert the reindexing writeMap.</span></div>
<div class="line"><a id="l00761" name="l00761"></a><span class="lineno">  761</span>    <span class="keywordflow">if</span> (!isa&lt;VectorType&gt;(value.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()))</div>
<div class="line"><a id="l00762" name="l00762"></a><span class="lineno">  762</span>      value = vector::BroadcastOp::create(rewriter, loc, vectorType, value);</div>
<div class="line"><a id="l00763" name="l00763"></a><span class="lineno">  763</span>    assert(value.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>() == vectorType &amp;&amp; <span class="stringliteral">&quot;Incorrect type&quot;</span>);</div>
<div class="line"><a id="l00764" name="l00764"></a><span class="lineno">  764</span>    write = vector::TransferWriteOp::create(rewriter, loc, value,</div>
<div class="line"><a id="l00765" name="l00765"></a><span class="lineno">  765</span>                                            outputOperand-&gt;<a class="code hl_function" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>(), <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>);</div>
<div class="line"><a id="l00766" name="l00766"></a><span class="lineno">  766</span>  }</div>
<div class="line"><a id="l00767" name="l00767"></a><span class="lineno">  767</span> </div>
<div class="line"><a id="l00768" name="l00768"></a><span class="lineno">  768</span>  write = state.maskOperation(rewriter, write, linalgOp, opOperandMap);</div>
<div class="line"><a id="l00769" name="l00769"></a><span class="lineno">  769</span> </div>
<div class="line"><a id="l00770" name="l00770"></a><span class="lineno">  770</span>  <span class="comment">// If masked, set in-bounds to true. Masking guarantees that the access will</span></div>
<div class="line"><a id="l00771" name="l00771"></a><span class="lineno">  771</span>  <span class="comment">// be in-bounds.</span></div>
<div class="line"><a id="l00772" name="l00772"></a><span class="lineno">  772</span>  <span class="keywordflow">if</span> (<span class="keyword">auto</span> maskOp = dyn_cast&lt;vector::MaskingOpInterface&gt;(write)) {</div>
<div class="line"><a id="l00773" name="l00773"></a><span class="lineno">  773</span>    <span class="keyword">auto</span> maskedWriteOp = cast&lt;vector::TransferWriteOp&gt;(maskOp.getMaskableOp());</div>
<div class="line"><a id="l00774" name="l00774"></a><span class="lineno">  774</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(maskedWriteOp.getVectorType().getRank(), <span class="keyword">true</span>);</div>
<div class="line"><a id="l00775" name="l00775"></a><span class="lineno">  775</span>    maskedWriteOp.setInBoundsAttr(rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a id="l00776" name="l00776"></a><span class="lineno">  776</span>  }</div>
<div class="line"><a id="l00777" name="l00777"></a><span class="lineno">  777</span> </div>
<div class="line"><a id="l00778" name="l00778"></a><span class="lineno">  778</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;vectorized op: &quot;</span> &lt;&lt; *write;</div>
<div class="line"><a id="l00779" name="l00779"></a><span class="lineno">  779</span>  <span class="keywordflow">if</span> (!write-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>().empty())</div>
<div class="line"><a id="l00780" name="l00780"></a><span class="lineno">  780</span>    <span class="keywordflow">return</span> write-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0);</div>
<div class="line"><a id="l00781" name="l00781"></a><span class="lineno">  781</span>  <span class="keywordflow">return</span> <a class="code hl_class" href="classmlir_1_1Value.html">Value</a>();</div>
<div class="line"><a id="l00782" name="l00782"></a><span class="lineno">  782</span>}</div>
</div>
<div class="line"><a id="l00783" name="l00783"></a><span class="lineno">  783</span> </div>
<div class="line"><a id="l00784" name="l00784"></a><span class="lineno">  784</span><span class="comment">// Custom vectorization precondition function type. This is intented to be used</span></div>
<div class="line"><a id="l00785" name="l00785"></a><span class="lineno">  785</span><span class="comment">// with CustomVectorizationHook. Returns success if the corresponding custom</span></div>
<div class="line"><a id="l00786" name="l00786"></a><span class="lineno">  786</span><span class="comment">// hook can vectorize the op.</span></div>
<div class="line"><a id="l00787" name="l00787"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a765387385c36b8245aca7e886c0e98fb">  787</a></span><span class="keyword">using </span><a class="code hl_typedef" href="Vectorization_8cpp.html#a765387385c36b8245aca7e886c0e98fb">CustomVectorizationPrecondition</a> =</div>
<div class="line"><a id="l00788" name="l00788"></a><span class="lineno">  788</span>    std::function&lt;LogicalResult(<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *, <span class="keywordtype">bool</span>)&gt;;</div>
<div class="line"><a id="l00789" name="l00789"></a><span class="lineno">  789</span> </div>
<div class="line"><a id="l00790" name="l00790"></a><span class="lineno">  790</span><span class="comment">// Custom vectorization function type. Produce a vector form of Operation*</span></div>
<div class="line"><a id="l00791" name="l00791"></a><span class="lineno">  791</span><span class="comment">// assuming all its vectorized operands are already in the IRMapping.</span></div>
<div class="line"><a id="l00792" name="l00792"></a><span class="lineno">  792</span><span class="comment">// Return nullptr if the Operation cannot be vectorized.</span></div>
<div class="line"><a id="l00793" name="l00793"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ac9d5de1ac70bcbcc2f773e554a39bd1e">  793</a></span><span class="keyword">using </span><a class="code hl_typedef" href="Vectorization_8cpp.html#ac9d5de1ac70bcbcc2f773e554a39bd1e">CustomVectorizationHook</a> =</div>
<div class="line"><a id="l00794" name="l00794"></a><span class="lineno">  794</span>    std::function&lt;<a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>(<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *, <span class="keyword">const</span> <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;)&gt;;</div>
<div class="line"><a id="l00795" name="l00795"></a><span class="lineno">  795</span><span class="comment"></span> </div>
<div class="line"><a id="l00796" name="l00796"></a><span class="lineno">  796</span><span class="comment">/// Helper function to vectorize the terminator of a `linalgOp`. New result</span></div>
<div class="line"><a id="l00797" name="l00797"></a><span class="lineno">  797</span><span class="comment">/// vector values are appended to `newResults`. Return</span></div>
<div class="line"><a id="l00798" name="l00798"></a><span class="lineno">  798</span><span class="comment">/// VectorizationHookStatus::NoReplace to signal the vectorization algorithm</span></div>
<div class="line"><a id="l00799" name="l00799"></a><span class="lineno">  799</span><span class="comment">/// that it should not try to map produced operations and instead return the</span></div>
<div class="line"><a id="l00800" name="l00800"></a><span class="lineno">  800</span><span class="comment">/// results using the `newResults` vector making them available to the</span></div>
<div class="line"><a id="l00801" name="l00801"></a><span class="lineno">  801</span><span class="comment">/// vectorization algorithm for RAUW. This function is meant to be used as a</span></div>
<div class="line"><a id="l00802" name="l00802"></a><span class="lineno">  802</span><span class="comment">/// CustomVectorizationHook.</span></div>
<div class="line"><a id="l00803" name="l00803"></a><span class="lineno">  803</span><span class="keyword">static</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a></div>
<div class="foldopen" id="foldopen00804" data-start="{" data-end="}">
<div class="line"><a id="l00804" name="l00804"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#af85a26f7c1860388d0e83d22745a27aa">  804</a></span><a class="code hl_function" href="Vectorization_8cpp.html#af85a26f7c1860388d0e83d22745a27aa">vectorizeLinalgYield</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op,</div>
<div class="line"><a id="l00805" name="l00805"></a><span class="lineno">  805</span>                     <span class="keyword">const</span> <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm, VectorizationState &amp;state,</div>
<div class="line"><a id="l00806" name="l00806"></a><span class="lineno">  806</span>                     LinalgOp linalgOp, <a class="code hl_class" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults) {</div>
<div class="line"><a id="l00807" name="l00807"></a><span class="lineno">  807</span>  <span class="keyword">auto</span> yieldOp = dyn_cast&lt;linalg::YieldOp&gt;(op);</div>
<div class="line"><a id="l00808" name="l00808"></a><span class="lineno">  808</span>  <span class="keywordflow">if</span> (!yieldOp)</div>
<div class="line"><a id="l00809" name="l00809"></a><span class="lineno">  809</span>    <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a id="l00810" name="l00810"></a><span class="lineno">  810</span>  <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;output : llvm::enumerate(yieldOp.getValues())) {</div>
<div class="line"><a id="l00811" name="l00811"></a><span class="lineno">  811</span>    <span class="comment">// TODO: Scan for an opportunity for reuse.</span></div>
<div class="line"><a id="l00812" name="l00812"></a><span class="lineno">  812</span>    <span class="comment">// TODO: use a map.</span></div>
<div class="line"><a id="l00813" name="l00813"></a><span class="lineno">  813</span>    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> vectorValue = bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(output.value());</div>
<div class="line"><a id="l00814" name="l00814"></a><span class="lineno">  814</span>    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> newResult =</div>
<div class="line"><a id="l00815" name="l00815"></a><span class="lineno">  815</span>        <a class="code hl_function" href="Vectorization_8cpp.html#a4ffeefd6b3cba67afe11ecdc2b48fcef">buildVectorWrite</a>(rewriter, vectorValue,</div>
<div class="line"><a id="l00816" name="l00816"></a><span class="lineno">  816</span>                         linalgOp.getDpsInitOperand(output.index()), state);</div>
<div class="line"><a id="l00817" name="l00817"></a><span class="lineno">  817</span>    <span class="keywordflow">if</span> (newResult)</div>
<div class="line"><a id="l00818" name="l00818"></a><span class="lineno">  818</span>      newResults.push_back(newResult);</div>
<div class="line"><a id="l00819" name="l00819"></a><span class="lineno">  819</span>  }</div>
<div class="line"><a id="l00820" name="l00820"></a><span class="lineno">  820</span> </div>
<div class="line"><a id="l00821" name="l00821"></a><span class="lineno">  821</span>  <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f">VectorizationHookStatus::NoReplace</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a id="l00822" name="l00822"></a><span class="lineno">  822</span>}</div>
</div>
<div class="line"><a id="l00823" name="l00823"></a><span class="lineno">  823</span><span class="comment"></span> </div>
<div class="line"><a id="l00824" name="l00824"></a><span class="lineno">  824</span><span class="comment">/// Helper function to vectorize the index operations of a `linalgOp`. Return</span></div>
<div class="line"><a id="l00825" name="l00825"></a><span class="lineno">  825</span><span class="comment">/// VectorizationHookStatus::NewOp to signal the vectorization algorithm that it</span></div>
<div class="line"><a id="l00826" name="l00826"></a><span class="lineno">  826</span><span class="comment">/// should map the produced operations. This function is meant to be used as a</span></div>
<div class="line"><a id="l00827" name="l00827"></a><span class="lineno">  827</span><span class="comment">/// CustomVectorizationHook.</span></div>
<div class="foldopen" id="foldopen00828" data-start="{" data-end="}">
<div class="line"><a id="l00828" name="l00828"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a280bd1ab81d418cd32713eeb0a2dfffd">  828</a></span><span class="keyword">static</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a> <a class="code hl_function" href="Vectorization_8cpp.html#a280bd1ab81d418cd32713eeb0a2dfffd">vectorizeLinalgIndex</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a id="l00829" name="l00829"></a><span class="lineno">  829</span>                                                    VectorizationState &amp;state,</div>
<div class="line"><a id="l00830" name="l00830"></a><span class="lineno">  830</span>                                                    <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op,</div>
<div class="line"><a id="l00831" name="l00831"></a><span class="lineno">  831</span>                                                    LinalgOp linalgOp) {</div>
<div class="line"><a id="l00832" name="l00832"></a><span class="lineno">  832</span>  IndexOp indexOp = dyn_cast&lt;linalg::IndexOp&gt;(op);</div>
<div class="line"><a id="l00833" name="l00833"></a><span class="lineno">  833</span>  <span class="keywordflow">if</span> (!indexOp)</div>
<div class="line"><a id="l00834" name="l00834"></a><span class="lineno">  834</span>    <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a id="l00835" name="l00835"></a><span class="lineno">  835</span>  <span class="keyword">auto</span> loc = indexOp.getLoc();</div>
<div class="line"><a id="l00836" name="l00836"></a><span class="lineno">  836</span>  <span class="comment">// Compute the static loop sizes of the index op.</span></div>
<div class="line"><a id="l00837" name="l00837"></a><span class="lineno">  837</span>  <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> targetShape = state.getCanonicalVecShape();</div>
<div class="line"><a id="l00838" name="l00838"></a><span class="lineno">  838</span>  <span class="keyword">auto</span> dim = indexOp.getDim();</div>
<div class="line"><a id="l00839" name="l00839"></a><span class="lineno">  839</span>  <span class="comment">// Compute a one-dimensional index vector for the index op dimension.</span></div>
<div class="line"><a id="l00840" name="l00840"></a><span class="lineno">  840</span>  <span class="keyword">auto</span> indexVectorType =</div>
<div class="line"><a id="l00841" name="l00841"></a><span class="lineno">  841</span>      VectorType::get({targetShape[dim]}, rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">getIndexType</a>(),</div>
<div class="line"><a id="l00842" name="l00842"></a><span class="lineno">  842</span>                      state.getScalableVecDims()[dim]);</div>
<div class="line"><a id="l00843" name="l00843"></a><span class="lineno">  843</span>  <span class="keyword">auto</span> indexSteps = vector::StepOp::create(rewriter, loc, indexVectorType);</div>
<div class="line"><a id="l00844" name="l00844"></a><span class="lineno">  844</span>  <span class="comment">// Return the one-dimensional index vector if it lives in the trailing</span></div>
<div class="line"><a id="l00845" name="l00845"></a><span class="lineno">  845</span>  <span class="comment">// dimension of the iteration space since the vectorization algorithm in this</span></div>
<div class="line"><a id="l00846" name="l00846"></a><span class="lineno">  846</span>  <span class="comment">// case can handle the broadcast.</span></div>
<div class="line"><a id="l00847" name="l00847"></a><span class="lineno">  847</span>  <span class="keywordflow">if</span> (dim == targetShape.size() - 1)</div>
<div class="line"><a id="l00848" name="l00848"></a><span class="lineno">  848</span>    <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>, indexSteps};</div>
<div class="line"><a id="l00849" name="l00849"></a><span class="lineno">  849</span>  <span class="comment">// Otherwise permute the targetShape to move the index dimension last,</span></div>
<div class="line"><a id="l00850" name="l00850"></a><span class="lineno">  850</span>  <span class="comment">// broadcast the one-dimensional index vector to the permuted shape, and</span></div>
<div class="line"><a id="l00851" name="l00851"></a><span class="lineno">  851</span>  <span class="comment">// finally transpose the broadcasted index vector to undo the permutation.</span></div>
<div class="line"><a id="l00852" name="l00852"></a><span class="lineno">  852</span>  <span class="keyword">auto</span> permPattern =</div>
<div class="line"><a id="l00853" name="l00853"></a><span class="lineno">  853</span>      llvm::to_vector(llvm::seq&lt;unsigned&gt;(0, targetShape.size()));</div>
<div class="line"><a id="l00854" name="l00854"></a><span class="lineno">  854</span>  std::swap(permPattern[dim], permPattern.back());</div>
<div class="line"><a id="l00855" name="l00855"></a><span class="lineno">  855</span>  <span class="keyword">auto</span> permMap =</div>
<div class="line"><a id="l00856" name="l00856"></a><span class="lineno">  856</span>      <a class="code hl_function" href="classmlir_1_1AffineMap.html#acd08312b1039c20f008d2f6785c47816">AffineMap::getPermutationMap</a>(permPattern, linalgOp.getContext());</div>
<div class="line"><a id="l00857" name="l00857"></a><span class="lineno">  857</span> </div>
<div class="line"><a id="l00858" name="l00858"></a><span class="lineno">  858</span>  <span class="keyword">auto</span> broadCastOp = vector::BroadcastOp::create(</div>
<div class="line"><a id="l00859" name="l00859"></a><span class="lineno">  859</span>      rewriter, loc,</div>
<div class="line"><a id="l00860" name="l00860"></a><span class="lineno">  860</span>      state.getCanonicalVecType(rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">getIndexType</a>(), permMap), indexSteps);</div>
<div class="line"><a id="l00861" name="l00861"></a><span class="lineno">  861</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> transposition =</div>
<div class="line"><a id="l00862" name="l00862"></a><span class="lineno">  862</span>      llvm::to_vector&lt;16&gt;(llvm::seq&lt;int64_t&gt;(0, linalgOp.getNumLoops()));</div>
<div class="line"><a id="l00863" name="l00863"></a><span class="lineno">  863</span>  std::swap(transposition.back(), transposition[dim]);</div>
<div class="line"><a id="l00864" name="l00864"></a><span class="lineno">  864</span>  <span class="keyword">auto</span> transposeOp =</div>
<div class="line"><a id="l00865" name="l00865"></a><span class="lineno">  865</span>      vector::TransposeOp::create(rewriter, loc, broadCastOp, transposition);</div>
<div class="line"><a id="l00866" name="l00866"></a><span class="lineno">  866</span>  <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>, transposeOp};</div>
<div class="line"><a id="l00867" name="l00867"></a><span class="lineno">  867</span>}</div>
</div>
<div class="line"><a id="l00868" name="l00868"></a><span class="lineno">  868</span><span class="comment"></span> </div>
<div class="line"><a id="l00869" name="l00869"></a><span class="lineno">  869</span><span class="comment">/// Helper function to check if the tensor.extract can be vectorized by the</span></div>
<div class="line"><a id="l00870" name="l00870"></a><span class="lineno">  870</span><span class="comment">/// custom hook vectorizeTensorExtract.</span></div>
<div class="line"><a id="l00871" name="l00871"></a><span class="lineno">  871</span><span class="keyword">static</span> LogicalResult</div>
<div class="foldopen" id="foldopen00872" data-start="{" data-end="}">
<div class="line"><a id="l00872" name="l00872"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ad09df73d48432e3de8291c7076164ba7">  872</a></span><a class="code hl_function" href="Vectorization_8cpp.html#ad09df73d48432e3de8291c7076164ba7">tensorExtractVectorizationPrecondition</a>(<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keywordtype">bool</span> vectorizeNDExtract) {</div>
<div class="line"><a id="l00873" name="l00873"></a><span class="lineno">  873</span>  tensor::ExtractOp extractOp = dyn_cast&lt;tensor::ExtractOp&gt;(op);</div>
<div class="line"><a id="l00874" name="l00874"></a><span class="lineno">  874</span>  <span class="keywordflow">if</span> (!extractOp)</div>
<div class="line"><a id="l00875" name="l00875"></a><span class="lineno">  875</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l00876" name="l00876"></a><span class="lineno">  876</span> </div>
<div class="line"><a id="l00877" name="l00877"></a><span class="lineno">  877</span>  <span class="keywordflow">if</span> (extractOp.getIndices().size() != 1 &amp;&amp; !vectorizeNDExtract)</div>
<div class="line"><a id="l00878" name="l00878"></a><span class="lineno">  878</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l00879" name="l00879"></a><span class="lineno">  879</span> </div>
<div class="line"><a id="l00880" name="l00880"></a><span class="lineno">  880</span>  <span class="comment">// Check the index type, but only for non 0-d tensors (for which we do need</span></div>
<div class="line"><a id="l00881" name="l00881"></a><span class="lineno">  881</span>  <span class="comment">// access indices).</span></div>
<div class="line"><a id="l00882" name="l00882"></a><span class="lineno">  882</span>  <span class="keywordflow">if</span> (not extractOp.getIndices().empty()) {</div>
<div class="line"><a id="l00883" name="l00883"></a><span class="lineno">  883</span>    <span class="keywordflow">if</span> (!VectorType::isValidElementType(extractOp.getIndices()[0].getType()))</div>
<div class="line"><a id="l00884" name="l00884"></a><span class="lineno">  884</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l00885" name="l00885"></a><span class="lineno">  885</span>  }</div>
<div class="line"><a id="l00886" name="l00886"></a><span class="lineno">  886</span> </div>
<div class="line"><a id="l00887" name="l00887"></a><span class="lineno">  887</span>  <span class="keywordflow">if</span> (!llvm::all_of(extractOp-&gt;getResultTypes(),</div>
<div class="line"><a id="l00888" name="l00888"></a><span class="lineno">  888</span>                    VectorType::isValidElementType)) {</div>
<div class="line"><a id="l00889" name="l00889"></a><span class="lineno">  889</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l00890" name="l00890"></a><span class="lineno">  890</span>  }</div>
<div class="line"><a id="l00891" name="l00891"></a><span class="lineno">  891</span> </div>
<div class="line"><a id="l00892" name="l00892"></a><span class="lineno">  892</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l00893" name="l00893"></a><span class="lineno">  893</span>}</div>
</div>
<div class="line"><a id="l00894" name="l00894"></a><span class="lineno">  894</span><span class="comment"></span> </div>
<div class="line"><a id="l00895" name="l00895"></a><span class="lineno">  895</span><span class="comment">/// Calculates the offsets (`$index_vec`) for `vector.gather` operations</span></div>
<div class="line"><a id="l00896" name="l00896"></a><span class="lineno">  896</span><span class="comment">/// generated from `tensor.extract`. The offset is calculated as follows</span></div>
<div class="line"><a id="l00897" name="l00897"></a><span class="lineno">  897</span><span class="comment">/// (example using scalar values):</span></div>
<div class="line"><a id="l00898" name="l00898"></a><span class="lineno">  898</span><span class="comment">///</span></div>
<div class="line"><a id="l00899" name="l00899"></a><span class="lineno">  899</span><span class="comment">///    offset = extractOp.indices[0]</span></div>
<div class="line"><a id="l00900" name="l00900"></a><span class="lineno">  900</span><span class="comment">///    for (i = 1; i &lt; numIndices; i++)</span></div>
<div class="line"><a id="l00901" name="l00901"></a><span class="lineno">  901</span><span class="comment">///      offset = extractOp.dimSize[i] * offset + extractOp.indices[i];</span></div>
<div class="line"><a id="l00902" name="l00902"></a><span class="lineno">  902</span><span class="comment">///</span></div>
<div class="line"><a id="l00903" name="l00903"></a><span class="lineno">  903</span><span class="comment">/// For tensor&lt;45 x 80 x 15 x f32&gt; and index [1, 2, 3], this leads to:</span></div>
<div class="line"><a id="l00904" name="l00904"></a><span class="lineno">  904</span><span class="comment">///  offset = ( ( 1 ) * 80 +  2 ) * 15  + 3</span></div>
<div class="foldopen" id="foldopen00905" data-start="{" data-end="}">
<div class="line"><a id="l00905" name="l00905"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#ae4411a5d89520c86474035493a7da7c1">  905</a></span><span class="keyword">static</span> <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> <a class="code hl_function" href="Vectorization_8cpp.html#ae4411a5d89520c86474035493a7da7c1">calculateGatherOffset</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter,</div>
<div class="line"><a id="l00906" name="l00906"></a><span class="lineno">  906</span>                                   VectorizationState &amp;state,</div>
<div class="line"><a id="l00907" name="l00907"></a><span class="lineno">  907</span>                                   tensor::ExtractOp extractOp,</div>
<div class="line"><a id="l00908" name="l00908"></a><span class="lineno">  908</span>                                   <span class="keyword">const</span> <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) {</div>
<div class="line"><a id="l00909" name="l00909"></a><span class="lineno">  909</span>  <span class="comment">// The vector of indices for GatherOp should be shaped as the output vector.</span></div>
<div class="line"><a id="l00910" name="l00910"></a><span class="lineno">  910</span>  <span class="keyword">auto</span> indexVecType = state.getCanonicalVecType(rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">getIndexType</a>());</div>
<div class="line"><a id="l00911" name="l00911"></a><span class="lineno">  911</span>  <span class="keyword">auto</span> loc = extractOp.getLoc();</div>
<div class="line"><a id="l00912" name="l00912"></a><span class="lineno">  912</span> </div>
<div class="line"><a id="l00913" name="l00913"></a><span class="lineno">  913</span>  <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> offset = <a class="code hl_function" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(</div>
<div class="line"><a id="l00914" name="l00914"></a><span class="lineno">  914</span>      rewriter, bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(extractOp.getIndices()[0]), indexVecType);</div>
<div class="line"><a id="l00915" name="l00915"></a><span class="lineno">  915</span> </div>
<div class="line"><a id="l00916" name="l00916"></a><span class="lineno">  916</span>  <span class="keyword">const</span> <span class="keywordtype">size_t</span> numIndices = extractOp.getIndices().size();</div>
<div class="line"><a id="l00917" name="l00917"></a><span class="lineno">  917</span>  <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 1; i &lt; numIndices; i++) {</div>
<div class="line"><a id="l00918" name="l00918"></a><span class="lineno">  918</span>    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> dimIdx = <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, i);</div>
<div class="line"><a id="l00919" name="l00919"></a><span class="lineno">  919</span> </div>
<div class="line"><a id="l00920" name="l00920"></a><span class="lineno">  920</span>    <span class="keyword">auto</span> dimSize = <a class="code hl_function" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(</div>
<div class="line"><a id="l00921" name="l00921"></a><span class="lineno">  921</span>        rewriter,</div>
<div class="line"><a id="l00922" name="l00922"></a><span class="lineno">  922</span>        tensor::DimOp::create(rewriter, loc, extractOp.getTensor(), dimIdx),</div>
<div class="line"><a id="l00923" name="l00923"></a><span class="lineno">  923</span>        indexVecType);</div>
<div class="line"><a id="l00924" name="l00924"></a><span class="lineno">  924</span> </div>
<div class="line"><a id="l00925" name="l00925"></a><span class="lineno">  925</span>    offset = arith::MulIOp::create(rewriter, loc, offset, dimSize);</div>
<div class="line"><a id="l00926" name="l00926"></a><span class="lineno">  926</span> </div>
<div class="line"><a id="l00927" name="l00927"></a><span class="lineno">  927</span>    <span class="keyword">auto</span> extractOpIndex = <a class="code hl_function" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(</div>
<div class="line"><a id="l00928" name="l00928"></a><span class="lineno">  928</span>        rewriter, bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(extractOp.getIndices()[i]), indexVecType);</div>
<div class="line"><a id="l00929" name="l00929"></a><span class="lineno">  929</span> </div>
<div class="line"><a id="l00930" name="l00930"></a><span class="lineno">  930</span>    offset = arith::AddIOp::create(rewriter, loc, extractOpIndex, offset);</div>
<div class="line"><a id="l00931" name="l00931"></a><span class="lineno">  931</span>  }</div>
<div class="line"><a id="l00932" name="l00932"></a><span class="lineno">  932</span> </div>
<div class="line"><a id="l00933" name="l00933"></a><span class="lineno">  933</span>  <span class="keywordflow">return</span> offset;</div>
<div class="line"><a id="l00934" name="l00934"></a><span class="lineno">  934</span>}</div>
</div>
<div class="line"><a id="l00935" name="l00935"></a><span class="lineno">  935</span> </div>
<div class="line"><a id="l00936" name="l00936"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea">  936</a></span><span class="keyword">enum</span> <a class="code hl_enumeration" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcc">VectorMemoryAccessKind</a> { <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">ScalarBroadcast</a>, <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea">Contiguous</a>, <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">Gather</a> };</div>
<div class="line"><a id="l00937" name="l00937"></a><span class="lineno">  937</span><span class="comment"></span> </div>
<div class="line"><a id="l00938" name="l00938"></a><span class="lineno">  938</span><span class="comment">/// Find the index of the trailing non-unit dim in linalgOp. This hook is used</span></div>
<div class="line"><a id="l00939" name="l00939"></a><span class="lineno">  939</span><span class="comment">/// when checking whether `tensor.extract` Op (within a `linalg.generic` Op)</span></div>
<div class="line"><a id="l00940" name="l00940"></a><span class="lineno">  940</span><span class="comment">/// represents a contiguous load operation.</span></div>
<div class="line"><a id="l00941" name="l00941"></a><span class="lineno">  941</span><span class="comment">///</span></div>
<div class="line"><a id="l00942" name="l00942"></a><span class="lineno">  942</span><span class="comment">/// Note that when calling this hook, it is assumed that the output vector is</span></div>
<div class="line"><a id="l00943" name="l00943"></a><span class="lineno">  943</span><span class="comment">/// effectively 1D. Other cases (i.e. reading n-D vectors) should&#39;ve been</span></div>
<div class="line"><a id="l00944" name="l00944"></a><span class="lineno">  944</span><span class="comment">/// labelled as a gather load before entering this method.</span></div>
<div class="line"><a id="l00945" name="l00945"></a><span class="lineno">  945</span><span class="comment">///</span></div>
<div class="line"><a id="l00946" name="l00946"></a><span class="lineno">  946</span><span class="comment">/// Following on from the above, it is assumed that:</span></div>
<div class="line"><a id="l00947" name="l00947"></a><span class="lineno">  947</span><span class="comment">///   * for statically shaped loops, when no masks are used, only one dim is !=</span></div>
<div class="line"><a id="l00948" name="l00948"></a><span class="lineno">  948</span><span class="comment">///   1 (that&#39;s what the shape of the output vector is based on).</span></div>
<div class="line"><a id="l00949" name="l00949"></a><span class="lineno">  949</span><span class="comment">///   * for dynamically shaped loops, there might be more non-unit dims</span></div>
<div class="line"><a id="l00950" name="l00950"></a><span class="lineno">  950</span><span class="comment">///   as the output vector type is user-specified.</span></div>
<div class="line"><a id="l00951" name="l00951"></a><span class="lineno">  951</span><span class="comment">///</span></div>
<div class="line"><a id="l00952" name="l00952"></a><span class="lineno">  952</span><span class="comment">/// TODO: Statically shaped loops + vector masking</span></div>
<div class="foldopen" id="foldopen00953" data-start="{" data-end="}">
<div class="line"><a id="l00953" name="l00953"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a7e9ce28bca426dd4de93ad09392b4ec1">  953</a></span><span class="keyword">static</span> uint64_t <a class="code hl_function" href="Vectorization_8cpp.html#a7e9ce28bca426dd4de93ad09392b4ec1">getTrailingNonUnitLoopDimIdx</a>(LinalgOp linalgOp) {</div>
<div class="line"><a id="l00954" name="l00954"></a><span class="lineno">  954</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> loopRanges = linalgOp.getStaticLoopRanges();</div>
<div class="line"><a id="l00955" name="l00955"></a><span class="lineno">  955</span>  assert(</div>
<div class="line"><a id="l00956" name="l00956"></a><span class="lineno">  956</span>      (linalgOp.hasDynamicShape() ||</div>
<div class="line"><a id="l00957" name="l00957"></a><span class="lineno">  957</span>       llvm::count_if(loopRanges, [](<a class="code hl_class" href="classint64__t.html">int64_t</a> dim) { return dim != 1; }) == 1) &amp;&amp;</div>
<div class="line"><a id="l00958" name="l00958"></a><span class="lineno">  958</span>      <span class="stringliteral">&quot;For statically shaped Linalg Ops, only one &quot;</span></div>
<div class="line"><a id="l00959" name="l00959"></a><span class="lineno">  959</span>      <span class="stringliteral">&quot;non-unit loop dim is expected&quot;</span>);</div>
<div class="line"><a id="l00960" name="l00960"></a><span class="lineno">  960</span>  assert(!loopRanges.empty() &amp;&amp; <span class="stringliteral">&quot;Empty loops, nothing to analyse.&quot;</span>);</div>
<div class="line"><a id="l00961" name="l00961"></a><span class="lineno">  961</span> </div>
<div class="line"><a id="l00962" name="l00962"></a><span class="lineno">  962</span>  <span class="keywordtype">size_t</span> idx = loopRanges.size() - 1;</div>
<div class="line"><a id="l00963" name="l00963"></a><span class="lineno">  963</span>  <span class="keywordflow">for</span> (; idx != 0; idx--)</div>
<div class="line"><a id="l00964" name="l00964"></a><span class="lineno">  964</span>    <span class="keywordflow">if</span> (loopRanges[idx] != 1)</div>
<div class="line"><a id="l00965" name="l00965"></a><span class="lineno">  965</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l00966" name="l00966"></a><span class="lineno">  966</span> </div>
<div class="line"><a id="l00967" name="l00967"></a><span class="lineno">  967</span>  <span class="keywordflow">return</span> idx;</div>
<div class="line"><a id="l00968" name="l00968"></a><span class="lineno">  968</span>}</div>
</div>
<div class="line"><a id="l00969" name="l00969"></a><span class="lineno">  969</span><span class="comment"></span> </div>
<div class="line"><a id="l00970" name="l00970"></a><span class="lineno">  970</span><span class="comment">/// Checks whether `val` can be used for calculating a loop invariant index.</span></div>
<div class="foldopen" id="foldopen00971" data-start="{" data-end="}">
<div class="line"><a id="l00971" name="l00971"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">  971</a></span><span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code hl_function" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a>(LinalgOp &amp;linalgOp, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> &amp;val,</div>
<div class="line"><a id="l00972" name="l00972"></a><span class="lineno">  972</span>                               VectorType resType) {</div>
<div class="line"><a id="l00973" name="l00973"></a><span class="lineno">  973</span> </div>
<div class="line"><a id="l00974" name="l00974"></a><span class="lineno">  974</span>  assert(((llvm::count_if(resType.getShape(),</div>
<div class="line"><a id="l00975" name="l00975"></a><span class="lineno">  975</span>                          [](<a class="code hl_class" href="classint64__t.html">int64_t</a> dimSize) { return dimSize &gt; 1; }) == 1)) &amp;&amp;</div>
<div class="line"><a id="l00976" name="l00976"></a><span class="lineno">  976</span>         <span class="stringliteral">&quot;n-D vectors are not yet supported&quot;</span>);</div>
<div class="line"><a id="l00977" name="l00977"></a><span class="lineno">  977</span> </div>
<div class="line"><a id="l00978" name="l00978"></a><span class="lineno">  978</span>  <span class="comment">// Blocks outside _this_ linalg.generic are effectively loop invariant.</span></div>
<div class="line"><a id="l00979" name="l00979"></a><span class="lineno">  979</span>  <span class="comment">// However, analysing block arguments for _this_ linalg.generic Op is a bit</span></div>
<div class="line"><a id="l00980" name="l00980"></a><span class="lineno">  980</span>  <span class="comment">// tricky. Just bail out in the latter case.</span></div>
<div class="line"><a id="l00981" name="l00981"></a><span class="lineno">  981</span>  <span class="comment">// TODO: We could try analysing the corresponding affine map here.</span></div>
<div class="line"><a id="l00982" name="l00982"></a><span class="lineno">  982</span>  <span class="keyword">auto</span> *block = linalgOp.getBlock();</div>
<div class="line"><a id="l00983" name="l00983"></a><span class="lineno">  983</span>  <span class="keywordflow">if</span> (isa&lt;BlockArgument&gt;(val))</div>
<div class="line"><a id="l00984" name="l00984"></a><span class="lineno">  984</span>    <span class="keywordflow">return</span> !llvm::is_contained(block-&gt;getArguments(), val);</div>
<div class="line"><a id="l00985" name="l00985"></a><span class="lineno">  985</span> </div>
<div class="line"><a id="l00986" name="l00986"></a><span class="lineno">  986</span>  <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *defOp = val.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>();</div>
<div class="line"><a id="l00987" name="l00987"></a><span class="lineno">  987</span>  assert(defOp &amp;&amp; <span class="stringliteral">&quot;This is neither a block argument nor an operation result&quot;</span>);</div>
<div class="line"><a id="l00988" name="l00988"></a><span class="lineno">  988</span> </div>
<div class="line"><a id="l00989" name="l00989"></a><span class="lineno">  989</span>  <span class="comment">// IndexOp is loop invariant as long as its result remains constant across</span></div>
<div class="line"><a id="l00990" name="l00990"></a><span class="lineno">  990</span>  <span class="comment">// iterations. Note that for dynamic shapes, the corresponding dim will also</span></div>
<div class="line"><a id="l00991" name="l00991"></a><span class="lineno">  991</span>  <span class="comment">// be conservatively treated as != 1.</span></div>
<div class="line"><a id="l00992" name="l00992"></a><span class="lineno">  992</span>  <span class="keywordflow">if</span> (<span class="keyword">auto</span> indexOp = dyn_cast&lt;linalg::IndexOp&gt;(defOp)) {</div>
<div class="line"><a id="l00993" name="l00993"></a><span class="lineno">  993</span>    <span class="keywordflow">return</span> linalgOp.getStaticLoopRanges()[indexOp.getDim()] == 1;</div>
<div class="line"><a id="l00994" name="l00994"></a><span class="lineno">  994</span>  }</div>
<div class="line"><a id="l00995" name="l00995"></a><span class="lineno">  995</span> </div>
<div class="line"><a id="l00996" name="l00996"></a><span class="lineno">  996</span>  <span class="keyword">auto</span> *ancestor = block-&gt;findAncestorOpInBlock(*defOp);</div>
<div class="line"><a id="l00997" name="l00997"></a><span class="lineno">  997</span> </div>
<div class="line"><a id="l00998" name="l00998"></a><span class="lineno">  998</span>  <span class="comment">// Values define outside `linalgOp` are loop invariant.</span></div>
<div class="line"><a id="l00999" name="l00999"></a><span class="lineno">  999</span>  <span class="keywordflow">if</span> (!ancestor)</div>
<div class="line"><a id="l01000" name="l01000"></a><span class="lineno"> 1000</span>    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l01001" name="l01001"></a><span class="lineno"> 1001</span> </div>
<div class="line"><a id="l01002" name="l01002"></a><span class="lineno"> 1002</span>  <span class="comment">// Values defined inside `linalgOp`, which are constant, are loop invariant.</span></div>
<div class="line"><a id="l01003" name="l01003"></a><span class="lineno"> 1003</span>  <span class="keywordflow">if</span> (isa&lt;arith::ConstantOp&gt;(ancestor))</div>
<div class="line"><a id="l01004" name="l01004"></a><span class="lineno"> 1004</span>    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l01005" name="l01005"></a><span class="lineno"> 1005</span> </div>
<div class="line"><a id="l01006" name="l01006"></a><span class="lineno"> 1006</span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a> = <span class="keyword">true</span>;</div>
<div class="line"><a id="l01007" name="l01007"></a><span class="lineno"> 1007</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> op : ancestor-&gt;getOperands())</div>
<div class="line"><a id="l01008" name="l01008"></a><span class="lineno"> 1008</span>    <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a> &amp;= <a class="code hl_function" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a>(linalgOp, op, resType);</div>
<div class="line"><a id="l01009" name="l01009"></a><span class="lineno"> 1009</span> </div>
<div class="line"><a id="l01010" name="l01010"></a><span class="lineno"> 1010</span>  <span class="keywordflow">return</span> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>;</div>
<div class="line"><a id="l01011" name="l01011"></a><span class="lineno"> 1011</span>}</div>
</div>
<div class="line"><a id="l01012" name="l01012"></a><span class="lineno"> 1012</span><span class="comment"></span> </div>
<div class="line"><a id="l01013" name="l01013"></a><span class="lineno"> 1013</span><span class="comment">/// Check whether `val` could be used for calculating the trailing index for a</span></div>
<div class="line"><a id="l01014" name="l01014"></a><span class="lineno"> 1014</span><span class="comment">/// contiguous load operation.</span></div>
<div class="line"><a id="l01015" name="l01015"></a><span class="lineno"> 1015</span><span class="comment">///</span></div>
<div class="line"><a id="l01016" name="l01016"></a><span class="lineno"> 1016</span><span class="comment">/// There are currently 3 types of values that are allowed here:</span></div>
<div class="line"><a id="l01017" name="l01017"></a><span class="lineno"> 1017</span><span class="comment">///   1. loop-invariant values,</span></div>
<div class="line"><a id="l01018" name="l01018"></a><span class="lineno"> 1018</span><span class="comment">///   2. values that increment by 1 with every loop iteration,</span></div>
<div class="line"><a id="l01019" name="l01019"></a><span class="lineno"> 1019</span><span class="comment">///   3. results of basic arithmetic operations (linear and continuous)</span></div>
<div class="line"><a id="l01020" name="l01020"></a><span class="lineno"> 1020</span><span class="comment">///      involving 1., 2. and 3.</span></div>
<div class="line"><a id="l01021" name="l01021"></a><span class="lineno"> 1021</span><span class="comment">/// This method returns True if indeed only such values are used in calculating</span></div>
<div class="line"><a id="l01022" name="l01022"></a><span class="lineno"> 1022</span><span class="comment">/// `val.`</span></div>
<div class="line"><a id="l01023" name="l01023"></a><span class="lineno"> 1023</span><span class="comment">///</span></div>
<div class="line"><a id="l01024" name="l01024"></a><span class="lineno"> 1024</span><span class="comment">/// Additionally, the trailing index for a contiguous load operation should</span></div>
<div class="line"><a id="l01025" name="l01025"></a><span class="lineno"> 1025</span><span class="comment">/// increment by 1 with every loop iteration, i.e. be based on:</span></div>
<div class="line"><a id="l01026" name="l01026"></a><span class="lineno"> 1026</span><span class="comment">///   * `linalg.index &lt;dim&gt;` ,</span></div>
<div class="line"><a id="l01027" name="l01027"></a><span class="lineno"> 1027</span><span class="comment">/// where &lt;dim&gt; is the trailing non-unit dim of the iteration space (this way,</span></div>
<div class="line"><a id="l01028" name="l01028"></a><span class="lineno"> 1028</span><span class="comment">/// `linalg.index &lt;dim&gt;` increments by 1 with every loop iteration).</span></div>
<div class="line"><a id="l01029" name="l01029"></a><span class="lineno"> 1029</span><span class="comment">/// `foundIndexOp` is updated to `true` when such Op is found.</span></div>
<div class="foldopen" id="foldopen01030" data-start="{" data-end="}">
<div class="line"><a id="l01030" name="l01030"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3"> 1030</a></span><span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code hl_function" href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3">isContiguousLoadIdx</a>(LinalgOp &amp;linalgOp, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> &amp;val,</div>
<div class="line"><a id="l01031" name="l01031"></a><span class="lineno"> 1031</span>                                <span class="keywordtype">bool</span> &amp;foundIndexOp, VectorType resType) {</div>
<div class="line"><a id="l01032" name="l01032"></a><span class="lineno"> 1032</span> </div>
<div class="line"><a id="l01033" name="l01033"></a><span class="lineno"> 1033</span>  assert(((llvm::count_if(resType.getShape(),</div>
<div class="line"><a id="l01034" name="l01034"></a><span class="lineno"> 1034</span>                          [](<a class="code hl_class" href="classint64__t.html">int64_t</a> dimSize) { return dimSize &gt; 1; }) == 1)) &amp;&amp;</div>
<div class="line"><a id="l01035" name="l01035"></a><span class="lineno"> 1035</span>         <span class="stringliteral">&quot;n-D vectors are not yet supported&quot;</span>);</div>
<div class="line"><a id="l01036" name="l01036"></a><span class="lineno"> 1036</span> </div>
<div class="line"><a id="l01037" name="l01037"></a><span class="lineno"> 1037</span>  <span class="comment">// Blocks outside _this_ linalg.generic are effectively loop invariant.</span></div>
<div class="line"><a id="l01038" name="l01038"></a><span class="lineno"> 1038</span>  <span class="comment">// However, analysing block arguments for _this_ linalg.generic Op is a bit</span></div>
<div class="line"><a id="l01039" name="l01039"></a><span class="lineno"> 1039</span>  <span class="comment">// tricky. Just bail out in the latter case.</span></div>
<div class="line"><a id="l01040" name="l01040"></a><span class="lineno"> 1040</span>  <span class="comment">// TODO: We could try analysing the corresponding affine map here.</span></div>
<div class="line"><a id="l01041" name="l01041"></a><span class="lineno"> 1041</span>  <span class="keyword">auto</span> *block = linalgOp.getBlock();</div>
<div class="line"><a id="l01042" name="l01042"></a><span class="lineno"> 1042</span>  <span class="keywordflow">if</span> (isa&lt;BlockArgument&gt;(val))</div>
<div class="line"><a id="l01043" name="l01043"></a><span class="lineno"> 1043</span>    <span class="keywordflow">return</span> !llvm::is_contained(block-&gt;getArguments(), val);</div>
<div class="line"><a id="l01044" name="l01044"></a><span class="lineno"> 1044</span> </div>
<div class="line"><a id="l01045" name="l01045"></a><span class="lineno"> 1045</span>  <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *defOp = val.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>();</div>
<div class="line"><a id="l01046" name="l01046"></a><span class="lineno"> 1046</span>  assert(defOp &amp;&amp; <span class="stringliteral">&quot;This is neither a block argument nor an operation result&quot;</span>);</div>
<div class="line"><a id="l01047" name="l01047"></a><span class="lineno"> 1047</span> </div>
<div class="line"><a id="l01048" name="l01048"></a><span class="lineno"> 1048</span>  <span class="keywordflow">if</span> (<span class="keyword">auto</span> indexOp = dyn_cast&lt;linalg::IndexOp&gt;(defOp)) {</div>
<div class="line"><a id="l01049" name="l01049"></a><span class="lineno"> 1049</span>    <span class="keyword">auto</span> loopDimThatIncrementsByOne = <a class="code hl_function" href="Vectorization_8cpp.html#a7e9ce28bca426dd4de93ad09392b4ec1">getTrailingNonUnitLoopDimIdx</a>(linalgOp);</div>
<div class="line"><a id="l01050" name="l01050"></a><span class="lineno"> 1050</span> </div>
<div class="line"><a id="l01051" name="l01051"></a><span class="lineno"> 1051</span>    foundIndexOp = (indexOp.getDim() == loopDimThatIncrementsByOne);</div>
<div class="line"><a id="l01052" name="l01052"></a><span class="lineno"> 1052</span>    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l01053" name="l01053"></a><span class="lineno"> 1053</span>  }</div>
<div class="line"><a id="l01054" name="l01054"></a><span class="lineno"> 1054</span> </div>
<div class="line"><a id="l01055" name="l01055"></a><span class="lineno"> 1055</span>  <span class="keyword">auto</span> *ancestor = block-&gt;findAncestorOpInBlock(*defOp);</div>
<div class="line"><a id="l01056" name="l01056"></a><span class="lineno"> 1056</span> </div>
<div class="line"><a id="l01057" name="l01057"></a><span class="lineno"> 1057</span>  <span class="keywordflow">if</span> (!ancestor)</div>
<div class="line"><a id="l01058" name="l01058"></a><span class="lineno"> 1058</span>    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l01059" name="l01059"></a><span class="lineno"> 1059</span> </div>
<div class="line"><a id="l01060" name="l01060"></a><span class="lineno"> 1060</span>  <span class="comment">// Conservatively reject Ops that could lead to indices with stride other</span></div>
<div class="line"><a id="l01061" name="l01061"></a><span class="lineno"> 1061</span>  <span class="comment">// than 1.</span></div>
<div class="line"><a id="l01062" name="l01062"></a><span class="lineno"> 1062</span>  <span class="keywordflow">if</span> (!isa&lt;arith::AddIOp, arith::ConstantOp, linalg::IndexOp&gt;(ancestor))</div>
<div class="line"><a id="l01063" name="l01063"></a><span class="lineno"> 1063</span>    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l01064" name="l01064"></a><span class="lineno"> 1064</span> </div>
<div class="line"><a id="l01065" name="l01065"></a><span class="lineno"> 1065</span>  <span class="keywordtype">bool</span> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a> = <span class="keyword">false</span>;</div>
<div class="line"><a id="l01066" name="l01066"></a><span class="lineno"> 1066</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> op : ancestor-&gt;getOperands())</div>
<div class="line"><a id="l01067" name="l01067"></a><span class="lineno"> 1067</span>    <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a> |= <a class="code hl_function" href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3">isContiguousLoadIdx</a>(linalgOp, op, foundIndexOp, resType);</div>
<div class="line"><a id="l01068" name="l01068"></a><span class="lineno"> 1068</span> </div>
<div class="line"><a id="l01069" name="l01069"></a><span class="lineno"> 1069</span>  <span class="keywordflow">return</span> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>;</div>
<div class="line"><a id="l01070" name="l01070"></a><span class="lineno"> 1070</span>}</div>
</div>
<div class="line"><a id="l01071" name="l01071"></a><span class="lineno"> 1071</span><span class="comment"></span> </div>
<div class="line"><a id="l01072" name="l01072"></a><span class="lineno"> 1072</span><span class="comment">/// Infer the memory access pattern for the input ExtractOp</span></div>
<div class="line"><a id="l01073" name="l01073"></a><span class="lineno"> 1073</span><span class="comment">///</span></div>
<div class="line"><a id="l01074" name="l01074"></a><span class="lineno"> 1074</span><span class="comment">/// Based on the ExtratOp result shape and the access indices, decides whether</span></div>
<div class="line"><a id="l01075" name="l01075"></a><span class="lineno"> 1075</span><span class="comment">/// this Op corresponds to a contiguous load (including a broadcast of a scalar)</span></div>
<div class="line"><a id="l01076" name="l01076"></a><span class="lineno"> 1076</span><span class="comment">/// or a gather load. When analysing the ExtractOp indices (to identify</span></div>
<div class="line"><a id="l01077" name="l01077"></a><span class="lineno"> 1077</span><span class="comment">/// contiguous laods), this method looks for &quot;loop&quot; invariant indices (e.g.</span></div>
<div class="line"><a id="l01078" name="l01078"></a><span class="lineno"> 1078</span><span class="comment">/// block arguments) and indices that change linearly (e.g. via `linalg.index`</span></div>
<div class="line"><a id="l01079" name="l01079"></a><span class="lineno"> 1079</span><span class="comment">/// Op).</span></div>
<div class="line"><a id="l01080" name="l01080"></a><span class="lineno"> 1080</span><span class="comment">///</span></div>
<div class="line"><a id="l01081" name="l01081"></a><span class="lineno"> 1081</span><span class="comment">/// Note that it is always safe to use gather load operations for contiguous</span></div>
<div class="line"><a id="l01082" name="l01082"></a><span class="lineno"> 1082</span><span class="comment">/// loads (albeit slow), but not vice-versa. When in doubt, bail out and assume</span></div>
<div class="line"><a id="l01083" name="l01083"></a><span class="lineno"> 1083</span><span class="comment">/// that `extractOp` is a gather load.</span></div>
<div class="line"><a id="l01084" name="l01084"></a><span class="lineno"> 1084</span><span class="keyword">static</span> <a class="code hl_enumeration" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcc">VectorMemoryAccessKind</a></div>
<div class="foldopen" id="foldopen01085" data-start="{" data-end="}">
<div class="line"><a id="l01085" name="l01085"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a172594be3a7384cb03a833aed99dc03c"> 1085</a></span><a class="code hl_function" href="Vectorization_8cpp.html#a172594be3a7384cb03a833aed99dc03c">getTensorExtractMemoryAccessPattern</a>(tensor::ExtractOp extractOp,</div>
<div class="line"><a id="l01086" name="l01086"></a><span class="lineno"> 1086</span>                                    LinalgOp &amp;linalgOp, VectorType resType) {</div>
<div class="line"><a id="l01087" name="l01087"></a><span class="lineno"> 1087</span> </div>
<div class="line"><a id="l01088" name="l01088"></a><span class="lineno"> 1088</span>  <span class="keyword">auto</span> inputShape = cast&lt;ShapedType&gt;(extractOp.getTensor().getType());</div>
<div class="line"><a id="l01089" name="l01089"></a><span class="lineno"> 1089</span> </div>
<div class="line"><a id="l01090" name="l01090"></a><span class="lineno"> 1090</span>  <span class="comment">// 0. Is this a 0-D vector? If yes then this is a scalar broadcast.</span></div>
<div class="line"><a id="l01091" name="l01091"></a><span class="lineno"> 1091</span>  <span class="keywordflow">if</span> (inputShape.getShape().empty())</div>
<div class="line"><a id="l01092" name="l01092"></a><span class="lineno"> 1092</span>    <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">VectorMemoryAccessKind::ScalarBroadcast</a>;</div>
<div class="line"><a id="l01093" name="l01093"></a><span class="lineno"> 1093</span> </div>
<div class="line"><a id="l01094" name="l01094"></a><span class="lineno"> 1094</span>  <span class="comment">// True for vectors that are effectively 1D, e.g. `vector&lt;1x4x1xi32&gt;`, false</span></div>
<div class="line"><a id="l01095" name="l01095"></a><span class="lineno"> 1095</span>  <span class="comment">// otherwise.</span></div>
<div class="line"><a id="l01096" name="l01096"></a><span class="lineno"> 1096</span>  <span class="keywordtype">bool</span> isOutput1DVector =</div>
<div class="line"><a id="l01097" name="l01097"></a><span class="lineno"> 1097</span>      (llvm::count_if(resType.getShape(),</div>
<div class="line"><a id="l01098" name="l01098"></a><span class="lineno"> 1098</span>                      [](<a class="code hl_class" href="classint64__t.html">int64_t</a> dimSize) { return dimSize &gt; 1; }) == 1);</div>
<div class="line"><a id="l01099" name="l01099"></a><span class="lineno"> 1099</span>  <span class="comment">// 1. Assume that it&#39;s a gather load when reading non-1D vector.</span></div>
<div class="line"><a id="l01100" name="l01100"></a><span class="lineno"> 1100</span>  <span class="keywordflow">if</span> (!isOutput1DVector)</div>
<div class="line"><a id="l01101" name="l01101"></a><span class="lineno"> 1101</span>    <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">VectorMemoryAccessKind::Gather</a>;</div>
<div class="line"><a id="l01102" name="l01102"></a><span class="lineno"> 1102</span> </div>
<div class="line"><a id="l01103" name="l01103"></a><span class="lineno"> 1103</span>  <span class="keywordtype">bool</span> leadingIdxsLoopInvariant = <span class="keyword">true</span>;</div>
<div class="line"><a id="l01104" name="l01104"></a><span class="lineno"> 1104</span> </div>
<div class="line"><a id="l01105" name="l01105"></a><span class="lineno"> 1105</span>  <span class="comment">// 2. Analyze the leading indices of `extractOp`.</span></div>
<div class="line"><a id="l01106" name="l01106"></a><span class="lineno"> 1106</span>  <span class="comment">// Look at the way each index is calculated and decide whether it is suitable</span></div>
<div class="line"><a id="l01107" name="l01107"></a><span class="lineno"> 1107</span>  <span class="comment">// for a contiguous load, i.e. whether it&#39;s loop invariant. If not, it&#39;s a</span></div>
<div class="line"><a id="l01108" name="l01108"></a><span class="lineno"> 1108</span>  <span class="comment">// gather load.</span></div>
<div class="line"><a id="l01109" name="l01109"></a><span class="lineno"> 1109</span>  <span class="keyword">auto</span> <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a> = extractOp.getIndices();</div>
<div class="line"><a id="l01110" name="l01110"></a><span class="lineno"> 1110</span>  <span class="keyword">auto</span> leadIndices = <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>.drop_back(1);</div>
<div class="line"><a id="l01111" name="l01111"></a><span class="lineno"> 1111</span> </div>
<div class="line"><a id="l01112" name="l01112"></a><span class="lineno"> 1112</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, indexVal] : llvm::enumerate(leadIndices)) {</div>
<div class="line"><a id="l01113" name="l01113"></a><span class="lineno"> 1113</span>    <span class="keywordflow">if</span> (inputShape.getShape()[i] == 1)</div>
<div class="line"><a id="l01114" name="l01114"></a><span class="lineno"> 1114</span>      <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l01115" name="l01115"></a><span class="lineno"> 1115</span> </div>
<div class="line"><a id="l01116" name="l01116"></a><span class="lineno"> 1116</span>    leadingIdxsLoopInvariant &amp;= <a class="code hl_function" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a>(linalgOp, indexVal, resType);</div>
<div class="line"><a id="l01117" name="l01117"></a><span class="lineno"> 1117</span>  }</div>
<div class="line"><a id="l01118" name="l01118"></a><span class="lineno"> 1118</span> </div>
<div class="line"><a id="l01119" name="l01119"></a><span class="lineno"> 1119</span>  <span class="keywordflow">if</span> (!leadingIdxsLoopInvariant) {</div>
<div class="line"><a id="l01120" name="l01120"></a><span class="lineno"> 1120</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Found gather load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a id="l01121" name="l01121"></a><span class="lineno"> 1121</span>    <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">VectorMemoryAccessKind::Gather</a>;</div>
<div class="line"><a id="l01122" name="l01122"></a><span class="lineno"> 1122</span>  }</div>
<div class="line"><a id="l01123" name="l01123"></a><span class="lineno"> 1123</span> </div>
<div class="line"><a id="l01124" name="l01124"></a><span class="lineno"> 1124</span>  <span class="comment">// 3. Analyze the trailing index for `extractOp`.</span></div>
<div class="line"><a id="l01125" name="l01125"></a><span class="lineno"> 1125</span>  <span class="comment">// At this point we know that the leading indices are loop invariant. This</span></div>
<div class="line"><a id="l01126" name="l01126"></a><span class="lineno"> 1126</span>  <span class="comment">// means that is potentially a scalar or a contiguous load. We can decide</span></div>
<div class="line"><a id="l01127" name="l01127"></a><span class="lineno"> 1127</span>  <span class="comment">// based on the trailing idx.</span></div>
<div class="line"><a id="l01128" name="l01128"></a><span class="lineno"> 1128</span>  <span class="keyword">auto</span> extractOpTrailingIdx = <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>.back();</div>
<div class="line"><a id="l01129" name="l01129"></a><span class="lineno"> 1129</span> </div>
<div class="line"><a id="l01130" name="l01130"></a><span class="lineno"> 1130</span>  <span class="comment">// 3a. Scalar broadcast load</span></div>
<div class="line"><a id="l01131" name="l01131"></a><span class="lineno"> 1131</span>  <span class="comment">// If the trailing index is loop invariant then this is a scalar load.</span></div>
<div class="line"><a id="l01132" name="l01132"></a><span class="lineno"> 1132</span>  <span class="keywordflow">if</span> (leadingIdxsLoopInvariant &amp;&amp;</div>
<div class="line"><a id="l01133" name="l01133"></a><span class="lineno"> 1133</span>      <a class="code hl_function" href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a>(linalgOp, extractOpTrailingIdx, resType)) {</div>
<div class="line"><a id="l01134" name="l01134"></a><span class="lineno"> 1134</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Found scalar broadcast load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a id="l01135" name="l01135"></a><span class="lineno"> 1135</span> </div>
<div class="line"><a id="l01136" name="l01136"></a><span class="lineno"> 1136</span>    <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">VectorMemoryAccessKind::ScalarBroadcast</a>;</div>
<div class="line"><a id="l01137" name="l01137"></a><span class="lineno"> 1137</span>  }</div>
<div class="line"><a id="l01138" name="l01138"></a><span class="lineno"> 1138</span> </div>
<div class="line"><a id="l01139" name="l01139"></a><span class="lineno"> 1139</span>  <span class="comment">// 3b. Contiguous loads</span></div>
<div class="line"><a id="l01140" name="l01140"></a><span class="lineno"> 1140</span>  <span class="comment">// The trailing `extractOp` index should increment with every loop iteration.</span></div>
<div class="line"><a id="l01141" name="l01141"></a><span class="lineno"> 1141</span>  <span class="comment">// This effectively means that it must be based on the trailing loop index.</span></div>
<div class="line"><a id="l01142" name="l01142"></a><span class="lineno"> 1142</span>  <span class="comment">// This is what the following bool captures.</span></div>
<div class="line"><a id="l01143" name="l01143"></a><span class="lineno"> 1143</span>  <span class="keywordtype">bool</span> foundIndexOp = <span class="keyword">false</span>;</div>
<div class="line"><a id="l01144" name="l01144"></a><span class="lineno"> 1144</span>  <span class="keywordtype">bool</span> isContiguousLoad = <a class="code hl_function" href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3">isContiguousLoadIdx</a>(linalgOp, extractOpTrailingIdx,</div>
<div class="line"><a id="l01145" name="l01145"></a><span class="lineno"> 1145</span>                                              foundIndexOp, resType);</div>
<div class="line"><a id="l01146" name="l01146"></a><span class="lineno"> 1146</span>  <span class="comment">// TODO: Support generating contiguous loads for column vectors - that will</span></div>
<div class="line"><a id="l01147" name="l01147"></a><span class="lineno"> 1147</span>  <span class="comment">// require adding a permutation map to tranfer_read Ops.</span></div>
<div class="line"><a id="l01148" name="l01148"></a><span class="lineno"> 1148</span>  <span class="keywordtype">bool</span> isRowVector = resType.getShape().back() != 1;</div>
<div class="line"><a id="l01149" name="l01149"></a><span class="lineno"> 1149</span>  isContiguousLoad &amp;= (foundIndexOp &amp;&amp; isRowVector);</div>
<div class="line"><a id="l01150" name="l01150"></a><span class="lineno"> 1150</span> </div>
<div class="line"><a id="l01151" name="l01151"></a><span class="lineno"> 1151</span>  <span class="keywordflow">if</span> (isContiguousLoad) {</div>
<div class="line"><a id="l01152" name="l01152"></a><span class="lineno"> 1152</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Found contigous load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a id="l01153" name="l01153"></a><span class="lineno"> 1153</span>    <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea">VectorMemoryAccessKind::Contiguous</a>;</div>
<div class="line"><a id="l01154" name="l01154"></a><span class="lineno"> 1154</span>  }</div>
<div class="line"><a id="l01155" name="l01155"></a><span class="lineno"> 1155</span> </div>
<div class="line"><a id="l01156" name="l01156"></a><span class="lineno"> 1156</span>  <span class="comment">// 4. Fallback case - gather load.</span></div>
<div class="line"><a id="l01157" name="l01157"></a><span class="lineno"> 1157</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Found gather load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a id="l01158" name="l01158"></a><span class="lineno"> 1158</span>  <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">VectorMemoryAccessKind::Gather</a>;</div>
<div class="line"><a id="l01159" name="l01159"></a><span class="lineno"> 1159</span>}</div>
</div>
<div class="line"><a id="l01160" name="l01160"></a><span class="lineno"> 1160</span><span class="comment"></span> </div>
<div class="line"><a id="l01161" name="l01161"></a><span class="lineno"> 1161</span><span class="comment">/// Helper function to vectorize the tensor.extract operations. Returns</span></div>
<div class="line"><a id="l01162" name="l01162"></a><span class="lineno"> 1162</span><span class="comment">/// VectorizationHookStatus::NewOp to signal the vectorization algorithm that it</span></div>
<div class="line"><a id="l01163" name="l01163"></a><span class="lineno"> 1163</span><span class="comment">/// should map the produced operations. This function is meant to be used as a</span></div>
<div class="line"><a id="l01164" name="l01164"></a><span class="lineno"> 1164</span><span class="comment">/// CustomVectorizationHook.</span></div>
<div class="line"><a id="l01165" name="l01165"></a><span class="lineno"> 1165</span><span class="keyword">static</span> VectorizationHookResult</div>
<div class="foldopen" id="foldopen01166" data-start="{" data-end="}">
<div class="line"><a id="l01166" name="l01166"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a26cb5e24425fdce30baaba6f7c0f5c84"> 1166</a></span><a class="code hl_function" href="Vectorization_8cpp.html#a26cb5e24425fdce30baaba6f7c0f5c84">vectorizeTensorExtract</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, VectorizationState &amp;state,</div>
<div class="line"><a id="l01167" name="l01167"></a><span class="lineno"> 1167</span>                       <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op, LinalgOp linalgOp, <span class="keyword">const</span> <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) {</div>
<div class="line"><a id="l01168" name="l01168"></a><span class="lineno"> 1168</span>  tensor::ExtractOp extractOp = dyn_cast&lt;tensor::ExtractOp&gt;(op);</div>
<div class="line"><a id="l01169" name="l01169"></a><span class="lineno"> 1169</span>  <span class="keywordflow">if</span> (!extractOp)</div>
<div class="line"><a id="l01170" name="l01170"></a><span class="lineno"> 1170</span>    <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a id="l01171" name="l01171"></a><span class="lineno"> 1171</span>  <span class="keyword">auto</span> loc = extractOp.getLoc();</div>
<div class="line"><a id="l01172" name="l01172"></a><span class="lineno"> 1172</span> </div>
<div class="line"><a id="l01173" name="l01173"></a><span class="lineno"> 1173</span>  <span class="comment">// Compute the static loop sizes of the extract op.</span></div>
<div class="line"><a id="l01174" name="l01174"></a><span class="lineno"> 1174</span>  <span class="keyword">auto</span> resultType = state.getCanonicalVecType(extractOp.getResult().getType());</div>
<div class="line"><a id="l01175" name="l01175"></a><span class="lineno"> 1175</span>  <span class="keyword">auto</span> maskConstantOp = arith::ConstantOp::create(</div>
<div class="line"><a id="l01176" name="l01176"></a><span class="lineno"> 1176</span>      rewriter, loc,</div>
<div class="line"><a id="l01177" name="l01177"></a><span class="lineno"> 1177</span>      <a class="code hl_function" href="classmlir_1_1DenseIntElementsAttr.html#a9db4e0b61c851fb050659e8a3cd4f4a0">DenseIntElementsAttr::get</a>(state.getCanonicalVecType(rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>()),</div>
<div class="line"><a id="l01178" name="l01178"></a><span class="lineno"> 1178</span>                                <span class="comment">/*value=*/</span><span class="keyword">true</span>));</div>
<div class="line"><a id="l01179" name="l01179"></a><span class="lineno"> 1179</span>  <span class="keyword">auto</span> passThruConstantOp = arith::ConstantOp::create(</div>
<div class="line"><a id="l01180" name="l01180"></a><span class="lineno"> 1180</span>      rewriter, loc, rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#a8e943986e58a8b0c88fcd51b0f0afafb">getZeroAttr</a>(resultType));</div>
<div class="line"><a id="l01181" name="l01181"></a><span class="lineno"> 1181</span> </div>
<div class="line"><a id="l01182" name="l01182"></a><span class="lineno"> 1182</span>  <span class="comment">// Base indices are currently set to 0. We will need to re-visit if more</span></div>
<div class="line"><a id="l01183" name="l01183"></a><span class="lineno"> 1183</span>  <span class="comment">// generic scenarios are to be supported.</span></div>
<div class="line"><a id="l01184" name="l01184"></a><span class="lineno"> 1184</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> baseIndices(</div>
<div class="line"><a id="l01185" name="l01185"></a><span class="lineno"> 1185</span>      extractOp.getIndices().size(),</div>
<div class="line"><a id="l01186" name="l01186"></a><span class="lineno"> 1186</span>      <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0));</div>
<div class="line"><a id="l01187" name="l01187"></a><span class="lineno"> 1187</span> </div>
<div class="line"><a id="l01188" name="l01188"></a><span class="lineno"> 1188</span>  <a class="code hl_enumeration" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcc">VectorMemoryAccessKind</a> memAccessKind =</div>
<div class="line"><a id="l01189" name="l01189"></a><span class="lineno"> 1189</span>      <a class="code hl_function" href="Vectorization_8cpp.html#a172594be3a7384cb03a833aed99dc03c">getTensorExtractMemoryAccessPattern</a>(extractOp, linalgOp, resultType);</div>
<div class="line"><a id="l01190" name="l01190"></a><span class="lineno"> 1190</span> </div>
<div class="line"><a id="l01191" name="l01191"></a><span class="lineno"> 1191</span>  <span class="comment">// 1. Handle gather access</span></div>
<div class="line"><a id="l01192" name="l01192"></a><span class="lineno"> 1192</span>  <span class="keywordflow">if</span> (memAccessKind == <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">VectorMemoryAccessKind::Gather</a>) {</div>
<div class="line"><a id="l01193" name="l01193"></a><span class="lineno"> 1193</span>    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> offset = <a class="code hl_function" href="Vectorization_8cpp.html#ae4411a5d89520c86474035493a7da7c1">calculateGatherOffset</a>(rewriter, state, extractOp, bvm);</div>
<div class="line"><a id="l01194" name="l01194"></a><span class="lineno"> 1194</span> </div>
<div class="line"><a id="l01195" name="l01195"></a><span class="lineno"> 1195</span>    <span class="comment">// Generate the gather load</span></div>
<div class="line"><a id="l01196" name="l01196"></a><span class="lineno"> 1196</span>    <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *gatherOp = vector::GatherOp::create(</div>
<div class="line"><a id="l01197" name="l01197"></a><span class="lineno"> 1197</span>        rewriter, loc, resultType, extractOp.getTensor(), baseIndices, offset,</div>
<div class="line"><a id="l01198" name="l01198"></a><span class="lineno"> 1198</span>        maskConstantOp, passThruConstantOp);</div>
<div class="line"><a id="l01199" name="l01199"></a><span class="lineno"> 1199</span>    gatherOp = state.maskOperation(rewriter, gatherOp, linalgOp);</div>
<div class="line"><a id="l01200" name="l01200"></a><span class="lineno"> 1200</span> </div>
<div class="line"><a id="l01201" name="l01201"></a><span class="lineno"> 1201</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorised as gather load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a id="l01202" name="l01202"></a><span class="lineno"> 1202</span>    <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>, gatherOp};</div>
<div class="line"><a id="l01203" name="l01203"></a><span class="lineno"> 1203</span>  }</div>
<div class="line"><a id="l01204" name="l01204"></a><span class="lineno"> 1204</span> </div>
<div class="line"><a id="l01205" name="l01205"></a><span class="lineno"> 1205</span>  <span class="comment">// 2. Handle:</span></div>
<div class="line"><a id="l01206" name="l01206"></a><span class="lineno"> 1206</span>  <span class="comment">//  a. scalar loads + broadcast,</span></div>
<div class="line"><a id="l01207" name="l01207"></a><span class="lineno"> 1207</span>  <span class="comment">//  b. contiguous loads.</span></div>
<div class="line"><a id="l01208" name="l01208"></a><span class="lineno"> 1208</span>  <span class="comment">// Both cases use vector.transfer_read.</span></div>
<div class="line"><a id="l01209" name="l01209"></a><span class="lineno"> 1209</span> </div>
<div class="line"><a id="l01210" name="l01210"></a><span class="lineno"> 1210</span>  <span class="comment">// Collect indices for `vector.transfer_read`. At this point, the indices will</span></div>
<div class="line"><a id="l01211" name="l01211"></a><span class="lineno"> 1211</span>  <span class="comment">// either be scalars or would have been broadcast to vectors matching the</span></div>
<div class="line"><a id="l01212" name="l01212"></a><span class="lineno"> 1212</span>  <span class="comment">// result type. For indices that are vectors, there are two options:</span></div>
<div class="line"><a id="l01213" name="l01213"></a><span class="lineno"> 1213</span>  <span class="comment">//    * for non-trailing indices, all elements are identical (contiguous</span></div>
<div class="line"><a id="l01214" name="l01214"></a><span class="lineno"> 1214</span>  <span class="comment">//      loads are identified by looking for non-trailing indices that are</span></div>
<div class="line"><a id="l01215" name="l01215"></a><span class="lineno"> 1215</span>  <span class="comment">//      invariant with respect to the corresponding linalg.generic), or</span></div>
<div class="line"><a id="l01216" name="l01216"></a><span class="lineno"> 1216</span>  <span class="comment">//    * for trailing indices, the index vector will contain values with stride</span></div>
<div class="line"><a id="l01217" name="l01217"></a><span class="lineno"> 1217</span>  <span class="comment">//      one, but for `vector.transfer_read` only the first (i.e. 0th) index is</span></div>
<div class="line"><a id="l01218" name="l01218"></a><span class="lineno"> 1218</span>  <span class="comment">//      needed.</span></div>
<div class="line"><a id="l01219" name="l01219"></a><span class="lineno"> 1219</span>  <span class="comment">// This means that</span></div>
<div class="line"><a id="l01220" name="l01220"></a><span class="lineno"> 1220</span>  <span class="comment">//   * for scalar indices - just re-use it,</span></div>
<div class="line"><a id="l01221" name="l01221"></a><span class="lineno"> 1221</span>  <span class="comment">//   * for vector indices (e.g. `vector&lt;1x1x4xindex&gt;`) - extract the bottom</span></div>
<div class="line"><a id="l01222" name="l01222"></a><span class="lineno"> 1222</span>  <span class="comment">//    (0th) element and use that.</span></div>
<div class="line"><a id="l01223" name="l01223"></a><span class="lineno"> 1223</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> transferReadIdxs;</div>
<div class="line"><a id="l01224" name="l01224"></a><span class="lineno"> 1224</span>  <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; extractOp.getIndices().size(); i++) {</div>
<div class="line"><a id="l01225" name="l01225"></a><span class="lineno"> 1225</span>    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> idx = bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(extractOp.getIndices()[i]);</div>
<div class="line"><a id="l01226" name="l01226"></a><span class="lineno"> 1226</span>    <span class="keywordflow">if</span> (idx.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>().<a class="code hl_function" href="classmlir_1_1Type.html#a5d5d5335ce4fc906636a2690155a7d72">isIndex</a>()) {</div>
<div class="line"><a id="l01227" name="l01227"></a><span class="lineno"> 1227</span>      transferReadIdxs.push_back(idx);</div>
<div class="line"><a id="l01228" name="l01228"></a><span class="lineno"> 1228</span>      <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l01229" name="l01229"></a><span class="lineno"> 1229</span>    }</div>
<div class="line"><a id="l01230" name="l01230"></a><span class="lineno"> 1230</span> </div>
<div class="line"><a id="l01231" name="l01231"></a><span class="lineno"> 1231</span>    <span class="keyword">auto</span> indexAs1dVector = vector::ShapeCastOp::create(</div>
<div class="line"><a id="l01232" name="l01232"></a><span class="lineno"> 1232</span>        rewriter, loc,</div>
<div class="line"><a id="l01233" name="l01233"></a><span class="lineno"> 1233</span>        VectorType::get(resultType.getShape().back(), rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">getIndexType</a>(),</div>
<div class="line"><a id="l01234" name="l01234"></a><span class="lineno"> 1234</span>                        resultType.getScalableDims().back()),</div>
<div class="line"><a id="l01235" name="l01235"></a><span class="lineno"> 1235</span>        idx);</div>
<div class="line"><a id="l01236" name="l01236"></a><span class="lineno"> 1236</span>    transferReadIdxs.push_back(</div>
<div class="line"><a id="l01237" name="l01237"></a><span class="lineno"> 1237</span>        vector::ExtractOp::create(rewriter, loc, indexAs1dVector, 0));</div>
<div class="line"><a id="l01238" name="l01238"></a><span class="lineno"> 1238</span>  }</div>
<div class="line"><a id="l01239" name="l01239"></a><span class="lineno"> 1239</span> </div>
<div class="line"><a id="l01240" name="l01240"></a><span class="lineno"> 1240</span>  <span class="comment">// `tensor.extract_element` is always in-bounds, hence the following holds.</span></div>
<div class="line"><a id="l01241" name="l01241"></a><span class="lineno"> 1241</span>  <span class="keyword">auto</span> dstRank = resultType.getRank();</div>
<div class="line"><a id="l01242" name="l01242"></a><span class="lineno"> 1242</span>  <span class="keyword">auto</span> srcRank = extractOp.getTensor().getType().getRank();</div>
<div class="line"><a id="l01243" name="l01243"></a><span class="lineno"> 1243</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(dstRank, <span class="keyword">true</span>);</div>
<div class="line"><a id="l01244" name="l01244"></a><span class="lineno"> 1244</span> </div>
<div class="line"><a id="l01245" name="l01245"></a><span class="lineno"> 1245</span>  <span class="comment">// 2a. Handle scalar broadcast access.</span></div>
<div class="line"><a id="l01246" name="l01246"></a><span class="lineno"> 1246</span>  <span class="keywordflow">if</span> (memAccessKind == <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">VectorMemoryAccessKind::ScalarBroadcast</a>) {</div>
<div class="line"><a id="l01247" name="l01247"></a><span class="lineno"> 1247</span>    <a class="code hl_class" href="classmlir_1_1MLIRContext.html">MLIRContext</a> *ctx = rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#acbdddd0c6fa53e5605c93109ad00953b">getContext</a>();</div>
<div class="line"><a id="l01248" name="l01248"></a><span class="lineno"> 1248</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;AffineExpr&gt;</a> exprs(dstRank, <a class="code hl_function" href="namespacemlir.html#ab26cdced424aa629fde4150cc8674d50">getAffineConstantExpr</a>(0, ctx));</div>
<div class="line"><a id="l01249" name="l01249"></a><span class="lineno"> 1249</span>    <span class="keyword">auto</span> permutationMap = <a class="code hl_function" href="classmlir_1_1AffineMap.html#a3cfca2eb29fddf3c4bda714cccaa53f9">AffineMap::get</a>(srcRank, 0, exprs, ctx);</div>
<div class="line"><a id="l01250" name="l01250"></a><span class="lineno"> 1250</span> </div>
<div class="line"><a id="l01251" name="l01251"></a><span class="lineno"> 1251</span>    <span class="keyword">auto</span> transferReadOp = vector::TransferReadOp::create(</div>
<div class="line"><a id="l01252" name="l01252"></a><span class="lineno"> 1252</span>        rewriter, loc, resultType, extractOp.getTensor(), transferReadIdxs,</div>
<div class="line"><a id="l01253" name="l01253"></a><span class="lineno"> 1253</span>        <span class="comment">/*padding=*/</span>std::nullopt, permutationMap, inBounds);</div>
<div class="line"><a id="l01254" name="l01254"></a><span class="lineno"> 1254</span> </div>
<div class="line"><a id="l01255" name="l01255"></a><span class="lineno"> 1255</span>    <span class="comment">// Mask this broadcasting xfer_read here rather than relying on the generic</span></div>
<div class="line"><a id="l01256" name="l01256"></a><span class="lineno"> 1256</span>    <span class="comment">// path (the generic path assumes identity masking map, which wouldn&#39;t be</span></div>
<div class="line"><a id="l01257" name="l01257"></a><span class="lineno"> 1257</span>    <span class="comment">// valid here).</span></div>
<div class="line"><a id="l01258" name="l01258"></a><span class="lineno"> 1258</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> readMaskShape = {1};</div>
<div class="line"><a id="l01259" name="l01259"></a><span class="lineno"> 1259</span>    <span class="keyword">auto</span> readMaskType = VectorType::get(readMaskShape, rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>());</div>
<div class="line"><a id="l01260" name="l01260"></a><span class="lineno"> 1260</span>    <span class="keyword">auto</span> allTrue = vector::ConstantMaskOp::create(</div>
<div class="line"><a id="l01261" name="l01261"></a><span class="lineno"> 1261</span>        rewriter, loc, readMaskType, <a class="code hl_enumvalue" href="namespacemlir_1_1vector.html#a4ba6d4a825dbd36205be5322733056efa822b19813c2556c566eec6864da1319f">vector::ConstantMaskKind::AllTrue</a>);</div>
<div class="line"><a id="l01262" name="l01262"></a><span class="lineno"> 1262</span>    <span class="keyword">auto</span> *maskedReadOp =</div>
<div class="line"><a id="l01263" name="l01263"></a><span class="lineno"> 1263</span>        <a class="code hl_function" href="namespacemlir_1_1vector.html#a21bfcee9196fe1a2cfa548b7df8193a9">mlir::vector::maskOperation</a>(rewriter, transferReadOp, allTrue);</div>
<div class="line"><a id="l01264" name="l01264"></a><span class="lineno"> 1264</span> </div>
<div class="line"><a id="l01265" name="l01265"></a><span class="lineno"> 1265</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorised as scalar broadcast load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a id="l01266" name="l01266"></a><span class="lineno"> 1266</span>    <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>,</div>
<div class="line"><a id="l01267" name="l01267"></a><span class="lineno"> 1267</span>                                   maskedReadOp};</div>
<div class="line"><a id="l01268" name="l01268"></a><span class="lineno"> 1268</span>  }</div>
<div class="line"><a id="l01269" name="l01269"></a><span class="lineno"> 1269</span> </div>
<div class="line"><a id="l01270" name="l01270"></a><span class="lineno"> 1270</span>  <span class="comment">// 2b. Handle contiguous access.</span></div>
<div class="line"><a id="l01271" name="l01271"></a><span class="lineno"> 1271</span>  <span class="keyword">auto</span> permutationMap = <a class="code hl_function" href="classmlir_1_1AffineMap.html#a035fc7c93286e3aa0354f522f2cd885a">AffineMap::getMinorIdentityMap</a>(</div>
<div class="line"><a id="l01272" name="l01272"></a><span class="lineno"> 1272</span>      srcRank, std::min(dstRank, srcRank), rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#acbdddd0c6fa53e5605c93109ad00953b">getContext</a>());</div>
<div class="line"><a id="l01273" name="l01273"></a><span class="lineno"> 1273</span> </div>
<div class="line"><a id="l01274" name="l01274"></a><span class="lineno"> 1274</span>  int32_t rankDiff = dstRank - srcRank;</div>
<div class="line"><a id="l01275" name="l01275"></a><span class="lineno"> 1275</span>  <span class="comment">// When dstRank &gt; srcRank, broadcast the source tensor to the unitary leading</span></div>
<div class="line"><a id="l01276" name="l01276"></a><span class="lineno"> 1276</span>  <span class="comment">// dims so that the ranks match. This is done by extending the map with 0s.</span></div>
<div class="line"><a id="l01277" name="l01277"></a><span class="lineno"> 1277</span>  <span class="comment">// For example, for dstRank = 3, srcRank = 2, the following map created</span></div>
<div class="line"><a id="l01278" name="l01278"></a><span class="lineno"> 1278</span>  <span class="comment">// above:</span></div>
<div class="line"><a id="l01279" name="l01279"></a><span class="lineno"> 1279</span>  <span class="comment">//    (d0, d1) --&gt; (d0, d1)</span></div>
<div class="line"><a id="l01280" name="l01280"></a><span class="lineno"> 1280</span>  <span class="comment">// is extended as:</span></div>
<div class="line"><a id="l01281" name="l01281"></a><span class="lineno"> 1281</span>  <span class="comment">//    (d0, d1) --&gt; (0, d0, d1)</span></div>
<div class="line"><a id="l01282" name="l01282"></a><span class="lineno"> 1282</span>  <span class="keywordflow">while</span> (rankDiff &gt; 0) {</div>
<div class="line"><a id="l01283" name="l01283"></a><span class="lineno"> 1283</span>    permutationMap = permutationMap.insertResult(</div>
<div class="line"><a id="l01284" name="l01284"></a><span class="lineno"> 1284</span>        <a class="code hl_function" href="namespacemlir.html#ab26cdced424aa629fde4150cc8674d50">mlir::getAffineConstantExpr</a>(0, rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#acbdddd0c6fa53e5605c93109ad00953b">getContext</a>()), 0);</div>
<div class="line"><a id="l01285" name="l01285"></a><span class="lineno"> 1285</span>    rankDiff--;</div>
<div class="line"><a id="l01286" name="l01286"></a><span class="lineno"> 1286</span>  }</div>
<div class="line"><a id="l01287" name="l01287"></a><span class="lineno"> 1287</span> </div>
<div class="line"><a id="l01288" name="l01288"></a><span class="lineno"> 1288</span>  <span class="keyword">auto</span> transferReadOp = vector::TransferReadOp::create(</div>
<div class="line"><a id="l01289" name="l01289"></a><span class="lineno"> 1289</span>      rewriter, loc, resultType, extractOp.getTensor(), transferReadIdxs,</div>
<div class="line"><a id="l01290" name="l01290"></a><span class="lineno"> 1290</span>      <span class="comment">/*padding=*/</span>std::nullopt, permutationMap, inBounds);</div>
<div class="line"><a id="l01291" name="l01291"></a><span class="lineno"> 1291</span> </div>
<div class="line"><a id="l01292" name="l01292"></a><span class="lineno"> 1292</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorised as contiguous load: &quot;</span> &lt;&lt; extractOp;</div>
<div class="line"><a id="l01293" name="l01293"></a><span class="lineno"> 1293</span>  <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>,</div>
<div class="line"><a id="l01294" name="l01294"></a><span class="lineno"> 1294</span>                                 transferReadOp};</div>
<div class="line"><a id="l01295" name="l01295"></a><span class="lineno"> 1295</span>}</div>
</div>
<div class="line"><a id="l01296" name="l01296"></a><span class="lineno"> 1296</span><span class="comment"></span> </div>
<div class="line"><a id="l01297" name="l01297"></a><span class="lineno"> 1297</span><span class="comment">/// Emit reduction operations if the shapes of the value to reduce is different</span></div>
<div class="line"><a id="l01298" name="l01298"></a><span class="lineno"> 1298</span><span class="comment">/// that the result shape.</span></div>
<div class="line"><a id="l01299" name="l01299"></a><span class="lineno"> 1299</span><span class="comment">// Note: this is a true builder that notifies the OpBuilder listener.</span></div>
<div class="line"><a id="l01300" name="l01300"></a><span class="lineno"> 1300</span><span class="comment">// TODO: Consider moving as a static helper on the ReduceOp.</span></div>
<div class="foldopen" id="foldopen01301" data-start="{" data-end="}">
<div class="line"><a id="l01301" name="l01301"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#aae426acd0929292f99ebde650870d27b"> 1301</a></span><span class="keyword">static</span> <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *<a class="code hl_function" href="Vectorization_8cpp.html#aae426acd0929292f99ebde650870d27b">reduceIfNeeded</a>(<a class="code hl_class" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;<a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a21ad0bd836b90d08f4cf640b4c298e7c">b</a>, LinalgOp linalgOp, <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op,</div>
<div class="line"><a id="l01302" name="l01302"></a><span class="lineno"> 1302</span>                                 <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> reduceValue, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> initialValue,</div>
<div class="line"><a id="l01303" name="l01303"></a><span class="lineno"> 1303</span>                                 <span class="keyword">const</span> <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) {</div>
<div class="line"><a id="l01304" name="l01304"></a><span class="lineno"> 1304</span>  <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> reduceVec = bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(reduceValue);</div>
<div class="line"><a id="l01305" name="l01305"></a><span class="lineno"> 1305</span>  <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> outputVec = bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(initialValue);</div>
<div class="line"><a id="l01306" name="l01306"></a><span class="lineno"> 1306</span>  <span class="keyword">auto</span> reduceType = dyn_cast&lt;VectorType&gt;(reduceVec.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a id="l01307" name="l01307"></a><span class="lineno"> 1307</span>  <span class="keyword">auto</span> outputType = dyn_cast&lt;VectorType&gt;(outputVec.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a id="l01308" name="l01308"></a><span class="lineno"> 1308</span>  <span class="comment">// Reduce only if needed as the value may already have been reduce for</span></div>
<div class="line"><a id="l01309" name="l01309"></a><span class="lineno"> 1309</span>  <span class="comment">// contraction vectorization.</span></div>
<div class="line"><a id="l01310" name="l01310"></a><span class="lineno"> 1310</span>  <span class="keywordflow">if</span> (!reduceType ||</div>
<div class="line"><a id="l01311" name="l01311"></a><span class="lineno"> 1311</span>      (outputType &amp;&amp; reduceType.getShape() == outputType.getShape()))</div>
<div class="line"><a id="l01312" name="l01312"></a><span class="lineno"> 1312</span>    <span class="keywordflow">return</span> <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l01313" name="l01313"></a><span class="lineno"> 1313</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> dimsToMask = <a class="code hl_function" href="Vectorization_8cpp.html#a129f4ae5f0a8071a3f98c8f73ee729f9">getDimsToReduce</a>(linalgOp);</div>
<div class="line"><a id="l01314" name="l01314"></a><span class="lineno"> 1314</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="Vectorization_8cpp.html#af936802591fc5ba398ba106887feac8f">buildMultiDimReduce</a>(<a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a21ad0bd836b90d08f4cf640b4c298e7c">b</a>, op, reduceVec, outputVec, dimsToMask);</div>
<div class="line"><a id="l01315" name="l01315"></a><span class="lineno"> 1315</span>}</div>
</div>
<div class="line"><a id="l01316" name="l01316"></a><span class="lineno"> 1316</span><span class="comment"></span> </div>
<div class="line"><a id="l01317" name="l01317"></a><span class="lineno"> 1317</span><span class="comment">/// Generic vectorization for a single operation `op`, given already vectorized</span></div>
<div class="line"><a id="l01318" name="l01318"></a><span class="lineno"> 1318</span><span class="comment">/// operands carried by `bvm`. Vectorization occurs as follows:</span></div>
<div class="line"><a id="l01319" name="l01319"></a><span class="lineno"> 1319</span><span class="comment">///   1. Try to apply any of the `customVectorizationHooks` and return its</span></div>
<div class="line"><a id="l01320" name="l01320"></a><span class="lineno"> 1320</span><span class="comment">///   result on success.</span></div>
<div class="line"><a id="l01321" name="l01321"></a><span class="lineno"> 1321</span><span class="comment">///   2. Clone any constant in the current scope without vectorization: each</span></div>
<div class="line"><a id="l01322" name="l01322"></a><span class="lineno"> 1322</span><span class="comment">///   consumer of the constant will later determine the shape to which the</span></div>
<div class="line"><a id="l01323" name="l01323"></a><span class="lineno"> 1323</span><span class="comment">///   constant needs to be broadcast to.</span></div>
<div class="line"><a id="l01324" name="l01324"></a><span class="lineno"> 1324</span><span class="comment">///   3. Fail on any remaining non `ElementwiseMappable` op. It is the purpose</span></div>
<div class="line"><a id="l01325" name="l01325"></a><span class="lineno"> 1325</span><span class="comment">///   of the `customVectorizationHooks` to cover such cases.</span></div>
<div class="line"><a id="l01326" name="l01326"></a><span class="lineno"> 1326</span><span class="comment">///   4. Clone `op` in vector form to a vector of shape prescribed by the first</span></div>
<div class="line"><a id="l01327" name="l01327"></a><span class="lineno"> 1327</span><span class="comment">///   operand of maximal rank. Other operands have smaller rank and are</span></div>
<div class="line"><a id="l01328" name="l01328"></a><span class="lineno"> 1328</span><span class="comment">///   broadcast accordingly. It is assumed this broadcast is always legal,</span></div>
<div class="line"><a id="l01329" name="l01329"></a><span class="lineno"> 1329</span><span class="comment">///   otherwise, it means one of the `customVectorizationHooks` is incorrect.</span></div>
<div class="line"><a id="l01330" name="l01330"></a><span class="lineno"> 1330</span><span class="comment">///</span></div>
<div class="line"><a id="l01331" name="l01331"></a><span class="lineno"> 1331</span><span class="comment">/// This function assumes all operands of `op` have been vectorized and are in</span></div>
<div class="line"><a id="l01332" name="l01332"></a><span class="lineno"> 1332</span><span class="comment">/// the `bvm` mapping. As a consequence, this function is meant to be called  on</span></div>
<div class="line"><a id="l01333" name="l01333"></a><span class="lineno"> 1333</span><span class="comment">/// a topologically-sorted list of ops.</span></div>
<div class="line"><a id="l01334" name="l01334"></a><span class="lineno"> 1334</span><span class="comment">/// This function does not update `bvm` but returns a VectorizationHookStatus</span></div>
<div class="line"><a id="l01335" name="l01335"></a><span class="lineno"> 1335</span><span class="comment">/// that instructs the caller what `bvm` update needs to occur.</span></div>
<div class="line"><a id="l01336" name="l01336"></a><span class="lineno"> 1336</span><span class="keyword">static</span> VectorizationHookResult</div>
<div class="foldopen" id="foldopen01337" data-start="{" data-end="}">
<div class="line"><a id="l01337" name="l01337"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a455f83de6534e53da06be057973f7e38"> 1337</a></span><a class="code hl_function" href="Vectorization_8cpp.html#a455f83de6534e53da06be057973f7e38">vectorizeOneOp</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, VectorizationState &amp;state,</div>
<div class="line"><a id="l01338" name="l01338"></a><span class="lineno"> 1338</span>               LinalgOp linalgOp, <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keyword">const</span> <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm,</div>
<div class="line"><a id="l01339" name="l01339"></a><span class="lineno"> 1339</span>               <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;CustomVectorizationHook&gt;</a> customVectorizationHooks) {</div>
<div class="line"><a id="l01340" name="l01340"></a><span class="lineno"> 1340</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;vectorize op &quot;</span> &lt;&lt; *op;</div>
<div class="line"><a id="l01341" name="l01341"></a><span class="lineno"> 1341</span> </div>
<div class="line"><a id="l01342" name="l01342"></a><span class="lineno"> 1342</span>  <span class="comment">// 1. Try to apply any CustomVectorizationHook.</span></div>
<div class="line"><a id="l01343" name="l01343"></a><span class="lineno"> 1343</span>  <span class="keywordflow">if</span> (!customVectorizationHooks.empty()) {</div>
<div class="line"><a id="l01344" name="l01344"></a><span class="lineno"> 1344</span>    <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;customFunc : customVectorizationHooks) {</div>
<div class="line"><a id="l01345" name="l01345"></a><span class="lineno"> 1345</span>      <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a> = customFunc(op, bvm);</div>
<div class="line"><a id="l01346" name="l01346"></a><span class="lineno"> 1346</span>      <span class="keywordflow">if</span> (<a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>.status == <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>)</div>
<div class="line"><a id="l01347" name="l01347"></a><span class="lineno"> 1347</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l01348" name="l01348"></a><span class="lineno"> 1348</span>      <span class="keywordflow">return</span> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>;</div>
<div class="line"><a id="l01349" name="l01349"></a><span class="lineno"> 1349</span>    }</div>
<div class="line"><a id="l01350" name="l01350"></a><span class="lineno"> 1350</span>  }</div>
<div class="line"><a id="l01351" name="l01351"></a><span class="lineno"> 1351</span> </div>
<div class="line"><a id="l01352" name="l01352"></a><span class="lineno"> 1352</span>  <span class="comment">// 2. Constant ops don&#39;t get vectorized but rather broadcasted at their users.</span></div>
<div class="line"><a id="l01353" name="l01353"></a><span class="lineno"> 1353</span>  <span class="comment">// Clone so that the constant is not confined to the linalgOp block .</span></div>
<div class="line"><a id="l01354" name="l01354"></a><span class="lineno"> 1354</span>  <span class="keywordflow">if</span> (isa&lt;arith::ConstantOp, func::ConstantOp&gt;(op))</div>
<div class="line"><a id="l01355" name="l01355"></a><span class="lineno"> 1355</span>    <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>,</div>
<div class="line"><a id="l01356" name="l01356"></a><span class="lineno"> 1356</span>                                   rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a394cad81296b42a24e1c37b045e15359">clone</a>(*op)};</div>
<div class="line"><a id="l01357" name="l01357"></a><span class="lineno"> 1357</span> </div>
<div class="line"><a id="l01358" name="l01358"></a><span class="lineno"> 1358</span>  <span class="comment">// 3. Only ElementwiseMappable are allowed in the generic vectorization.</span></div>
<div class="line"><a id="l01359" name="l01359"></a><span class="lineno"> 1359</span>  <span class="keywordflow">if</span> (!<a class="code hl_function" href="namespacemlir_1_1OpTrait.html#a0c5480822c4898f287f588dfe98d1c85">OpTrait::hasElementwiseMappableTraits</a>(op))</div>
<div class="line"><a id="l01360" name="l01360"></a><span class="lineno"> 1360</span>    <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>, <span class="keyword">nullptr</span>};</div>
<div class="line"><a id="l01361" name="l01361"></a><span class="lineno"> 1361</span> </div>
<div class="line"><a id="l01362" name="l01362"></a><span class="lineno"> 1362</span>  <span class="comment">// 4 . Check if the operation is a reduction.</span></div>
<div class="line"><a id="l01363" name="l01363"></a><span class="lineno"> 1363</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;std::pair&lt;Value, Value&gt;</a>&gt; reductionOperands;</div>
<div class="line"><a id="l01364" name="l01364"></a><span class="lineno"> 1364</span>  <span class="keywordflow">for</span> (<a class="code hl_class" href="classmlir_1_1Value.html">Value</a> operand : op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>()) {</div>
<div class="line"><a id="l01365" name="l01365"></a><span class="lineno"> 1365</span>    <span class="keyword">auto</span> blockArg = dyn_cast&lt;BlockArgument&gt;(operand);</div>
<div class="line"><a id="l01366" name="l01366"></a><span class="lineno"> 1366</span>    <span class="keywordflow">if</span> (!blockArg || blockArg.getOwner() != linalgOp.getBlock() ||</div>
<div class="line"><a id="l01367" name="l01367"></a><span class="lineno"> 1367</span>        blockArg.getArgNumber() &lt; linalgOp.getNumDpsInputs())</div>
<div class="line"><a id="l01368" name="l01368"></a><span class="lineno"> 1368</span>      <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l01369" name="l01369"></a><span class="lineno"> 1369</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Operation *&gt;</a> reductionOps;</div>
<div class="line"><a id="l01370" name="l01370"></a><span class="lineno"> 1370</span>    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> reduceValue = <a class="code hl_function" href="namespacemlir.html#a6bc751bc8f30d71ad4cb771c0fcc788b">matchReduction</a>(</div>
<div class="line"><a id="l01371" name="l01371"></a><span class="lineno"> 1371</span>        linalgOp.getRegionOutputArgs(),</div>
<div class="line"><a id="l01372" name="l01372"></a><span class="lineno"> 1372</span>        blockArg.getArgNumber() - linalgOp.getNumDpsInputs(), reductionOps);</div>
<div class="line"><a id="l01373" name="l01373"></a><span class="lineno"> 1373</span>    <span class="keywordflow">if</span> (!reduceValue)</div>
<div class="line"><a id="l01374" name="l01374"></a><span class="lineno"> 1374</span>      <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l01375" name="l01375"></a><span class="lineno"> 1375</span>    reductionOperands.push_back(std::make_pair(reduceValue, operand));</div>
<div class="line"><a id="l01376" name="l01376"></a><span class="lineno"> 1376</span>  }</div>
<div class="line"><a id="l01377" name="l01377"></a><span class="lineno"> 1377</span>  <span class="keywordflow">if</span> (!reductionOperands.empty()) {</div>
<div class="line"><a id="l01378" name="l01378"></a><span class="lineno"> 1378</span>    assert(reductionOperands.size() == 1);</div>
<div class="line"><a id="l01379" name="l01379"></a><span class="lineno"> 1379</span>    <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *reduceOp =</div>
<div class="line"><a id="l01380" name="l01380"></a><span class="lineno"> 1380</span>        <a class="code hl_function" href="Vectorization_8cpp.html#aae426acd0929292f99ebde650870d27b">reduceIfNeeded</a>(rewriter, linalgOp, op, reductionOperands[0].first,</div>
<div class="line"><a id="l01381" name="l01381"></a><span class="lineno"> 1381</span>                       reductionOperands[0].second, bvm);</div>
<div class="line"><a id="l01382" name="l01382"></a><span class="lineno"> 1382</span>    <span class="keywordflow">if</span> (reduceOp)</div>
<div class="line"><a id="l01383" name="l01383"></a><span class="lineno"> 1383</span>      <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>, reduceOp};</div>
<div class="line"><a id="l01384" name="l01384"></a><span class="lineno"> 1384</span>  }</div>
<div class="line"><a id="l01385" name="l01385"></a><span class="lineno"> 1385</span> </div>
<div class="line"><a id="l01386" name="l01386"></a><span class="lineno"> 1386</span>  <span class="comment">// 5. Generic vectorization path for ElementwiseMappable ops.</span></div>
<div class="line"><a id="l01387" name="l01387"></a><span class="lineno"> 1387</span>  <span class="comment">//   a. Get the first max ranked shape.</span></div>
<div class="line"><a id="l01388" name="l01388"></a><span class="lineno"> 1388</span>  VectorType firstMaxRankedType;</div>
<div class="line"><a id="l01389" name="l01389"></a><span class="lineno"> 1389</span>  <span class="keywordflow">for</span> (<a class="code hl_class" href="classmlir_1_1Value.html">Value</a> operand : op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>()) {</div>
<div class="line"><a id="l01390" name="l01390"></a><span class="lineno"> 1390</span>    <span class="keyword">auto</span> vecOperand = bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(operand);</div>
<div class="line"><a id="l01391" name="l01391"></a><span class="lineno"> 1391</span>    assert(vecOperand &amp;&amp; <span class="stringliteral">&quot;Vector operand couldn&#39;t be found&quot;</span>);</div>
<div class="line"><a id="l01392" name="l01392"></a><span class="lineno"> 1392</span> </div>
<div class="line"><a id="l01393" name="l01393"></a><span class="lineno"> 1393</span>    <span class="keyword">auto</span> vecType = dyn_cast&lt;VectorType&gt;(vecOperand.getType());</div>
<div class="line"><a id="l01394" name="l01394"></a><span class="lineno"> 1394</span>    <span class="keywordflow">if</span> (vecType &amp;&amp; (!firstMaxRankedType ||</div>
<div class="line"><a id="l01395" name="l01395"></a><span class="lineno"> 1395</span>                    firstMaxRankedType.getRank() &lt; vecType.getRank()))</div>
<div class="line"><a id="l01396" name="l01396"></a><span class="lineno"> 1396</span>      firstMaxRankedType = vecType;</div>
<div class="line"><a id="l01397" name="l01397"></a><span class="lineno"> 1397</span>  }</div>
<div class="line"><a id="l01398" name="l01398"></a><span class="lineno"> 1398</span>  <span class="comment">//   b. Broadcast each op if needed.</span></div>
<div class="line"><a id="l01399" name="l01399"></a><span class="lineno"> 1399</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> vecOperands;</div>
<div class="line"><a id="l01400" name="l01400"></a><span class="lineno"> 1400</span>  <span class="keywordflow">for</span> (<a class="code hl_class" href="classmlir_1_1Value.html">Value</a> scalarOperand : op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>()) {</div>
<div class="line"><a id="l01401" name="l01401"></a><span class="lineno"> 1401</span>    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> vecOperand = bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">lookup</a>(scalarOperand);</div>
<div class="line"><a id="l01402" name="l01402"></a><span class="lineno"> 1402</span>    assert(vecOperand &amp;&amp; <span class="stringliteral">&quot;Vector operand couldn&#39;t be found&quot;</span>);</div>
<div class="line"><a id="l01403" name="l01403"></a><span class="lineno"> 1403</span> </div>
<div class="line"><a id="l01404" name="l01404"></a><span class="lineno"> 1404</span>    <span class="keywordflow">if</span> (firstMaxRankedType) {</div>
<div class="line"><a id="l01405" name="l01405"></a><span class="lineno"> 1405</span>      <span class="keyword">auto</span> vecType = VectorType::get(firstMaxRankedType.getShape(),</div>
<div class="line"><a id="l01406" name="l01406"></a><span class="lineno"> 1406</span>                                     <a class="code hl_function" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(vecOperand.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()),</div>
<div class="line"><a id="l01407" name="l01407"></a><span class="lineno"> 1407</span>                                     firstMaxRankedType.getScalableDims());</div>
<div class="line"><a id="l01408" name="l01408"></a><span class="lineno"> 1408</span>      vecOperands.push_back(<a class="code hl_function" href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a>(rewriter, vecOperand, vecType));</div>
<div class="line"><a id="l01409" name="l01409"></a><span class="lineno"> 1409</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l01410" name="l01410"></a><span class="lineno"> 1410</span>      vecOperands.push_back(vecOperand);</div>
<div class="line"><a id="l01411" name="l01411"></a><span class="lineno"> 1411</span>    }</div>
<div class="line"><a id="l01412" name="l01412"></a><span class="lineno"> 1412</span>  }</div>
<div class="line"><a id="l01413" name="l01413"></a><span class="lineno"> 1413</span>  <span class="comment">//   c. for elementwise, the result is the vector with the firstMaxRankedShape</span></div>
<div class="line"><a id="l01414" name="l01414"></a><span class="lineno"> 1414</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Type&gt;</a> resultTypes;</div>
<div class="line"><a id="l01415" name="l01415"></a><span class="lineno"> 1415</span>  <span class="keywordflow">for</span> (<a class="code hl_class" href="classmlir_1_1Type.html">Type</a> resultType : op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac3095b4b7756a4974ba1c21b0e8ed762">getResultTypes</a>()) {</div>
<div class="line"><a id="l01416" name="l01416"></a><span class="lineno"> 1416</span>    resultTypes.push_back(</div>
<div class="line"><a id="l01417" name="l01417"></a><span class="lineno"> 1417</span>        firstMaxRankedType</div>
<div class="line"><a id="l01418" name="l01418"></a><span class="lineno"> 1418</span>            ? VectorType::get(firstMaxRankedType.getShape(), resultType,</div>
<div class="line"><a id="l01419" name="l01419"></a><span class="lineno"> 1419</span>                              firstMaxRankedType.getScalableDims())</div>
<div class="line"><a id="l01420" name="l01420"></a><span class="lineno"> 1420</span>            : resultType);</div>
<div class="line"><a id="l01421" name="l01421"></a><span class="lineno"> 1421</span>  }</div>
<div class="line"><a id="l01422" name="l01422"></a><span class="lineno"> 1422</span>  <span class="comment">//   d. Build and return the new op.</span></div>
<div class="line"><a id="l01423" name="l01423"></a><span class="lineno"> 1423</span>  <span class="keywordflow">return</span> <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a>{</div>
<div class="line"><a id="l01424" name="l01424"></a><span class="lineno"> 1424</span>      <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>,</div>
<div class="line"><a id="l01425" name="l01425"></a><span class="lineno"> 1425</span>      rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#ac6a6edadd39800db410864ef06a004b2">create</a>(op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a6c0b8ce5ff714a34f0192f3aa60dc7ea">getLoc</a>(), op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ab2e11ba83ff765eb7595554f97aaaa75">getName</a>().<a class="code hl_function" href="classmlir_1_1OperationName.html#a2c83cffa9a4c4fb68436d9ee3497c226">getIdentifier</a>(), vecOperands,</div>
<div class="line"><a id="l01426" name="l01426"></a><span class="lineno"> 1426</span>                      resultTypes, op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a49874022040c036fac50ce8f07668a76">getAttrs</a>())};</div>
<div class="line"><a id="l01427" name="l01427"></a><span class="lineno"> 1427</span>}</div>
</div>
<div class="line"><a id="l01428" name="l01428"></a><span class="lineno"> 1428</span><span class="comment"></span> </div>
<div class="line"><a id="l01429" name="l01429"></a><span class="lineno"> 1429</span><span class="comment">/// Generic vectorization function that rewrites the body of a `linalgOp` into</span></div>
<div class="line"><a id="l01430" name="l01430"></a><span class="lineno"> 1430</span><span class="comment">/// vector form. Generic vectorization proceeds as follows:</span></div>
<div class="line"><a id="l01431" name="l01431"></a><span class="lineno"> 1431</span><span class="comment">///   1. Verify the `linalgOp` has one non-empty region.</span></div>
<div class="line"><a id="l01432" name="l01432"></a><span class="lineno"> 1432</span><span class="comment">///   2. Values defined above the region are mapped to themselves and will be</span></div>
<div class="line"><a id="l01433" name="l01433"></a><span class="lineno"> 1433</span><span class="comment">///   broadcasted on a per-need basis by their consumers.</span></div>
<div class="line"><a id="l01434" name="l01434"></a><span class="lineno"> 1434</span><span class="comment">///   3. Each region argument is vectorized into a vector.transfer_read (or 0-d</span></div>
<div class="line"><a id="l01435" name="l01435"></a><span class="lineno"> 1435</span><span class="comment">///   load).</span></div>
<div class="line"><a id="l01436" name="l01436"></a><span class="lineno"> 1436</span><span class="comment">///   TODO: Reuse opportunities for RAR dependencies.</span></div>
<div class="line"><a id="l01437" name="l01437"></a><span class="lineno"> 1437</span><span class="comment">///   4a. Register CustomVectorizationHook for YieldOp to capture the results.</span></div>
<div class="line"><a id="l01438" name="l01438"></a><span class="lineno"> 1438</span><span class="comment">///   4rewriter. Register CustomVectorizationHook for IndexOp to access the</span></div>
<div class="line"><a id="l01439" name="l01439"></a><span class="lineno"> 1439</span><span class="comment">///   iteration indices.</span></div>
<div class="line"><a id="l01440" name="l01440"></a><span class="lineno"> 1440</span><span class="comment">///   5. Iteratively call vectorizeOneOp on the region operations.</span></div>
<div class="line"><a id="l01441" name="l01441"></a><span class="lineno"> 1441</span><span class="comment">///</span></div>
<div class="line"><a id="l01442" name="l01442"></a><span class="lineno"> 1442</span><span class="comment">/// When `broadcastToMaximalCommonShape` is set to true, eager broadcasting is</span></div>
<div class="line"><a id="l01443" name="l01443"></a><span class="lineno"> 1443</span><span class="comment">/// performed to the maximal common vector size implied by the `linalgOp`</span></div>
<div class="line"><a id="l01444" name="l01444"></a><span class="lineno"> 1444</span><span class="comment">/// iteration space. This eager broadcasting is introduced in the</span></div>
<div class="line"><a id="l01445" name="l01445"></a><span class="lineno"> 1445</span><span class="comment">/// permutation_map of the vector.transfer_read operations. The eager</span></div>
<div class="line"><a id="l01446" name="l01446"></a><span class="lineno"> 1446</span><span class="comment">/// broadcasting makes it trivial to determine where broadcast, transposes and</span></div>
<div class="line"><a id="l01447" name="l01447"></a><span class="lineno"> 1447</span><span class="comment">/// reductions should occur, without any bookkeeping. The tradeoff is that, in</span></div>
<div class="line"><a id="l01448" name="l01448"></a><span class="lineno"> 1448</span><span class="comment">/// the absence of good canonicalizations, the amount of work increases.</span></div>
<div class="line"><a id="l01449" name="l01449"></a><span class="lineno"> 1449</span><span class="comment">/// This is not deemed a problem as we expect canonicalizations and foldings to</span></div>
<div class="line"><a id="l01450" name="l01450"></a><span class="lineno"> 1450</span><span class="comment">/// aggressively clean up the useless work.</span></div>
<div class="line"><a id="l01451" name="l01451"></a><span class="lineno"> 1451</span><span class="keyword">static</span> LogicalResult</div>
<div class="foldopen" id="foldopen01452" data-start="{" data-end="}">
<div class="line"><a id="l01452" name="l01452"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a35e1ec347850959af0bc7cbdf61b9da3"> 1452</a></span><a class="code hl_function" href="Vectorization_8cpp.html#a35e1ec347850959af0bc7cbdf61b9da3">vectorizeAsLinalgGeneric</a>(<a class="code hl_class" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, VectorizationState &amp;state,</div>
<div class="line"><a id="l01453" name="l01453"></a><span class="lineno"> 1453</span>                         LinalgOp linalgOp,</div>
<div class="line"><a id="l01454" name="l01454"></a><span class="lineno"> 1454</span>                         <a class="code hl_class" href="classllvm_1_1SmallVectorImpl.html">SmallVectorImpl&lt;Value&gt;</a> &amp;newResults) {</div>
<div class="line"><a id="l01455" name="l01455"></a><span class="lineno"> 1455</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorizing operation as linalg generic/n&quot;</span>;</div>
<div class="line"><a id="l01456" name="l01456"></a><span class="lineno"> 1456</span>  <a class="code hl_class" href="classmlir_1_1Block.html">Block</a> *block = linalgOp.getBlock();</div>
<div class="line"><a id="l01457" name="l01457"></a><span class="lineno"> 1457</span> </div>
<div class="line"><a id="l01458" name="l01458"></a><span class="lineno"> 1458</span>  <span class="comment">// 2. Values defined above the region can only be broadcast for now. Make them</span></div>
<div class="line"><a id="l01459" name="l01459"></a><span class="lineno"> 1459</span>  <span class="comment">// map to themselves.</span></div>
<div class="line"><a id="l01460" name="l01460"></a><span class="lineno"> 1460</span>  <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> bvm;</div>
<div class="line"><a id="l01461" name="l01461"></a><span class="lineno"> 1461</span>  <a class="code hl_typedef" href="namespacemlir.html#a70f70d8c0fc9767c6d18b1592cd9a7ee">SetVector&lt;Value&gt;</a> valuesSet;</div>
<div class="line"><a id="l01462" name="l01462"></a><span class="lineno"> 1462</span>  <a class="code hl_function" href="namespacemlir.html#a98f08e970a346cd42559db87f97f0b91">mlir::getUsedValuesDefinedAbove</a>(linalgOp-&gt;getRegion(0), valuesSet);</div>
<div class="line"><a id="l01463" name="l01463"></a><span class="lineno"> 1463</span>  bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(valuesSet.getArrayRef(), valuesSet.getArrayRef());</div>
<div class="line"><a id="l01464" name="l01464"></a><span class="lineno"> 1464</span> </div>
<div class="line"><a id="l01465" name="l01465"></a><span class="lineno"> 1465</span>  <span class="keywordflow">if</span> (linalgOp.getNumDpsInits() == 0)</div>
<div class="line"><a id="l01466" name="l01466"></a><span class="lineno"> 1466</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l01467" name="l01467"></a><span class="lineno"> 1467</span> </div>
<div class="line"><a id="l01468" name="l01468"></a><span class="lineno"> 1468</span>  <span class="comment">// 3. Turn all BBArgs into vector.transfer_read / load.</span></div>
<div class="line"><a id="l01469" name="l01469"></a><span class="lineno"> 1469</span>  <a class="code hl_class" href="classmlir_1_1Location.html">Location</a> loc = linalgOp.getLoc();</div>
<div class="line"><a id="l01470" name="l01470"></a><span class="lineno"> 1470</span>  <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> zero = <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0);</div>
<div class="line"><a id="l01471" name="l01471"></a><span class="lineno"> 1471</span>  <span class="keywordflow">for</span> (<a class="code hl_class" href="classmlir_1_1OpOperand.html">OpOperand</a> *opOperand : linalgOp.getOpOperandsMatchingBBargs()) {</div>
<div class="line"><a id="l01472" name="l01472"></a><span class="lineno"> 1472</span>    <a class="code hl_class" href="classmlir_1_1BlockArgument.html">BlockArgument</a> bbarg = linalgOp.getMatchingBlockArgument(opOperand);</div>
<div class="line"><a id="l01473" name="l01473"></a><span class="lineno"> 1473</span>    <span class="keywordflow">if</span> (linalgOp.isScalar(opOperand)) {</div>
<div class="line"><a id="l01474" name="l01474"></a><span class="lineno"> 1474</span>      bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(bbarg, opOperand-&gt;get());</div>
<div class="line"><a id="l01475" name="l01475"></a><span class="lineno"> 1475</span>      <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l01476" name="l01476"></a><span class="lineno"> 1476</span>    }</div>
<div class="line"><a id="l01477" name="l01477"></a><span class="lineno"> 1477</span> </div>
<div class="line"><a id="l01478" name="l01478"></a><span class="lineno"> 1478</span>    <span class="comment">// 3.a. Convert the indexing map for this input/output to a transfer read</span></div>
<div class="line"><a id="l01479" name="l01479"></a><span class="lineno"> 1479</span>    <span class="comment">// permutation map and masking map.</span></div>
<div class="line"><a id="l01480" name="l01480"></a><span class="lineno"> 1480</span>    <a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> indexingMap = linalgOp.getMatchingIndexingMap(opOperand);</div>
<div class="line"><a id="l01481" name="l01481"></a><span class="lineno"> 1481</span> </div>
<div class="line"><a id="l01482" name="l01482"></a><span class="lineno"> 1482</span>    <a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> readMap;</div>
<div class="line"><a id="l01483" name="l01483"></a><span class="lineno"> 1483</span>    VectorType readType;</div>
<div class="line"><a id="l01484" name="l01484"></a><span class="lineno"> 1484</span>    <a class="code hl_class" href="classmlir_1_1Type.html">Type</a> elemType = <a class="code hl_function" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(opOperand-&gt;get());</div>
<div class="line"><a id="l01485" name="l01485"></a><span class="lineno"> 1485</span>    <span class="keywordflow">if</span> (linalgOp.isDpsInput(opOperand)) {</div>
<div class="line"><a id="l01486" name="l01486"></a><span class="lineno"> 1486</span>      <span class="comment">// 3.a.i. For input reads we use the canonical vector shape.</span></div>
<div class="line"><a id="l01487" name="l01487"></a><span class="lineno"> 1487</span>      readMap = <a class="code hl_function" href="namespacemlir.html#a39612be2ef116102866d3bb9c6a8ca88">inverseAndBroadcastProjectedPermutation</a>(indexingMap);</div>
<div class="line"><a id="l01488" name="l01488"></a><span class="lineno"> 1488</span>      readType = state.getCanonicalVecType(elemType);</div>
<div class="line"><a id="l01489" name="l01489"></a><span class="lineno"> 1489</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l01490" name="l01490"></a><span class="lineno"> 1490</span>      <span class="comment">// 3.a.ii. For output reads (iteration-carried dependence, e.g.,</span></div>
<div class="line"><a id="l01491" name="l01491"></a><span class="lineno"> 1491</span>      <span class="comment">// reductions), the vector shape is computed by mapping the canonical</span></div>
<div class="line"><a id="l01492" name="l01492"></a><span class="lineno"> 1492</span>      <span class="comment">// vector shape to the output domain and back to the canonical domain.</span></div>
<div class="line"><a id="l01493" name="l01493"></a><span class="lineno"> 1493</span>      readMap = <a class="code hl_function" href="namespacemlir.html#a52b322818d83a2256d4e4391acbf78a2">inversePermutation</a>(<a class="code hl_function" href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">reindexIndexingMap</a>(indexingMap));</div>
<div class="line"><a id="l01494" name="l01494"></a><span class="lineno"> 1494</span>      readType =</div>
<div class="line"><a id="l01495" name="l01495"></a><span class="lineno"> 1495</span>          state.getCanonicalVecType(elemType, readMap.<a class="code hl_function" href="classmlir_1_1AffineMap.html#af2baf4561cf7d74a9959fd9e875c9a82">compose</a>(indexingMap));</div>
<div class="line"><a id="l01496" name="l01496"></a><span class="lineno"> 1496</span>    }</div>
<div class="line"><a id="l01497" name="l01497"></a><span class="lineno"> 1497</span> </div>
<div class="line"><a id="l01498" name="l01498"></a><span class="lineno"> 1498</span>    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>(linalgOp.getShape(opOperand).size(), zero);</div>
<div class="line"><a id="l01499" name="l01499"></a><span class="lineno"> 1499</span> </div>
<div class="line"><a id="l01500" name="l01500"></a><span class="lineno"> 1500</span>    <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *read = vector::TransferReadOp::create(</div>
<div class="line"><a id="l01501" name="l01501"></a><span class="lineno"> 1501</span>        rewriter, loc, readType, opOperand-&gt;get(), <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>,</div>
<div class="line"><a id="l01502" name="l01502"></a><span class="lineno"> 1502</span>        <span class="comment">/*padding=*/</span>std::nullopt, readMap);</div>
<div class="line"><a id="l01503" name="l01503"></a><span class="lineno"> 1503</span>    read = state.maskOperation(rewriter, read, linalgOp, indexingMap);</div>
<div class="line"><a id="l01504" name="l01504"></a><span class="lineno"> 1504</span>    <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> readValue = read-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0);</div>
<div class="line"><a id="l01505" name="l01505"></a><span class="lineno"> 1505</span> </div>
<div class="line"><a id="l01506" name="l01506"></a><span class="lineno"> 1506</span>    <span class="comment">// 3.b. If masked, set in-bounds to true. Masking guarantees that the access</span></div>
<div class="line"><a id="l01507" name="l01507"></a><span class="lineno"> 1507</span>    <span class="comment">// will be in-bounds.</span></div>
<div class="line"><a id="l01508" name="l01508"></a><span class="lineno"> 1508</span>    <span class="keywordflow">if</span> (<span class="keyword">auto</span> maskOp = dyn_cast&lt;vector::MaskingOpInterface&gt;(read)) {</div>
<div class="line"><a id="l01509" name="l01509"></a><span class="lineno"> 1509</span>      <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> inBounds(readType.getRank(), <span class="keyword">true</span>);</div>
<div class="line"><a id="l01510" name="l01510"></a><span class="lineno"> 1510</span>      cast&lt;vector::TransferReadOp&gt;(maskOp.getMaskableOp())</div>
<div class="line"><a id="l01511" name="l01511"></a><span class="lineno"> 1511</span>          .setInBoundsAttr(rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a id="l01512" name="l01512"></a><span class="lineno"> 1512</span>    }</div>
<div class="line"><a id="l01513" name="l01513"></a><span class="lineno"> 1513</span> </div>
<div class="line"><a id="l01514" name="l01514"></a><span class="lineno"> 1514</span>    <span class="comment">// 3.c. Not all ops support 0-d vectors, extract the scalar for now.</span></div>
<div class="line"><a id="l01515" name="l01515"></a><span class="lineno"> 1515</span>    <span class="comment">// TODO: remove this.</span></div>
<div class="line"><a id="l01516" name="l01516"></a><span class="lineno"> 1516</span>    <span class="keywordflow">if</span> (readType.getRank() == 0)</div>
<div class="line"><a id="l01517" name="l01517"></a><span class="lineno"> 1517</span>      readValue = vector::ExtractOp::create(rewriter, loc, readValue,</div>
<div class="line"><a id="l01518" name="l01518"></a><span class="lineno"> 1518</span>                                            <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a>());</div>
<div class="line"><a id="l01519" name="l01519"></a><span class="lineno"> 1519</span> </div>
<div class="line"><a id="l01520" name="l01520"></a><span class="lineno"> 1520</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;New vectorized bbarg(&quot;</span> &lt;&lt; bbarg.<a class="code hl_function" href="classmlir_1_1BlockArgument.html#a5396ce59c00cd3ef7a8a500c59af295c">getArgNumber</a>()</div>
<div class="line"><a id="l01521" name="l01521"></a><span class="lineno"> 1521</span>           &lt;&lt; <span class="stringliteral">&quot;): &quot;</span> &lt;&lt; readValue;</div>
<div class="line"><a id="l01522" name="l01522"></a><span class="lineno"> 1522</span>    bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(bbarg, readValue);</div>
<div class="line"><a id="l01523" name="l01523"></a><span class="lineno"> 1523</span>    bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(opOperand-&gt;get(), readValue);</div>
<div class="line"><a id="l01524" name="l01524"></a><span class="lineno"> 1524</span>  }</div>
<div class="line"><a id="l01525" name="l01525"></a><span class="lineno"> 1525</span> </div>
<div class="line"><a id="l01526" name="l01526"></a><span class="lineno"> 1526</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;CustomVectorizationHook&gt;</a> hooks;</div>
<div class="line"><a id="l01527" name="l01527"></a><span class="lineno"> 1527</span>  <span class="comment">// 4a. Register CustomVectorizationHook for yieldOp.</span></div>
<div class="line"><a id="l01528" name="l01528"></a><span class="lineno"> 1528</span>  <a class="code hl_typedef" href="Vectorization_8cpp.html#ac9d5de1ac70bcbcc2f773e554a39bd1e">CustomVectorizationHook</a> vectorizeYield =</div>
<div class="line"><a id="l01529" name="l01529"></a><span class="lineno"> 1529</span>      [&amp;](<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keyword">const</span> <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) -&gt; <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a> {</div>
<div class="line"><a id="l01530" name="l01530"></a><span class="lineno"> 1530</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="Vectorization_8cpp.html#af85a26f7c1860388d0e83d22745a27aa">vectorizeLinalgYield</a>(rewriter, op, bvm, state, linalgOp, newResults);</div>
<div class="line"><a id="l01531" name="l01531"></a><span class="lineno"> 1531</span>  };</div>
<div class="line"><a id="l01532" name="l01532"></a><span class="lineno"> 1532</span>  hooks.push_back(vectorizeYield);</div>
<div class="line"><a id="l01533" name="l01533"></a><span class="lineno"> 1533</span> </div>
<div class="line"><a id="l01534" name="l01534"></a><span class="lineno"> 1534</span>  <span class="comment">// 4b. Register CustomVectorizationHook for indexOp.</span></div>
<div class="line"><a id="l01535" name="l01535"></a><span class="lineno"> 1535</span>  <a class="code hl_typedef" href="Vectorization_8cpp.html#ac9d5de1ac70bcbcc2f773e554a39bd1e">CustomVectorizationHook</a> vectorizeIndex =</div>
<div class="line"><a id="l01536" name="l01536"></a><span class="lineno"> 1536</span>      [&amp;](<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keyword">const</span> <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) -&gt; <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a> {</div>
<div class="line"><a id="l01537" name="l01537"></a><span class="lineno"> 1537</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="Vectorization_8cpp.html#a280bd1ab81d418cd32713eeb0a2dfffd">vectorizeLinalgIndex</a>(rewriter, state, op, linalgOp);</div>
<div class="line"><a id="l01538" name="l01538"></a><span class="lineno"> 1538</span>  };</div>
<div class="line"><a id="l01539" name="l01539"></a><span class="lineno"> 1539</span>  hooks.push_back(vectorizeIndex);</div>
<div class="line"><a id="l01540" name="l01540"></a><span class="lineno"> 1540</span> </div>
<div class="line"><a id="l01541" name="l01541"></a><span class="lineno"> 1541</span>  <span class="comment">// 4c. Register CustomVectorizationHook for extractOp.</span></div>
<div class="line"><a id="l01542" name="l01542"></a><span class="lineno"> 1542</span>  <a class="code hl_typedef" href="Vectorization_8cpp.html#ac9d5de1ac70bcbcc2f773e554a39bd1e">CustomVectorizationHook</a> vectorizeExtract =</div>
<div class="line"><a id="l01543" name="l01543"></a><span class="lineno"> 1543</span>      [&amp;](<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *op, <span class="keyword">const</span> <a class="code hl_class" href="classmlir_1_1IRMapping.html">IRMapping</a> &amp;bvm) -&gt; <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a> {</div>
<div class="line"><a id="l01544" name="l01544"></a><span class="lineno"> 1544</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="Vectorization_8cpp.html#a26cb5e24425fdce30baaba6f7c0f5c84">vectorizeTensorExtract</a>(rewriter, state, op, linalgOp, bvm);</div>
<div class="line"><a id="l01545" name="l01545"></a><span class="lineno"> 1545</span>  };</div>
<div class="line"><a id="l01546" name="l01546"></a><span class="lineno"> 1546</span>  hooks.push_back(vectorizeExtract);</div>
<div class="line"><a id="l01547" name="l01547"></a><span class="lineno"> 1547</span> </div>
<div class="line"><a id="l01548" name="l01548"></a><span class="lineno"> 1548</span>  <span class="comment">// 5. Iteratively call `vectorizeOneOp` to each op in the slice.</span></div>
<div class="line"><a id="l01549" name="l01549"></a><span class="lineno"> 1549</span>  <span class="keywordflow">for</span> (<a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> &amp;op : block-&gt;<a class="code hl_function" href="classmlir_1_1Block.html#a522e33225c6c47ffd8a36588483e0bd9">getOperations</a>()) {</div>
<div class="line"><a id="l01550" name="l01550"></a><span class="lineno"> 1550</span>    <a class="code hl_struct" href="structVectorizationHookResult.html">VectorizationHookResult</a> <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a> =</div>
<div class="line"><a id="l01551" name="l01551"></a><span class="lineno"> 1551</span>        <a class="code hl_function" href="Vectorization_8cpp.html#a455f83de6534e53da06be057973f7e38">vectorizeOneOp</a>(rewriter, state, linalgOp, &amp;op, bvm, hooks);</div>
<div class="line"><a id="l01552" name="l01552"></a><span class="lineno"> 1552</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>.status == <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">VectorizationHookStatus::Failure</a>) {</div>
<div class="line"><a id="l01553" name="l01553"></a><span class="lineno"> 1553</span>      LDBG() &lt;&lt; <span class="stringliteral">&quot;failed to vectorize: &quot;</span> &lt;&lt; op;</div>
<div class="line"><a id="l01554" name="l01554"></a><span class="lineno"> 1554</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l01555" name="l01555"></a><span class="lineno"> 1555</span>    }</div>
<div class="line"><a id="l01556" name="l01556"></a><span class="lineno"> 1556</span>    <span class="keywordflow">if</span> (<a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>.status == <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">VectorizationHookStatus::NewOp</a>) {</div>
<div class="line"><a id="l01557" name="l01557"></a><span class="lineno"> 1557</span>      <a class="code hl_class" href="classmlir_1_1Operation.html">Operation</a> *maybeMaskedOp =</div>
<div class="line"><a id="l01558" name="l01558"></a><span class="lineno"> 1558</span>          state.maskOperation(rewriter, <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a>.newOp, linalgOp);</div>
<div class="line"><a id="l01559" name="l01559"></a><span class="lineno"> 1559</span>      LDBG() &lt;&lt; <span class="stringliteral">&quot;New vector op: &quot;</span> &lt;&lt; *maybeMaskedOp;</div>
<div class="line"><a id="l01560" name="l01560"></a><span class="lineno"> 1560</span>      bvm.<a class="code hl_function" href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">map</a>(op.<a class="code hl_function" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>(), maybeMaskedOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>());</div>
<div class="line"><a id="l01561" name="l01561"></a><span class="lineno"> 1561</span>    }</div>
<div class="line"><a id="l01562" name="l01562"></a><span class="lineno"> 1562</span>  }</div>
<div class="line"><a id="l01563" name="l01563"></a><span class="lineno"> 1563</span> </div>
<div class="line"><a id="l01564" name="l01564"></a><span class="lineno"> 1564</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l01565" name="l01565"></a><span class="lineno"> 1565</span>}</div>
</div>
<div class="line"><a id="l01566" name="l01566"></a><span class="lineno"> 1566</span><span class="comment"></span> </div>
<div class="line"><a id="l01567" name="l01567"></a><span class="lineno"> 1567</span><span class="comment">/// Determines whether a mask for xfer_write is trivially &quot;all true&quot;</span></div>
<div class="line"><a id="l01568" name="l01568"></a><span class="lineno"> 1568</span><span class="comment">///</span></div>
<div class="line"><a id="l01569" name="l01569"></a><span class="lineno"> 1569</span><span class="comment">/// Given all the inputs required to generate a mask (mask sizes and shapes),</span></div>
<div class="line"><a id="l01570" name="l01570"></a><span class="lineno"> 1570</span><span class="comment">/// and an xfer_write operation (write indices and the destination tensor</span></div>
<div class="line"><a id="l01571" name="l01571"></a><span class="lineno"> 1571</span><span class="comment">/// shape), determines whether the corresponding mask would be trivially</span></div>
<div class="line"><a id="l01572" name="l01572"></a><span class="lineno"> 1572</span><span class="comment">/// foldable (i.e., trivially &quot;all true&quot;).</span></div>
<div class="line"><a id="l01573" name="l01573"></a><span class="lineno"> 1573</span><span class="comment">///</span></div>
<div class="line"><a id="l01574" name="l01574"></a><span class="lineno"> 1574</span><span class="comment">/// Use this method to avoid generating spurious masks and relaying on</span></div>
<div class="line"><a id="l01575" name="l01575"></a><span class="lineno"> 1575</span><span class="comment">/// vectorization post-processing to remove them.</span></div>
<div class="line"><a id="l01576" name="l01576"></a><span class="lineno"> 1576</span><span class="comment">///</span></div>
<div class="line"><a id="l01577" name="l01577"></a><span class="lineno"> 1577</span><span class="comment">/// Pre-conditions for a mask to be trivially foldable:</span></div>
<div class="line"><a id="l01578" name="l01578"></a><span class="lineno"> 1578</span><span class="comment">///   * All involved shapes (mask + destination tensor) are static.</span></div>
<div class="line"><a id="l01579" name="l01579"></a><span class="lineno"> 1579</span><span class="comment">///   * All write indices are constant.</span></div>
<div class="line"><a id="l01580" name="l01580"></a><span class="lineno"> 1580</span><span class="comment">///   * All mask sizes are constant (including `arith.constant`).</span></div>
<div class="line"><a id="l01581" name="l01581"></a><span class="lineno"> 1581</span><span class="comment">///</span></div>
<div class="line"><a id="l01582" name="l01582"></a><span class="lineno"> 1582</span><span class="comment">/// If the pre-conditions are met, the method checks for each destination</span></div>
<div class="line"><a id="l01583" name="l01583"></a><span class="lineno"> 1583</span><span class="comment">/// dimension `d`:</span></div>
<div class="line"><a id="l01584" name="l01584"></a><span class="lineno"> 1584</span><span class="comment">///   (1) destDimSize[rankDiff + d] &lt;= maskShape[d]</span></div>
<div class="line"><a id="l01585" name="l01585"></a><span class="lineno"> 1585</span><span class="comment">///   (2) destDimSize[rankDiff + d] &lt;= writeIndex[d] + maskSize[d]</span></div>
<div class="line"><a id="l01586" name="l01586"></a><span class="lineno"> 1586</span><span class="comment">///</span></div>
<div class="line"><a id="l01587" name="l01587"></a><span class="lineno"> 1587</span><span class="comment">/// rankDiff = rank(dest) - rank(mask).</span></div>
<div class="line"><a id="l01588" name="l01588"></a><span class="lineno"> 1588</span><span class="comment">///</span></div>
<div class="line"><a id="l01589" name="l01589"></a><span class="lineno"> 1589</span><span class="comment">/// This method takes a conservative view: it may return false even if the mask</span></div>
<div class="line"><a id="l01590" name="l01590"></a><span class="lineno"> 1590</span><span class="comment">/// is technically foldable.</span></div>
<div class="line"><a id="l01591" name="l01591"></a><span class="lineno"> 1591</span><span class="comment">///</span></div>
<div class="line"><a id="l01592" name="l01592"></a><span class="lineno"> 1592</span><span class="comment">/// EXAMPLE 1 (trivially foldable, all shapes match, mask sizes match the shape</span></div>
<div class="line"><a id="l01593" name="l01593"></a><span class="lineno"> 1593</span><span class="comment">/// of the dest tensor):</span></div>
<div class="line"><a id="l01594" name="l01594"></a><span class="lineno"> 1594</span><span class="comment">///   %c0 = arith.constant 0 : index</span></div>
<div class="line"><a id="l01595" name="l01595"></a><span class="lineno"> 1595</span><span class="comment">///   %mask = vector.create_mask 5, 1</span></div>
<div class="line"><a id="l01596" name="l01596"></a><span class="lineno"> 1596</span><span class="comment">///   vector.mask %mask {</span></div>
<div class="line"><a id="l01597" name="l01597"></a><span class="lineno"> 1597</span><span class="comment">///     vector.transfer_write %vecToStore_1, %dest{[%c0, %c0]</span></div>
<div class="line"><a id="l01598" name="l01598"></a><span class="lineno"> 1598</span><span class="comment">///       {in_bounds = [true, true]}</span></div>
<div class="line"><a id="l01599" name="l01599"></a><span class="lineno"> 1599</span><span class="comment">///     : vector&lt;5x1xi32&gt;, tensor&lt;5x1xi32&gt;</span></div>
<div class="line"><a id="l01600" name="l01600"></a><span class="lineno"> 1600</span><span class="comment">///   }</span></div>
<div class="line"><a id="l01601" name="l01601"></a><span class="lineno"> 1601</span><span class="comment">///</span></div>
<div class="line"><a id="l01602" name="l01602"></a><span class="lineno"> 1602</span><span class="comment">/// EXAMPLE 2 (not trivially foldable - vector shape exceeds the tensor shape,</span></div>
<div class="line"><a id="l01603" name="l01603"></a><span class="lineno"> 1603</span><span class="comment">/// mask is required to avoid out-of-bounds write):</span></div>
<div class="line"><a id="l01604" name="l01604"></a><span class="lineno"> 1604</span><span class="comment">///   %c0 = arith.constant 0 : index</span></div>
<div class="line"><a id="l01605" name="l01605"></a><span class="lineno"> 1605</span><span class="comment">///   %mask = vector.create_mask 5, 1</span></div>
<div class="line"><a id="l01606" name="l01606"></a><span class="lineno"> 1606</span><span class="comment">///   vector.mask %mask {</span></div>
<div class="line"><a id="l01607" name="l01607"></a><span class="lineno"> 1607</span><span class="comment">///     vector.transfer_write %vecToStore_2, %dest[%c0, %c0]</span></div>
<div class="line"><a id="l01608" name="l01608"></a><span class="lineno"> 1608</span><span class="comment">///      {in_bounds = [true, true]}</span></div>
<div class="line"><a id="l01609" name="l01609"></a><span class="lineno"> 1609</span><span class="comment">///     : vector&lt;8x1xi32&gt;, tensor&lt;5x1xi32&gt;</span></div>
<div class="line"><a id="l01610" name="l01610"></a><span class="lineno"> 1610</span><span class="comment">///   }</span></div>
<div class="line"><a id="l01611" name="l01611"></a><span class="lineno"> 1611</span><span class="comment">///</span></div>
<div class="line"><a id="l01612" name="l01612"></a><span class="lineno"> 1612</span><span class="comment">/// TODO: Re-use in createReadOrMaskedRead</span></div>
<div class="foldopen" id="foldopen01613" data-start="{" data-end="}">
<div class="line"><a id="l01613" name="l01613"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a1bedce144a30ca3ef5eac6628b35d4a9"> 1613</a></span><span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code hl_function" href="Vectorization_8cpp.html#a1bedce144a30ca3ef5eac6628b35d4a9">isMaskTriviallyFoldable</a>(<a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;OpFoldResult&gt;</a> &amp;maskSizes,</div>
<div class="line"><a id="l01614" name="l01614"></a><span class="lineno"> 1614</span>                                    <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> &amp;writeIdxs,</div>
<div class="line"><a id="l01615" name="l01615"></a><span class="lineno"> 1615</span>                                    <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> destShape,</div>
<div class="line"><a id="l01616" name="l01616"></a><span class="lineno"> 1616</span>                                    <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int64_t&gt;</a> maskShape) {</div>
<div class="line"><a id="l01617" name="l01617"></a><span class="lineno"> 1617</span>  <span class="comment">// Masking is unavoidable in the case of dynamic tensors.</span></div>
<div class="line"><a id="l01618" name="l01618"></a><span class="lineno"> 1618</span>  <span class="keywordflow">if</span> (ShapedType::isDynamicShape(destShape))</div>
<div class="line"><a id="l01619" name="l01619"></a><span class="lineno"> 1619</span>    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l01620" name="l01620"></a><span class="lineno"> 1620</span> </div>
<div class="line"><a id="l01621" name="l01621"></a><span class="lineno"> 1621</span>  <span class="comment">// Collect all constant mask sizes.</span></div>
<div class="line"><a id="l01622" name="l01622"></a><span class="lineno"> 1622</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t, 4&gt;</a> cstMaskSizes;</div>
<div class="line"><a id="l01623" name="l01623"></a><span class="lineno"> 1623</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, dimSize] : llvm::enumerate(maskSizes)) {</div>
<div class="line"><a id="l01624" name="l01624"></a><span class="lineno"> 1624</span>    <span class="keywordflow">if</span> (<span class="keyword">auto</span> intSize = <a class="code hl_function" href="namespacemlir.html#a22bfcc5fa9deffb32e7c39183f732c90">getConstantIntValue</a>(dimSize)) {</div>
<div class="line"><a id="l01625" name="l01625"></a><span class="lineno"> 1625</span>      cstMaskSizes.push_back(*intSize);</div>
<div class="line"><a id="l01626" name="l01626"></a><span class="lineno"> 1626</span>    }</div>
<div class="line"><a id="l01627" name="l01627"></a><span class="lineno"> 1627</span>  }</div>
<div class="line"><a id="l01628" name="l01628"></a><span class="lineno"> 1628</span> </div>
<div class="line"><a id="l01629" name="l01629"></a><span class="lineno"> 1629</span>  <span class="comment">// If any of the mask sizes is non-constant, bail out.</span></div>
<div class="line"><a id="l01630" name="l01630"></a><span class="lineno"> 1630</span>  <span class="keywordflow">if</span> (cstMaskSizes.size() != maskShape.size())</div>
<div class="line"><a id="l01631" name="l01631"></a><span class="lineno"> 1631</span>    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l01632" name="l01632"></a><span class="lineno"> 1632</span> </div>
<div class="line"><a id="l01633" name="l01633"></a><span class="lineno"> 1633</span>  <span class="comment">// Collect all constant write indices.</span></div>
<div class="line"><a id="l01634" name="l01634"></a><span class="lineno"> 1634</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t, 4&gt;</a> cstWriteIdxs;</div>
<div class="line"><a id="l01635" name="l01635"></a><span class="lineno"> 1635</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, idx] : llvm::enumerate(writeIdxs)) {</div>
<div class="line"><a id="l01636" name="l01636"></a><span class="lineno"> 1636</span>    APSInt intVal;</div>
<div class="line"><a id="l01637" name="l01637"></a><span class="lineno"> 1637</span>    <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir.html#a0190228b09e7b51a4bc1e013c01d404c">matchPattern</a>(idx, <a class="code hl_function" href="namespacemlir.html#a091c0686ba6d6f3ad4af9db1aea8063f">m_ConstantInt</a>(&amp;intVal))) {</div>
<div class="line"><a id="l01638" name="l01638"></a><span class="lineno"> 1638</span>      cstWriteIdxs.push_back(intVal.getSExtValue());</div>
<div class="line"><a id="l01639" name="l01639"></a><span class="lineno"> 1639</span>    }</div>
<div class="line"><a id="l01640" name="l01640"></a><span class="lineno"> 1640</span>  }</div>
<div class="line"><a id="l01641" name="l01641"></a><span class="lineno"> 1641</span> </div>
<div class="line"><a id="l01642" name="l01642"></a><span class="lineno"> 1642</span>  <span class="comment">// If any of the write indices is non-constant, bail out.</span></div>
<div class="line"><a id="l01643" name="l01643"></a><span class="lineno"> 1643</span>  <span class="keywordflow">if</span> (cstWriteIdxs.size() != destShape.size())</div>
<div class="line"><a id="l01644" name="l01644"></a><span class="lineno"> 1644</span>    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l01645" name="l01645"></a><span class="lineno"> 1645</span> </div>
<div class="line"><a id="l01646" name="l01646"></a><span class="lineno"> 1646</span>  <span class="comment">// Go over all destination dims and check (1) and (2). Take into account that:</span></div>
<div class="line"><a id="l01647" name="l01647"></a><span class="lineno"> 1647</span>  <span class="comment">//  * The number of mask sizes will match the rank of the vector to store.</span></div>
<div class="line"><a id="l01648" name="l01648"></a><span class="lineno"> 1648</span>  <span class="comment">//    This could be lower than the rank of the destination tensor.</span></div>
<div class="line"><a id="l01649" name="l01649"></a><span class="lineno"> 1649</span>  <span class="comment">//  * Mask sizes could be larger than the corresponding mask shape (hence</span></div>
<div class="line"><a id="l01650" name="l01650"></a><span class="lineno"> 1650</span>  <span class="comment">//  `clamp`).</span></div>
<div class="line"><a id="l01651" name="l01651"></a><span class="lineno"> 1651</span>  <span class="comment">// TODO: The 2nd item should be rejected by the verifier.</span></div>
<div class="line"><a id="l01652" name="l01652"></a><span class="lineno"> 1652</span>  <a class="code hl_class" href="classint64__t.html">int64_t</a> rankDiff = destShape.size() - cstMaskSizes.size();</div>
<div class="line"><a id="l01653" name="l01653"></a><span class="lineno"> 1653</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, idx] : llvm::enumerate(cstMaskSizes)) {</div>
<div class="line"><a id="l01654" name="l01654"></a><span class="lineno"> 1654</span>    <span class="keywordflow">if</span> (<span class="comment">/*(1)*/</span> maskShape[i] &gt; destShape[rankDiff + i] ||</div>
<div class="line"><a id="l01655" name="l01655"></a><span class="lineno"> 1655</span>        <span class="comment">/*(2)*/</span> destShape[rankDiff + i] &lt;</div>
<div class="line"><a id="l01656" name="l01656"></a><span class="lineno"> 1656</span>            (std::clamp(cstMaskSizes[i], <a class="code hl_class" href="classint64__t.html">int64_t</a>(0), maskShape[i]) +</div>
<div class="line"><a id="l01657" name="l01657"></a><span class="lineno"> 1657</span>             cstWriteIdxs[i]))</div>
<div class="line"><a id="l01658" name="l01658"></a><span class="lineno"> 1658</span>      <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l01659" name="l01659"></a><span class="lineno"> 1659</span>  }</div>
<div class="line"><a id="l01660" name="l01660"></a><span class="lineno"> 1660</span> </div>
<div class="line"><a id="l01661" name="l01661"></a><span class="lineno"> 1661</span>  <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l01662" name="l01662"></a><span class="lineno"> 1662</span>}</div>
</div>
<div class="line"><a id="l01663" name="l01663"></a><span class="lineno"> 1663</span><span class="comment"></span> </div>
<div class="line"><a id="l01664" name="l01664"></a><span class="lineno"> 1664</span><span class="comment">/// Creates an optionally masked TransferWriteOp</span></div>
<div class="line"><a id="l01665" name="l01665"></a><span class="lineno"> 1665</span><span class="comment">///</span></div>
<div class="line"><a id="l01666" name="l01666"></a><span class="lineno"> 1666</span><span class="comment">/// Generates the following operation:</span></div>
<div class="line"><a id="l01667" name="l01667"></a><span class="lineno"> 1667</span><span class="comment">///   %res = vector.transfer_write %vecToStore into %dest</span></div>
<div class="line"><a id="l01668" name="l01668"></a><span class="lineno"> 1668</span><span class="comment">///</span></div>
<div class="line"><a id="l01669" name="l01669"></a><span class="lineno"> 1669</span><span class="comment">/// If shape(vecToStore) != shape(dest), masking is used to ensure correctness:</span></div>
<div class="line"><a id="l01670" name="l01670"></a><span class="lineno"> 1670</span><span class="comment">///</span></div>
<div class="line"><a id="l01671" name="l01671"></a><span class="lineno"> 1671</span><span class="comment">///   %mask = vector.create_mask(%destShape) : %vecToStoreShape</span></div>
<div class="line"><a id="l01672" name="l01672"></a><span class="lineno"> 1672</span><span class="comment">///   %res = vector.mask %mask {</span></div>
<div class="line"><a id="l01673" name="l01673"></a><span class="lineno"> 1673</span><span class="comment">///     vector.transfer_write %vecToStore into %dest</span></div>
<div class="line"><a id="l01674" name="l01674"></a><span class="lineno"> 1674</span><span class="comment">///   }</span></div>
<div class="line"><a id="l01675" name="l01675"></a><span class="lineno"> 1675</span><span class="comment">///</span></div>
<div class="line"><a id="l01676" name="l01676"></a><span class="lineno"> 1676</span><span class="comment">/// The mask shape is identical to `vecToStore` (with the element type ==</span></div>
<div class="line"><a id="l01677" name="l01677"></a><span class="lineno"> 1677</span><span class="comment">/// i1), and the mask values are based on the shape of the `dest` tensor.</span></div>
<div class="line"><a id="l01678" name="l01678"></a><span class="lineno"> 1678</span><span class="comment">///</span></div>
<div class="line"><a id="l01679" name="l01679"></a><span class="lineno"> 1679</span><span class="comment">/// If `useInBoundsInsteadOfMasking` is set to `true`, the `in_bounds` attribute</span></div>
<div class="line"><a id="l01680" name="l01680"></a><span class="lineno"> 1680</span><span class="comment">/// is used instead of masking:</span></div>
<div class="line"><a id="l01681" name="l01681"></a><span class="lineno"> 1681</span><span class="comment">///</span></div>
<div class="line"><a id="l01682" name="l01682"></a><span class="lineno"> 1682</span><span class="comment">///   %write = vector.transfer_write %vecToStore into %dest</span></div>
<div class="line"><a id="l01683" name="l01683"></a><span class="lineno"> 1683</span><span class="comment">///   in_bounds_flags = (...)</span></div>
<div class="line"><a id="l01684" name="l01684"></a><span class="lineno"> 1684</span><span class="comment">///   %res = vector.transfer_write %input into %dest</span></div>
<div class="line"><a id="l01685" name="l01685"></a><span class="lineno"> 1685</span><span class="comment">///       {in_bounds = in_bounds_flags}</span></div>
<div class="line"><a id="l01686" name="l01686"></a><span class="lineno"> 1686</span><span class="comment">///</span></div>
<div class="line"><a id="l01687" name="l01687"></a><span class="lineno"> 1687</span><span class="comment">/// Finally, `writeIndices` specifies the offsets to use. If empty, all indices</span></div>
<div class="line"><a id="l01688" name="l01688"></a><span class="lineno"> 1688</span><span class="comment">/// are set to 0.</span></div>
<div class="line"><a id="l01689" name="l01689"></a><span class="lineno"> 1689</span><span class="keyword">static</span> Operation *</div>
<div class="foldopen" id="foldopen01690" data-start="{" data-end="}">
<div class="line"><a id="l01690" name="l01690"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a2d04989901c1df355793bb8a71328797"> 1690</a></span><a class="code hl_function" href="Vectorization_8cpp.html#a2d04989901c1df355793bb8a71328797">createWriteOrMaskedWrite</a>(<a class="code hl_class" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;builder, <a class="code hl_class" href="classmlir_1_1Location.html">Location</a> loc, <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> vecToStore,</div>
<div class="line"><a id="l01691" name="l01691"></a><span class="lineno"> 1691</span>                         <a class="code hl_class" href="classmlir_1_1Value.html">Value</a> dest, <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> writeIndices = {},</div>
<div class="line"><a id="l01692" name="l01692"></a><span class="lineno"> 1692</span>                         <span class="keywordtype">bool</span> useInBoundsInsteadOfMasking = <span class="keyword">false</span>) {</div>
<div class="line"><a id="l01693" name="l01693"></a><span class="lineno"> 1693</span> </div>
<div class="line"><a id="l01694" name="l01694"></a><span class="lineno"> 1694</span>  ShapedType destType = cast&lt;ShapedType&gt;(dest.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a id="l01695" name="l01695"></a><span class="lineno"> 1695</span>  int64_t destRank = destType.getRank();</div>
<div class="line"><a id="l01696" name="l01696"></a><span class="lineno"> 1696</span>  <span class="keyword">auto</span> destShape = destType.getShape();</div>
<div class="line"><a id="l01697" name="l01697"></a><span class="lineno"> 1697</span> </div>
<div class="line"><a id="l01698" name="l01698"></a><span class="lineno"> 1698</span>  VectorType vecToStoreType = cast&lt;VectorType&gt;(vecToStore.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a id="l01699" name="l01699"></a><span class="lineno"> 1699</span>  int64_t vecToStoreRank = vecToStoreType.getRank();</div>
<div class="line"><a id="l01700" name="l01700"></a><span class="lineno"> 1700</span>  <span class="keyword">auto</span> vecToStoreShape = vecToStoreType.getShape();</div>
<div class="line"><a id="l01701" name="l01701"></a><span class="lineno"> 1701</span> </div>
<div class="line"><a id="l01702" name="l01702"></a><span class="lineno"> 1702</span>  <span class="comment">// Compute the in_bounds attribute</span></div>
<div class="line"><a id="l01703" name="l01703"></a><span class="lineno"> 1703</span>  SmallVector&lt;bool&gt; inBoundsVal(vecToStoreRank, <span class="keyword">true</span>);</div>
<div class="line"><a id="l01704" name="l01704"></a><span class="lineno"> 1704</span>  <span class="keywordflow">if</span> (useInBoundsInsteadOfMasking) {</div>
<div class="line"><a id="l01705" name="l01705"></a><span class="lineno"> 1705</span>    <span class="comment">// Update the inBounds attribute.</span></div>
<div class="line"><a id="l01706" name="l01706"></a><span class="lineno"> 1706</span>    <span class="comment">// FIXME: This computation is too weak - it ignores the write indices.</span></div>
<div class="line"><a id="l01707" name="l01707"></a><span class="lineno"> 1707</span>    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; vecToStoreRank; i++)</div>
<div class="line"><a id="l01708" name="l01708"></a><span class="lineno"> 1708</span>      inBoundsVal[i] =</div>
<div class="line"><a id="l01709" name="l01709"></a><span class="lineno"> 1709</span>          (destShape[destRank - vecToStoreRank + i] &gt;= vecToStoreShape[i]) &amp;&amp;</div>
<div class="line"><a id="l01710" name="l01710"></a><span class="lineno"> 1710</span>          ShapedType::isStatic(destShape[destRank - vecToStoreRank + i]);</div>
<div class="line"><a id="l01711" name="l01711"></a><span class="lineno"> 1711</span>  }</div>
<div class="line"><a id="l01712" name="l01712"></a><span class="lineno"> 1712</span> </div>
<div class="line"><a id="l01713" name="l01713"></a><span class="lineno"> 1713</span>  <span class="comment">// If missing, initialize the write indices to 0.</span></div>
<div class="line"><a id="l01714" name="l01714"></a><span class="lineno"> 1714</span>  assert((writeIndices.empty() ||</div>
<div class="line"><a id="l01715" name="l01715"></a><span class="lineno"> 1715</span>          writeIndices.size() == <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(destRank)) &amp;&amp;</div>
<div class="line"><a id="l01716" name="l01716"></a><span class="lineno"> 1716</span>         <span class="stringliteral">&quot;Invalid number of write indices!&quot;</span>);</div>
<div class="line"><a id="l01717" name="l01717"></a><span class="lineno"> 1717</span>  <span class="keywordflow">if</span> (writeIndices.empty()) {</div>
<div class="line"><a id="l01718" name="l01718"></a><span class="lineno"> 1718</span>    <span class="keyword">auto</span> zero = <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(builder, loc, 0);</div>
<div class="line"><a id="l01719" name="l01719"></a><span class="lineno"> 1719</span>    writeIndices.assign(destRank, zero);</div>
<div class="line"><a id="l01720" name="l01720"></a><span class="lineno"> 1720</span>  }</div>
<div class="line"><a id="l01721" name="l01721"></a><span class="lineno"> 1721</span> </div>
<div class="line"><a id="l01722" name="l01722"></a><span class="lineno"> 1722</span>  <span class="comment">// Generate the xfer_write Op</span></div>
<div class="line"><a id="l01723" name="l01723"></a><span class="lineno"> 1723</span>  Operation *write = vector::TransferWriteOp::create(builder, loc,</div>
<div class="line"><a id="l01724" name="l01724"></a><span class="lineno"> 1724</span>                                                     <span class="comment">/*vector=*/</span>vecToStore,</div>
<div class="line"><a id="l01725" name="l01725"></a><span class="lineno"> 1725</span>                                                     <span class="comment">/*source=*/</span>dest,</div>
<div class="line"><a id="l01726" name="l01726"></a><span class="lineno"> 1726</span>                                                     <span class="comment">/*indices=*/</span>writeIndices,</div>
<div class="line"><a id="l01727" name="l01727"></a><span class="lineno"> 1727</span>                                                     <span class="comment">/*inBounds=*/</span>inBoundsVal);</div>
<div class="line"><a id="l01728" name="l01728"></a><span class="lineno"> 1728</span> </div>
<div class="line"><a id="l01729" name="l01729"></a><span class="lineno"> 1729</span>  <span class="comment">// If masking is disabled, exit.</span></div>
<div class="line"><a id="l01730" name="l01730"></a><span class="lineno"> 1730</span>  <span class="keywordflow">if</span> (useInBoundsInsteadOfMasking)</div>
<div class="line"><a id="l01731" name="l01731"></a><span class="lineno"> 1731</span>    <span class="keywordflow">return</span> write;</div>
<div class="line"><a id="l01732" name="l01732"></a><span class="lineno"> 1732</span> </div>
<div class="line"><a id="l01733" name="l01733"></a><span class="lineno"> 1733</span>  <span class="comment">// Check if masking is needed. If not, exit.</span></div>
<div class="line"><a id="l01734" name="l01734"></a><span class="lineno"> 1734</span>  <span class="keywordflow">if</span> (llvm::equal(vecToStoreShape, destShape.take_back(vecToStoreRank)))</div>
<div class="line"><a id="l01735" name="l01735"></a><span class="lineno"> 1735</span>    <span class="keywordflow">return</span> write;</div>
<div class="line"><a id="l01736" name="l01736"></a><span class="lineno"> 1736</span> </div>
<div class="line"><a id="l01737" name="l01737"></a><span class="lineno"> 1737</span>  <span class="comment">// Compute the mask and mask the write Op.</span></div>
<div class="line"><a id="l01738" name="l01738"></a><span class="lineno"> 1738</span>  <span class="keyword">auto</span> writeMaskType = VectorType::get(vecToStoreShape, builder.<a class="code hl_function" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>(),</div>
<div class="line"><a id="l01739" name="l01739"></a><span class="lineno"> 1739</span>                                       vecToStoreType.getScalableDims());</div>
<div class="line"><a id="l01740" name="l01740"></a><span class="lineno"> 1740</span> </div>
<div class="line"><a id="l01741" name="l01741"></a><span class="lineno"> 1741</span>  SmallVector&lt;OpFoldResult&gt; destSizes =</div>
<div class="line"><a id="l01742" name="l01742"></a><span class="lineno"> 1742</span>      isa&lt;MemRefType&gt;(dest.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>())</div>
<div class="line"><a id="l01743" name="l01743"></a><span class="lineno"> 1743</span>          ? <a class="code hl_function" href="namespacemlir_1_1memref.html#ab0c13e32e47a301b4ccac4b27404de51">memref::getMixedSizes</a>(builder, loc, dest)</div>
<div class="line"><a id="l01744" name="l01744"></a><span class="lineno"> 1744</span>          : tensor::<a class="code hl_function" href="namespacemlir_1_1memref.html#ab0c13e32e47a301b4ccac4b27404de51">getMixedSizes</a>(builder, loc, dest);</div>
<div class="line"><a id="l01745" name="l01745"></a><span class="lineno"> 1745</span>  SmallVector&lt;OpFoldResult&gt; maskSizes(destSizes.end() - vecToStoreRank,</div>
<div class="line"><a id="l01746" name="l01746"></a><span class="lineno"> 1746</span>                                      destSizes.end());</div>
<div class="line"><a id="l01747" name="l01747"></a><span class="lineno"> 1747</span> </div>
<div class="line"><a id="l01748" name="l01748"></a><span class="lineno"> 1748</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="Vectorization_8cpp.html#a1bedce144a30ca3ef5eac6628b35d4a9">isMaskTriviallyFoldable</a>(maskSizes, writeIndices, destShape,</div>
<div class="line"><a id="l01749" name="l01749"></a><span class="lineno"> 1749</span>                              vecToStoreShape))</div>
<div class="line"><a id="l01750" name="l01750"></a><span class="lineno"> 1750</span>    <span class="keywordflow">return</span> write;</div>
<div class="line"><a id="l01751" name="l01751"></a><span class="lineno"> 1751</span> </div>
<div class="line"><a id="l01752" name="l01752"></a><span class="lineno"> 1752</span>  Value maskForWrite =</div>
<div class="line"><a id="l01753" name="l01753"></a><span class="lineno"> 1753</span>      builder.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a9bfa9ca1c08777d5eba6276c24c0cf9a">createOrFold</a>&lt;vector::CreateMaskOp&gt;(loc, writeMaskType, maskSizes);</div>
<div class="line"><a id="l01754" name="l01754"></a><span class="lineno"> 1754</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="namespacemlir_1_1vector.html#a21bfcee9196fe1a2cfa548b7df8193a9">mlir::vector::maskOperation</a>(builder, write, maskForWrite);</div>
<div class="line"><a id="l01755" name="l01755"></a><span class="lineno"> 1755</span>}</div>
</div>
<div class="line"><a id="l01756" name="l01756"></a><span class="lineno"> 1756</span><span class="comment"></span> </div>
<div class="line"><a id="l01757" name="l01757"></a><span class="lineno"> 1757</span><span class="comment">/// Given the re-associations, &quot;collapses&quot; the input Vector type</span></div>
<div class="line"><a id="l01758" name="l01758"></a><span class="lineno"> 1758</span><span class="comment">///</span></div>
<div class="line"><a id="l01759" name="l01759"></a><span class="lineno"> 1759</span><span class="comment">/// This is similar to CollapseShapeOp::inferCollapsedType with two notable</span></div>
<div class="line"><a id="l01760" name="l01760"></a><span class="lineno"> 1760</span><span class="comment">/// differences:</span></div>
<div class="line"><a id="l01761" name="l01761"></a><span class="lineno"> 1761</span><span class="comment">///   * We can safely assume that there are no dynamic sizes.</span></div>
<div class="line"><a id="l01762" name="l01762"></a><span class="lineno"> 1762</span><span class="comment">///   * Scalable flags are updated alongside regular dims.</span></div>
<div class="line"><a id="l01763" name="l01763"></a><span class="lineno"> 1763</span><span class="comment">///</span></div>
<div class="line"><a id="l01764" name="l01764"></a><span class="lineno"> 1764</span><span class="comment">/// When collapsing scalable flags, conservatively avoids cases with two</span></div>
<div class="line"><a id="l01765" name="l01765"></a><span class="lineno"> 1765</span><span class="comment">/// scalable dims. We could re-visit this in the future.</span></div>
<div class="line"><a id="l01766" name="l01766"></a><span class="lineno"> 1766</span><span class="comment">///</span></div>
<div class="line"><a id="l01767" name="l01767"></a><span class="lineno"> 1767</span><span class="comment">/// EXAMPLE:</span></div>
<div class="line"><a id="l01768" name="l01768"></a><span class="lineno"> 1768</span><span class="comment">///  type = vector&lt;4x16x[8]x16xf32&gt;</span></div>
<div class="line"><a id="l01769" name="l01769"></a><span class="lineno"> 1769</span><span class="comment">///  reassociation =  [(d0, d1, d2, d3) -&gt; (d0, d1),</span></div>
<div class="line"><a id="l01770" name="l01770"></a><span class="lineno"> 1770</span><span class="comment">///                    (d0, d1, d2, d3) -&gt; (d2, d3)]</span></div>
<div class="line"><a id="l01771" name="l01771"></a><span class="lineno"> 1771</span><span class="comment">///  Result:</span></div>
<div class="line"><a id="l01772" name="l01772"></a><span class="lineno"> 1772</span><span class="comment">///   vector&lt;64x[128]xf32&gt;</span></div>
<div class="foldopen" id="foldopen01773" data-start="{" data-end="}">
<div class="line"><a id="l01773" name="l01773"></a><span class="lineno"><a class="line" href="Vectorization_8cpp.html#a8019302085ef04a05864f2bb3f198f5c"> 1773</a></span><span class="keyword">static</span> VectorType <a class="code hl_function" href="Vectorization_8cpp.html#a8019302085ef04a05864f2bb3f198f5c">getCollapsedVecType</a>(VectorType type,</div>
<div class="line"><a id="l01774" name="l01774"></a><span class="lineno"> 1774</span>                                      <a class="code hl_class" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;AffineMap&gt;</a> reassociation) {</div>
<div class="line"><a id="l01775" name="l01775"></a><span class="lineno"> 1775</span>  assert(type.getNumScalableDims() &lt; 2 &amp;&amp;</div>
<div class="line"><a id="l01776" name="l01776"></a><span class="lineno"> 1776</span>         <span class="stringliteral">&quot;Collapsing more than 1 scalable dim is not supported ATM&quot;</span>);</div>
<div class="line"><a id="l01777" name="l01777"></a><span class="lineno"> 1777</span> </div>
<div class="line"><a id="l01778" name="l01778"></a><span class="lineno"> 1778</span>  <span class="comment">// Use the fact that reassociation is valid to simplify the logic: only use</span></div>
<div class="line"><a id="l01779" name="l01779"></a><span class="lineno"> 1779</span>  <span class="comment">// each map&#39;s rank.</span></div>
<div class="line"><a id="l01780" name="l01780"></a><span class="lineno"> 1780</span>  assert(<a class="code hl_function" href="namespacemlir.html#a9e3d6f94b6a941066c3e7e5535817a9b">isReassociationValid</a>(reassociation) &amp;&amp; <span class="stringliteral">&quot;invalid reassociation&quot;</span>);</div>
<div class="line"><a id="l01781" name="l01781"></a><span class="lineno"> 1781</span> </div>
<div class="line"><a id="l01782" name="l01782"></a><span class="lineno"> 1782</span>  <span class="keyword">auto</span> <a class="code hl_namespace" href="namespacemlir_1_1shape.html">shape</a> = type.getShape();</div>
<div class="line"><a id="l01783" name="l01783"></a><span class="lineno"> 1783</span>  <span class="keyword">auto</span> scalableFlags = type.getScalableDims();</div>
<div class="line"><a id="l01784" name="l01784"></a><span class="lineno"> 1784</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> newShape;</div>
<div class="line"><a id="l01785" name="l01785"></a><span class="lineno"> 1785</span>  <a class="code hl_class" href="classllvm_1_1SmallVector.html">SmallVector&lt;bool&gt;</a> newScalableFlags;</div>
<div class="line"><a id="l01786" name="l01786"></a><span class="lineno"> 1786</span> </div>
<div class="line"><a id="l01787" name="l01787"></a><span class="lineno"> 1787</span>  <span class="keywordtype">unsigned</span> currentDim = 0;</div>
<div class="line"><a id="l01788" name="l01788"></a><span class="lineno"> 1788</span>  <span class="keywordflow">for</span> (<a class="code hl_class" href="classmlir_1_1AffineMap.html">AffineMap</a> m : reassociation) {</div>
<div class="line"><a id="l01789" name="l01789"></a><span class="lineno"> 1789</span>    <span class="keywordtype">unsigned</span> dim = m.getNumResults();</div>
<div class="line"><a id="l01790" name="l01790"></a><span class="lineno"> 1790</span>    <a class="code hl_class" href="classint64__t.html">int64_t</a> size = 1;</div>
<div class="line"><a id="l01791" name="l01791"></a><span class="lineno"> 1791</span>    <span class="keywordtype">bool</span> flag = <span class="keyword">false</span>;</div>
<div class="line"><a id="l01792" name="l01792"></a><span class="lineno"> 1792</span>    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> d = 0; d &lt; dim; ++d) {</div>
<div class="line"><a id="l01793" name="l01793"></a><span class="lineno"> 1793</span>      size *= <a class="code hl_namespace" href="namespacemlir_1_1shape.html">shape</a>[currentDim + d];</div>
<div class="line"><a id="l01794" name="l01794"></a><span class="lineno"> 1794</span>      flag |= scalableFlags[currentDim + d];</div>
<div class="line"><a id="l01795" name="l01795"></a><span class="lineno"> 1795</span>    }</div>
<div class="line"><a id="l01796" name="l01796"></a><span class="lineno"> 1796</span>    newShape.push_back(size);</div>
<div class="line"><a id="l01797" name="l01797"></a><span class="lineno"> 1797</span>    newScalableFlags.push_back(flag);</div>
<div class="line"><a id="l01798" name="l01798"></a><span class="lineno"> 1798</span>    currentDim += dim;</div>
<div class="line"><a id="l01799" name="l01799"></a><span class="lineno"> 1799</span>  }</div>
<div class="line"><a id="l01800" name="l01800"></a><span class="lineno"> 1800</span> </div>
<div class="line"><a id="l01801" name="l01801"></a><span class="lineno"> 1801</span>  <span class="keywordflow">return</span> VectorType::get(newShape, type.getElementType(), newScalableFlags);</div>
<div class="line"><a id="l01802" name="l01802"></a><span class="lineno"> 1802</span>}</div>
</div>
<div class="line"><a id="l01803" name="l01803"></a><span class="lineno"> 1803</span><span class="comment"></span> </div>
<div class="line"><a id="l01804" name="l01804"></a><span class="lineno"> 1804</span><span class="comment">/// Vectorize `linalg.pack` as:</span></div>
<div class="line"><a id="l01805" name="l01805"></a><span class="lineno"> 1805</span><span class="comment">///   * xfer_read -&gt; shape_cast -&gt; transpose -&gt; xfer_write</span></div>
<div class="line"><a id="l01806" name="l01806"></a><span class="lineno"> 1806</span><span class="comment">///</span></div>
<div class="line"><a id="l01807" name="l01807"></a><span class="lineno"> 1807</span><span class="comment">/// The input-vector-sizes specify the _write_ vector sizes (i.e. the vector</span></div>
<div class="line"><a id="l01808" name="l01808"></a><span class="lineno"> 1808</span><span class="comment">/// sizes for the xfer_write operation). This is sufficient to infer the other</span></div>
<div class="line"><a id="l01809" name="l01809"></a><span class="lineno"> 1809</span><span class="comment">/// vector sizes required here.</span></div>
<div class="line"><a id="l01810" name="l01810"></a><span class="lineno"> 1810</span><span class="comment">///</span></div>
<div class="line"><a id="l01811" name="l01811"></a><span class="lineno"> 1811</span><span class="comment">/// If the vector sizes are not provided:</span></div>
<div class="line"><a id="l01812" name="l01812"></a><span class="lineno"> 1812</span><span class="comment">///  * the vector sizes are determined from the destination tensor static shape.</span></div>
<div class="line"><a id="l01813" name="l01813"></a><span class="lineno"> 1813</span><span class="comment">///  * the inBounds attribute is used instead of masking.</span></div>
<div class="line"><a id="l01814" name="l01814"></a><span class="lineno"> 1814</span><span class="comment">///</span></div>
<div class="line"><a id="l01815" name="l01815"></a><span class="lineno"> 1815</span><span class="comment">/// EXAMPLE (no vector sizes):</span></div>
<div class="line"><a id="l01816" name="l01816"></a><span class="lineno"> 1816</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l01817" name="l01817"></a><span class="lineno"> 1817</span><span class="comment">///   %pack = tensor.pack %src</span></div>
<div class="line"><a id="l01818" name="l01818"></a><span class="lineno"> 1818</span><span class="comment">///     inner_dims_pos = [2, 1]</span></div>
<div class="line"><a id="l01819" name="l01819"></a><span class="lineno"> 1819</span><span class="comment">///     inner_tiles = [16, 2]</span></div>
<div class="line"><a id="l01820" name="l01820"></a><span class="lineno"> 1820</span><span class="comment">///     into %dst : tensor&lt;32x8x16xf32&gt; -&gt; tensor&lt;32x4x1x16x2xf32&gt;</span></div>
<div class="line"><a id="l01821" name="l01821"></a><span class="lineno"> 1821</span><span class="comment">/// ``</span></div>
<div class="line"><a id="l01822" name="l01822"></a><span class="lineno"> 1822</span><span class="comment">/// is vectorizes as:</span></div>
<div class="line"><a id="l01823" name="l01823"></a><span class="lineno"> 1823</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l01824" name="l01824"></a><span class="lineno"> 1824</span><span class="comment">///   %read = vector.transfer_read %src</span></div>
<div class="line"><a id="l01825" name="l01825"></a><span class="lineno"> 1825</span><span class="comment">///     : tensor&lt;32x7x16xf32&gt;, vector&lt;32x8x16xf32&gt;</span></div>
<div class="line"><a id="l01826" name="l01826"></a><span class="lineno"> 1826</span><span class="comment">///   %sc = vector.shape_cast %read</span></div>
<div class="line"><a id="l01827" name="l01827"></a><span class="lineno"> 1827</span><span class="comment">///     : vector&lt;32x8x16xf32&gt; to vector&lt;32x4x2x1x16xf32&gt;</span></div>
<div class="line"><a id="l01828" name="l01828"></a><span class="lineno"> 1828</span><span class="comment">///   %tr = vector.transpose %sc, [0, 1, 3, 4, 2]</span></div>
<div class="line"><a id="l01829" name="l01829"></a><span class="lineno"> 1829</span><span class="comment">///     : vector&lt;32x4x2x1x16xf32&gt; to vector&lt;32x4x1x16x2xf32&gt;</span></div>
<div class="line"><a id="l01830" name="l01830"></a><span class="lineno"> 1830</span><span class="comment">///   %write = vector.transfer_write %tr into %dest</span></div>
<div class="line"><a id="l01831" name="l01831"></a><span class="lineno"> 1831</span><span class="comment">///     : vector&lt;32x4x1x16x2xf32&gt;, tensor&lt;32x4x1x16x2xf32&gt;</span></div>
<div class="line"><a id="l01832" name="l01832"></a><span class="lineno"> 1832</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l01833" name="l01833"></a><span class="lineno"> 1833</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l01834" name="l01834"></a><span class="lineno"> 1834</span>vectorizeAsTensorPackOp(RewriterBase &amp;rewriter, linalg::PackOp packOp,</div>
<div class="line"><a id="l01835" name="l01835"></a><span class="lineno"> 1835</span>                        ArrayRef&lt;int64_t&gt; inputVectorSizes,</div>
<div class="line"><a id="l01836" name="l01836"></a><span class="lineno"> 1836</span>                        SmallVectorImpl&lt;Value&gt; &amp;newResults) {</div>
<div class="line"><a id="l01837" name="l01837"></a><span class="lineno"> 1837</span>  <span class="keywordflow">if</span> (!inputVectorSizes.empty()) {</div>
<div class="line"><a id="l01838" name="l01838"></a><span class="lineno"> 1838</span>    assert(inputVectorSizes.size() == packOp.getDestRank() &amp;&amp;</div>
<div class="line"><a id="l01839" name="l01839"></a><span class="lineno"> 1839</span>           <span class="stringliteral">&quot;Invalid number of input vector sizes!&quot;</span>);</div>
<div class="line"><a id="l01840" name="l01840"></a><span class="lineno"> 1840</span>  }</div>
<div class="line"><a id="l01841" name="l01841"></a><span class="lineno"> 1841</span> </div>
<div class="line"><a id="l01842" name="l01842"></a><span class="lineno"> 1842</span>  <span class="comment">// TODO: Introduce a parent class that will handle the insertion point update.</span></div>
<div class="line"><a id="l01843" name="l01843"></a><span class="lineno"> 1843</span>  OpBuilder::InsertionGuard g(rewriter);</div>
<div class="line"><a id="l01844" name="l01844"></a><span class="lineno"> 1844</span>  rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(packOp);</div>
<div class="line"><a id="l01845" name="l01845"></a><span class="lineno"> 1845</span> </div>
<div class="line"><a id="l01846" name="l01846"></a><span class="lineno"> 1846</span>  Location loc = packOp.getLoc();</div>
<div class="line"><a id="l01847" name="l01847"></a><span class="lineno"> 1847</span>  std::optional&lt;Value&gt; padValue = packOp.getPaddingValue()</div>
<div class="line"><a id="l01848" name="l01848"></a><span class="lineno"> 1848</span>                                      ? std::optional(packOp.getPaddingValue())</div>
<div class="line"><a id="l01849" name="l01849"></a><span class="lineno"> 1849</span>                                      : std::nullopt;</div>
<div class="line"><a id="l01850" name="l01850"></a><span class="lineno"> 1850</span> </div>
<div class="line"><a id="l01851" name="l01851"></a><span class="lineno"> 1851</span>  SmallVector&lt;int64_t&gt; destShape =</div>
<div class="line"><a id="l01852" name="l01852"></a><span class="lineno"> 1852</span>      SmallVector&lt;int64_t&gt;(packOp.getDestType().getShape());</div>
<div class="line"><a id="l01853" name="l01853"></a><span class="lineno"> 1853</span> </div>
<div class="line"><a id="l01854" name="l01854"></a><span class="lineno"> 1854</span>  <span class="comment">// This is just a convenience alias to clearly communicate that the input</span></div>
<div class="line"><a id="l01855" name="l01855"></a><span class="lineno"> 1855</span>  <span class="comment">// vector sizes determine the _write_ sizes.</span></div>
<div class="line"><a id="l01856" name="l01856"></a><span class="lineno"> 1856</span>  ArrayRef&lt;int64_t&gt; &amp;writeVectorSizes = inputVectorSizes;</div>
<div class="line"><a id="l01857" name="l01857"></a><span class="lineno"> 1857</span> </div>
<div class="line"><a id="l01858" name="l01858"></a><span class="lineno"> 1858</span>  <span class="comment">// In the absence of input-vector-sizes, use the _static_ input tensor shape.</span></div>
<div class="line"><a id="l01859" name="l01859"></a><span class="lineno"> 1859</span>  <span class="comment">// In addition, use the inBounds attribute instead of masking.</span></div>
<div class="line"><a id="l01860" name="l01860"></a><span class="lineno"> 1860</span>  <span class="keywordtype">bool</span> useInBoundsInsteadOfMasking = <span class="keyword">false</span>;</div>
<div class="line"><a id="l01861" name="l01861"></a><span class="lineno"> 1861</span>  <span class="keywordflow">if</span> (writeVectorSizes.empty()) {</div>
<div class="line"><a id="l01862" name="l01862"></a><span class="lineno"> 1862</span>    <span class="keywordflow">if</span> (ShapedType::isDynamicShape(destShape))</div>
<div class="line"><a id="l01863" name="l01863"></a><span class="lineno"> 1863</span>      <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(packOp,</div>
<div class="line"><a id="l01864" name="l01864"></a><span class="lineno"> 1864</span>                                         <span class="stringliteral">&quot;unable to infer vector sizes&quot;</span>);</div>
<div class="line"><a id="l01865" name="l01865"></a><span class="lineno"> 1865</span> </div>
<div class="line"><a id="l01866" name="l01866"></a><span class="lineno"> 1866</span>    writeVectorSizes = destShape;</div>
<div class="line"><a id="l01867" name="l01867"></a><span class="lineno"> 1867</span>    useInBoundsInsteadOfMasking = <span class="keyword">true</span>;</div>
<div class="line"><a id="l01868" name="l01868"></a><span class="lineno"> 1868</span>  }</div>
<div class="line"><a id="l01869" name="l01869"></a><span class="lineno"> 1869</span> </div>
<div class="line"><a id="l01870" name="l01870"></a><span class="lineno"> 1870</span>  <span class="comment">// Compute pre-transpose-write-vector-type, i.e. the write vector type</span></div>
<div class="line"><a id="l01871" name="l01871"></a><span class="lineno"> 1871</span>  <span class="comment">// _before_ the transposition (i.e. before dimension permutation). This is</span></div>
<div class="line"><a id="l01872" name="l01872"></a><span class="lineno"> 1872</span>  <span class="comment">// done by inverting the permutation/transposition that&#39;s part of the Pack</span></div>
<div class="line"><a id="l01873" name="l01873"></a><span class="lineno"> 1873</span>  <span class="comment">// operation. This type is required to:</span></div>
<div class="line"><a id="l01874" name="l01874"></a><span class="lineno"> 1874</span>  <span class="comment">//   1) compute the read vector type for masked-read below, and</span></div>
<div class="line"><a id="l01875" name="l01875"></a><span class="lineno"> 1875</span>  <span class="comment">//   2) generate shape-cast Op below that expands the read vector type.</span></div>
<div class="line"><a id="l01876" name="l01876"></a><span class="lineno"> 1876</span>  PackingMetadata packMetadata;</div>
<div class="line"><a id="l01877" name="l01877"></a><span class="lineno"> 1877</span>  SmallVector&lt;int64_t&gt; preTransposeWriteVecSizses(writeVectorSizes);</div>
<div class="line"><a id="l01878" name="l01878"></a><span class="lineno"> 1878</span>  <span class="keyword">auto</span> destInvPermutation = <a class="code hl_function" href="namespacemlir_1_1linalg.html#a92b42ab91002d8c468cb54eaebdb3989">getPackInverseDestPerm</a>(packOp, packMetadata);</div>
<div class="line"><a id="l01879" name="l01879"></a><span class="lineno"> 1879</span>  <a class="code hl_function" href="namespacemlir.html#adbcff71555e8c1965e508f324f43a55a">applyPermutationToVector</a>(preTransposeWriteVecSizses, destInvPermutation);</div>
<div class="line"><a id="l01880" name="l01880"></a><span class="lineno"> 1880</span>  <span class="keyword">auto</span> preTransposeWriteVecType = VectorType::get(</div>
<div class="line"><a id="l01881" name="l01881"></a><span class="lineno"> 1881</span>      preTransposeWriteVecSizses, packOp.getType().getElementType());</div>
<div class="line"><a id="l01882" name="l01882"></a><span class="lineno"> 1882</span> </div>
<div class="line"><a id="l01883" name="l01883"></a><span class="lineno"> 1883</span>  <span class="comment">// Compute vector type for the _read_ opeartion. This is simply</span></div>
<div class="line"><a id="l01884" name="l01884"></a><span class="lineno"> 1884</span>  <span class="comment">// pre-transpose-write-vector-type with the dimensions collapsed</span></div>
<div class="line"><a id="l01885" name="l01885"></a><span class="lineno"> 1885</span>  <span class="comment">// as per the Pack operation.</span></div>
<div class="line"><a id="l01886" name="l01886"></a><span class="lineno"> 1886</span>  VectorType readVecType = <a class="code hl_function" href="Vectorization_8cpp.html#a8019302085ef04a05864f2bb3f198f5c">getCollapsedVecType</a>(</div>
<div class="line"><a id="l01887" name="l01887"></a><span class="lineno"> 1887</span>      preTransposeWriteVecType,</div>
<div class="line"><a id="l01888" name="l01888"></a><span class="lineno"> 1888</span>      <a class="code hl_function" href="namespacemlir.html#a561d5231fcefc471a4c9069fce2eaf87">getSymbolLessAffineMaps</a>(<a class="code hl_function" href="namespacemlir.html#a9b2799e8f52860dadc460b88a8f2df32">convertReassociationIndicesToExprs</a>(</div>
<div class="line"><a id="l01889" name="l01889"></a><span class="lineno"> 1889</span>          rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#acbdddd0c6fa53e5605c93109ad00953b">getContext</a>(), packMetadata.reassociations)));</div>
<div class="line"><a id="l01890" name="l01890"></a><span class="lineno"> 1890</span> </div>
<div class="line"><a id="l01891" name="l01891"></a><span class="lineno"> 1891</span>  <span class="comment">// Create masked TransferReadOp.</span></div>
<div class="line"><a id="l01892" name="l01892"></a><span class="lineno"> 1892</span>  <span class="keyword">auto</span> maskedRead = <a class="code hl_function" href="namespacemlir_1_1vector.html#ac1f704d81959566caaf92245061960fb">vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a id="l01893" name="l01893"></a><span class="lineno"> 1893</span>      rewriter, loc, packOp.getSource(), readVecType, padValue,</div>
<div class="line"><a id="l01894" name="l01894"></a><span class="lineno"> 1894</span>      useInBoundsInsteadOfMasking);</div>
<div class="line"><a id="l01895" name="l01895"></a><span class="lineno"> 1895</span> </div>
<div class="line"><a id="l01896" name="l01896"></a><span class="lineno"> 1896</span>  <span class="comment">// Create ShapeCastOp.</span></div>
<div class="line"><a id="l01897" name="l01897"></a><span class="lineno"> 1897</span>  <span class="keyword">auto</span> shapeCastOp = vector::ShapeCastOp::create(</div>
<div class="line"><a id="l01898" name="l01898"></a><span class="lineno"> 1898</span>      rewriter, loc, preTransposeWriteVecType, maskedRead);</div>
<div class="line"><a id="l01899" name="l01899"></a><span class="lineno"> 1899</span> </div>
<div class="line"><a id="l01900" name="l01900"></a><span class="lineno"> 1900</span>  <span class="comment">// Create TransposeOp.</span></div>
<div class="line"><a id="l01901" name="l01901"></a><span class="lineno"> 1901</span>  <span class="keyword">auto</span> destPermutation = <a class="code hl_function" href="namespacemlir.html#afc254f56cba37671e1e5b2b933c6a090">invertPermutationVector</a>(destInvPermutation);</div>
<div class="line"><a id="l01902" name="l01902"></a><span class="lineno"> 1902</span>  <span class="keyword">auto</span> transposeOp = vector::TransposeOp::create(</div>
<div class="line"><a id="l01903" name="l01903"></a><span class="lineno"> 1903</span>      rewriter, loc, shapeCastOp.getResult(), destPermutation);</div>
<div class="line"><a id="l01904" name="l01904"></a><span class="lineno"> 1904</span> </div>
<div class="line"><a id="l01905" name="l01905"></a><span class="lineno"> 1905</span>  <span class="comment">// Create TransferWriteOp.</span></div>
<div class="line"><a id="l01906" name="l01906"></a><span class="lineno"> 1906</span>  Operation *write = <a class="code hl_function" href="Vectorization_8cpp.html#a2d04989901c1df355793bb8a71328797">createWriteOrMaskedWrite</a>(</div>
<div class="line"><a id="l01907" name="l01907"></a><span class="lineno"> 1907</span>      rewriter, loc, transposeOp.getResult(), packOp.getDest());</div>
<div class="line"><a id="l01908" name="l01908"></a><span class="lineno"> 1908</span>  newResults.push_back(write-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a id="l01909" name="l01909"></a><span class="lineno"> 1909</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l01910" name="l01910"></a><span class="lineno"> 1910</span>}</div>
<div class="line"><a id="l01911" name="l01911"></a><span class="lineno"> 1911</span><span class="comment"></span> </div>
<div class="line"><a id="l01912" name="l01912"></a><span class="lineno"> 1912</span><span class="comment">/// Vectorize `linalg.unpack` as:</span></div>
<div class="line"><a id="l01913" name="l01913"></a><span class="lineno"> 1913</span><span class="comment">///   * xfer_read -&gt; vector.transpose -&gt; vector.shape_cast -&gt; xfer_write</span></div>
<div class="line"><a id="l01914" name="l01914"></a><span class="lineno"> 1914</span><span class="comment">///</span></div>
<div class="line"><a id="l01915" name="l01915"></a><span class="lineno"> 1915</span><span class="comment">/// The input-vector-sizes specify the _read_ vector sizes (i.e. the vector</span></div>
<div class="line"><a id="l01916" name="l01916"></a><span class="lineno"> 1916</span><span class="comment">/// sizes for the xfer_read operation). This is sufficient to infer the other</span></div>
<div class="line"><a id="l01917" name="l01917"></a><span class="lineno"> 1917</span><span class="comment">/// vector sizes required here.</span></div>
<div class="line"><a id="l01918" name="l01918"></a><span class="lineno"> 1918</span><span class="comment">///</span></div>
<div class="line"><a id="l01919" name="l01919"></a><span class="lineno"> 1919</span><span class="comment">/// If the vector sizes are not provided:</span></div>
<div class="line"><a id="l01920" name="l01920"></a><span class="lineno"> 1920</span><span class="comment">///  * the vector sizes are determined from the input tensor static shape.</span></div>
<div class="line"><a id="l01921" name="l01921"></a><span class="lineno"> 1921</span><span class="comment">///  * the inBounds attribute is used instead of masking.</span></div>
<div class="line"><a id="l01922" name="l01922"></a><span class="lineno"> 1922</span><span class="comment">///</span></div>
<div class="line"><a id="l01923" name="l01923"></a><span class="lineno"> 1923</span><span class="comment">/// EXAMPLE (no vector sizes):</span></div>
<div class="line"><a id="l01924" name="l01924"></a><span class="lineno"> 1924</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l01925" name="l01925"></a><span class="lineno"> 1925</span><span class="comment">///   %unpack = linalg.unpack  %src</span></div>
<div class="line"><a id="l01926" name="l01926"></a><span class="lineno"> 1926</span><span class="comment">///    inner_dims_pos = [0, 1]</span></div>
<div class="line"><a id="l01927" name="l01927"></a><span class="lineno"> 1927</span><span class="comment">///    inner_tiles = [8, 8]</span></div>
<div class="line"><a id="l01928" name="l01928"></a><span class="lineno"> 1928</span><span class="comment">///    into %dest : tensor&lt;1x1x8x8xf32&gt; -&gt; tensor&lt;8x8xf32&gt;</span></div>
<div class="line"><a id="l01929" name="l01929"></a><span class="lineno"> 1929</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l01930" name="l01930"></a><span class="lineno"> 1930</span><span class="comment">/// is vectorized as:</span></div>
<div class="line"><a id="l01931" name="l01931"></a><span class="lineno"> 1931</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l01932" name="l01932"></a><span class="lineno"> 1932</span><span class="comment">///   %read = vector.transfer_read %src</span></div>
<div class="line"><a id="l01933" name="l01933"></a><span class="lineno"> 1933</span><span class="comment">///     : tensor&lt;1x1x8x8xf32&gt;, vector&lt;1x1x8x8xf32&gt;</span></div>
<div class="line"><a id="l01934" name="l01934"></a><span class="lineno"> 1934</span><span class="comment">///   %tr = vector.transpose %read, [0, 2, 1, 3]</span></div>
<div class="line"><a id="l01935" name="l01935"></a><span class="lineno"> 1935</span><span class="comment">///     : vector&lt;1x1x8x8xf32&gt; to vector&lt;1x8x1x8xf32&gt;</span></div>
<div class="line"><a id="l01936" name="l01936"></a><span class="lineno"> 1936</span><span class="comment">///   %sc = vector.shape_cast %tr</span></div>
<div class="line"><a id="l01937" name="l01937"></a><span class="lineno"> 1937</span><span class="comment">///     : vector&lt;1x8x1x8xf32&gt; to vector&lt;8x8xf32&gt;</span></div>
<div class="line"><a id="l01938" name="l01938"></a><span class="lineno"> 1938</span><span class="comment">///   %vector = vector.transfer_write %sc into %dest</span></div>
<div class="line"><a id="l01939" name="l01939"></a><span class="lineno"> 1939</span><span class="comment">///     : vector&lt;8x8xf32&gt;, tensor&lt;8x8xf32&gt;</span></div>
<div class="line"><a id="l01940" name="l01940"></a><span class="lineno"> 1940</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l01941" name="l01941"></a><span class="lineno"> 1941</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l01942" name="l01942"></a><span class="lineno"> 1942</span>vectorizeAsTensorUnpackOp(RewriterBase &amp;rewriter, linalg::UnPackOp unpackOp,</div>
<div class="line"><a id="l01943" name="l01943"></a><span class="lineno"> 1943</span>                          ArrayRef&lt;int64_t&gt; inputVectorSizes,</div>
<div class="line"><a id="l01944" name="l01944"></a><span class="lineno"> 1944</span>                          ArrayRef&lt;bool&gt; inputScalableVecDims,</div>
<div class="line"><a id="l01945" name="l01945"></a><span class="lineno"> 1945</span>                          SmallVectorImpl&lt;Value&gt; &amp;newResults) {</div>
<div class="line"><a id="l01946" name="l01946"></a><span class="lineno"> 1946</span>  <span class="keywordflow">if</span> (!inputVectorSizes.empty()) {</div>
<div class="line"><a id="l01947" name="l01947"></a><span class="lineno"> 1947</span>    assert(inputVectorSizes.size() == unpackOp.getSourceRank() &amp;&amp;</div>
<div class="line"><a id="l01948" name="l01948"></a><span class="lineno"> 1948</span>           <span class="stringliteral">&quot;Invalid number of input vector sizes!&quot;</span>);</div>
<div class="line"><a id="l01949" name="l01949"></a><span class="lineno"> 1949</span>    assert(inputVectorSizes.size() == inputScalableVecDims.size() &amp;&amp;</div>
<div class="line"><a id="l01950" name="l01950"></a><span class="lineno"> 1950</span>           <span class="stringliteral">&quot;Incompatible number of vector sizes and vector scalable flags!&quot;</span>);</div>
<div class="line"><a id="l01951" name="l01951"></a><span class="lineno"> 1951</span>  }</div>
<div class="line"><a id="l01952" name="l01952"></a><span class="lineno"> 1952</span> </div>
<div class="line"><a id="l01953" name="l01953"></a><span class="lineno"> 1953</span>  <span class="comment">// TODO: Introduce a parent class that will handle the insertion point update.</span></div>
<div class="line"><a id="l01954" name="l01954"></a><span class="lineno"> 1954</span>  OpBuilder::InsertionGuard g(rewriter);</div>
<div class="line"><a id="l01955" name="l01955"></a><span class="lineno"> 1955</span>  rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(unpackOp);</div>
<div class="line"><a id="l01956" name="l01956"></a><span class="lineno"> 1956</span> </div>
<div class="line"><a id="l01957" name="l01957"></a><span class="lineno"> 1957</span>  RankedTensorType unpackTensorType = unpackOp.getSourceType();</div>
<div class="line"><a id="l01958" name="l01958"></a><span class="lineno"> 1958</span> </div>
<div class="line"><a id="l01959" name="l01959"></a><span class="lineno"> 1959</span>  ArrayRef&lt;int64_t&gt; sourceShape = unpackTensorType.getShape();</div>
<div class="line"><a id="l01960" name="l01960"></a><span class="lineno"> 1960</span>  <span class="keywordtype">bool</span> useInBoundsInsteadOfMasking = <span class="keyword">false</span>;</div>
<div class="line"><a id="l01961" name="l01961"></a><span class="lineno"> 1961</span> </div>
<div class="line"><a id="l01962" name="l01962"></a><span class="lineno"> 1962</span>  Location loc = unpackOp-&gt;getLoc();</div>
<div class="line"><a id="l01963" name="l01963"></a><span class="lineno"> 1963</span> </div>
<div class="line"><a id="l01964" name="l01964"></a><span class="lineno"> 1964</span>  <span class="comment">// Obtain vector sizes for the read operation.</span></div>
<div class="line"><a id="l01965" name="l01965"></a><span class="lineno"> 1965</span>  SmallVector&lt;int64_t&gt; readVectorSizes(inputVectorSizes);</div>
<div class="line"><a id="l01966" name="l01966"></a><span class="lineno"> 1966</span>  SmallVector&lt;bool&gt; readScalableVectorFlags(inputScalableVecDims);</div>
<div class="line"><a id="l01967" name="l01967"></a><span class="lineno"> 1967</span> </div>
<div class="line"><a id="l01968" name="l01968"></a><span class="lineno"> 1968</span>  <span class="comment">// In the absence of input-vector-sizes, use the _static_ input tensor shape.</span></div>
<div class="line"><a id="l01969" name="l01969"></a><span class="lineno"> 1969</span>  <span class="keywordflow">if</span> (inputVectorSizes.empty()) {</div>
<div class="line"><a id="l01970" name="l01970"></a><span class="lineno"> 1970</span>    <span class="keywordflow">if</span> (ShapedType::isDynamicShape(sourceShape))</div>
<div class="line"><a id="l01971" name="l01971"></a><span class="lineno"> 1971</span>      <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(unpackOp,</div>
<div class="line"><a id="l01972" name="l01972"></a><span class="lineno"> 1972</span>                                         <span class="stringliteral">&quot;Unable to infer vector sizes!&quot;</span>);</div>
<div class="line"><a id="l01973" name="l01973"></a><span class="lineno"> 1973</span> </div>
<div class="line"><a id="l01974" name="l01974"></a><span class="lineno"> 1974</span>    readVectorSizes.assign(sourceShape.begin(), sourceShape.end());</div>
<div class="line"><a id="l01975" name="l01975"></a><span class="lineno"> 1975</span>    useInBoundsInsteadOfMasking = <span class="keyword">true</span>;</div>
<div class="line"><a id="l01976" name="l01976"></a><span class="lineno"> 1976</span>  }</div>
<div class="line"><a id="l01977" name="l01977"></a><span class="lineno"> 1977</span> </div>
<div class="line"><a id="l01978" name="l01978"></a><span class="lineno"> 1978</span>  <span class="comment">// -- Generate the read operation --</span></div>
<div class="line"><a id="l01979" name="l01979"></a><span class="lineno"> 1979</span>  VectorType readVecType =</div>
<div class="line"><a id="l01980" name="l01980"></a><span class="lineno"> 1980</span>      VectorType::get(readVectorSizes, unpackTensorType.getElementType(),</div>
<div class="line"><a id="l01981" name="l01981"></a><span class="lineno"> 1981</span>                      readScalableVectorFlags);</div>
<div class="line"><a id="l01982" name="l01982"></a><span class="lineno"> 1982</span>  Value readResult = <a class="code hl_function" href="namespacemlir_1_1vector.html#ac1f704d81959566caaf92245061960fb">vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a id="l01983" name="l01983"></a><span class="lineno"> 1983</span>      rewriter, loc, unpackOp.getSource(), readVecType, std::nullopt,</div>
<div class="line"><a id="l01984" name="l01984"></a><span class="lineno"> 1984</span>      useInBoundsInsteadOfMasking);</div>
<div class="line"><a id="l01985" name="l01985"></a><span class="lineno"> 1985</span> </div>
<div class="line"><a id="l01986" name="l01986"></a><span class="lineno"> 1986</span>  <span class="comment">// -- Generate the transpose operation --</span></div>
<div class="line"><a id="l01987" name="l01987"></a><span class="lineno"> 1987</span>  PackingMetadata packMetadata;</div>
<div class="line"><a id="l01988" name="l01988"></a><span class="lineno"> 1988</span>  SmallVector&lt;int64_t&gt; lastDimToInsertPosPerm =</div>
<div class="line"><a id="l01989" name="l01989"></a><span class="lineno"> 1989</span>      <a class="code hl_function" href="namespacemlir_1_1linalg.html#a1a3bb0a48c5e2778ea2bfd81a41db65d">getUnPackInverseSrcPerm</a>(unpackOp, packMetadata);</div>
<div class="line"><a id="l01990" name="l01990"></a><span class="lineno"> 1990</span>  vector::TransposeOp transposeOp = vector::TransposeOp::create(</div>
<div class="line"><a id="l01991" name="l01991"></a><span class="lineno"> 1991</span>      rewriter, loc, readResult, lastDimToInsertPosPerm);</div>
<div class="line"><a id="l01992" name="l01992"></a><span class="lineno"> 1992</span> </div>
<div class="line"><a id="l01993" name="l01993"></a><span class="lineno"> 1993</span>  <span class="comment">// -- Generate the shape_cast operation --</span></div>
<div class="line"><a id="l01994" name="l01994"></a><span class="lineno"> 1994</span>  VectorType collapsedVecType = <a class="code hl_function" href="Vectorization_8cpp.html#a8019302085ef04a05864f2bb3f198f5c">getCollapsedVecType</a>(</div>
<div class="line"><a id="l01995" name="l01995"></a><span class="lineno"> 1995</span>      transposeOp.getType(),</div>
<div class="line"><a id="l01996" name="l01996"></a><span class="lineno"> 1996</span>      <a class="code hl_function" href="namespacemlir.html#a561d5231fcefc471a4c9069fce2eaf87">getSymbolLessAffineMaps</a>(<a class="code hl_function" href="namespacemlir.html#a9b2799e8f52860dadc460b88a8f2df32">convertReassociationIndicesToExprs</a>(</div>
<div class="line"><a id="l01997" name="l01997"></a><span class="lineno"> 1997</span>          rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#acbdddd0c6fa53e5605c93109ad00953b">getContext</a>(), packMetadata.reassociations)));</div>
<div class="line"><a id="l01998" name="l01998"></a><span class="lineno"> 1998</span>  vector::ShapeCastOp shapeCastOp = vector::ShapeCastOp::create(</div>
<div class="line"><a id="l01999" name="l01999"></a><span class="lineno"> 1999</span>      rewriter, loc, collapsedVecType, transposeOp-&gt;getResult(0));</div>
<div class="line"><a id="l02000" name="l02000"></a><span class="lineno"> 2000</span> </div>
<div class="line"><a id="l02001" name="l02001"></a><span class="lineno"> 2001</span>  <span class="comment">// -- Generate the write operation --</span></div>
<div class="line"><a id="l02002" name="l02002"></a><span class="lineno"> 2002</span>  Operation *write = <a class="code hl_function" href="Vectorization_8cpp.html#a2d04989901c1df355793bb8a71328797">createWriteOrMaskedWrite</a>(</div>
<div class="line"><a id="l02003" name="l02003"></a><span class="lineno"> 2003</span>      rewriter, loc, shapeCastOp.getResult(), unpackOp.getDest(),</div>
<div class="line"><a id="l02004" name="l02004"></a><span class="lineno"> 2004</span>      <span class="comment">/*writeIndices=*/</span>{}, useInBoundsInsteadOfMasking);</div>
<div class="line"><a id="l02005" name="l02005"></a><span class="lineno"> 2005</span> </div>
<div class="line"><a id="l02006" name="l02006"></a><span class="lineno"> 2006</span>  newResults.push_back(write-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a id="l02007" name="l02007"></a><span class="lineno"> 2007</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02008" name="l02008"></a><span class="lineno"> 2008</span>}</div>
<div class="line"><a id="l02009" name="l02009"></a><span class="lineno"> 2009</span><span class="comment"></span> </div>
<div class="line"><a id="l02010" name="l02010"></a><span class="lineno"> 2010</span><span class="comment">/// Vectorize a `padOp` with (1) static result type, (2) constant padding value</span></div>
<div class="line"><a id="l02011" name="l02011"></a><span class="lineno"> 2011</span><span class="comment">/// and (3) all-zero lowPad to</span></div>
<div class="line"><a id="l02012" name="l02012"></a><span class="lineno"> 2012</span><span class="comment">///   `transfer_write_in_bounds(transfer_read_masked(pad_source, pad_value))`.</span></div>
<div class="line"><a id="l02013" name="l02013"></a><span class="lineno"> 2013</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l02014" name="l02014"></a><span class="lineno"> 2014</span>vectorizeAsTensorPadOp(RewriterBase &amp;rewriter, tensor::PadOp padOp,</div>
<div class="line"><a id="l02015" name="l02015"></a><span class="lineno"> 2015</span>                       ArrayRef&lt;int64_t&gt; inputVectorSizes,</div>
<div class="line"><a id="l02016" name="l02016"></a><span class="lineno"> 2016</span>                       SmallVectorImpl&lt;Value&gt; &amp;newResults) {</div>
<div class="line"><a id="l02017" name="l02017"></a><span class="lineno"> 2017</span>  <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a id="l02018" name="l02018"></a><span class="lineno"> 2018</span>  Location loc = padOp.getLoc();</div>
<div class="line"><a id="l02019" name="l02019"></a><span class="lineno"> 2019</span> </div>
<div class="line"><a id="l02020" name="l02020"></a><span class="lineno"> 2020</span>  <span class="comment">// TODO: Introduce a parent class that will handle the insertion point update.</span></div>
<div class="line"><a id="l02021" name="l02021"></a><span class="lineno"> 2021</span>  OpBuilder::InsertionGuard g(rewriter);</div>
<div class="line"><a id="l02022" name="l02022"></a><span class="lineno"> 2022</span>  rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(padOp);</div>
<div class="line"><a id="l02023" name="l02023"></a><span class="lineno"> 2023</span> </div>
<div class="line"><a id="l02024" name="l02024"></a><span class="lineno"> 2024</span>  <a class="code hl_typedef" href="namespacemlir.html#a676bc3fbf14bd5dba33f962b259d2034">ReifiedRankedShapedTypeDims</a> reifiedReturnShapes;</div>
<div class="line"><a id="l02025" name="l02025"></a><span class="lineno"> 2025</span>  LogicalResult status =</div>
<div class="line"><a id="l02026" name="l02026"></a><span class="lineno"> 2026</span>      cast&lt;ReifyRankedShapedTypeOpInterface&gt;(padOp.getOperation())</div>
<div class="line"><a id="l02027" name="l02027"></a><span class="lineno"> 2027</span>          .reifyResultShapes(rewriter, reifiedReturnShapes);</div>
<div class="line"><a id="l02028" name="l02028"></a><span class="lineno"> 2028</span>  (void)status; <span class="comment">// prevent unused variable warning on non-assert builds</span></div>
<div class="line"><a id="l02029" name="l02029"></a><span class="lineno"> 2029</span>  assert(succeeded(status) &amp;&amp; <span class="stringliteral">&quot;failed to reify result shapes&quot;</span>);</div>
<div class="line"><a id="l02030" name="l02030"></a><span class="lineno"> 2030</span>  <span class="keyword">auto</span> readType = VectorType::get(inputVectorSizes, padValue.getType());</div>
<div class="line"><a id="l02031" name="l02031"></a><span class="lineno"> 2031</span>  <span class="keyword">auto</span> maskedRead = <a class="code hl_function" href="namespacemlir_1_1vector.html#ac1f704d81959566caaf92245061960fb">vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a id="l02032" name="l02032"></a><span class="lineno"> 2032</span>      rewriter, loc, padOp.getSource(), readType, padValue,</div>
<div class="line"><a id="l02033" name="l02033"></a><span class="lineno"> 2033</span>      <span class="comment">/*useInBoundsInsteadOfMasking=*/</span><span class="keyword">false</span>);</div>
<div class="line"><a id="l02034" name="l02034"></a><span class="lineno"> 2034</span> </div>
<div class="line"><a id="l02035" name="l02035"></a><span class="lineno"> 2035</span>  <span class="comment">// Create Xfer write Op</span></div>
<div class="line"><a id="l02036" name="l02036"></a><span class="lineno"> 2036</span>  Value dest = tensor::EmptyOp::create(rewriter, loc, reifiedReturnShapes[0],</div>
<div class="line"><a id="l02037" name="l02037"></a><span class="lineno"> 2037</span>                                       padOp.getResultType().getElementType());</div>
<div class="line"><a id="l02038" name="l02038"></a><span class="lineno"> 2038</span>  Operation *write = <a class="code hl_function" href="Vectorization_8cpp.html#a2d04989901c1df355793bb8a71328797">createWriteOrMaskedWrite</a>(rewriter, loc, maskedRead, dest);</div>
<div class="line"><a id="l02039" name="l02039"></a><span class="lineno"> 2039</span>  newResults.push_back(write-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a id="l02040" name="l02040"></a><span class="lineno"> 2040</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02041" name="l02041"></a><span class="lineno"> 2041</span>}</div>
<div class="line"><a id="l02042" name="l02042"></a><span class="lineno"> 2042</span> </div>
<div class="line"><a id="l02043" name="l02043"></a><span class="lineno"> 2043</span><span class="comment">// TODO: probably need some extra checks for reduction followed by consumer</span></div>
<div class="line"><a id="l02044" name="l02044"></a><span class="lineno"> 2044</span><span class="comment">// ops that may not commute (e.g. linear reduction + non-linear instructions).</span></div>
<div class="line"><a id="l02045" name="l02045"></a><span class="lineno"> 2045</span><span class="keyword">static</span> LogicalResult reductionPreconditions(LinalgOp op) {</div>
<div class="line"><a id="l02046" name="l02046"></a><span class="lineno"> 2046</span>  <span class="keywordflow">if</span> (llvm::none_of(op.getIteratorTypesArray(), <a class="code hl_function" href="namespacemlir_1_1linalg.html#a5377722f56e02541897c157260bd1eee">isReductionIterator</a>)) {</div>
<div class="line"><a id="l02047" name="l02047"></a><span class="lineno"> 2047</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;reduction precondition failed: no reduction iterator&quot;</span>;</div>
<div class="line"><a id="l02048" name="l02048"></a><span class="lineno"> 2048</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02049" name="l02049"></a><span class="lineno"> 2049</span>  }</div>
<div class="line"><a id="l02050" name="l02050"></a><span class="lineno"> 2050</span>  <span class="keywordflow">for</span> (OpOperand &amp;opOperand : op.getDpsInitsMutable()) {</div>
<div class="line"><a id="l02051" name="l02051"></a><span class="lineno"> 2051</span>    AffineMap indexingMap = op.getMatchingIndexingMap(&amp;opOperand);</div>
<div class="line"><a id="l02052" name="l02052"></a><span class="lineno"> 2052</span>    <span class="keywordflow">if</span> (indexingMap.<a class="code hl_function" href="classmlir_1_1AffineMap.html#af6e665372add0df0668e1ebd231488b4">isPermutation</a>())</div>
<div class="line"><a id="l02053" name="l02053"></a><span class="lineno"> 2053</span>      <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l02054" name="l02054"></a><span class="lineno"> 2054</span> </div>
<div class="line"><a id="l02055" name="l02055"></a><span class="lineno"> 2055</span>    Operation *reduceOp = <a class="code hl_function" href="Vectorization_8cpp.html#a4c99d55a1274aa91b750b22a4a3c76e2">matchLinalgReduction</a>(&amp;opOperand);</div>
<div class="line"><a id="l02056" name="l02056"></a><span class="lineno"> 2056</span>    <span class="keywordflow">if</span> (!reduceOp || !<a class="code hl_function" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp)) {</div>
<div class="line"><a id="l02057" name="l02057"></a><span class="lineno"> 2057</span>      LDBG() &lt;&lt; <span class="stringliteral">&quot;reduction precondition failed: reduction detection failed&quot;</span>;</div>
<div class="line"><a id="l02058" name="l02058"></a><span class="lineno"> 2058</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02059" name="l02059"></a><span class="lineno"> 2059</span>    }</div>
<div class="line"><a id="l02060" name="l02060"></a><span class="lineno"> 2060</span>  }</div>
<div class="line"><a id="l02061" name="l02061"></a><span class="lineno"> 2061</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02062" name="l02062"></a><span class="lineno"> 2062</span>}</div>
<div class="line"><a id="l02063" name="l02063"></a><span class="lineno"> 2063</span> </div>
<div class="line"><a id="l02064" name="l02064"></a><span class="lineno"> 2064</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l02065" name="l02065"></a><span class="lineno"> 2065</span>vectorizeDynamicConvOpPrecondition(linalg::LinalgOp conv,</div>
<div class="line"><a id="l02066" name="l02066"></a><span class="lineno"> 2066</span>                                   <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a id="l02067" name="l02067"></a><span class="lineno"> 2067</span>  <span class="keywordflow">if</span> (flatten1DDepthwiseConv) {</div>
<div class="line"><a id="l02068" name="l02068"></a><span class="lineno"> 2068</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorization of flattened convs with dynamic shapes is not &quot;</span></div>
<div class="line"><a id="l02069" name="l02069"></a><span class="lineno"> 2069</span>              <span class="stringliteral">&quot;supported&quot;</span>;</div>
<div class="line"><a id="l02070" name="l02070"></a><span class="lineno"> 2070</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02071" name="l02071"></a><span class="lineno"> 2071</span>  }</div>
<div class="line"><a id="l02072" name="l02072"></a><span class="lineno"> 2072</span> </div>
<div class="line"><a id="l02073" name="l02073"></a><span class="lineno"> 2073</span>  <span class="keywordflow">if</span> (!isa&lt;linalg::DepthwiseConv1DNwcWcOp&gt;(conv)) {</div>
<div class="line"><a id="l02074" name="l02074"></a><span class="lineno"> 2074</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Not a 1D depth-wise WC conv, dynamic shapes are not supported&quot;</span>;</div>
<div class="line"><a id="l02075" name="l02075"></a><span class="lineno"> 2075</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02076" name="l02076"></a><span class="lineno"> 2076</span>  }</div>
<div class="line"><a id="l02077" name="l02077"></a><span class="lineno"> 2077</span> </div>
<div class="line"><a id="l02078" name="l02078"></a><span class="lineno"> 2078</span>  <span class="comment">// Support dynamic shapes in 1D depthwise convolution, but only in the</span></div>
<div class="line"><a id="l02079" name="l02079"></a><span class="lineno"> 2079</span>  <span class="comment">// _channel_ dimension.</span></div>
<div class="line"><a id="l02080" name="l02080"></a><span class="lineno"> 2080</span>  Value <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a> = conv.getDpsInputOperand(0)-&gt;get();</div>
<div class="line"><a id="l02081" name="l02081"></a><span class="lineno"> 2081</span>  ArrayRef&lt;int64_t&gt; lhsShape = cast&lt;ShapedType&gt;(<a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>.getType()).getShape();</div>
<div class="line"><a id="l02082" name="l02082"></a><span class="lineno"> 2082</span>  <span class="keyword">auto</span> shapeWithoutCh = lhsShape.drop_back(1);</div>
<div class="line"><a id="l02083" name="l02083"></a><span class="lineno"> 2083</span>  <span class="keywordflow">if</span> (ShapedType::isDynamicShape(shapeWithoutCh)) {</div>
<div class="line"><a id="l02084" name="l02084"></a><span class="lineno"> 2084</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Dynamically-shaped op vectorization precondition failed: only &quot;</span></div>
<div class="line"><a id="l02085" name="l02085"></a><span class="lineno"> 2085</span>              <span class="stringliteral">&quot;channel dim can be dynamic&quot;</span>;</div>
<div class="line"><a id="l02086" name="l02086"></a><span class="lineno"> 2086</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02087" name="l02087"></a><span class="lineno"> 2087</span>  }</div>
<div class="line"><a id="l02088" name="l02088"></a><span class="lineno"> 2088</span> </div>
<div class="line"><a id="l02089" name="l02089"></a><span class="lineno"> 2089</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02090" name="l02090"></a><span class="lineno"> 2090</span>}</div>
<div class="line"><a id="l02091" name="l02091"></a><span class="lineno"> 2091</span> </div>
<div class="line"><a id="l02092" name="l02092"></a><span class="lineno"> 2092</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l02093" name="l02093"></a><span class="lineno"> 2093</span>vectorizeDynamicLinalgOpPrecondition(linalg::LinalgOp op,</div>
<div class="line"><a id="l02094" name="l02094"></a><span class="lineno"> 2094</span>                                     <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a id="l02095" name="l02095"></a><span class="lineno"> 2095</span>  <span class="keywordflow">if</span> (isa&lt;ConvolutionOpInterface&gt;(op.getOperation()))</div>
<div class="line"><a id="l02096" name="l02096"></a><span class="lineno"> 2096</span>    <span class="keywordflow">return</span> vectorizeDynamicConvOpPrecondition(op, flatten1DDepthwiseConv);</div>
<div class="line"><a id="l02097" name="l02097"></a><span class="lineno"> 2097</span> </div>
<div class="line"><a id="l02098" name="l02098"></a><span class="lineno"> 2098</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">hasReductionIterator</a>(op))</div>
<div class="line"><a id="l02099" name="l02099"></a><span class="lineno"> 2099</span>    <span class="keywordflow">return</span> reductionPreconditions(op);</div>
<div class="line"><a id="l02100" name="l02100"></a><span class="lineno"> 2100</span> </div>
<div class="line"><a id="l02101" name="l02101"></a><span class="lineno"> 2101</span>  <span class="comment">// TODO: Masking only supports dynamic element-wise ops, linalg.generic ops,</span></div>
<div class="line"><a id="l02102" name="l02102"></a><span class="lineno"> 2102</span>  <span class="comment">// linalg.copy ops and ops that implement ContractionOpInterface for now.</span></div>
<div class="line"><a id="l02103" name="l02103"></a><span class="lineno"> 2103</span>  <span class="keywordflow">if</span> (!<a class="code hl_function" href="namespacemlir_1_1linalg.html#a8b1c347bc995910212c197f9f8728b12">isElementwise</a>(op) &amp;&amp;</div>
<div class="line"><a id="l02104" name="l02104"></a><span class="lineno"> 2104</span>      !isa&lt;linalg::GenericOp, linalg::CopyOp, linalg::ContractionOpInterface&gt;(</div>
<div class="line"><a id="l02105" name="l02105"></a><span class="lineno"> 2105</span>          op.getOperation()))</div>
<div class="line"><a id="l02106" name="l02106"></a><span class="lineno"> 2106</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02107" name="l02107"></a><span class="lineno"> 2107</span> </div>
<div class="line"><a id="l02108" name="l02108"></a><span class="lineno"> 2108</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Dynamically-shaped op meets vectorization pre-conditions&quot;</span>;</div>
<div class="line"><a id="l02109" name="l02109"></a><span class="lineno"> 2109</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02110" name="l02110"></a><span class="lineno"> 2110</span>}</div>
<div class="line"><a id="l02111" name="l02111"></a><span class="lineno"> 2111</span><span class="comment"></span> </div>
<div class="line"><a id="l02112" name="l02112"></a><span class="lineno"> 2112</span><span class="comment">//// This hook considers two cases:</span></div>
<div class="line"><a id="l02113" name="l02113"></a><span class="lineno"> 2113</span><span class="comment">///   (1) If the input-vector-sizes are empty, then the vector sizes will be</span></div>
<div class="line"><a id="l02114" name="l02114"></a><span class="lineno"> 2114</span><span class="comment">///       infered. This is only possible when all shapes are static.</span></div>
<div class="line"><a id="l02115" name="l02115"></a><span class="lineno"> 2115</span><span class="comment">///   (2) If the input-vector-sizes are non-empty (i.e. user provided), then</span></div>
<div class="line"><a id="l02116" name="l02116"></a><span class="lineno"> 2116</span><span class="comment">///       carry out basic sanity-checking.</span></div>
<div class="line"><a id="l02117" name="l02117"></a><span class="lineno"> 2117</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l02118" name="l02118"></a><span class="lineno"> 2118</span>vectorizeUnPackOpPrecondition(linalg::UnPackOp unpackOp,</div>
<div class="line"><a id="l02119" name="l02119"></a><span class="lineno"> 2119</span>                              ArrayRef&lt;int64_t&gt; inputVectorSizes) {</div>
<div class="line"><a id="l02120" name="l02120"></a><span class="lineno"> 2120</span>  <span class="comment">// If there are no input vector sizes and all shapes are static, there is</span></div>
<div class="line"><a id="l02121" name="l02121"></a><span class="lineno"> 2121</span>  <span class="comment">// nothing left to check.</span></div>
<div class="line"><a id="l02122" name="l02122"></a><span class="lineno"> 2122</span>  <span class="keywordflow">if</span> (inputVectorSizes.empty() &amp;&amp; unpackOp.getDestType().hasStaticShape() &amp;&amp;</div>
<div class="line"><a id="l02123" name="l02123"></a><span class="lineno"> 2123</span>      unpackOp.getSourceType().hasStaticShape())</div>
<div class="line"><a id="l02124" name="l02124"></a><span class="lineno"> 2124</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02125" name="l02125"></a><span class="lineno"> 2125</span> </div>
<div class="line"><a id="l02126" name="l02126"></a><span class="lineno"> 2126</span>  <span class="comment">// The number of input vector sizes must be equal to:</span></div>
<div class="line"><a id="l02127" name="l02127"></a><span class="lineno"> 2127</span>  <span class="comment">//  * read-vector-rank</span></div>
<div class="line"><a id="l02128" name="l02128"></a><span class="lineno"> 2128</span>  <span class="keywordflow">if</span> (!inputVectorSizes.empty() &amp;&amp;</div>
<div class="line"><a id="l02129" name="l02129"></a><span class="lineno"> 2129</span>      (inputVectorSizes.size() != unpackOp.getSourceRank())) {</div>
<div class="line"><a id="l02130" name="l02130"></a><span class="lineno"> 2130</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Incorrect number of input vector sizes&quot;</span>;</div>
<div class="line"><a id="l02131" name="l02131"></a><span class="lineno"> 2131</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02132" name="l02132"></a><span class="lineno"> 2132</span>  }</div>
<div class="line"><a id="l02133" name="l02133"></a><span class="lineno"> 2133</span> </div>
<div class="line"><a id="l02134" name="l02134"></a><span class="lineno"> 2134</span>  <span class="comment">// Check the vector sizes for the read operation.</span></div>
<div class="line"><a id="l02135" name="l02135"></a><span class="lineno"> 2135</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(<a class="code hl_function" href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">vector::isValidMaskedInputVector</a>(</div>
<div class="line"><a id="l02136" name="l02136"></a><span class="lineno"> 2136</span>          unpackOp.getSourceType().getShape(), inputVectorSizes))) {</div>
<div class="line"><a id="l02137" name="l02137"></a><span class="lineno"> 2137</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Invalid vector sizes for the read operation&quot;</span>;</div>
<div class="line"><a id="l02138" name="l02138"></a><span class="lineno"> 2138</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02139" name="l02139"></a><span class="lineno"> 2139</span>  }</div>
<div class="line"><a id="l02140" name="l02140"></a><span class="lineno"> 2140</span> </div>
<div class="line"><a id="l02141" name="l02141"></a><span class="lineno"> 2141</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02142" name="l02142"></a><span class="lineno"> 2142</span>}</div>
<div class="line"><a id="l02143" name="l02143"></a><span class="lineno"> 2143</span> </div>
<div class="line"><a id="l02144" name="l02144"></a><span class="lineno"> 2144</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l02145" name="l02145"></a><span class="lineno"> 2145</span>vectorizeInsertSliceOpPrecondition(tensor::InsertSliceOp sliceOp,</div>
<div class="line"><a id="l02146" name="l02146"></a><span class="lineno"> 2146</span>                                   ArrayRef&lt;int64_t&gt; inputVectorSizes) {</div>
<div class="line"><a id="l02147" name="l02147"></a><span class="lineno"> 2147</span> </div>
<div class="line"><a id="l02148" name="l02148"></a><span class="lineno"> 2148</span>  <a class="code hl_typedef" href="namespacemlir.html#a864cb5eb1fea4a548c28cda535ba7213">TypedValue&lt;RankedTensorType&gt;</a> source = sliceOp.getSource();</div>
<div class="line"><a id="l02149" name="l02149"></a><span class="lineno"> 2149</span>  <span class="keyword">auto</span> sourceType = source.getType();</div>
<div class="line"><a id="l02150" name="l02150"></a><span class="lineno"> 2150</span>  <span class="keywordflow">if</span> (!VectorType::isValidElementType(sourceType.getElementType()))</div>
<div class="line"><a id="l02151" name="l02151"></a><span class="lineno"> 2151</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02152" name="l02152"></a><span class="lineno"> 2152</span> </div>
<div class="line"><a id="l02153" name="l02153"></a><span class="lineno"> 2153</span>  <span class="comment">// Get the pad value.</span></div>
<div class="line"><a id="l02154" name="l02154"></a><span class="lineno"> 2154</span>  <span class="comment">// TransferReadOp (which is used to vectorize InsertSliceOp), requires a</span></div>
<div class="line"><a id="l02155" name="l02155"></a><span class="lineno"> 2155</span>  <span class="comment">// scalar padding value. Note that:</span></div>
<div class="line"><a id="l02156" name="l02156"></a><span class="lineno"> 2156</span>  <span class="comment">//    * for in-bounds accesses,</span></div>
<div class="line"><a id="l02157" name="l02157"></a><span class="lineno"> 2157</span>  <span class="comment">// the value is actually irrelevant. There are 2 cases in which xfer.read</span></div>
<div class="line"><a id="l02158" name="l02158"></a><span class="lineno"> 2158</span>  <span class="comment">// accesses are known to be in-bounds:</span></div>
<div class="line"><a id="l02159" name="l02159"></a><span class="lineno"> 2159</span>  <span class="comment">//  1. The source shape is static (output vector sizes would be based on</span></div>
<div class="line"><a id="l02160" name="l02160"></a><span class="lineno"> 2160</span>  <span class="comment">//     the source shape and hence all memory accesses would be in-bounds),</span></div>
<div class="line"><a id="l02161" name="l02161"></a><span class="lineno"> 2161</span>  <span class="comment">//  2. Masking is used, i.e. the output vector sizes are user-provided. In</span></div>
<div class="line"><a id="l02162" name="l02162"></a><span class="lineno"> 2162</span>  <span class="comment">//     this case it is safe to assume that all memory accesses are in-bounds.</span></div>
<div class="line"><a id="l02163" name="l02163"></a><span class="lineno"> 2163</span>  <span class="comment">//</span></div>
<div class="line"><a id="l02164" name="l02164"></a><span class="lineno"> 2164</span>  <span class="comment">// When the value is not known and not needed, use 0. Otherwise, bail out.</span></div>
<div class="line"><a id="l02165" name="l02165"></a><span class="lineno"> 2165</span>  Value padValue = <a class="code hl_function" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(sliceOp);</div>
<div class="line"><a id="l02166" name="l02166"></a><span class="lineno"> 2166</span>  <span class="keywordtype">bool</span> isOutOfBoundsRead =</div>
<div class="line"><a id="l02167" name="l02167"></a><span class="lineno"> 2167</span>      !sourceType.hasStaticShape() &amp;&amp; inputVectorSizes.empty();</div>
<div class="line"><a id="l02168" name="l02168"></a><span class="lineno"> 2168</span> </div>
<div class="line"><a id="l02169" name="l02169"></a><span class="lineno"> 2169</span>  <span class="keywordflow">if</span> (!padValue &amp;&amp; isOutOfBoundsRead) {</div>
<div class="line"><a id="l02170" name="l02170"></a><span class="lineno"> 2170</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Failed to get a pad value for out-of-bounds read access&quot;</span>;</div>
<div class="line"><a id="l02171" name="l02171"></a><span class="lineno"> 2171</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02172" name="l02172"></a><span class="lineno"> 2172</span>  }</div>
<div class="line"><a id="l02173" name="l02173"></a><span class="lineno"> 2173</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02174" name="l02174"></a><span class="lineno"> 2174</span>}</div>
<div class="line"><a id="l02175" name="l02175"></a><span class="lineno"> 2175</span><span class="comment"></span> </div>
<div class="line"><a id="l02176" name="l02176"></a><span class="lineno"> 2176</span><span class="comment">/// Vectorize a named linalg contraction op into:</span></div>
<div class="line"><a id="l02177" name="l02177"></a><span class="lineno"> 2177</span><span class="comment">///   vector::TransferReadOp - Reads vectors from the operands</span></div>
<div class="line"><a id="l02178" name="l02178"></a><span class="lineno"> 2178</span><span class="comment">///   vector::ContractionOp - Performs contraction</span></div>
<div class="line"><a id="l02179" name="l02179"></a><span class="lineno"> 2179</span><span class="comment">///   vector::TransferWriteOp - Write the result vector back to the</span></div>
<div class="line"><a id="l02180" name="l02180"></a><span class="lineno"> 2180</span><span class="comment">///   destination</span></div>
<div class="line"><a id="l02181" name="l02181"></a><span class="lineno"> 2181</span><span class="comment">/// The operands shapes are preserved and loaded directly into vectors.</span></div>
<div class="line"><a id="l02182" name="l02182"></a><span class="lineno"> 2182</span><span class="comment">/// Any further permutations or numerical casting remain within contraction op.</span></div>
<div class="line"><a id="l02183" name="l02183"></a><span class="lineno"> 2183</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l02184" name="l02184"></a><span class="lineno"> 2184</span>vectorizeAsLinalgContraction(RewriterBase &amp;rewriter, VectorizationState &amp;state,</div>
<div class="line"><a id="l02185" name="l02185"></a><span class="lineno"> 2185</span>                             LinalgOp linalgOp,</div>
<div class="line"><a id="l02186" name="l02186"></a><span class="lineno"> 2186</span>                             SmallVectorImpl&lt;Value&gt; &amp;newResults) {</div>
<div class="line"><a id="l02187" name="l02187"></a><span class="lineno"> 2187</span>  Location loc = linalgOp.getLoc();</div>
<div class="line"><a id="l02188" name="l02188"></a><span class="lineno"> 2188</span>  MLIRContext *ctx = linalgOp.getContext();</div>
<div class="line"><a id="l02189" name="l02189"></a><span class="lineno"> 2189</span> </div>
<div class="line"><a id="l02190" name="l02190"></a><span class="lineno"> 2190</span>  <span class="comment">// For simplicity, contraction vectorization is limited to linalg named ops.</span></div>
<div class="line"><a id="l02191" name="l02191"></a><span class="lineno"> 2191</span>  <span class="comment">// Generic op is ignored as not every arbitrary contraction body can be</span></div>
<div class="line"><a id="l02192" name="l02192"></a><span class="lineno"> 2192</span>  <span class="comment">// expressed by a vector.contract.</span></div>
<div class="line"><a id="l02193" name="l02193"></a><span class="lineno"> 2193</span>  <span class="keywordflow">if</span> (!isa&lt;ContractionOpInterface&gt;(linalgOp.getOperation()))</div>
<div class="line"><a id="l02194" name="l02194"></a><span class="lineno"> 2194</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02195" name="l02195"></a><span class="lineno"> 2195</span> </div>
<div class="line"><a id="l02196" name="l02196"></a><span class="lineno"> 2196</span>  OpOperand *outOperand = linalgOp.getDpsInitOperand(0);</div>
<div class="line"><a id="l02197" name="l02197"></a><span class="lineno"> 2197</span>  Operation *reduceOp = <a class="code hl_function" href="Vectorization_8cpp.html#a4c99d55a1274aa91b750b22a4a3c76e2">matchLinalgReduction</a>(outOperand);</div>
<div class="line"><a id="l02198" name="l02198"></a><span class="lineno"> 2198</span>  <span class="keyword">auto</span> maybeKind = <a class="code hl_function" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp);</div>
<div class="line"><a id="l02199" name="l02199"></a><span class="lineno"> 2199</span>  <span class="keywordflow">if</span> (!maybeKind) {</div>
<div class="line"><a id="l02200" name="l02200"></a><span class="lineno"> 2200</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Failed to determine contraction combining kind.&quot;</span>;</div>
<div class="line"><a id="l02201" name="l02201"></a><span class="lineno"> 2201</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02202" name="l02202"></a><span class="lineno"> 2202</span>  }</div>
<div class="line"><a id="l02203" name="l02203"></a><span class="lineno"> 2203</span> </div>
<div class="line"><a id="l02204" name="l02204"></a><span class="lineno"> 2204</span>  <span class="comment">// Check that all dimensions are present in the input operands.</span></div>
<div class="line"><a id="l02205" name="l02205"></a><span class="lineno"> 2205</span>  <span class="comment">// Arbitrary broadcasts are not supported by the vector contraction.</span></div>
<div class="line"><a id="l02206" name="l02206"></a><span class="lineno"> 2206</span>  <span class="comment">// Broadcasts are expected to be decomposed before vectorization.</span></div>
<div class="line"><a id="l02207" name="l02207"></a><span class="lineno"> 2207</span>  AffineMap lhsMap = linalgOp.getIndexingMapsArray()[0];</div>
<div class="line"><a id="l02208" name="l02208"></a><span class="lineno"> 2208</span>  AffineMap rhsMap = linalgOp.getIndexingMapsArray()[1];</div>
<div class="line"><a id="l02209" name="l02209"></a><span class="lineno"> 2209</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir.html#ac61c6bb6068af953a0711cf404a99645">getUnusedDimsBitVector</a>({lhsMap, rhsMap}).any()) {</div>
<div class="line"><a id="l02210" name="l02210"></a><span class="lineno"> 2210</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Contractions with broadcasts are not supported.&quot;</span>;</div>
<div class="line"><a id="l02211" name="l02211"></a><span class="lineno"> 2211</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02212" name="l02212"></a><span class="lineno"> 2212</span>  }</div>
<div class="line"><a id="l02213" name="l02213"></a><span class="lineno"> 2213</span> </div>
<div class="line"><a id="l02214" name="l02214"></a><span class="lineno"> 2214</span>  <span class="comment">// Load operands.</span></div>
<div class="line"><a id="l02215" name="l02215"></a><span class="lineno"> 2215</span>  SmallVector&lt;Value&gt; vecOperands;</div>
<div class="line"><a id="l02216" name="l02216"></a><span class="lineno"> 2216</span>  <span class="keywordflow">for</span> (OpOperand &amp;opOperand : linalgOp-&gt;getOpOperands()) {</div>
<div class="line"><a id="l02217" name="l02217"></a><span class="lineno"> 2217</span>    <span class="comment">// The operand vector shape is computed by mapping the canonical vector</span></div>
<div class="line"><a id="l02218" name="l02218"></a><span class="lineno"> 2218</span>    <span class="comment">// shape to the operand&#39;s domain. Further permutations are left as a part of</span></div>
<div class="line"><a id="l02219" name="l02219"></a><span class="lineno"> 2219</span>    <span class="comment">// the contraction.</span></div>
<div class="line"><a id="l02220" name="l02220"></a><span class="lineno"> 2220</span>    AffineMap indexingMap = linalgOp.getMatchingIndexingMap(&amp;opOperand);</div>
<div class="line"><a id="l02221" name="l02221"></a><span class="lineno"> 2221</span>    AffineMap readMap = <a class="code hl_function" href="classmlir_1_1AffineMap.html#a39ed2c2a4c743450a4a999fa6db1bf84">AffineMap::getMultiDimIdentityMap</a>(</div>
<div class="line"><a id="l02222" name="l02222"></a><span class="lineno"> 2222</span>        indexingMap.<a class="code hl_function" href="classmlir_1_1AffineMap.html#a96f194ae3b4baf33c67b10c9f795b564">getNumResults</a>(), rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#acbdddd0c6fa53e5605c93109ad00953b">getContext</a>());</div>
<div class="line"><a id="l02223" name="l02223"></a><span class="lineno"> 2223</span>    Type elemType = <a class="code hl_function" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(opOperand.get());</div>
<div class="line"><a id="l02224" name="l02224"></a><span class="lineno"> 2224</span>    VectorType readType =</div>
<div class="line"><a id="l02225" name="l02225"></a><span class="lineno"> 2225</span>        state.getCanonicalVecType(elemType, readMap.<a class="code hl_function" href="classmlir_1_1AffineMap.html#af2baf4561cf7d74a9959fd9e875c9a82">compose</a>(indexingMap));</div>
<div class="line"><a id="l02226" name="l02226"></a><span class="lineno"> 2226</span> </div>
<div class="line"><a id="l02227" name="l02227"></a><span class="lineno"> 2227</span>    Value read = <a class="code hl_function" href="namespacemlir_1_1vector.html#ac1f704d81959566caaf92245061960fb">mlir::vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a id="l02228" name="l02228"></a><span class="lineno"> 2228</span>        rewriter, loc, opOperand.get(), readType,</div>
<div class="line"><a id="l02229" name="l02229"></a><span class="lineno"> 2229</span>        <span class="comment">/*padding=*/</span>arith::getZeroConstant(rewriter, loc, elemType),</div>
<div class="line"><a id="l02230" name="l02230"></a><span class="lineno"> 2230</span>        <span class="comment">/*useInBoundsInsteadOfMasking=*/</span><span class="keyword">false</span>);</div>
<div class="line"><a id="l02231" name="l02231"></a><span class="lineno"> 2231</span>    vecOperands.push_back(read);</div>
<div class="line"><a id="l02232" name="l02232"></a><span class="lineno"> 2232</span>  }</div>
<div class="line"><a id="l02233" name="l02233"></a><span class="lineno"> 2233</span> </div>
<div class="line"><a id="l02234" name="l02234"></a><span class="lineno"> 2234</span>  <span class="comment">// Remap iterators from linalg to vector.</span></div>
<div class="line"><a id="l02235" name="l02235"></a><span class="lineno"> 2235</span>  SmallVector&lt;Attribute&gt; iterAttrs;</div>
<div class="line"><a id="l02236" name="l02236"></a><span class="lineno"> 2236</span>  <span class="keyword">auto</span> iterators = linalgOp.getIteratorTypesArray();</div>
<div class="line"><a id="l02237" name="l02237"></a><span class="lineno"> 2237</span>  <span class="keywordflow">for</span> (utils::IteratorType iter : iterators) {</div>
<div class="line"><a id="l02238" name="l02238"></a><span class="lineno"> 2238</span>    <span class="keyword">auto</span> vecIter = iter == utils::IteratorType::parallel</div>
<div class="line"><a id="l02239" name="l02239"></a><span class="lineno"> 2239</span>                       ? vector::IteratorType::parallel</div>
<div class="line"><a id="l02240" name="l02240"></a><span class="lineno"> 2240</span>                       : vector::IteratorType::reduction;</div>
<div class="line"><a id="l02241" name="l02241"></a><span class="lineno"> 2241</span>    iterAttrs.push_back(vector::IteratorTypeAttr::get(ctx, vecIter));</div>
<div class="line"><a id="l02242" name="l02242"></a><span class="lineno"> 2242</span>  }</div>
<div class="line"><a id="l02243" name="l02243"></a><span class="lineno"> 2243</span> </div>
<div class="line"><a id="l02244" name="l02244"></a><span class="lineno"> 2244</span>  <span class="comment">// Create contraction.</span></div>
<div class="line"><a id="l02245" name="l02245"></a><span class="lineno"> 2245</span>  Operation *contractOp = vector::ContractionOp::create(</div>
<div class="line"><a id="l02246" name="l02246"></a><span class="lineno"> 2246</span>      rewriter, loc, <span class="comment">/*lhs=*/</span>vecOperands[0],</div>
<div class="line"><a id="l02247" name="l02247"></a><span class="lineno"> 2247</span>      <span class="comment">/*rhs=*/</span>vecOperands[1], <span class="comment">/*acc=*/</span>vecOperands[2],</div>
<div class="line"><a id="l02248" name="l02248"></a><span class="lineno"> 2248</span>      linalgOp.getIndexingMaps(), rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#ac9e0170e1b16f9c7464823b7b2fcb042">getArrayAttr</a>(iterAttrs), *maybeKind);</div>
<div class="line"><a id="l02249" name="l02249"></a><span class="lineno"> 2249</span>  contractOp = state.maskOperation(rewriter, contractOp, linalgOp);</div>
<div class="line"><a id="l02250" name="l02250"></a><span class="lineno"> 2250</span> </div>
<div class="line"><a id="l02251" name="l02251"></a><span class="lineno"> 2251</span>  <span class="comment">// Store result.</span></div>
<div class="line"><a id="l02252" name="l02252"></a><span class="lineno"> 2252</span>  Operation *write = <a class="code hl_function" href="Vectorization_8cpp.html#a2d04989901c1df355793bb8a71328797">createWriteOrMaskedWrite</a>(</div>
<div class="line"><a id="l02253" name="l02253"></a><span class="lineno"> 2253</span>      rewriter, loc, contractOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0), outOperand-&gt;<a class="code hl_function" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>());</div>
<div class="line"><a id="l02254" name="l02254"></a><span class="lineno"> 2254</span> </div>
<div class="line"><a id="l02255" name="l02255"></a><span class="lineno"> 2255</span>  <span class="comment">// Finalize.</span></div>
<div class="line"><a id="l02256" name="l02256"></a><span class="lineno"> 2256</span>  <span class="keywordflow">if</span> (!write-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>().empty())</div>
<div class="line"><a id="l02257" name="l02257"></a><span class="lineno"> 2257</span>    newResults.push_back(write-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a id="l02258" name="l02258"></a><span class="lineno"> 2258</span> </div>
<div class="line"><a id="l02259" name="l02259"></a><span class="lineno"> 2259</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02260" name="l02260"></a><span class="lineno"> 2260</span>}</div>
<div class="line"><a id="l02261" name="l02261"></a><span class="lineno"> 2261</span> </div>
<div class="line"><a id="l02262" name="l02262"></a><span class="lineno"> 2262</span><span class="keyword">namespace </span>{</div>
<div class="line"><a id="l02263" name="l02263"></a><span class="lineno"> 2263</span><span class="keyword">enum class</span> ConvOperationKind { Conv, Pool };</div>
<div class="line"><a id="l02264" name="l02264"></a><span class="lineno"> 2264</span>} <span class="comment">// namespace</span></div>
<div class="line"><a id="l02265" name="l02265"></a><span class="lineno"> 2265</span> </div>
<div class="line"><a id="l02266" name="l02266"></a><span class="lineno"> 2266</span><span class="keyword">static</span> <span class="keywordtype">bool</span> isCastOfBlockArgument(Operation *op) {</div>
<div class="line"><a id="l02267" name="l02267"></a><span class="lineno"> 2267</span>  <span class="keywordflow">return</span> isa&lt;CastOpInterface&gt;(op) &amp;&amp; op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a80db2165a86e0837b30f5f3e0dc899df">getNumOperands</a>() == 1 &amp;&amp;</div>
<div class="line"><a id="l02268" name="l02268"></a><span class="lineno"> 2268</span>         isa&lt;BlockArgument&gt;(op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a1eecfffb7445e24f9fbdec2d619251ff">getOperand</a>(0));</div>
<div class="line"><a id="l02269" name="l02269"></a><span class="lineno"> 2269</span>}</div>
<div class="line"><a id="l02270" name="l02270"></a><span class="lineno"> 2270</span> </div>
<div class="line"><a id="l02271" name="l02271"></a><span class="lineno"> 2271</span><span class="comment">// Returns the ConvOperationKind of the op using reduceOp of the generic</span></div>
<div class="line"><a id="l02272" name="l02272"></a><span class="lineno"> 2272</span><span class="comment">// payload. If it is neither a convolution nor a pooling, it returns</span></div>
<div class="line"><a id="l02273" name="l02273"></a><span class="lineno"> 2273</span><span class="comment">// std::nullopt.</span></div>
<div class="line"><a id="l02274" name="l02274"></a><span class="lineno"> 2274</span><span class="comment">//</span></div>
<div class="line"><a id="l02275" name="l02275"></a><span class="lineno"> 2275</span><span class="comment">// If (region has 2 ops (reduction + yield) or 3 ops (extension + reduction</span></div>
<div class="line"><a id="l02276" name="l02276"></a><span class="lineno"> 2276</span><span class="comment">// + yield) and rhs is not used) then it is the body of a pooling</span></div>
<div class="line"><a id="l02277" name="l02277"></a><span class="lineno"> 2277</span><span class="comment">// If conv, check for single `mul` predecessor. The `mul` operands must be</span></div>
<div class="line"><a id="l02278" name="l02278"></a><span class="lineno"> 2278</span><span class="comment">// block arguments or extension of block arguments.</span></div>
<div class="line"><a id="l02279" name="l02279"></a><span class="lineno"> 2279</span><span class="comment">// Otherwise, check for one or zero `ext` predecessor. The `ext` operands</span></div>
<div class="line"><a id="l02280" name="l02280"></a><span class="lineno"> 2280</span><span class="comment">// must be block arguments or extension of block arguments.</span></div>
<div class="line"><a id="l02281" name="l02281"></a><span class="lineno"> 2281</span><span class="keyword">static</span> std::optional&lt;ConvOperationKind&gt;</div>
<div class="line"><a id="l02282" name="l02282"></a><span class="lineno"> 2282</span>getConvOperationKind(Operation *reduceOp) {</div>
<div class="line"><a id="l02283" name="l02283"></a><span class="lineno"> 2283</span>  <span class="keywordtype">int</span> numBlockArguments =</div>
<div class="line"><a id="l02284" name="l02284"></a><span class="lineno"> 2284</span>      llvm::count_if(reduceOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(), llvm::IsaPred&lt;BlockArgument&gt;);</div>
<div class="line"><a id="l02285" name="l02285"></a><span class="lineno"> 2285</span> </div>
<div class="line"><a id="l02286" name="l02286"></a><span class="lineno"> 2286</span>  <span class="keywordflow">switch</span> (numBlockArguments) {</div>
<div class="line"><a id="l02287" name="l02287"></a><span class="lineno"> 2287</span>  <span class="keywordflow">case</span> 1: {</div>
<div class="line"><a id="l02288" name="l02288"></a><span class="lineno"> 2288</span>    <span class="comment">// Will be convolution if feeder is a MulOp.</span></div>
<div class="line"><a id="l02289" name="l02289"></a><span class="lineno"> 2289</span>    <span class="comment">// A strength reduced version of MulOp for i1 type is AndOp which is also</span></div>
<div class="line"><a id="l02290" name="l02290"></a><span class="lineno"> 2290</span>    <span class="comment">// supported. Otherwise, it can be pooling. This strength reduction logic</span></div>
<div class="line"><a id="l02291" name="l02291"></a><span class="lineno"> 2291</span>    <span class="comment">// is in `buildBinaryFn` helper in the Linalg dialect.</span></div>
<div class="line"><a id="l02292" name="l02292"></a><span class="lineno"> 2292</span>    <span class="keyword">auto</span> feedValIt = llvm::find_if_not(reduceOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(),</div>
<div class="line"><a id="l02293" name="l02293"></a><span class="lineno"> 2293</span>                                       llvm::IsaPred&lt;BlockArgument&gt;);</div>
<div class="line"><a id="l02294" name="l02294"></a><span class="lineno"> 2294</span>    assert(feedValIt != reduceOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a9d3b09f8e60b126070e82957d78d9fd0">operand_end</a>() &amp;&amp;</div>
<div class="line"><a id="l02295" name="l02295"></a><span class="lineno"> 2295</span>           <span class="stringliteral">&quot;Expected a non-block argument operand&quot;</span>);</div>
<div class="line"><a id="l02296" name="l02296"></a><span class="lineno"> 2296</span>    Operation *feedOp = (*feedValIt).getDefiningOp();</div>
<div class="line"><a id="l02297" name="l02297"></a><span class="lineno"> 2297</span>    <span class="keywordflow">if</span> (isCastOfBlockArgument(feedOp)) {</div>
<div class="line"><a id="l02298" name="l02298"></a><span class="lineno"> 2298</span>      <span class="keywordflow">return</span> ConvOperationKind::Pool;</div>
<div class="line"><a id="l02299" name="l02299"></a><span class="lineno"> 2299</span>    }</div>
<div class="line"><a id="l02300" name="l02300"></a><span class="lineno"> 2300</span> </div>
<div class="line"><a id="l02301" name="l02301"></a><span class="lineno"> 2301</span>    <span class="keywordflow">if</span> (!((isa&lt;arith::MulIOp, arith::MulFOp&gt;(feedOp) ||</div>
<div class="line"><a id="l02302" name="l02302"></a><span class="lineno"> 2302</span>           (isa&lt;arith::AndIOp&gt;(feedOp) &amp;&amp;</div>
<div class="line"><a id="l02303" name="l02303"></a><span class="lineno"> 2303</span>            feedOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac3095b4b7756a4974ba1c21b0e8ed762">getResultTypes</a>()[0].isInteger(1))) &amp;&amp;</div>
<div class="line"><a id="l02304" name="l02304"></a><span class="lineno"> 2304</span>          llvm::all_of(feedOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(), [](Value v) {</div>
<div class="line"><a id="l02305" name="l02305"></a><span class="lineno"> 2305</span>            if (isa&lt;BlockArgument&gt;(v))</div>
<div class="line"><a id="l02306" name="l02306"></a><span class="lineno"> 2306</span>              return true;</div>
<div class="line"><a id="l02307" name="l02307"></a><span class="lineno"> 2307</span>            if (Operation *op = v.getDefiningOp())</div>
<div class="line"><a id="l02308" name="l02308"></a><span class="lineno"> 2308</span>              return isCastOfBlockArgument(op);</div>
<div class="line"><a id="l02309" name="l02309"></a><span class="lineno"> 2309</span>            return false;</div>
<div class="line"><a id="l02310" name="l02310"></a><span class="lineno"> 2310</span>          }))) {</div>
<div class="line"><a id="l02311" name="l02311"></a><span class="lineno"> 2311</span>      <span class="keywordflow">return</span> std::nullopt;</div>
<div class="line"><a id="l02312" name="l02312"></a><span class="lineno"> 2312</span>    }</div>
<div class="line"><a id="l02313" name="l02313"></a><span class="lineno"> 2313</span> </div>
<div class="line"><a id="l02314" name="l02314"></a><span class="lineno"> 2314</span>    <span class="keywordflow">return</span> ConvOperationKind::Conv;</div>
<div class="line"><a id="l02315" name="l02315"></a><span class="lineno"> 2315</span>  }</div>
<div class="line"><a id="l02316" name="l02316"></a><span class="lineno"> 2316</span>  <span class="keywordflow">case</span> 2:</div>
<div class="line"><a id="l02317" name="l02317"></a><span class="lineno"> 2317</span>    <span class="comment">// Must be pooling</span></div>
<div class="line"><a id="l02318" name="l02318"></a><span class="lineno"> 2318</span>    <span class="keywordflow">return</span> ConvOperationKind::Pool;</div>
<div class="line"><a id="l02319" name="l02319"></a><span class="lineno"> 2319</span>  <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l02320" name="l02320"></a><span class="lineno"> 2320</span>    <span class="keywordflow">return</span> std::nullopt;</div>
<div class="line"><a id="l02321" name="l02321"></a><span class="lineno"> 2321</span>  }</div>
<div class="line"><a id="l02322" name="l02322"></a><span class="lineno"> 2322</span>}</div>
<div class="line"><a id="l02323" name="l02323"></a><span class="lineno"> 2323</span> </div>
<div class="line"><a id="l02324" name="l02324"></a><span class="lineno"> 2324</span><span class="keyword">static</span> <span class="keywordtype">bool</span> isSupportedPoolKind(vector::CombiningKind kind) {</div>
<div class="line"><a id="l02325" name="l02325"></a><span class="lineno"> 2325</span>  <span class="keywordflow">switch</span> (kind) {</div>
<div class="line"><a id="l02326" name="l02326"></a><span class="lineno"> 2326</span>  <span class="keywordflow">case</span> vector::CombiningKind::ADD:</div>
<div class="line"><a id="l02327" name="l02327"></a><span class="lineno"> 2327</span>  <span class="keywordflow">case</span> vector::CombiningKind::MAXNUMF:</div>
<div class="line"><a id="l02328" name="l02328"></a><span class="lineno"> 2328</span>  <span class="keywordflow">case</span> vector::CombiningKind::MAXIMUMF:</div>
<div class="line"><a id="l02329" name="l02329"></a><span class="lineno"> 2329</span>  <span class="keywordflow">case</span> vector::CombiningKind::MAXSI:</div>
<div class="line"><a id="l02330" name="l02330"></a><span class="lineno"> 2330</span>  <span class="keywordflow">case</span> vector::CombiningKind::MAXUI:</div>
<div class="line"><a id="l02331" name="l02331"></a><span class="lineno"> 2331</span>  <span class="keywordflow">case</span> vector::CombiningKind::MINNUMF:</div>
<div class="line"><a id="l02332" name="l02332"></a><span class="lineno"> 2332</span>  <span class="keywordflow">case</span> vector::CombiningKind::MINIMUMF:</div>
<div class="line"><a id="l02333" name="l02333"></a><span class="lineno"> 2333</span>  <span class="keywordflow">case</span> vector::CombiningKind::MINSI:</div>
<div class="line"><a id="l02334" name="l02334"></a><span class="lineno"> 2334</span>  <span class="keywordflow">case</span> vector::CombiningKind::MINUI:</div>
<div class="line"><a id="l02335" name="l02335"></a><span class="lineno"> 2335</span>    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l02336" name="l02336"></a><span class="lineno"> 2336</span>  <span class="keywordflow">default</span>:</div>
<div class="line"><a id="l02337" name="l02337"></a><span class="lineno"> 2337</span>    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l02338" name="l02338"></a><span class="lineno"> 2338</span>  }</div>
<div class="line"><a id="l02339" name="l02339"></a><span class="lineno"> 2339</span>}</div>
<div class="line"><a id="l02340" name="l02340"></a><span class="lineno"> 2340</span> </div>
<div class="line"><a id="l02341" name="l02341"></a><span class="lineno"> 2341</span><span class="keyword">static</span> LogicalResult vectorizeConvOpPrecondition(linalg::LinalgOp convOp) {</div>
<div class="line"><a id="l02342" name="l02342"></a><span class="lineno"> 2342</span>  <span class="keyword">auto</span> getOperandType = [&amp;](<span class="keyword">auto</span> operand) {</div>
<div class="line"><a id="l02343" name="l02343"></a><span class="lineno"> 2343</span>    <span class="keywordflow">return</span> dyn_cast&lt;ShapedType&gt;((operand-&gt;get()).getType());</div>
<div class="line"><a id="l02344" name="l02344"></a><span class="lineno"> 2344</span>  };</div>
<div class="line"><a id="l02345" name="l02345"></a><span class="lineno"> 2345</span>  ShapedType lhsShapedType = getOperandType(convOp.getDpsInputOperand(0));</div>
<div class="line"><a id="l02346" name="l02346"></a><span class="lineno"> 2346</span>  ShapedType rhsShapedType = getOperandType(convOp.getDpsInputOperand(1));</div>
<div class="line"><a id="l02347" name="l02347"></a><span class="lineno"> 2347</span>  ShapedType resShapedType = getOperandType(convOp.getDpsInitOperand(0));</div>
<div class="line"><a id="l02348" name="l02348"></a><span class="lineno"> 2348</span>  <span class="comment">// (LHS has dimension NCW/NWC and RES has dimension NFW/NCW/NWF/NWC) OR</span></div>
<div class="line"><a id="l02349" name="l02349"></a><span class="lineno"> 2349</span>  <span class="comment">// (non-channeled convolution -&gt; LHS and RHS both have single dimensions).</span></div>
<div class="line"><a id="l02350" name="l02350"></a><span class="lineno"> 2350</span>  <span class="comment">// Note that this also ensures 2D and 3D convolutions are rejected.</span></div>
<div class="line"><a id="l02351" name="l02351"></a><span class="lineno"> 2351</span>  <span class="keywordflow">if</span> ((lhsShapedType.getRank() != 3 || resShapedType.getRank() != 3) &amp;&amp;</div>
<div class="line"><a id="l02352" name="l02352"></a><span class="lineno"> 2352</span>      (lhsShapedType.getRank() != 1 || resShapedType.getRank() != 1))</div>
<div class="line"><a id="l02353" name="l02353"></a><span class="lineno"> 2353</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02354" name="l02354"></a><span class="lineno"> 2354</span> </div>
<div class="line"><a id="l02355" name="l02355"></a><span class="lineno"> 2355</span>  Operation *reduceOp = <a class="code hl_function" href="Vectorization_8cpp.html#a4c99d55a1274aa91b750b22a4a3c76e2">matchLinalgReduction</a>(convOp.getDpsInitOperand(0));</div>
<div class="line"><a id="l02356" name="l02356"></a><span class="lineno"> 2356</span>  <span class="keywordflow">if</span> (!reduceOp)</div>
<div class="line"><a id="l02357" name="l02357"></a><span class="lineno"> 2357</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02358" name="l02358"></a><span class="lineno"> 2358</span> </div>
<div class="line"><a id="l02359" name="l02359"></a><span class="lineno"> 2359</span>  <span class="keyword">auto</span> maybeOper = getConvOperationKind(reduceOp);</div>
<div class="line"><a id="l02360" name="l02360"></a><span class="lineno"> 2360</span>  <span class="keywordflow">if</span> (!maybeOper.has_value())</div>
<div class="line"><a id="l02361" name="l02361"></a><span class="lineno"> 2361</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02362" name="l02362"></a><span class="lineno"> 2362</span> </div>
<div class="line"><a id="l02363" name="l02363"></a><span class="lineno"> 2363</span>  <span class="keyword">auto</span> maybeKind = <a class="code hl_function" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp);</div>
<div class="line"><a id="l02364" name="l02364"></a><span class="lineno"> 2364</span>  <span class="comment">// Typically convolution will have a `Add` CombiningKind but for i1 type it</span></div>
<div class="line"><a id="l02365" name="l02365"></a><span class="lineno"> 2365</span>  <span class="comment">// can get strength reduced to `OR` which is also supported. This strength</span></div>
<div class="line"><a id="l02366" name="l02366"></a><span class="lineno"> 2366</span>  <span class="comment">// reduction logic is in `buildBinaryFn` helper in the Linalg dialect.</span></div>
<div class="line"><a id="l02367" name="l02367"></a><span class="lineno"> 2367</span>  <span class="keywordflow">if</span> (!maybeKind || ((*maybeKind != vector::CombiningKind::ADD &amp;&amp;</div>
<div class="line"><a id="l02368" name="l02368"></a><span class="lineno"> 2368</span>                      *maybeKind != vector::CombiningKind::OR) &amp;&amp;</div>
<div class="line"><a id="l02369" name="l02369"></a><span class="lineno"> 2369</span>                     (*maybeOper != ConvOperationKind::Pool ||</div>
<div class="line"><a id="l02370" name="l02370"></a><span class="lineno"> 2370</span>                      !isSupportedPoolKind(*maybeKind)))) {</div>
<div class="line"><a id="l02371" name="l02371"></a><span class="lineno"> 2371</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02372" name="l02372"></a><span class="lineno"> 2372</span>  }</div>
<div class="line"><a id="l02373" name="l02373"></a><span class="lineno"> 2373</span> </div>
<div class="line"><a id="l02374" name="l02374"></a><span class="lineno"> 2374</span>  <span class="keyword">auto</span> rhsRank = rhsShapedType.getRank();</div>
<div class="line"><a id="l02375" name="l02375"></a><span class="lineno"> 2375</span>  <span class="keywordflow">if</span> (*maybeOper == ConvOperationKind::Pool) {</div>
<div class="line"><a id="l02376" name="l02376"></a><span class="lineno"> 2376</span>    <span class="keywordflow">if</span> (rhsRank != 1)</div>
<div class="line"><a id="l02377" name="l02377"></a><span class="lineno"> 2377</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02378" name="l02378"></a><span class="lineno"> 2378</span>  } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l02379" name="l02379"></a><span class="lineno"> 2379</span>    <span class="keywordflow">if</span> (rhsRank != 1 &amp;&amp; rhsRank != 2 &amp;&amp; rhsRank != 3)</div>
<div class="line"><a id="l02380" name="l02380"></a><span class="lineno"> 2380</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02381" name="l02381"></a><span class="lineno"> 2381</span>  }</div>
<div class="line"><a id="l02382" name="l02382"></a><span class="lineno"> 2382</span> </div>
<div class="line"><a id="l02383" name="l02383"></a><span class="lineno"> 2383</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02384" name="l02384"></a><span class="lineno"> 2384</span>}</div>
<div class="line"><a id="l02385" name="l02385"></a><span class="lineno"> 2385</span> </div>
<div class="line"><a id="l02386" name="l02386"></a><span class="lineno"> 2386</span><span class="keyword">static</span> LogicalResult vectorizeLinalgOpPrecondition(</div>
<div class="line"><a id="l02387" name="l02387"></a><span class="lineno"> 2387</span>    LinalgOp linalgOp, ArrayRef&lt;int64_t&gt; inputVectorSizes,</div>
<div class="line"><a id="l02388" name="l02388"></a><span class="lineno"> 2388</span>    <span class="keywordtype">bool</span> vectorizeNDExtract, <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a id="l02389" name="l02389"></a><span class="lineno"> 2389</span>  <span class="comment">// tensor with dimension of 0 cannot be vectorized.</span></div>
<div class="line"><a id="l02390" name="l02390"></a><span class="lineno"> 2390</span>  <span class="keywordflow">if</span> (llvm::any_of(linalgOp-&gt;getOpOperands(), [&amp;](OpOperand &amp;operand) {</div>
<div class="line"><a id="l02391" name="l02391"></a><span class="lineno"> 2391</span>        return llvm::is_contained(linalgOp.getShape(&amp;operand), 0);</div>
<div class="line"><a id="l02392" name="l02392"></a><span class="lineno"> 2392</span>      }))</div>
<div class="line"><a id="l02393" name="l02393"></a><span class="lineno"> 2393</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02394" name="l02394"></a><span class="lineno"> 2394</span>  <span class="comment">// Check API contract for input vector sizes.</span></div>
<div class="line"><a id="l02395" name="l02395"></a><span class="lineno"> 2395</span>  <span class="keywordflow">if</span> (!inputVectorSizes.empty() &amp;&amp;</div>
<div class="line"><a id="l02396" name="l02396"></a><span class="lineno"> 2396</span>      <a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(<a class="code hl_function" href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">vector::isValidMaskedInputVector</a>(linalgOp.getStaticLoopRanges(),</div>
<div class="line"><a id="l02397" name="l02397"></a><span class="lineno"> 2397</span>                                              inputVectorSizes)))</div>
<div class="line"><a id="l02398" name="l02398"></a><span class="lineno"> 2398</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02399" name="l02399"></a><span class="lineno"> 2399</span> </div>
<div class="line"><a id="l02400" name="l02400"></a><span class="lineno"> 2400</span>  <span class="keywordflow">if</span> (linalgOp.hasDynamicShape() &amp;&amp; <a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(vectorizeDynamicLinalgOpPrecondition(</div>
<div class="line"><a id="l02401" name="l02401"></a><span class="lineno"> 2401</span>                                        linalgOp, flatten1DDepthwiseConv))) {</div>
<div class="line"><a id="l02402" name="l02402"></a><span class="lineno"> 2402</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Dynamically-shaped op failed vectorization pre-conditions&quot;</span>;</div>
<div class="line"><a id="l02403" name="l02403"></a><span class="lineno"> 2403</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02404" name="l02404"></a><span class="lineno"> 2404</span>  }</div>
<div class="line"><a id="l02405" name="l02405"></a><span class="lineno"> 2405</span> </div>
<div class="line"><a id="l02406" name="l02406"></a><span class="lineno"> 2406</span>  SmallVector&lt;CustomVectorizationPrecondition&gt; customPreconditions;</div>
<div class="line"><a id="l02407" name="l02407"></a><span class="lineno"> 2407</span> </div>
<div class="line"><a id="l02408" name="l02408"></a><span class="lineno"> 2408</span>  <span class="comment">// Register CustomVectorizationPrecondition for extractOp.</span></div>
<div class="line"><a id="l02409" name="l02409"></a><span class="lineno"> 2409</span>  customPreconditions.push_back(<a class="code hl_function" href="Vectorization_8cpp.html#ad09df73d48432e3de8291c7076164ba7">tensorExtractVectorizationPrecondition</a>);</div>
<div class="line"><a id="l02410" name="l02410"></a><span class="lineno"> 2410</span> </div>
<div class="line"><a id="l02411" name="l02411"></a><span class="lineno"> 2411</span>  <span class="comment">// All types in the body should be a supported element type for VectorType.</span></div>
<div class="line"><a id="l02412" name="l02412"></a><span class="lineno"> 2412</span>  <span class="keywordflow">for</span> (Operation &amp;innerOp : linalgOp-&gt;getRegion(0).front()) {</div>
<div class="line"><a id="l02413" name="l02413"></a><span class="lineno"> 2413</span>    <span class="comment">// Check if any custom hook can vectorize the inner op.</span></div>
<div class="line"><a id="l02414" name="l02414"></a><span class="lineno"> 2414</span>    <span class="keywordflow">if</span> (llvm::any_of(</div>
<div class="line"><a id="l02415" name="l02415"></a><span class="lineno"> 2415</span>            customPreconditions,</div>
<div class="line"><a id="l02416" name="l02416"></a><span class="lineno"> 2416</span>            [&amp;](<span class="keyword">const</span> <a class="code hl_typedef" href="Vectorization_8cpp.html#a765387385c36b8245aca7e886c0e98fb">CustomVectorizationPrecondition</a> &amp;customPrecondition) {</div>
<div class="line"><a id="l02417" name="l02417"></a><span class="lineno"> 2417</span>              <span class="keywordflow">return</span> succeeded(</div>
<div class="line"><a id="l02418" name="l02418"></a><span class="lineno"> 2418</span>                  customPrecondition(&amp;innerOp, vectorizeNDExtract));</div>
<div class="line"><a id="l02419" name="l02419"></a><span class="lineno"> 2419</span>            })) {</div>
<div class="line"><a id="l02420" name="l02420"></a><span class="lineno"> 2420</span>      <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l02421" name="l02421"></a><span class="lineno"> 2421</span>    }</div>
<div class="line"><a id="l02422" name="l02422"></a><span class="lineno"> 2422</span>    <span class="keywordflow">if</span> (!llvm::all_of(innerOp.getOperandTypes(),</div>
<div class="line"><a id="l02423" name="l02423"></a><span class="lineno"> 2423</span>                      VectorType::isValidElementType)) {</div>
<div class="line"><a id="l02424" name="l02424"></a><span class="lineno"> 2424</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02425" name="l02425"></a><span class="lineno"> 2425</span>    }</div>
<div class="line"><a id="l02426" name="l02426"></a><span class="lineno"> 2426</span>    <span class="keywordflow">if</span> (!llvm::all_of(innerOp.getResultTypes(),</div>
<div class="line"><a id="l02427" name="l02427"></a><span class="lineno"> 2427</span>                      VectorType::isValidElementType)) {</div>
<div class="line"><a id="l02428" name="l02428"></a><span class="lineno"> 2428</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02429" name="l02429"></a><span class="lineno"> 2429</span>    }</div>
<div class="line"><a id="l02430" name="l02430"></a><span class="lineno"> 2430</span>  }</div>
<div class="line"><a id="l02431" name="l02431"></a><span class="lineno"> 2431</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1linalg.html#a8b1c347bc995910212c197f9f8728b12">isElementwise</a>(linalgOp))</div>
<div class="line"><a id="l02432" name="l02432"></a><span class="lineno"> 2432</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02433" name="l02433"></a><span class="lineno"> 2433</span> </div>
<div class="line"><a id="l02434" name="l02434"></a><span class="lineno"> 2434</span>  <span class="comment">// TODO: isaConvolutionOpInterface that can also infer from generic</span></div>
<div class="line"><a id="l02435" name="l02435"></a><span class="lineno"> 2435</span>  <span class="comment">// features. But we will still need stride/dilation attributes that will be</span></div>
<div class="line"><a id="l02436" name="l02436"></a><span class="lineno"> 2436</span>  <span class="comment">// annoying to reverse-engineer...</span></div>
<div class="line"><a id="l02437" name="l02437"></a><span class="lineno"> 2437</span>  <span class="keywordflow">if</span> (isa&lt;ConvolutionOpInterface&gt;(linalgOp.getOperation()))</div>
<div class="line"><a id="l02438" name="l02438"></a><span class="lineno"> 2438</span>    <span class="keywordflow">return</span> vectorizeConvOpPrecondition(linalgOp);</div>
<div class="line"><a id="l02439" name="l02439"></a><span class="lineno"> 2439</span> </div>
<div class="line"><a id="l02440" name="l02440"></a><span class="lineno"> 2440</span>  <span class="comment">// TODO: the common vector shape is equal to the static loop sizes only when</span></div>
<div class="line"><a id="l02441" name="l02441"></a><span class="lineno"> 2441</span>  <span class="comment">// all indexing maps are projected permutations. For convs and stencils the</span></div>
<div class="line"><a id="l02442" name="l02442"></a><span class="lineno"> 2442</span>  <span class="comment">// logic will need to evolve.</span></div>
<div class="line"><a id="l02443" name="l02443"></a><span class="lineno"> 2443</span>  <span class="keywordflow">if</span> (!<a class="code hl_function" href="namespacemlir_1_1linalg.html#a1eda2843cbf0dc5507bc64ec67f46f22">allIndexingsAreProjectedPermutation</a>(linalgOp)) {</div>
<div class="line"><a id="l02444" name="l02444"></a><span class="lineno"> 2444</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;precondition failed: not projected permutations&quot;</span>;</div>
<div class="line"><a id="l02445" name="l02445"></a><span class="lineno"> 2445</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02446" name="l02446"></a><span class="lineno"> 2446</span>  }</div>
<div class="line"><a id="l02447" name="l02447"></a><span class="lineno"> 2447</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(reductionPreconditions(linalgOp))) {</div>
<div class="line"><a id="l02448" name="l02448"></a><span class="lineno"> 2448</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;precondition failed: reduction preconditions&quot;</span>;</div>
<div class="line"><a id="l02449" name="l02449"></a><span class="lineno"> 2449</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02450" name="l02450"></a><span class="lineno"> 2450</span>  }</div>
<div class="line"><a id="l02451" name="l02451"></a><span class="lineno"> 2451</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02452" name="l02452"></a><span class="lineno"> 2452</span>}</div>
<div class="line"><a id="l02453" name="l02453"></a><span class="lineno"> 2453</span> </div>
<div class="line"><a id="l02454" name="l02454"></a><span class="lineno"> 2454</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l02455" name="l02455"></a><span class="lineno"> 2455</span>vectorizePackOpPrecondition(linalg::PackOp packOp,</div>
<div class="line"><a id="l02456" name="l02456"></a><span class="lineno"> 2456</span>                            ArrayRef&lt;int64_t&gt; inputVectorSizes) {</div>
<div class="line"><a id="l02457" name="l02457"></a><span class="lineno"> 2457</span>  <span class="keyword">auto</span> padValue = packOp.getPaddingValue();</div>
<div class="line"><a id="l02458" name="l02458"></a><span class="lineno"> 2458</span>  Attribute cstAttr;</div>
<div class="line"><a id="l02459" name="l02459"></a><span class="lineno"> 2459</span>  <span class="comment">// TODO: Relax this condiiton</span></div>
<div class="line"><a id="l02460" name="l02460"></a><span class="lineno"> 2460</span>  <span class="keywordflow">if</span> (padValue &amp;&amp; !<a class="code hl_function" href="namespacemlir.html#a0190228b09e7b51a4bc1e013c01d404c">matchPattern</a>(padValue, <a class="code hl_function" href="namespacemlir.html#ad402a86ee4c9000c6fa1fceaddab560b">m_Constant</a>(&amp;cstAttr))) {</div>
<div class="line"><a id="l02461" name="l02461"></a><span class="lineno"> 2461</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;pad value is not constant: &quot;</span> &lt;&lt; packOp;</div>
<div class="line"><a id="l02462" name="l02462"></a><span class="lineno"> 2462</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02463" name="l02463"></a><span class="lineno"> 2463</span>  }</div>
<div class="line"><a id="l02464" name="l02464"></a><span class="lineno"> 2464</span> </div>
<div class="line"><a id="l02465" name="l02465"></a><span class="lineno"> 2465</span>  ArrayRef&lt;int64_t&gt; resultTensorShape = packOp.getDestType().getShape();</div>
<div class="line"><a id="l02466" name="l02466"></a><span class="lineno"> 2466</span>  <span class="keywordtype">bool</span> satisfyEmptyCond = <span class="keyword">true</span>;</div>
<div class="line"><a id="l02467" name="l02467"></a><span class="lineno"> 2467</span>  <span class="keywordflow">if</span> (inputVectorSizes.empty()) {</div>
<div class="line"><a id="l02468" name="l02468"></a><span class="lineno"> 2468</span>    <span class="keywordflow">if</span> (!packOp.getDestType().hasStaticShape() ||</div>
<div class="line"><a id="l02469" name="l02469"></a><span class="lineno"> 2469</span>        !packOp.getSourceType().hasStaticShape())</div>
<div class="line"><a id="l02470" name="l02470"></a><span class="lineno"> 2470</span>      satisfyEmptyCond = <span class="keyword">false</span>;</div>
<div class="line"><a id="l02471" name="l02471"></a><span class="lineno"> 2471</span>  }</div>
<div class="line"><a id="l02472" name="l02472"></a><span class="lineno"> 2472</span> </div>
<div class="line"><a id="l02473" name="l02473"></a><span class="lineno"> 2473</span>  <span class="keywordflow">if</span> (!satisfyEmptyCond &amp;&amp;</div>
<div class="line"><a id="l02474" name="l02474"></a><span class="lineno"> 2474</span>      <a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(<a class="code hl_function" href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">vector::isValidMaskedInputVector</a>(</div>
<div class="line"><a id="l02475" name="l02475"></a><span class="lineno"> 2475</span>          resultTensorShape.take_front(packOp.getSourceRank()),</div>
<div class="line"><a id="l02476" name="l02476"></a><span class="lineno"> 2476</span>          inputVectorSizes)))</div>
<div class="line"><a id="l02477" name="l02477"></a><span class="lineno"> 2477</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02478" name="l02478"></a><span class="lineno"> 2478</span> </div>
<div class="line"><a id="l02479" name="l02479"></a><span class="lineno"> 2479</span>  <span class="keywordflow">if</span> (llvm::any_of(packOp.getInnerTiles(), [](OpFoldResult v) {</div>
<div class="line"><a id="l02480" name="l02480"></a><span class="lineno"> 2480</span>        return !getConstantIntValue(v).has_value();</div>
<div class="line"><a id="l02481" name="l02481"></a><span class="lineno"> 2481</span>      })) {</div>
<div class="line"><a id="l02482" name="l02482"></a><span class="lineno"> 2482</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;inner_tiles must be constant: &quot;</span> &lt;&lt; packOp;</div>
<div class="line"><a id="l02483" name="l02483"></a><span class="lineno"> 2483</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02484" name="l02484"></a><span class="lineno"> 2484</span>  }</div>
<div class="line"><a id="l02485" name="l02485"></a><span class="lineno"> 2485</span> </div>
<div class="line"><a id="l02486" name="l02486"></a><span class="lineno"> 2486</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02487" name="l02487"></a><span class="lineno"> 2487</span>}</div>
<div class="line"><a id="l02488" name="l02488"></a><span class="lineno"> 2488</span> </div>
<div class="line"><a id="l02489" name="l02489"></a><span class="lineno"> 2489</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l02490" name="l02490"></a><span class="lineno"> 2490</span>vectorizePadOpPrecondition(tensor::PadOp padOp,</div>
<div class="line"><a id="l02491" name="l02491"></a><span class="lineno"> 2491</span>                           ArrayRef&lt;int64_t&gt; inputVectorSizes) {</div>
<div class="line"><a id="l02492" name="l02492"></a><span class="lineno"> 2492</span>  <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a id="l02493" name="l02493"></a><span class="lineno"> 2493</span>  <span class="keywordflow">if</span> (!padValue) {</div>
<div class="line"><a id="l02494" name="l02494"></a><span class="lineno"> 2494</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;pad value is not constant: &quot;</span> &lt;&lt; padOp;</div>
<div class="line"><a id="l02495" name="l02495"></a><span class="lineno"> 2495</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02496" name="l02496"></a><span class="lineno"> 2496</span>  }</div>
<div class="line"><a id="l02497" name="l02497"></a><span class="lineno"> 2497</span> </div>
<div class="line"><a id="l02498" name="l02498"></a><span class="lineno"> 2498</span>  ArrayRef&lt;int64_t&gt; resultTensorShape = padOp.getResultType().getShape();</div>
<div class="line"><a id="l02499" name="l02499"></a><span class="lineno"> 2499</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(<a class="code hl_function" href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">vector::isValidMaskedInputVector</a>(resultTensorShape,</div>
<div class="line"><a id="l02500" name="l02500"></a><span class="lineno"> 2500</span>                                              inputVectorSizes)))</div>
<div class="line"><a id="l02501" name="l02501"></a><span class="lineno"> 2501</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02502" name="l02502"></a><span class="lineno"> 2502</span> </div>
<div class="line"><a id="l02503" name="l02503"></a><span class="lineno"> 2503</span>  <span class="comment">// Padding with non-zero low pad values is not supported, unless the</span></div>
<div class="line"><a id="l02504" name="l02504"></a><span class="lineno"> 2504</span>  <span class="comment">// corresponding result dim is 1 as this would require shifting the results to</span></div>
<div class="line"><a id="l02505" name="l02505"></a><span class="lineno"> 2505</span>  <span class="comment">// the right for the low padded dims by the required amount of low padding.</span></div>
<div class="line"><a id="l02506" name="l02506"></a><span class="lineno"> 2506</span>  <span class="comment">// However, we do support low padding if the dims being low padded have result</span></div>
<div class="line"><a id="l02507" name="l02507"></a><span class="lineno"> 2507</span>  <span class="comment">// sizes of 1. The reason is when we have a low pad on a unit result dim, the</span></div>
<div class="line"><a id="l02508" name="l02508"></a><span class="lineno"> 2508</span>  <span class="comment">// input size of that dimension will be dynamically zero (as the sum of the</span></div>
<div class="line"><a id="l02509" name="l02509"></a><span class="lineno"> 2509</span>  <span class="comment">// low pad and input dim size has to be one) and hence we will create a zero</span></div>
<div class="line"><a id="l02510" name="l02510"></a><span class="lineno"> 2510</span>  <span class="comment">// mask as the lowering logic just makes the mask one for the input dim size -</span></div>
<div class="line"><a id="l02511" name="l02511"></a><span class="lineno"> 2511</span>  <span class="comment">// which is zero here. Hence we will load the pad value which is what we want</span></div>
<div class="line"><a id="l02512" name="l02512"></a><span class="lineno"> 2512</span>  <span class="comment">// in this case. If the low pad is dynamically zero then the lowering is</span></div>
<div class="line"><a id="l02513" name="l02513"></a><span class="lineno"> 2513</span>  <span class="comment">// correct as well as no shifts are necessary.</span></div>
<div class="line"><a id="l02514" name="l02514"></a><span class="lineno"> 2514</span>  <span class="keywordflow">if</span> (llvm::any_of(llvm::enumerate(padOp.getLow()), [&amp;](<span class="keyword">const</span> <span class="keyword">auto</span> &amp;en) {</div>
<div class="line"><a id="l02515" name="l02515"></a><span class="lineno"> 2515</span>        Value padValue = en.value();</div>
<div class="line"><a id="l02516" name="l02516"></a><span class="lineno"> 2516</span>        unsigned pos = en.index();</div>
<div class="line"><a id="l02517" name="l02517"></a><span class="lineno"> 2517</span>        std::optional&lt;int64_t&gt; pad = getConstantIntValue(padValue);</div>
<div class="line"><a id="l02518" name="l02518"></a><span class="lineno"> 2518</span>        return (!pad.has_value() || pad.value() != 0) &amp;&amp;</div>
<div class="line"><a id="l02519" name="l02519"></a><span class="lineno"> 2519</span>               resultTensorShape[pos] != 1;</div>
<div class="line"><a id="l02520" name="l02520"></a><span class="lineno"> 2520</span>      })) {</div>
<div class="line"><a id="l02521" name="l02521"></a><span class="lineno"> 2521</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;low pad must all be zero for all non unit dims: &quot;</span> &lt;&lt; padOp;</div>
<div class="line"><a id="l02522" name="l02522"></a><span class="lineno"> 2522</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02523" name="l02523"></a><span class="lineno"> 2523</span>  }</div>
<div class="line"><a id="l02524" name="l02524"></a><span class="lineno"> 2524</span> </div>
<div class="line"><a id="l02525" name="l02525"></a><span class="lineno"> 2525</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02526" name="l02526"></a><span class="lineno"> 2526</span>}</div>
<div class="line"><a id="l02527" name="l02527"></a><span class="lineno"> 2527</span><span class="comment"></span> </div>
<div class="line"><a id="l02528" name="l02528"></a><span class="lineno"> 2528</span><span class="comment">/// Preconditions for scalable vectors.</span></div>
<div class="line"><a id="l02529" name="l02529"></a><span class="lineno"> 2529</span><span class="comment">///</span></div>
<div class="line"><a id="l02530" name="l02530"></a><span class="lineno"> 2530</span><span class="comment">/// For Ops implementing the LinalgOp interface, this is quite restrictive - it</span></div>
<div class="line"><a id="l02531" name="l02531"></a><span class="lineno"> 2531</span><span class="comment">/// models the fact that in practice we would only make selected dimensions</span></div>
<div class="line"><a id="l02532" name="l02532"></a><span class="lineno"> 2532</span><span class="comment">/// scalable. For other Ops (e.g. `linalg.unpack`), this will succeed</span></div>
<div class="line"><a id="l02533" name="l02533"></a><span class="lineno"> 2533</span><span class="comment">/// unconditionally - we are yet to identify meaningful conditions.</span></div>
<div class="line"><a id="l02534" name="l02534"></a><span class="lineno"> 2534</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l02535" name="l02535"></a><span class="lineno"> 2535</span>vectorizeScalableVectorPrecondition(Operation *op,</div>
<div class="line"><a id="l02536" name="l02536"></a><span class="lineno"> 2536</span>                                    ArrayRef&lt;int64_t&gt; inputVectorSizes,</div>
<div class="line"><a id="l02537" name="l02537"></a><span class="lineno"> 2537</span>                                    ArrayRef&lt;bool&gt; inputScalableVecDims) {</div>
<div class="line"><a id="l02538" name="l02538"></a><span class="lineno"> 2538</span>  assert(inputVectorSizes.size() == inputScalableVecDims.size() &amp;&amp;</div>
<div class="line"><a id="l02539" name="l02539"></a><span class="lineno"> 2539</span>         <span class="stringliteral">&quot;Number of input vector sizes and scalable dims doesn&#39;t match&quot;</span>);</div>
<div class="line"><a id="l02540" name="l02540"></a><span class="lineno"> 2540</span> </div>
<div class="line"><a id="l02541" name="l02541"></a><span class="lineno"> 2541</span>  <span class="keywordtype">size_t</span> numOfScalableDims =</div>
<div class="line"><a id="l02542" name="l02542"></a><span class="lineno"> 2542</span>      llvm::count_if(inputScalableVecDims, [](<span class="keywordtype">bool</span> flag) { <span class="keywordflow">return</span> flag; });</div>
<div class="line"><a id="l02543" name="l02543"></a><span class="lineno"> 2543</span> </div>
<div class="line"><a id="l02544" name="l02544"></a><span class="lineno"> 2544</span>  <span class="keywordflow">if</span> (numOfScalableDims == 0)</div>
<div class="line"><a id="l02545" name="l02545"></a><span class="lineno"> 2545</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02546" name="l02546"></a><span class="lineno"> 2546</span> </div>
<div class="line"><a id="l02547" name="l02547"></a><span class="lineno"> 2547</span>  <span class="keyword">auto</span> linalgOp = dyn_cast&lt;LinalgOp&gt;(op);</div>
<div class="line"><a id="l02548" name="l02548"></a><span class="lineno"> 2548</span> </div>
<div class="line"><a id="l02549" name="l02549"></a><span class="lineno"> 2549</span>  <span class="comment">// Cond 1: Reject Ops that don&#39;t implement the LinalgOp interface, with the</span></div>
<div class="line"><a id="l02550" name="l02550"></a><span class="lineno"> 2550</span>  <span class="comment">// exception of UnpackOp for which there is a dedicated hook.</span></div>
<div class="line"><a id="l02551" name="l02551"></a><span class="lineno"> 2551</span>  <span class="keywordflow">if</span> (!linalgOp) {</div>
<div class="line"><a id="l02552" name="l02552"></a><span class="lineno"> 2552</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>(isa&lt;linalg::UnPackOp&gt;(op));</div>
<div class="line"><a id="l02553" name="l02553"></a><span class="lineno"> 2553</span>  }</div>
<div class="line"><a id="l02554" name="l02554"></a><span class="lineno"> 2554</span> </div>
<div class="line"><a id="l02555" name="l02555"></a><span class="lineno"> 2555</span>  <span class="comment">// Cond 2: There&#39;s been no need for more than 2 scalable dims so far</span></div>
<div class="line"><a id="l02556" name="l02556"></a><span class="lineno"> 2556</span>  <span class="keywordflow">if</span> (numOfScalableDims &gt; 2)</div>
<div class="line"><a id="l02557" name="l02557"></a><span class="lineno"> 2557</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02558" name="l02558"></a><span class="lineno"> 2558</span> </div>
<div class="line"><a id="l02559" name="l02559"></a><span class="lineno"> 2559</span>  <span class="comment">// Cond 3: Look at the configuration in `inputScalableVecDims` and verify that</span></div>
<div class="line"><a id="l02560" name="l02560"></a><span class="lineno"> 2560</span>  <span class="comment">// it matches one of the supported cases:</span></div>
<div class="line"><a id="l02561" name="l02561"></a><span class="lineno"> 2561</span>  <span class="comment">//  1. Exactly 1 dim is scalable and that&#39;s the _last_ non-unit parallel dim</span></div>
<div class="line"><a id="l02562" name="l02562"></a><span class="lineno"> 2562</span>  <span class="comment">//    (*).</span></div>
<div class="line"><a id="l02563" name="l02563"></a><span class="lineno"> 2563</span>  <span class="comment">//  2. Exactly 2 dims are scalable and those are the _last two adjacent_</span></div>
<div class="line"><a id="l02564" name="l02564"></a><span class="lineno"> 2564</span>  <span class="comment">//     parallel dims.</span></div>
<div class="line"><a id="l02565" name="l02565"></a><span class="lineno"> 2565</span>  <span class="comment">//  3. Exactly 1 reduction dim is scalable and that&#39;s the last (innermost)</span></div>
<div class="line"><a id="l02566" name="l02566"></a><span class="lineno"> 2566</span>  <span class="comment">//  dim.</span></div>
<div class="line"><a id="l02567" name="l02567"></a><span class="lineno"> 2567</span>  <span class="comment">// The 2nd restriction above means that only Matmul-like Ops are supported</span></div>
<div class="line"><a id="l02568" name="l02568"></a><span class="lineno"> 2568</span>  <span class="comment">// when 2 dims are scalable, e.g. :</span></div>
<div class="line"><a id="l02569" name="l02569"></a><span class="lineno"> 2569</span>  <span class="comment">//    * iterators = [parallel, parallel, reduction]</span></div>
<div class="line"><a id="l02570" name="l02570"></a><span class="lineno"> 2570</span>  <span class="comment">//    * scalable flags = [true, true, false]</span></div>
<div class="line"><a id="l02571" name="l02571"></a><span class="lineno"> 2571</span>  <span class="comment">//</span></div>
<div class="line"><a id="l02572" name="l02572"></a><span class="lineno"> 2572</span>  <span class="comment">// (*) Non-unit dims get folded away in practice.</span></div>
<div class="line"><a id="l02573" name="l02573"></a><span class="lineno"> 2573</span>  <span class="comment">// TODO: Relax these conditions as good motivating examples are identified.</span></div>
<div class="line"><a id="l02574" name="l02574"></a><span class="lineno"> 2574</span> </div>
<div class="line"><a id="l02575" name="l02575"></a><span class="lineno"> 2575</span>  <span class="comment">// Find the first scalable flag.</span></div>
<div class="line"><a id="l02576" name="l02576"></a><span class="lineno"> 2576</span>  <span class="keywordtype">bool</span> seenNonUnitParallel = <span class="keyword">false</span>;</div>
<div class="line"><a id="l02577" name="l02577"></a><span class="lineno"> 2577</span>  <span class="keyword">auto</span> iterators = linalgOp.getIteratorTypesArray();</div>
<div class="line"><a id="l02578" name="l02578"></a><span class="lineno"> 2578</span>  SmallVector&lt;bool&gt; scalableFlags(inputScalableVecDims);</div>
<div class="line"><a id="l02579" name="l02579"></a><span class="lineno"> 2579</span>  int64_t idx = scalableFlags.size() - 1;</div>
<div class="line"><a id="l02580" name="l02580"></a><span class="lineno"> 2580</span>  <span class="keywordflow">while</span> (!scalableFlags[idx]) {</div>
<div class="line"><a id="l02581" name="l02581"></a><span class="lineno"> 2581</span>    <span class="keywordtype">bool</span> isNonUnitDim = (inputVectorSizes[idx] != 1);</div>
<div class="line"><a id="l02582" name="l02582"></a><span class="lineno"> 2582</span>    seenNonUnitParallel |=</div>
<div class="line"><a id="l02583" name="l02583"></a><span class="lineno"> 2583</span>        (iterators[idx] == utils::IteratorType::parallel &amp;&amp; isNonUnitDim);</div>
<div class="line"><a id="l02584" name="l02584"></a><span class="lineno"> 2584</span> </div>
<div class="line"><a id="l02585" name="l02585"></a><span class="lineno"> 2585</span>    iterators.pop_back();</div>
<div class="line"><a id="l02586" name="l02586"></a><span class="lineno"> 2586</span>    scalableFlags.pop_back();</div>
<div class="line"><a id="l02587" name="l02587"></a><span class="lineno"> 2587</span>    --idx;</div>
<div class="line"><a id="l02588" name="l02588"></a><span class="lineno"> 2588</span>  }</div>
<div class="line"><a id="l02589" name="l02589"></a><span class="lineno"> 2589</span> </div>
<div class="line"><a id="l02590" name="l02590"></a><span class="lineno"> 2590</span>  <span class="comment">// Analyze the iterator corresponding to the first scalable dim.</span></div>
<div class="line"><a id="l02591" name="l02591"></a><span class="lineno"> 2591</span>  <span class="keywordflow">switch</span> (iterators.back()) {</div>
<div class="line"><a id="l02592" name="l02592"></a><span class="lineno"> 2592</span>  <span class="keywordflow">case</span> utils::IteratorType::reduction: {</div>
<div class="line"><a id="l02593" name="l02593"></a><span class="lineno"> 2593</span>    <span class="comment">// Check 3. above is met.</span></div>
<div class="line"><a id="l02594" name="l02594"></a><span class="lineno"> 2594</span>    <span class="keywordflow">if</span> (iterators.size() != inputVectorSizes.size()) {</div>
<div class="line"><a id="l02595" name="l02595"></a><span class="lineno"> 2595</span>      LDBG() &lt;&lt; <span class="stringliteral">&quot;Non-trailing reduction dim requested for scalable &quot;</span></div>
<div class="line"><a id="l02596" name="l02596"></a><span class="lineno"> 2596</span>                <span class="stringliteral">&quot;vectorization&quot;</span>;</div>
<div class="line"><a id="l02597" name="l02597"></a><span class="lineno"> 2597</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02598" name="l02598"></a><span class="lineno"> 2598</span>    }</div>
<div class="line"><a id="l02599" name="l02599"></a><span class="lineno"> 2599</span>    <span class="keywordflow">if</span> (isa&lt;linalg::MatmulOp&gt;(op)) {</div>
<div class="line"><a id="l02600" name="l02600"></a><span class="lineno"> 2600</span>      LDBG()</div>
<div class="line"><a id="l02601" name="l02601"></a><span class="lineno"> 2601</span>          &lt;&lt; <span class="stringliteral">&quot;Scalable vectorization of the reduction dim in Matmul-like ops &quot;</span></div>
<div class="line"><a id="l02602" name="l02602"></a><span class="lineno"> 2602</span>             <span class="stringliteral">&quot;is not supported&quot;</span>;</div>
<div class="line"><a id="l02603" name="l02603"></a><span class="lineno"> 2603</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02604" name="l02604"></a><span class="lineno"> 2604</span>    }</div>
<div class="line"><a id="l02605" name="l02605"></a><span class="lineno"> 2605</span>    <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l02606" name="l02606"></a><span class="lineno"> 2606</span>  }</div>
<div class="line"><a id="l02607" name="l02607"></a><span class="lineno"> 2607</span>  <span class="keywordflow">case</span> utils::IteratorType::parallel: {</div>
<div class="line"><a id="l02608" name="l02608"></a><span class="lineno"> 2608</span>    <span class="comment">// Check 1. and 2. above are met.</span></div>
<div class="line"><a id="l02609" name="l02609"></a><span class="lineno"> 2609</span>    <span class="keywordflow">if</span> (seenNonUnitParallel) {</div>
<div class="line"><a id="l02610" name="l02610"></a><span class="lineno"> 2610</span>      LDBG() &lt;&lt; <span class="stringliteral">&quot;Inner parallel dim not requested for scalable &quot;</span></div>
<div class="line"><a id="l02611" name="l02611"></a><span class="lineno"> 2611</span>                <span class="stringliteral">&quot;vectorization&quot;</span>;</div>
<div class="line"><a id="l02612" name="l02612"></a><span class="lineno"> 2612</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02613" name="l02613"></a><span class="lineno"> 2613</span>    }</div>
<div class="line"><a id="l02614" name="l02614"></a><span class="lineno"> 2614</span>    <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l02615" name="l02615"></a><span class="lineno"> 2615</span>  }</div>
<div class="line"><a id="l02616" name="l02616"></a><span class="lineno"> 2616</span>  }</div>
<div class="line"><a id="l02617" name="l02617"></a><span class="lineno"> 2617</span> </div>
<div class="line"><a id="l02618" name="l02618"></a><span class="lineno"> 2618</span>  <span class="comment">// If present, check the 2nd scalable dim. ATM, only Matmul-like Ops are</span></div>
<div class="line"><a id="l02619" name="l02619"></a><span class="lineno"> 2619</span>  <span class="comment">// supported for which expect the folowing config:</span></div>
<div class="line"><a id="l02620" name="l02620"></a><span class="lineno"> 2620</span>  <span class="comment">//    * iterators = [parallel, parallel, reduction]</span></div>
<div class="line"><a id="l02621" name="l02621"></a><span class="lineno"> 2621</span>  <span class="comment">//    * scalable flags = [true, true, false]</span></div>
<div class="line"><a id="l02622" name="l02622"></a><span class="lineno"> 2622</span>  <span class="keywordflow">if</span> (numOfScalableDims == 2) {</div>
<div class="line"><a id="l02623" name="l02623"></a><span class="lineno"> 2623</span>    <span class="comment">// Disallow below case which breaks 3. above:</span></div>
<div class="line"><a id="l02624" name="l02624"></a><span class="lineno"> 2624</span>    <span class="comment">//    * iterators = [..., parallel, reduction]</span></div>
<div class="line"><a id="l02625" name="l02625"></a><span class="lineno"> 2625</span>    <span class="comment">//    * scalable flags = [..., true, true]</span></div>
<div class="line"><a id="l02626" name="l02626"></a><span class="lineno"> 2626</span>    <span class="keywordflow">if</span> (iterators.back() == utils::IteratorType::reduction) {</div>
<div class="line"><a id="l02627" name="l02627"></a><span class="lineno"> 2627</span>      LDBG() &lt;&lt; <span class="stringliteral">&quot;Higher dim than the trailing reduction dim requested for &quot;</span></div>
<div class="line"><a id="l02628" name="l02628"></a><span class="lineno"> 2628</span>                <span class="stringliteral">&quot;scalable &quot;</span></div>
<div class="line"><a id="l02629" name="l02629"></a><span class="lineno"> 2629</span>                <span class="stringliteral">&quot;vectorizatio&quot;</span>;</div>
<div class="line"><a id="l02630" name="l02630"></a><span class="lineno"> 2630</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02631" name="l02631"></a><span class="lineno"> 2631</span>    }</div>
<div class="line"><a id="l02632" name="l02632"></a><span class="lineno"> 2632</span>    scalableFlags.pop_back();</div>
<div class="line"><a id="l02633" name="l02633"></a><span class="lineno"> 2633</span>    iterators.pop_back();</div>
<div class="line"><a id="l02634" name="l02634"></a><span class="lineno"> 2634</span> </div>
<div class="line"><a id="l02635" name="l02635"></a><span class="lineno"> 2635</span>    <span class="keywordflow">if</span> (!scalableFlags.back() ||</div>
<div class="line"><a id="l02636" name="l02636"></a><span class="lineno"> 2636</span>        (iterators.back() != utils::IteratorType::parallel))</div>
<div class="line"><a id="l02637" name="l02637"></a><span class="lineno"> 2637</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02638" name="l02638"></a><span class="lineno"> 2638</span>  }</div>
<div class="line"><a id="l02639" name="l02639"></a><span class="lineno"> 2639</span> </div>
<div class="line"><a id="l02640" name="l02640"></a><span class="lineno"> 2640</span>  <span class="comment">// Cond 4: Only the following ops are supported in the</span></div>
<div class="line"><a id="l02641" name="l02641"></a><span class="lineno"> 2641</span>  <span class="comment">// presence of scalable vectors</span></div>
<div class="line"><a id="l02642" name="l02642"></a><span class="lineno"> 2642</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>(<a class="code hl_function" href="namespacemlir_1_1linalg.html#a8b1c347bc995910212c197f9f8728b12">isElementwise</a>(linalgOp) || isa&lt;linalg::MatmulOp&gt;(op) ||</div>
<div class="line"><a id="l02643" name="l02643"></a><span class="lineno"> 2643</span>                 isa&lt;linalg::DepthwiseConv1DNwcWcOp&gt;(op) ||</div>
<div class="line"><a id="l02644" name="l02644"></a><span class="lineno"> 2644</span>                 isa&lt;linalg::MatvecOp&gt;(op) || isa&lt;linalg::Mmt4DOp&gt;(op) ||</div>
<div class="line"><a id="l02645" name="l02645"></a><span class="lineno"> 2645</span>                 isa&lt;linalg::BatchMmt4DOp&gt;(op) ||</div>
<div class="line"><a id="l02646" name="l02646"></a><span class="lineno"> 2646</span>                 <a class="code hl_function" href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">hasReductionIterator</a>(linalgOp));</div>
<div class="line"><a id="l02647" name="l02647"></a><span class="lineno"> 2647</span>}</div>
<div class="line"><a id="l02648" name="l02648"></a><span class="lineno"> 2648</span> </div>
<div class="line"><a id="l02649" name="l02649"></a><span class="lineno"> 2649</span>LogicalResult <a class="code hl_function" href="namespacemlir_1_1linalg.html#a8d0310adee4f127279f9147a71db0181">mlir::linalg::vectorizeOpPrecondition</a>(</div>
<div class="line"><a id="l02650" name="l02650"></a><span class="lineno"> 2650</span>    Operation *op, ArrayRef&lt;int64_t&gt; inputVectorSizes,</div>
<div class="line"><a id="l02651" name="l02651"></a><span class="lineno"> 2651</span>    ArrayRef&lt;bool&gt; inputScalableVecDims, <span class="keywordtype">bool</span> vectorizeNDExtract,</div>
<div class="line"><a id="l02652" name="l02652"></a><span class="lineno"> 2652</span>    <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a id="l02653" name="l02653"></a><span class="lineno"> 2653</span> </div>
<div class="line"><a id="l02654" name="l02654"></a><span class="lineno"> 2654</span>  <span class="keywordflow">if</span> (!<a class="code hl_function" href="namespacemlir_1_1linalg.html#a142a09c03dbaa0d795e44f62d4b6b395">hasVectorizationImpl</a>(op))</div>
<div class="line"><a id="l02655" name="l02655"></a><span class="lineno"> 2655</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02656" name="l02656"></a><span class="lineno"> 2656</span> </div>
<div class="line"><a id="l02657" name="l02657"></a><span class="lineno"> 2657</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(vectorizeScalableVectorPrecondition(op, inputVectorSizes,</div>
<div class="line"><a id="l02658" name="l02658"></a><span class="lineno"> 2658</span>                                                 inputScalableVecDims)))</div>
<div class="line"><a id="l02659" name="l02659"></a><span class="lineno"> 2659</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02660" name="l02660"></a><span class="lineno"> 2660</span> </div>
<div class="line"><a id="l02661" name="l02661"></a><span class="lineno"> 2661</span>  <span class="keywordflow">return</span> <a class="code hl_typedef" href="namespacemlir.html#a9eabc3974d2131e15fad199b34b2eaa0">TypeSwitch&lt;Operation *, LogicalResult&gt;</a>(op)</div>
<div class="line"><a id="l02662" name="l02662"></a><span class="lineno"> 2662</span>      .Case&lt;linalg::LinalgOp&gt;([&amp;](<span class="keyword">auto</span> linalgOp) {</div>
<div class="line"><a id="l02663" name="l02663"></a><span class="lineno"> 2663</span>        <span class="keywordflow">return</span> vectorizeLinalgOpPrecondition(linalgOp, inputVectorSizes,</div>
<div class="line"><a id="l02664" name="l02664"></a><span class="lineno"> 2664</span>                                             vectorizeNDExtract,</div>
<div class="line"><a id="l02665" name="l02665"></a><span class="lineno"> 2665</span>                                             flatten1DDepthwiseConv);</div>
<div class="line"><a id="l02666" name="l02666"></a><span class="lineno"> 2666</span>      })</div>
<div class="line"><a id="l02667" name="l02667"></a><span class="lineno"> 2667</span>      .Case&lt;tensor::PadOp&gt;([&amp;](<span class="keyword">auto</span> padOp) {</div>
<div class="line"><a id="l02668" name="l02668"></a><span class="lineno"> 2668</span>        <span class="keywordflow">return</span> vectorizePadOpPrecondition(padOp, inputVectorSizes);</div>
<div class="line"><a id="l02669" name="l02669"></a><span class="lineno"> 2669</span>      })</div>
<div class="line"><a id="l02670" name="l02670"></a><span class="lineno"> 2670</span>      .Case&lt;linalg::PackOp&gt;([&amp;](<span class="keyword">auto</span> packOp) {</div>
<div class="line"><a id="l02671" name="l02671"></a><span class="lineno"> 2671</span>        <span class="keywordflow">return</span> vectorizePackOpPrecondition(packOp, inputVectorSizes);</div>
<div class="line"><a id="l02672" name="l02672"></a><span class="lineno"> 2672</span>      })</div>
<div class="line"><a id="l02673" name="l02673"></a><span class="lineno"> 2673</span>      .Case&lt;linalg::UnPackOp&gt;([&amp;](<span class="keyword">auto</span> unpackOp) {</div>
<div class="line"><a id="l02674" name="l02674"></a><span class="lineno"> 2674</span>        <span class="keywordflow">return</span> vectorizeUnPackOpPrecondition(unpackOp, inputVectorSizes);</div>
<div class="line"><a id="l02675" name="l02675"></a><span class="lineno"> 2675</span>      })</div>
<div class="line"><a id="l02676" name="l02676"></a><span class="lineno"> 2676</span>      .Case&lt;tensor::InsertSliceOp&gt;([&amp;](<span class="keyword">auto</span> sliceOp) {</div>
<div class="line"><a id="l02677" name="l02677"></a><span class="lineno"> 2677</span>        <span class="keywordflow">return</span> vectorizeInsertSliceOpPrecondition(sliceOp, inputVectorSizes);</div>
<div class="line"><a id="l02678" name="l02678"></a><span class="lineno"> 2678</span>      })</div>
<div class="line"><a id="l02679" name="l02679"></a><span class="lineno"> 2679</span>      .Default([](<span class="keyword">auto</span>) { <span class="keywordflow">return</span> failure(); });</div>
<div class="line"><a id="l02680" name="l02680"></a><span class="lineno"> 2680</span>}</div>
<div class="line"><a id="l02681" name="l02681"></a><span class="lineno"> 2681</span><span class="comment"></span> </div>
<div class="line"><a id="l02682" name="l02682"></a><span class="lineno"> 2682</span><span class="comment">/// Converts affine.apply Ops to arithmetic operations.</span></div>
<div class="line"><a id="l02683" name="l02683"></a><span class="lineno"> 2683</span><span class="keyword">static</span> <span class="keywordtype">void</span> convertAffineApply(RewriterBase &amp;rewriter, LinalgOp linalgOp) {</div>
<div class="line"><a id="l02684" name="l02684"></a><span class="lineno"> 2684</span>  OpBuilder::InsertionGuard g(rewriter);</div>
<div class="line"><a id="l02685" name="l02685"></a><span class="lineno"> 2685</span>  <span class="keyword">auto</span> toReplace = linalgOp.getBlock()-&gt;getOps&lt;affine::AffineApplyOp&gt;();</div>
<div class="line"><a id="l02686" name="l02686"></a><span class="lineno"> 2686</span> </div>
<div class="line"><a id="l02687" name="l02687"></a><span class="lineno"> 2687</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> op : make_early_inc_range(toReplace)) {</div>
<div class="line"><a id="l02688" name="l02688"></a><span class="lineno"> 2688</span>    rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(op);</div>
<div class="line"><a id="l02689" name="l02689"></a><span class="lineno"> 2689</span>    <span class="keyword">auto</span> expanded = affine::expandAffineExpr(</div>
<div class="line"><a id="l02690" name="l02690"></a><span class="lineno"> 2690</span>        rewriter, op-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a6c0b8ce5ff714a34f0192f3aa60dc7ea">getLoc</a>(), op.getAffineMap().<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0),</div>
<div class="line"><a id="l02691" name="l02691"></a><span class="lineno"> 2691</span>        op.<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>().take_front(op.getAffineMap().getNumDims()),</div>
<div class="line"><a id="l02692" name="l02692"></a><span class="lineno"> 2692</span>        op.<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>().take_back(op.getAffineMap().getNumSymbols()));</div>
<div class="line"><a id="l02693" name="l02693"></a><span class="lineno"> 2693</span>    rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(op, expanded);</div>
<div class="line"><a id="l02694" name="l02694"></a><span class="lineno"> 2694</span>  }</div>
<div class="line"><a id="l02695" name="l02695"></a><span class="lineno"> 2695</span>}</div>
<div class="line"><a id="l02696" name="l02696"></a><span class="lineno"> 2696</span> </div>
<div class="line"><a id="l02697" name="l02697"></a><span class="lineno"> 2697</span><span class="keywordtype">bool</span> <a class="code hl_function" href="namespacemlir_1_1linalg.html#a142a09c03dbaa0d795e44f62d4b6b395">mlir::linalg::hasVectorizationImpl</a>(Operation *op) {</div>
<div class="line"><a id="l02698" name="l02698"></a><span class="lineno"> 2698</span>  <span class="keywordflow">return</span> isa&lt;linalg::LinalgOp, tensor::PadOp, linalg::PackOp, linalg::UnPackOp,</div>
<div class="line"><a id="l02699" name="l02699"></a><span class="lineno"> 2699</span>             tensor::InsertSliceOp&gt;(op);</div>
<div class="line"><a id="l02700" name="l02700"></a><span class="lineno"> 2700</span>}</div>
<div class="line"><a id="l02701" name="l02701"></a><span class="lineno"> 2701</span> </div>
<div class="line"><a id="l02702" name="l02702"></a><span class="lineno"> 2702</span>FailureOr&lt;VectorizationResult&gt; <a class="code hl_function" href="namespacemlir_1_1linalg.html#a303bb59c046a82276569e6b906002997">mlir::linalg::vectorize</a>(</div>
<div class="line"><a id="l02703" name="l02703"></a><span class="lineno"> 2703</span>    RewriterBase &amp;rewriter, Operation *op, ArrayRef&lt;int64_t&gt; inputVectorSizes,</div>
<div class="line"><a id="l02704" name="l02704"></a><span class="lineno"> 2704</span>    ArrayRef&lt;bool&gt; inputScalableVecDims, <span class="keywordtype">bool</span> vectorizeNDExtract,</div>
<div class="line"><a id="l02705" name="l02705"></a><span class="lineno"> 2705</span>    <span class="keywordtype">bool</span> flatten1DDepthwiseConv, <span class="keywordtype">bool</span> assumeDynamicDimsMatchVecSizes,</div>
<div class="line"><a id="l02706" name="l02706"></a><span class="lineno"> 2706</span>    <span class="keywordtype">bool</span> createNamedContraction) {</div>
<div class="line"><a id="l02707" name="l02707"></a><span class="lineno"> 2707</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Attempting to vectorize: &quot;</span> &lt;&lt; *op;</div>
<div class="line"><a id="l02708" name="l02708"></a><span class="lineno"> 2708</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Input vector sizes: &quot;</span> &lt;&lt; llvm::interleaved(inputVectorSizes);</div>
<div class="line"><a id="l02709" name="l02709"></a><span class="lineno"> 2709</span>  LDBG() &lt;&lt; <span class="stringliteral">&quot;Input scalable vector dims: &quot;</span></div>
<div class="line"><a id="l02710" name="l02710"></a><span class="lineno"> 2710</span>         &lt;&lt; llvm::interleaved(inputScalableVecDims);</div>
<div class="line"><a id="l02711" name="l02711"></a><span class="lineno"> 2711</span> </div>
<div class="line"><a id="l02712" name="l02712"></a><span class="lineno"> 2712</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(<a class="code hl_function" href="namespacemlir_1_1linalg.html#a8d0310adee4f127279f9147a71db0181">vectorizeOpPrecondition</a>(op, inputVectorSizes, inputScalableVecDims,</div>
<div class="line"><a id="l02713" name="l02713"></a><span class="lineno"> 2713</span>                                     vectorizeNDExtract,</div>
<div class="line"><a id="l02714" name="l02714"></a><span class="lineno"> 2714</span>                                     flatten1DDepthwiseConv))) {</div>
<div class="line"><a id="l02715" name="l02715"></a><span class="lineno"> 2715</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorization pre-conditions failed&quot;</span>;</div>
<div class="line"><a id="l02716" name="l02716"></a><span class="lineno"> 2716</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02717" name="l02717"></a><span class="lineno"> 2717</span>  }</div>
<div class="line"><a id="l02718" name="l02718"></a><span class="lineno"> 2718</span> </div>
<div class="line"><a id="l02719" name="l02719"></a><span class="lineno"> 2719</span>  <span class="comment">// Initialize vectorization state.</span></div>
<div class="line"><a id="l02720" name="l02720"></a><span class="lineno"> 2720</span>  VectorizationState state(rewriter);</div>
<div class="line"><a id="l02721" name="l02721"></a><span class="lineno"> 2721</span>  <span class="keywordflow">if</span> (<span class="keyword">auto</span> linalgOp = dyn_cast&lt;linalg::LinalgOp&gt;(op)) {</div>
<div class="line"><a id="l02722" name="l02722"></a><span class="lineno"> 2722</span>    <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(state.initState(rewriter, linalgOp, inputVectorSizes,</div>
<div class="line"><a id="l02723" name="l02723"></a><span class="lineno"> 2723</span>                               inputScalableVecDims,</div>
<div class="line"><a id="l02724" name="l02724"></a><span class="lineno"> 2724</span>                               assumeDynamicDimsMatchVecSizes))) {</div>
<div class="line"><a id="l02725" name="l02725"></a><span class="lineno"> 2725</span>      LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorization state couldn&#39;t be initialized&quot;</span>;</div>
<div class="line"><a id="l02726" name="l02726"></a><span class="lineno"> 2726</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02727" name="l02727"></a><span class="lineno"> 2727</span>    }</div>
<div class="line"><a id="l02728" name="l02728"></a><span class="lineno"> 2728</span>  }</div>
<div class="line"><a id="l02729" name="l02729"></a><span class="lineno"> 2729</span> </div>
<div class="line"><a id="l02730" name="l02730"></a><span class="lineno"> 2730</span>  SmallVector&lt;Value&gt; results;</div>
<div class="line"><a id="l02731" name="l02731"></a><span class="lineno"> 2731</span>  <span class="keyword">auto</span> vectorizeResult =</div>
<div class="line"><a id="l02732" name="l02732"></a><span class="lineno"> 2732</span>      <a class="code hl_typedef" href="namespacemlir.html#a9eabc3974d2131e15fad199b34b2eaa0">TypeSwitch&lt;Operation *, LogicalResult&gt;</a>(op)</div>
<div class="line"><a id="l02733" name="l02733"></a><span class="lineno"> 2733</span>          .Case&lt;linalg::LinalgOp&gt;([&amp;](<span class="keyword">auto</span> linalgOp) {</div>
<div class="line"><a id="l02734" name="l02734"></a><span class="lineno"> 2734</span>            <span class="comment">// TODO: isaConvolutionOpInterface that can also infer from</span></div>
<div class="line"><a id="l02735" name="l02735"></a><span class="lineno"> 2735</span>            <span class="comment">// generic features. Will require stride/dilation attributes</span></div>
<div class="line"><a id="l02736" name="l02736"></a><span class="lineno"> 2736</span>            <span class="comment">// inference.</span></div>
<div class="line"><a id="l02737" name="l02737"></a><span class="lineno"> 2737</span>            <span class="keywordflow">if</span> (isa&lt;ConvolutionOpInterface&gt;(linalgOp.getOperation())) {</div>
<div class="line"><a id="l02738" name="l02738"></a><span class="lineno"> 2738</span>              FailureOr&lt;Operation *&gt; convOr = <a class="code hl_function" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a>(</div>
<div class="line"><a id="l02739" name="l02739"></a><span class="lineno"> 2739</span>                  rewriter, linalgOp, inputVectorSizes, inputScalableVecDims,</div>
<div class="line"><a id="l02740" name="l02740"></a><span class="lineno"> 2740</span>                  flatten1DDepthwiseConv);</div>
<div class="line"><a id="l02741" name="l02741"></a><span class="lineno"> 2741</span>              <span class="keywordflow">if</span> (succeeded(convOr)) {</div>
<div class="line"><a id="l02742" name="l02742"></a><span class="lineno"> 2742</span>                llvm::append_range(results, (*convOr)-&gt;getResults());</div>
<div class="line"><a id="l02743" name="l02743"></a><span class="lineno"> 2743</span>                <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02744" name="l02744"></a><span class="lineno"> 2744</span>              }</div>
<div class="line"><a id="l02745" name="l02745"></a><span class="lineno"> 2745</span> </div>
<div class="line"><a id="l02746" name="l02746"></a><span class="lineno"> 2746</span>              LDBG() &lt;&lt; <span class="stringliteral">&quot;Unsupported convolution can&#39;t be vectorized.&quot;</span>;</div>
<div class="line"><a id="l02747" name="l02747"></a><span class="lineno"> 2747</span>              <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02748" name="l02748"></a><span class="lineno"> 2748</span>            }</div>
<div class="line"><a id="l02749" name="l02749"></a><span class="lineno"> 2749</span> </div>
<div class="line"><a id="l02750" name="l02750"></a><span class="lineno"> 2750</span>            <span class="keywordflow">if</span> (createNamedContraction &amp;&amp;</div>
<div class="line"><a id="l02751" name="l02751"></a><span class="lineno"> 2751</span>                isa&lt;ContractionOpInterface&gt;(linalgOp.getOperation()))</div>
<div class="line"><a id="l02752" name="l02752"></a><span class="lineno"> 2752</span>              <span class="keywordflow">return</span> vectorizeAsLinalgContraction(rewriter, state, linalgOp,</div>
<div class="line"><a id="l02753" name="l02753"></a><span class="lineno"> 2753</span>                                                  results);</div>
<div class="line"><a id="l02754" name="l02754"></a><span class="lineno"> 2754</span> </div>
<div class="line"><a id="l02755" name="l02755"></a><span class="lineno"> 2755</span>            LDBG()</div>
<div class="line"><a id="l02756" name="l02756"></a><span class="lineno"> 2756</span>                &lt;&lt; <span class="stringliteral">&quot;Vectorize generic by broadcasting to the canonical vector &quot;</span></div>
<div class="line"><a id="l02757" name="l02757"></a><span class="lineno"> 2757</span>                   <span class="stringliteral">&quot;shape&quot;</span>;</div>
<div class="line"><a id="l02758" name="l02758"></a><span class="lineno"> 2758</span> </div>
<div class="line"><a id="l02759" name="l02759"></a><span class="lineno"> 2759</span>            <span class="comment">// Pre-process before proceeding.</span></div>
<div class="line"><a id="l02760" name="l02760"></a><span class="lineno"> 2760</span>            convertAffineApply(rewriter, linalgOp);</div>
<div class="line"><a id="l02761" name="l02761"></a><span class="lineno"> 2761</span> </div>
<div class="line"><a id="l02762" name="l02762"></a><span class="lineno"> 2762</span>            <span class="comment">// TODO: &#39;vectorize&#39; takes in a &#39;RewriterBase&#39; which is up-casted</span></div>
<div class="line"><a id="l02763" name="l02763"></a><span class="lineno"> 2763</span>            <span class="comment">// to &#39;OpBuilder&#39; when it is passed over to some methods like</span></div>
<div class="line"><a id="l02764" name="l02764"></a><span class="lineno"> 2764</span>            <span class="comment">// &#39;vectorizeAsLinalgGeneric&#39;. This is highly problematic: if we</span></div>
<div class="line"><a id="l02765" name="l02765"></a><span class="lineno"> 2765</span>            <span class="comment">// erase an op within these methods, the actual rewriter won&#39;t be</span></div>
<div class="line"><a id="l02766" name="l02766"></a><span class="lineno"> 2766</span>            <span class="comment">// notified and we will end up with read-after-free issues!</span></div>
<div class="line"><a id="l02767" name="l02767"></a><span class="lineno"> 2767</span>            <span class="keywordflow">return</span> <a class="code hl_function" href="Vectorization_8cpp.html#a35e1ec347850959af0bc7cbdf61b9da3">vectorizeAsLinalgGeneric</a>(rewriter, state, linalgOp, results);</div>
<div class="line"><a id="l02768" name="l02768"></a><span class="lineno"> 2768</span>          })</div>
<div class="line"><a id="l02769" name="l02769"></a><span class="lineno"> 2769</span>          .Case&lt;tensor::PadOp&gt;([&amp;](<span class="keyword">auto</span> padOp) {</div>
<div class="line"><a id="l02770" name="l02770"></a><span class="lineno"> 2770</span>            <span class="keywordflow">return</span> vectorizeAsTensorPadOp(rewriter, padOp, inputVectorSizes,</div>
<div class="line"><a id="l02771" name="l02771"></a><span class="lineno"> 2771</span>                                          results);</div>
<div class="line"><a id="l02772" name="l02772"></a><span class="lineno"> 2772</span>          })</div>
<div class="line"><a id="l02773" name="l02773"></a><span class="lineno"> 2773</span>          .Case&lt;linalg::PackOp&gt;([&amp;](<span class="keyword">auto</span> packOp) {</div>
<div class="line"><a id="l02774" name="l02774"></a><span class="lineno"> 2774</span>            <span class="keywordflow">return</span> vectorizeAsTensorPackOp(rewriter, packOp, inputVectorSizes,</div>
<div class="line"><a id="l02775" name="l02775"></a><span class="lineno"> 2775</span>                                           results);</div>
<div class="line"><a id="l02776" name="l02776"></a><span class="lineno"> 2776</span>          })</div>
<div class="line"><a id="l02777" name="l02777"></a><span class="lineno"> 2777</span>          .Case&lt;linalg::UnPackOp&gt;([&amp;](<span class="keyword">auto</span> unpackOp) {</div>
<div class="line"><a id="l02778" name="l02778"></a><span class="lineno"> 2778</span>            <span class="keywordflow">return</span> vectorizeAsTensorUnpackOp(rewriter, unpackOp,</div>
<div class="line"><a id="l02779" name="l02779"></a><span class="lineno"> 2779</span>                                             inputVectorSizes,</div>
<div class="line"><a id="l02780" name="l02780"></a><span class="lineno"> 2780</span>                                             inputScalableVecDims, results);</div>
<div class="line"><a id="l02781" name="l02781"></a><span class="lineno"> 2781</span>          })</div>
<div class="line"><a id="l02782" name="l02782"></a><span class="lineno"> 2782</span>          .Case&lt;tensor::InsertSliceOp&gt;([&amp;](<span class="keyword">auto</span> sliceOp) {</div>
<div class="line"><a id="l02783" name="l02783"></a><span class="lineno"> 2783</span>            <span class="keywordflow">return</span> <a class="code hl_function" href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926">vectorizeAsInsertSliceOp</a>(rewriter, sliceOp, inputVectorSizes,</div>
<div class="line"><a id="l02784" name="l02784"></a><span class="lineno"> 2784</span>                                            results);</div>
<div class="line"><a id="l02785" name="l02785"></a><span class="lineno"> 2785</span>          })</div>
<div class="line"><a id="l02786" name="l02786"></a><span class="lineno"> 2786</span>          .Default([](<span class="keyword">auto</span>) { <span class="keywordflow">return</span> failure(); });</div>
<div class="line"><a id="l02787" name="l02787"></a><span class="lineno"> 2787</span> </div>
<div class="line"><a id="l02788" name="l02788"></a><span class="lineno"> 2788</span>  <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(vectorizeResult)) {</div>
<div class="line"><a id="l02789" name="l02789"></a><span class="lineno"> 2789</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;Vectorization failed&quot;</span>;</div>
<div class="line"><a id="l02790" name="l02790"></a><span class="lineno"> 2790</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02791" name="l02791"></a><span class="lineno"> 2791</span>  }</div>
<div class="line"><a id="l02792" name="l02792"></a><span class="lineno"> 2792</span> </div>
<div class="line"><a id="l02793" name="l02793"></a><span class="lineno"> 2793</span>  <span class="keywordflow">return</span> VectorizationResult{results};</div>
<div class="line"><a id="l02794" name="l02794"></a><span class="lineno"> 2794</span>}</div>
<div class="line"><a id="l02795" name="l02795"></a><span class="lineno"> 2795</span> </div>
<div class="line"><a id="l02796" name="l02796"></a><span class="lineno"> 2796</span>LogicalResult <a class="code hl_function" href="namespacemlir_1_1linalg.html#a8c63bc9239511b70751c238a12f5b1da">mlir::linalg::vectorizeCopy</a>(RewriterBase &amp;rewriter,</div>
<div class="line"><a id="l02797" name="l02797"></a><span class="lineno"> 2797</span>                                          memref::CopyOp copyOp) {</div>
<div class="line"><a id="l02798" name="l02798"></a><span class="lineno"> 2798</span>  <span class="keyword">auto</span> srcType = cast&lt;MemRefType&gt;(copyOp.getSource().getType());</div>
<div class="line"><a id="l02799" name="l02799"></a><span class="lineno"> 2799</span>  <span class="keyword">auto</span> dstType = cast&lt;MemRefType&gt;(copyOp.getTarget().getType());</div>
<div class="line"><a id="l02800" name="l02800"></a><span class="lineno"> 2800</span>  <span class="keywordflow">if</span> (!srcType.hasStaticShape() || !dstType.hasStaticShape())</div>
<div class="line"><a id="l02801" name="l02801"></a><span class="lineno"> 2801</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02802" name="l02802"></a><span class="lineno"> 2802</span> </div>
<div class="line"><a id="l02803" name="l02803"></a><span class="lineno"> 2803</span>  <span class="keyword">auto</span> srcElementType = <a class="code hl_function" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(srcType);</div>
<div class="line"><a id="l02804" name="l02804"></a><span class="lineno"> 2804</span>  <span class="keyword">auto</span> dstElementType = <a class="code hl_function" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(dstType);</div>
<div class="line"><a id="l02805" name="l02805"></a><span class="lineno"> 2805</span>  <span class="keywordflow">if</span> (!VectorType::isValidElementType(srcElementType) ||</div>
<div class="line"><a id="l02806" name="l02806"></a><span class="lineno"> 2806</span>      !VectorType::isValidElementType(dstElementType))</div>
<div class="line"><a id="l02807" name="l02807"></a><span class="lineno"> 2807</span>    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02808" name="l02808"></a><span class="lineno"> 2808</span> </div>
<div class="line"><a id="l02809" name="l02809"></a><span class="lineno"> 2809</span>  <span class="keyword">auto</span> readType = VectorType::get(srcType.getShape(), srcElementType);</div>
<div class="line"><a id="l02810" name="l02810"></a><span class="lineno"> 2810</span>  <span class="keyword">auto</span> writeType = VectorType::get(dstType.getShape(), dstElementType);</div>
<div class="line"><a id="l02811" name="l02811"></a><span class="lineno"> 2811</span> </div>
<div class="line"><a id="l02812" name="l02812"></a><span class="lineno"> 2812</span>  Location loc = copyOp-&gt;getLoc();</div>
<div class="line"><a id="l02813" name="l02813"></a><span class="lineno"> 2813</span>  Value zero = <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0);</div>
<div class="line"><a id="l02814" name="l02814"></a><span class="lineno"> 2814</span>  SmallVector&lt;Value&gt; <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>(srcType.getRank(), zero);</div>
<div class="line"><a id="l02815" name="l02815"></a><span class="lineno"> 2815</span> </div>
<div class="line"><a id="l02816" name="l02816"></a><span class="lineno"> 2816</span>  Value <a class="code hl_function" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a44d6ca01c15a8cea3f63df24849cc449">readValue</a> = vector::TransferReadOp::create(</div>
<div class="line"><a id="l02817" name="l02817"></a><span class="lineno"> 2817</span>      rewriter, loc, readType, copyOp.getSource(), <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>,</div>
<div class="line"><a id="l02818" name="l02818"></a><span class="lineno"> 2818</span>      <span class="comment">/*padding=*/</span>std::nullopt,</div>
<div class="line"><a id="l02819" name="l02819"></a><span class="lineno"> 2819</span>      rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#a422a9ab33af4134efcb4044fb81deab1">getMultiDimIdentityMap</a>(srcType.getRank()));</div>
<div class="line"><a id="l02820" name="l02820"></a><span class="lineno"> 2820</span>  <span class="keywordflow">if</span> (cast&lt;VectorType&gt;(<a class="code hl_function" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a44d6ca01c15a8cea3f63df24849cc449">readValue</a>.getType()).getRank() == 0) {</div>
<div class="line"><a id="l02821" name="l02821"></a><span class="lineno"> 2821</span>    <a class="code hl_function" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a44d6ca01c15a8cea3f63df24849cc449">readValue</a> = vector::ExtractOp::create(rewriter, loc, readValue,</div>
<div class="line"><a id="l02822" name="l02822"></a><span class="lineno"> 2822</span>                                          ArrayRef&lt;int64_t&gt;());</div>
<div class="line"><a id="l02823" name="l02823"></a><span class="lineno"> 2823</span>    <a class="code hl_function" href="namespacemlir_1_1sparse__tensor_1_1detail.html#a44d6ca01c15a8cea3f63df24849cc449">readValue</a> =</div>
<div class="line"><a id="l02824" name="l02824"></a><span class="lineno"> 2824</span>        vector::BroadcastOp::create(rewriter, loc, writeType, readValue);</div>
<div class="line"><a id="l02825" name="l02825"></a><span class="lineno"> 2825</span>  }</div>
<div class="line"><a id="l02826" name="l02826"></a><span class="lineno"> 2826</span>  Operation *writeValue = vector::TransferWriteOp::create(</div>
<div class="line"><a id="l02827" name="l02827"></a><span class="lineno"> 2827</span>      rewriter, loc, readValue, copyOp.getTarget(), <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>,</div>
<div class="line"><a id="l02828" name="l02828"></a><span class="lineno"> 2828</span>      rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#a422a9ab33af4134efcb4044fb81deab1">getMultiDimIdentityMap</a>(srcType.getRank()));</div>
<div class="line"><a id="l02829" name="l02829"></a><span class="lineno"> 2829</span>  rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(copyOp, writeValue-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">getResults</a>());</div>
<div class="line"><a id="l02830" name="l02830"></a><span class="lineno"> 2830</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02831" name="l02831"></a><span class="lineno"> 2831</span>}</div>
<div class="line"><a id="l02832" name="l02832"></a><span class="lineno"> 2832</span> </div>
<div class="line"><a id="l02833" name="l02833"></a><span class="lineno"> 2833</span><span class="comment">//----------------------------------------------------------------------------//</span></div>
<div class="line"><a id="l02834" name="l02834"></a><span class="lineno"> 2834</span><span class="comment">// Misc. vectorization patterns.</span></div>
<div class="line"><a id="l02835" name="l02835"></a><span class="lineno"> 2835</span><span class="comment">//----------------------------------------------------------------------------//</span><span class="comment"></span></div>
<div class="line"><a id="l02836" name="l02836"></a><span class="lineno"> 2836</span><span class="comment">/// Base pattern for rewriting tensor::PadOps whose result is consumed by a</span></div>
<div class="line"><a id="l02837" name="l02837"></a><span class="lineno"> 2837</span><span class="comment">/// given operation type OpTy.</span></div>
<div class="line"><a id="l02838" name="l02838"></a><span class="lineno"> 2838</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> OpTy&gt;</div>
<div class="line"><a id="l02839" name="l02839"></a><span class="lineno"> 2839</span><span class="keyword">struct </span>VectorizePadOpUserPattern : <span class="keyword">public</span> OpRewritePattern&lt;tensor::PadOp&gt; {</div>
<div class="line"><a id="l02840" name="l02840"></a><span class="lineno"> 2840</span>  <span class="keyword">using </span>OpRewritePattern&lt;tensor::PadOp&gt;::OpRewritePattern;</div>
<div class="line"><a id="l02841" name="l02841"></a><span class="lineno"> 2841</span> </div>
<div class="line"><a id="l02842" name="l02842"></a><span class="lineno"> 2842</span>  LogicalResult matchAndRewrite(tensor::PadOp padOp,</div>
<div class="line"><a id="l02843" name="l02843"></a><span class="lineno"> 2843</span>                                PatternRewriter &amp;rewriter) <span class="keyword">const</span> <span class="keyword">final</span> {</div>
<div class="line"><a id="l02844" name="l02844"></a><span class="lineno"> 2844</span>    <span class="keywordtype">bool</span> <a class="code hl_variable" href="namespacemlir.html#a1c6ebcdda896c9a0316c2367d2843775">changed</a> = <span class="keyword">false</span>;</div>
<div class="line"><a id="l02845" name="l02845"></a><span class="lineno"> 2845</span>    <span class="comment">// Insert users in vector, because some users may be replaced/removed.</span></div>
<div class="line"><a id="l02846" name="l02846"></a><span class="lineno"> 2846</span>    <span class="keywordflow">for</span> (<span class="keyword">auto</span> *user : llvm::to_vector&lt;4&gt;(padOp-&gt;getUsers()))</div>
<div class="line"><a id="l02847" name="l02847"></a><span class="lineno"> 2847</span>      <span class="keywordflow">if</span> (<span class="keyword">auto</span> op = dyn_cast&lt;OpTy&gt;(user))</div>
<div class="line"><a id="l02848" name="l02848"></a><span class="lineno"> 2848</span>        <a class="code hl_variable" href="namespacemlir.html#a1c6ebcdda896c9a0316c2367d2843775">changed</a> |= rewriteUser(rewriter, padOp, op).succeeded();</div>
<div class="line"><a id="l02849" name="l02849"></a><span class="lineno"> 2849</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>(<a class="code hl_variable" href="namespacemlir.html#a1c6ebcdda896c9a0316c2367d2843775">changed</a>);</div>
<div class="line"><a id="l02850" name="l02850"></a><span class="lineno"> 2850</span>  }</div>
<div class="line"><a id="l02851" name="l02851"></a><span class="lineno"> 2851</span> </div>
<div class="line"><a id="l02852" name="l02852"></a><span class="lineno"> 2852</span><span class="keyword">protected</span>:</div>
<div class="line"><a id="l02853" name="l02853"></a><span class="lineno"> 2853</span>  <span class="keyword">virtual</span> LogicalResult rewriteUser(PatternRewriter &amp;rewriter,</div>
<div class="line"><a id="l02854" name="l02854"></a><span class="lineno"> 2854</span>                                    tensor::PadOp padOp, OpTy op) <span class="keyword">const</span> = 0;</div>
<div class="line"><a id="l02855" name="l02855"></a><span class="lineno"> 2855</span>};</div>
<div class="line"><a id="l02856" name="l02856"></a><span class="lineno"> 2856</span><span class="comment"></span> </div>
<div class="line"><a id="l02857" name="l02857"></a><span class="lineno"> 2857</span><span class="comment">/// Rewrite use of tensor::PadOp result in TransferReadOp. E.g.:</span></div>
<div class="line"><a id="l02858" name="l02858"></a><span class="lineno"> 2858</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l02859" name="l02859"></a><span class="lineno"> 2859</span><span class="comment">/// %0 = tensor.pad %src ... : tensor&lt;?x?xf32&gt; to tensor&lt;17x5xf32&gt;</span></div>
<div class="line"><a id="l02860" name="l02860"></a><span class="lineno"> 2860</span><span class="comment">/// %r = vector.transfer_read %0[%c0, %c0], %cst</span></div>
<div class="line"><a id="l02861" name="l02861"></a><span class="lineno"> 2861</span><span class="comment">///     {in_bounds = [true, true]} : tensor&lt;17x5xf32&gt;, vector&lt;17x5xf32&gt;</span></div>
<div class="line"><a id="l02862" name="l02862"></a><span class="lineno"> 2862</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l02863" name="l02863"></a><span class="lineno"> 2863</span><span class="comment">/// is rewritten to:</span></div>
<div class="line"><a id="l02864" name="l02864"></a><span class="lineno"> 2864</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l02865" name="l02865"></a><span class="lineno"> 2865</span><span class="comment">/// %r = vector.transfer_read %src[%c0, %c0], %padding</span></div>
<div class="line"><a id="l02866" name="l02866"></a><span class="lineno"> 2866</span><span class="comment">///     {in_bounds = [true, true]}</span></div>
<div class="line"><a id="l02867" name="l02867"></a><span class="lineno"> 2867</span><span class="comment">///     : tensor&lt;?x?xf32&gt;, vector&lt;17x5xf32&gt;</span></div>
<div class="line"><a id="l02868" name="l02868"></a><span class="lineno"> 2868</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l02869" name="l02869"></a><span class="lineno"> 2869</span><span class="comment">/// Note: By restricting this pattern to in-bounds TransferReadOps, we can be</span></div>
<div class="line"><a id="l02870" name="l02870"></a><span class="lineno"> 2870</span><span class="comment">/// sure that the original padding value %cst was never used.</span></div>
<div class="line"><a id="l02871" name="l02871"></a><span class="lineno"> 2871</span><span class="comment">///</span></div>
<div class="line"><a id="l02872" name="l02872"></a><span class="lineno"> 2872</span><span class="comment">/// This rewrite is possible if:</span></div>
<div class="line"><a id="l02873" name="l02873"></a><span class="lineno"> 2873</span><span class="comment">/// - `xferOp` has no out-of-bounds dims or mask.</span></div>
<div class="line"><a id="l02874" name="l02874"></a><span class="lineno"> 2874</span><span class="comment">/// - Low padding is static 0.</span></div>
<div class="line"><a id="l02875" name="l02875"></a><span class="lineno"> 2875</span><span class="comment">/// - Single, scalar padding value.</span></div>
<div class="line"><a id="l02876" name="l02876"></a><span class="lineno"> 2876</span><span class="keyword">struct </span>PadOpVectorizationWithTransferReadPattern</div>
<div class="line"><a id="l02877" name="l02877"></a><span class="lineno"> 2877</span>    : <span class="keyword">public</span> VectorizePadOpUserPattern&lt;vector::TransferReadOp&gt; {</div>
<div class="line"><a id="l02878" name="l02878"></a><span class="lineno"> 2878</span>  <span class="keyword">using </span>VectorizePadOpUserPattern&lt;</div>
<div class="line"><a id="l02879" name="l02879"></a><span class="lineno"> 2879</span>      vector::TransferReadOp&gt;::VectorizePadOpUserPattern;</div>
<div class="line"><a id="l02880" name="l02880"></a><span class="lineno"> 2880</span> </div>
<div class="line"><a id="l02881" name="l02881"></a><span class="lineno"> 2881</span>  LogicalResult rewriteUser(PatternRewriter &amp;rewriter, tensor::PadOp padOp,</div>
<div class="line"><a id="l02882" name="l02882"></a><span class="lineno"> 2882</span>                            vector::TransferReadOp xferOp)<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l02883" name="l02883"></a><span class="lineno"> 2883</span>    <span class="comment">// Low padding must be static 0.</span></div>
<div class="line"><a id="l02884" name="l02884"></a><span class="lineno"> 2884</span>    <span class="keywordflow">if</span> (!padOp.hasZeroLowPad())</div>
<div class="line"><a id="l02885" name="l02885"></a><span class="lineno"> 2885</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02886" name="l02886"></a><span class="lineno"> 2886</span>    <span class="comment">// Pad value must be a constant.</span></div>
<div class="line"><a id="l02887" name="l02887"></a><span class="lineno"> 2887</span>    <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a id="l02888" name="l02888"></a><span class="lineno"> 2888</span>    <span class="keywordflow">if</span> (!padValue)</div>
<div class="line"><a id="l02889" name="l02889"></a><span class="lineno"> 2889</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02890" name="l02890"></a><span class="lineno"> 2890</span>    <span class="comment">// Padding value of existing `xferOp` is unused.</span></div>
<div class="line"><a id="l02891" name="l02891"></a><span class="lineno"> 2891</span>    <span class="keywordflow">if</span> (xferOp.hasOutOfBoundsDim() || xferOp.getMask())</div>
<div class="line"><a id="l02892" name="l02892"></a><span class="lineno"> 2892</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02893" name="l02893"></a><span class="lineno"> 2893</span> </div>
<div class="line"><a id="l02894" name="l02894"></a><span class="lineno"> 2894</span>    rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#abd8bae753b51386417536a36cf52d3f7">modifyOpInPlace</a>(xferOp, [&amp;]() {</div>
<div class="line"><a id="l02895" name="l02895"></a><span class="lineno"> 2895</span>      SmallVector&lt;bool&gt; inBounds(xferOp.getVectorType().getRank(), <span class="keyword">false</span>);</div>
<div class="line"><a id="l02896" name="l02896"></a><span class="lineno"> 2896</span>      xferOp-&gt;setAttr(xferOp.getInBoundsAttrName(),</div>
<div class="line"><a id="l02897" name="l02897"></a><span class="lineno"> 2897</span>                      rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a id="l02898" name="l02898"></a><span class="lineno"> 2898</span>      xferOp.getBaseMutable().assign(padOp.getSource());</div>
<div class="line"><a id="l02899" name="l02899"></a><span class="lineno"> 2899</span>      xferOp.getPaddingMutable().assign(padValue);</div>
<div class="line"><a id="l02900" name="l02900"></a><span class="lineno"> 2900</span>    });</div>
<div class="line"><a id="l02901" name="l02901"></a><span class="lineno"> 2901</span> </div>
<div class="line"><a id="l02902" name="l02902"></a><span class="lineno"> 2902</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02903" name="l02903"></a><span class="lineno"> 2903</span>  }</div>
<div class="line"><a id="l02904" name="l02904"></a><span class="lineno"> 2904</span>};</div>
<div class="line"><a id="l02905" name="l02905"></a><span class="lineno"> 2905</span><span class="comment"></span> </div>
<div class="line"><a id="l02906" name="l02906"></a><span class="lineno"> 2906</span><span class="comment">/// Rewrite use of tensor::PadOp result in TransferWriteOp.</span></div>
<div class="line"><a id="l02907" name="l02907"></a><span class="lineno"> 2907</span><span class="comment">/// This pattern rewrites TransferWriteOps that write to a padded tensor</span></div>
<div class="line"><a id="l02908" name="l02908"></a><span class="lineno"> 2908</span><span class="comment">/// value, where the same amount of padding is immediately removed again after</span></div>
<div class="line"><a id="l02909" name="l02909"></a><span class="lineno"> 2909</span><span class="comment">/// the write. In such cases, the TransferWriteOp can write to the non-padded</span></div>
<div class="line"><a id="l02910" name="l02910"></a><span class="lineno"> 2910</span><span class="comment">/// tensor value and apply out-of-bounds masking. E.g.:</span></div>
<div class="line"><a id="l02911" name="l02911"></a><span class="lineno"> 2911</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l02912" name="l02912"></a><span class="lineno"> 2912</span><span class="comment">/// %0 = tensor.extract_slice ...[...] [%s0, %s1] [1, 1]</span></div>
<div class="line"><a id="l02913" name="l02913"></a><span class="lineno"> 2913</span><span class="comment">///     : tensor&lt;...&gt; to tensor&lt;?x?xf32&gt;</span></div>
<div class="line"><a id="l02914" name="l02914"></a><span class="lineno"> 2914</span><span class="comment">/// %1 = tensor.pad %0 ... : tensor&lt;?x?xf32&gt; to tensor&lt;17x5xf32&gt;</span></div>
<div class="line"><a id="l02915" name="l02915"></a><span class="lineno"> 2915</span><span class="comment">/// %2 = vector.transfer_write %vec, %1[...]</span></div>
<div class="line"><a id="l02916" name="l02916"></a><span class="lineno"> 2916</span><span class="comment">///     : vector&lt;17x5xf32&gt;, tensor&lt;17x5xf32&gt;</span></div>
<div class="line"><a id="l02917" name="l02917"></a><span class="lineno"> 2917</span><span class="comment">/// %r = tensor.extract_slice %2[0, 0] [%s0, %s1] [1, 1]</span></div>
<div class="line"><a id="l02918" name="l02918"></a><span class="lineno"> 2918</span><span class="comment">///     : tensor&lt;17x5xf32&gt; to tensor&lt;?x?xf32&gt;</span></div>
<div class="line"><a id="l02919" name="l02919"></a><span class="lineno"> 2919</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l02920" name="l02920"></a><span class="lineno"> 2920</span><span class="comment">/// is rewritten to:</span></div>
<div class="line"><a id="l02921" name="l02921"></a><span class="lineno"> 2921</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l02922" name="l02922"></a><span class="lineno"> 2922</span><span class="comment">/// %0 = tensor.extract_slice ...[...] [%s0, %s1] [1, 1]</span></div>
<div class="line"><a id="l02923" name="l02923"></a><span class="lineno"> 2923</span><span class="comment">///     : tensor&lt;...&gt; to tensor&lt;?x?xf32&gt;</span></div>
<div class="line"><a id="l02924" name="l02924"></a><span class="lineno"> 2924</span><span class="comment">/// %r = vector.transfer_write %vec, %0[...] : vector&lt;17x5xf32&gt;,</span></div>
<div class="line"><a id="l02925" name="l02925"></a><span class="lineno"> 2925</span><span class="comment">/// tensor&lt;?x?xf32&gt;</span></div>
<div class="line"><a id="l02926" name="l02926"></a><span class="lineno"> 2926</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l02927" name="l02927"></a><span class="lineno"> 2927</span><span class="comment">/// Note: It is important that the ExtractSliceOp %r resizes the result of the</span></div>
<div class="line"><a id="l02928" name="l02928"></a><span class="lineno"> 2928</span><span class="comment">/// TransferWriteOp to the same size as the input of the TensorPadOp (or an</span></div>
<div class="line"><a id="l02929" name="l02929"></a><span class="lineno"> 2929</span><span class="comment">/// even smaller size). Otherwise, %r&#39;s new (dynamic) dimensions would differ</span></div>
<div class="line"><a id="l02930" name="l02930"></a><span class="lineno"> 2930</span><span class="comment">/// from %r&#39;s old dimensions.</span></div>
<div class="line"><a id="l02931" name="l02931"></a><span class="lineno"> 2931</span><span class="comment">///</span></div>
<div class="line"><a id="l02932" name="l02932"></a><span class="lineno"> 2932</span><span class="comment">/// This rewrite is possible if:</span></div>
<div class="line"><a id="l02933" name="l02933"></a><span class="lineno"> 2933</span><span class="comment">/// - Low padding is static 0.</span></div>
<div class="line"><a id="l02934" name="l02934"></a><span class="lineno"> 2934</span><span class="comment">/// - `xferOp` has exactly one use, which is an ExtractSliceOp. This</span></div>
<div class="line"><a id="l02935" name="l02935"></a><span class="lineno"> 2935</span><span class="comment">///   ExtractSliceOp trims the same amount of padding that was added</span></div>
<div class="line"><a id="l02936" name="l02936"></a><span class="lineno"> 2936</span><span class="comment">///   beforehand.</span></div>
<div class="line"><a id="l02937" name="l02937"></a><span class="lineno"> 2937</span><span class="comment">/// - Single, scalar padding value.</span></div>
<div class="line"><a id="l02938" name="l02938"></a><span class="lineno"> 2938</span><span class="keyword">struct </span>PadOpVectorizationWithTransferWritePattern</div>
<div class="line"><a id="l02939" name="l02939"></a><span class="lineno"> 2939</span>    : <span class="keyword">public</span> VectorizePadOpUserPattern&lt;vector::TransferWriteOp&gt; {</div>
<div class="line"><a id="l02940" name="l02940"></a><span class="lineno"> 2940</span>  <span class="keyword">using </span>VectorizePadOpUserPattern&lt;</div>
<div class="line"><a id="l02941" name="l02941"></a><span class="lineno"> 2941</span>      vector::TransferWriteOp&gt;::VectorizePadOpUserPattern;</div>
<div class="line"><a id="l02942" name="l02942"></a><span class="lineno"> 2942</span> </div>
<div class="line"><a id="l02943" name="l02943"></a><span class="lineno"> 2943</span>  LogicalResult rewriteUser(PatternRewriter &amp;rewriter, tensor::PadOp padOp,</div>
<div class="line"><a id="l02944" name="l02944"></a><span class="lineno"> 2944</span>                            vector::TransferWriteOp xferOp)<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l02945" name="l02945"></a><span class="lineno"> 2945</span>    <span class="comment">// TODO: support 0-d corner case.</span></div>
<div class="line"><a id="l02946" name="l02946"></a><span class="lineno"> 2946</span>    <span class="keywordflow">if</span> (xferOp.getTransferRank() == 0)</div>
<div class="line"><a id="l02947" name="l02947"></a><span class="lineno"> 2947</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02948" name="l02948"></a><span class="lineno"> 2948</span> </div>
<div class="line"><a id="l02949" name="l02949"></a><span class="lineno"> 2949</span>    <span class="comment">// Low padding must be static 0.</span></div>
<div class="line"><a id="l02950" name="l02950"></a><span class="lineno"> 2950</span>    <span class="keywordflow">if</span> (!padOp.hasZeroLowPad())</div>
<div class="line"><a id="l02951" name="l02951"></a><span class="lineno"> 2951</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02952" name="l02952"></a><span class="lineno"> 2952</span>    <span class="comment">// Pad value must be a constant.</span></div>
<div class="line"><a id="l02953" name="l02953"></a><span class="lineno"> 2953</span>    <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a id="l02954" name="l02954"></a><span class="lineno"> 2954</span>    <span class="keywordflow">if</span> (!padValue)</div>
<div class="line"><a id="l02955" name="l02955"></a><span class="lineno"> 2955</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02956" name="l02956"></a><span class="lineno"> 2956</span>    <span class="comment">// TransferWriteOp result must be directly consumed by an ExtractSliceOp.</span></div>
<div class="line"><a id="l02957" name="l02957"></a><span class="lineno"> 2957</span>    <span class="keywordflow">if</span> (!xferOp-&gt;hasOneUse())</div>
<div class="line"><a id="l02958" name="l02958"></a><span class="lineno"> 2958</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02959" name="l02959"></a><span class="lineno"> 2959</span>    <span class="keyword">auto</span> trimPadding = dyn_cast&lt;tensor::ExtractSliceOp&gt;(*xferOp-&gt;user_begin());</div>
<div class="line"><a id="l02960" name="l02960"></a><span class="lineno"> 2960</span>    <span class="keywordflow">if</span> (!trimPadding)</div>
<div class="line"><a id="l02961" name="l02961"></a><span class="lineno"> 2961</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02962" name="l02962"></a><span class="lineno"> 2962</span>    <span class="comment">// Only static zero offsets supported when trimming padding.</span></div>
<div class="line"><a id="l02963" name="l02963"></a><span class="lineno"> 2963</span>    <span class="keywordflow">if</span> (!trimPadding.hasZeroOffset())</div>
<div class="line"><a id="l02964" name="l02964"></a><span class="lineno"> 2964</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02965" name="l02965"></a><span class="lineno"> 2965</span>    <span class="comment">// trimPadding must remove the amount of padding that was added earlier.</span></div>
<div class="line"><a id="l02966" name="l02966"></a><span class="lineno"> 2966</span>    <span class="keywordflow">if</span> (!hasSameTensorSize(padOp.getSource(), trimPadding))</div>
<div class="line"><a id="l02967" name="l02967"></a><span class="lineno"> 2967</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l02968" name="l02968"></a><span class="lineno"> 2968</span> </div>
<div class="line"><a id="l02969" name="l02969"></a><span class="lineno"> 2969</span>    <span class="comment">// Insert the new TransferWriteOp at position of the old TransferWriteOp.</span></div>
<div class="line"><a id="l02970" name="l02970"></a><span class="lineno"> 2970</span>    rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(xferOp);</div>
<div class="line"><a id="l02971" name="l02971"></a><span class="lineno"> 2971</span> </div>
<div class="line"><a id="l02972" name="l02972"></a><span class="lineno"> 2972</span>    SmallVector&lt;bool&gt; inBounds(xferOp.getVectorType().getRank(), <span class="keyword">false</span>);</div>
<div class="line"><a id="l02973" name="l02973"></a><span class="lineno"> 2973</span>    <span class="keyword">auto</span> newXferOp = rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#afb1c910a57707f518d2b9c903c2bb5bc">replaceOpWithNewOp</a>&lt;vector::TransferWriteOp&gt;(</div>
<div class="line"><a id="l02974" name="l02974"></a><span class="lineno"> 2974</span>        xferOp, padOp.getSource().<a class="code hl_function" href="namespacemlir.html#a348ed9fcbefe1f5094cc571c346c7080">getType</a>(), xferOp.getVector(),</div>
<div class="line"><a id="l02975" name="l02975"></a><span class="lineno"> 2975</span>        padOp.getSource(), xferOp.getIndices(), xferOp.getPermutationMapAttr(),</div>
<div class="line"><a id="l02976" name="l02976"></a><span class="lineno"> 2976</span>        xferOp.getMask(), rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a id="l02977" name="l02977"></a><span class="lineno"> 2977</span>    rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(trimPadding, newXferOp-&gt;getResult(0));</div>
<div class="line"><a id="l02978" name="l02978"></a><span class="lineno"> 2978</span> </div>
<div class="line"><a id="l02979" name="l02979"></a><span class="lineno"> 2979</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l02980" name="l02980"></a><span class="lineno"> 2980</span>  }</div>
<div class="line"><a id="l02981" name="l02981"></a><span class="lineno"> 2981</span><span class="comment"></span> </div>
<div class="line"><a id="l02982" name="l02982"></a><span class="lineno"> 2982</span><span class="comment">  /// Check if `beforePadding` and `afterTrimming` have the same tensor size,</span></div>
<div class="line"><a id="l02983" name="l02983"></a><span class="lineno"> 2983</span><span class="comment">  /// i.e., same dimensions.</span></div>
<div class="line"><a id="l02984" name="l02984"></a><span class="lineno"> 2984</span><span class="comment">  ///</span></div>
<div class="line"><a id="l02985" name="l02985"></a><span class="lineno"> 2985</span><span class="comment">  /// Dimensions may be static, dynamic or mix of both. In case of dynamic</span></div>
<div class="line"><a id="l02986" name="l02986"></a><span class="lineno"> 2986</span><span class="comment">  /// dimensions, this function tries to infer the (static) tensor size by</span></div>
<div class="line"><a id="l02987" name="l02987"></a><span class="lineno"> 2987</span><span class="comment">  /// looking at the defining op and utilizing op-specific knowledge.</span></div>
<div class="line"><a id="l02988" name="l02988"></a><span class="lineno"> 2988</span><span class="comment">  ///</span></div>
<div class="line"><a id="l02989" name="l02989"></a><span class="lineno"> 2989</span><span class="comment">  /// This is a conservative analysis. In case equal tensor sizes cannot be</span></div>
<div class="line"><a id="l02990" name="l02990"></a><span class="lineno"> 2990</span><span class="comment">  /// proven statically, this analysis returns `false` even though the tensor</span></div>
<div class="line"><a id="l02991" name="l02991"></a><span class="lineno"> 2991</span><span class="comment">  /// sizes may turn out to be equal at runtime.</span></div>
<div class="line"><a id="l02992" name="l02992"></a><span class="lineno"> 2992</span>  <span class="keywordtype">bool</span> hasSameTensorSize(Value beforePadding,</div>
<div class="line"><a id="l02993" name="l02993"></a><span class="lineno"> 2993</span>                         tensor::ExtractSliceOp afterTrimming)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l02994" name="l02994"></a><span class="lineno"> 2994</span>    <span class="comment">// If the input to tensor::PadOp is a CastOp, try with both CastOp</span></div>
<div class="line"><a id="l02995" name="l02995"></a><span class="lineno"> 2995</span>    <span class="comment">// result and CastOp operand.</span></div>
<div class="line"><a id="l02996" name="l02996"></a><span class="lineno"> 2996</span>    <span class="keywordflow">if</span> (<span class="keyword">auto</span> castOp = beforePadding.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;tensor::CastOp&gt;())</div>
<div class="line"><a id="l02997" name="l02997"></a><span class="lineno"> 2997</span>      <span class="keywordflow">if</span> (hasSameTensorSize(castOp.getSource(), afterTrimming))</div>
<div class="line"><a id="l02998" name="l02998"></a><span class="lineno"> 2998</span>        <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l02999" name="l02999"></a><span class="lineno"> 2999</span> </div>
<div class="line"><a id="l03000" name="l03000"></a><span class="lineno"> 3000</span>    <span class="keyword">auto</span> t1 = dyn_cast&lt;RankedTensorType&gt;(beforePadding.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a id="l03001" name="l03001"></a><span class="lineno"> 3001</span>    <span class="keyword">auto</span> t2 = dyn_cast&lt;RankedTensorType&gt;(afterTrimming.getType());</div>
<div class="line"><a id="l03002" name="l03002"></a><span class="lineno"> 3002</span>    <span class="comment">// Only RankedTensorType supported.</span></div>
<div class="line"><a id="l03003" name="l03003"></a><span class="lineno"> 3003</span>    <span class="keywordflow">if</span> (!t1 || !t2)</div>
<div class="line"><a id="l03004" name="l03004"></a><span class="lineno"> 3004</span>      <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l03005" name="l03005"></a><span class="lineno"> 3005</span>    <span class="comment">// Rank of both values must be the same.</span></div>
<div class="line"><a id="l03006" name="l03006"></a><span class="lineno"> 3006</span>    <span class="keywordflow">if</span> (t1.getRank() != t2.getRank())</div>
<div class="line"><a id="l03007" name="l03007"></a><span class="lineno"> 3007</span>      <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l03008" name="l03008"></a><span class="lineno"> 3008</span> </div>
<div class="line"><a id="l03009" name="l03009"></a><span class="lineno"> 3009</span>    <span class="comment">// All static dimensions must be the same. Mixed cases (e.g., dimension</span></div>
<div class="line"><a id="l03010" name="l03010"></a><span class="lineno"> 3010</span>    <span class="comment">// static in `t1` but dynamic in `t2`) are not supported.</span></div>
<div class="line"><a id="l03011" name="l03011"></a><span class="lineno"> 3011</span>    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; t1.getRank(); ++i) {</div>
<div class="line"><a id="l03012" name="l03012"></a><span class="lineno"> 3012</span>      <span class="keywordflow">if</span> (t1.isDynamicDim(i) != t2.isDynamicDim(i))</div>
<div class="line"><a id="l03013" name="l03013"></a><span class="lineno"> 3013</span>        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l03014" name="l03014"></a><span class="lineno"> 3014</span>      <span class="keywordflow">if</span> (!t1.isDynamicDim(i) &amp;&amp; t1.getDimSize(i) != t2.getDimSize(i))</div>
<div class="line"><a id="l03015" name="l03015"></a><span class="lineno"> 3015</span>        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l03016" name="l03016"></a><span class="lineno"> 3016</span>    }</div>
<div class="line"><a id="l03017" name="l03017"></a><span class="lineno"> 3017</span> </div>
<div class="line"><a id="l03018" name="l03018"></a><span class="lineno"> 3018</span>    <span class="comment">// Nothing more to check if all dimensions are static.</span></div>
<div class="line"><a id="l03019" name="l03019"></a><span class="lineno"> 3019</span>    <span class="keywordflow">if</span> (t1.getNumDynamicDims() == 0)</div>
<div class="line"><a id="l03020" name="l03020"></a><span class="lineno"> 3020</span>      <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l03021" name="l03021"></a><span class="lineno"> 3021</span> </div>
<div class="line"><a id="l03022" name="l03022"></a><span class="lineno"> 3022</span>    <span class="comment">// All dynamic sizes must be the same. The only supported case at the</span></div>
<div class="line"><a id="l03023" name="l03023"></a><span class="lineno"> 3023</span>    <span class="comment">// moment is when `beforePadding` is an ExtractSliceOp (or a cast</span></div>
<div class="line"><a id="l03024" name="l03024"></a><span class="lineno"> 3024</span>    <span class="comment">// thereof).</span></div>
<div class="line"><a id="l03025" name="l03025"></a><span class="lineno"> 3025</span> </div>
<div class="line"><a id="l03026" name="l03026"></a><span class="lineno"> 3026</span>    <span class="comment">// Apart from CastOp, only ExtractSliceOp is supported.</span></div>
<div class="line"><a id="l03027" name="l03027"></a><span class="lineno"> 3027</span>    <span class="keyword">auto</span> beforeSlice = beforePadding.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;tensor::ExtractSliceOp&gt;();</div>
<div class="line"><a id="l03028" name="l03028"></a><span class="lineno"> 3028</span>    <span class="keywordflow">if</span> (!beforeSlice)</div>
<div class="line"><a id="l03029" name="l03029"></a><span class="lineno"> 3029</span>      <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l03030" name="l03030"></a><span class="lineno"> 3030</span> </div>
<div class="line"><a id="l03031" name="l03031"></a><span class="lineno"> 3031</span>    assert(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(t1.getRank()) ==</div>
<div class="line"><a id="l03032" name="l03032"></a><span class="lineno"> 3032</span>           beforeSlice.getMixedSizes().size());</div>
<div class="line"><a id="l03033" name="l03033"></a><span class="lineno"> 3033</span>    assert(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(t2.getRank()) ==</div>
<div class="line"><a id="l03034" name="l03034"></a><span class="lineno"> 3034</span>           afterTrimming.getMixedSizes().size());</div>
<div class="line"><a id="l03035" name="l03035"></a><span class="lineno"> 3035</span> </div>
<div class="line"><a id="l03036" name="l03036"></a><span class="lineno"> 3036</span>    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; t1.getRank(); ++i) {</div>
<div class="line"><a id="l03037" name="l03037"></a><span class="lineno"> 3037</span>      <span class="comment">// Skip static dimensions.</span></div>
<div class="line"><a id="l03038" name="l03038"></a><span class="lineno"> 3038</span>      <span class="keywordflow">if</span> (!t1.isDynamicDim(i))</div>
<div class="line"><a id="l03039" name="l03039"></a><span class="lineno"> 3039</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03040" name="l03040"></a><span class="lineno"> 3040</span>      <span class="keyword">auto</span> size1 = beforeSlice.getMixedSizes()[i];</div>
<div class="line"><a id="l03041" name="l03041"></a><span class="lineno"> 3041</span>      <span class="keyword">auto</span> size2 = afterTrimming.getMixedSizes()[i];</div>
<div class="line"><a id="l03042" name="l03042"></a><span class="lineno"> 3042</span> </div>
<div class="line"><a id="l03043" name="l03043"></a><span class="lineno"> 3043</span>      <span class="comment">// Case 1: Same value or same constant int.</span></div>
<div class="line"><a id="l03044" name="l03044"></a><span class="lineno"> 3044</span>      <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir.html#a2ee77c6f0feb82212b1b817785f95f48">isEqualConstantIntOrValue</a>(size1, size2))</div>
<div class="line"><a id="l03045" name="l03045"></a><span class="lineno"> 3045</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03046" name="l03046"></a><span class="lineno"> 3046</span> </div>
<div class="line"><a id="l03047" name="l03047"></a><span class="lineno"> 3047</span>      <span class="comment">// Other cases: Take a deeper look at defining ops of values.</span></div>
<div class="line"><a id="l03048" name="l03048"></a><span class="lineno"> 3048</span>      <span class="keyword">auto</span> v1 = llvm::dyn_cast_if_present&lt;Value&gt;(size1);</div>
<div class="line"><a id="l03049" name="l03049"></a><span class="lineno"> 3049</span>      <span class="keyword">auto</span> v2 = llvm::dyn_cast_if_present&lt;Value&gt;(size2);</div>
<div class="line"><a id="l03050" name="l03050"></a><span class="lineno"> 3050</span>      <span class="keywordflow">if</span> (!v1 || !v2)</div>
<div class="line"><a id="l03051" name="l03051"></a><span class="lineno"> 3051</span>        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l03052" name="l03052"></a><span class="lineno"> 3052</span> </div>
<div class="line"><a id="l03053" name="l03053"></a><span class="lineno"> 3053</span>      <span class="comment">// Case 2: Both values are identical AffineMinOps. (Should not happen if</span></div>
<div class="line"><a id="l03054" name="l03054"></a><span class="lineno"> 3054</span>      <span class="comment">// CSE is run.)</span></div>
<div class="line"><a id="l03055" name="l03055"></a><span class="lineno"> 3055</span>      <span class="keyword">auto</span> minOp1 = v1.getDefiningOp&lt;affine::AffineMinOp&gt;();</div>
<div class="line"><a id="l03056" name="l03056"></a><span class="lineno"> 3056</span>      <span class="keyword">auto</span> minOp2 = v2.getDefiningOp&lt;affine::AffineMinOp&gt;();</div>
<div class="line"><a id="l03057" name="l03057"></a><span class="lineno"> 3057</span>      <span class="keywordflow">if</span> (minOp1 &amp;&amp; minOp2 &amp;&amp; minOp1.getAffineMap() == minOp2.getAffineMap() &amp;&amp;</div>
<div class="line"><a id="l03058" name="l03058"></a><span class="lineno"> 3058</span>          minOp1.getOperands() == minOp2.getOperands())</div>
<div class="line"><a id="l03059" name="l03059"></a><span class="lineno"> 3059</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03060" name="l03060"></a><span class="lineno"> 3060</span> </div>
<div class="line"><a id="l03061" name="l03061"></a><span class="lineno"> 3061</span>      <span class="comment">// Add additional cases as needed.</span></div>
<div class="line"><a id="l03062" name="l03062"></a><span class="lineno"> 3062</span>    }</div>
<div class="line"><a id="l03063" name="l03063"></a><span class="lineno"> 3063</span> </div>
<div class="line"><a id="l03064" name="l03064"></a><span class="lineno"> 3064</span>    <span class="comment">// All tests passed.</span></div>
<div class="line"><a id="l03065" name="l03065"></a><span class="lineno"> 3065</span>    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l03066" name="l03066"></a><span class="lineno"> 3066</span>  }</div>
<div class="line"><a id="l03067" name="l03067"></a><span class="lineno"> 3067</span>};</div>
<div class="line"><a id="l03068" name="l03068"></a><span class="lineno"> 3068</span><span class="comment"></span> </div>
<div class="line"><a id="l03069" name="l03069"></a><span class="lineno"> 3069</span><span class="comment">/// Returns the effective Pad value for the input op, provided it&#39;s a scalar.</span></div>
<div class="line"><a id="l03070" name="l03070"></a><span class="lineno"> 3070</span><span class="comment">///</span></div>
<div class="line"><a id="l03071" name="l03071"></a><span class="lineno"> 3071</span><span class="comment">/// Many Ops exhibit pad-like behaviour, but this isn&#39;t always explicit. If</span></div>
<div class="line"><a id="l03072" name="l03072"></a><span class="lineno"> 3072</span><span class="comment">/// this Op performs padding, retrieve the padding value provided that it&#39;s</span></div>
<div class="line"><a id="l03073" name="l03073"></a><span class="lineno"> 3073</span><span class="comment">/// a scalar and static/fixed for all the padded values. Returns an empty value</span></div>
<div class="line"><a id="l03074" name="l03074"></a><span class="lineno"> 3074</span><span class="comment">/// otherwise.</span></div>
<div class="line"><a id="l03075" name="l03075"></a><span class="lineno"> 3075</span><span class="comment">///</span></div>
<div class="line"><a id="l03076" name="l03076"></a><span class="lineno"> 3076</span><span class="comment">/// TODO: This is used twice (when checking vectorization pre-conditions and</span></div>
<div class="line"><a id="l03077" name="l03077"></a><span class="lineno"> 3077</span><span class="comment">/// when vectorizing). Cache results instead of re-running.</span></div>
<div class="line"><a id="l03078" name="l03078"></a><span class="lineno"> 3078</span><span class="keyword">static</span> Value <a class="code hl_function" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(Operation *op) {</div>
<div class="line"><a id="l03079" name="l03079"></a><span class="lineno"> 3079</span>  <span class="keywordflow">if</span> (!op)</div>
<div class="line"><a id="l03080" name="l03080"></a><span class="lineno"> 3080</span>    <span class="keywordflow">return</span> {};</div>
<div class="line"><a id="l03081" name="l03081"></a><span class="lineno"> 3081</span> </div>
<div class="line"><a id="l03082" name="l03082"></a><span class="lineno"> 3082</span>  <span class="comment">// 1. vector.broadcast (f32 -&gt; vector &lt;...xf32&gt;) - return the value that&#39;s</span></div>
<div class="line"><a id="l03083" name="l03083"></a><span class="lineno"> 3083</span>  <span class="comment">// being broadcast, provided that it&#39;s a scalar.</span></div>
<div class="line"><a id="l03084" name="l03084"></a><span class="lineno"> 3084</span>  <span class="keywordflow">if</span> (<span class="keyword">auto</span> bcast = llvm::dyn_cast&lt;vector::BroadcastOp&gt;(op)) {</div>
<div class="line"><a id="l03085" name="l03085"></a><span class="lineno"> 3085</span>    <span class="keyword">auto</span> source = bcast.getSource();</div>
<div class="line"><a id="l03086" name="l03086"></a><span class="lineno"> 3086</span>    <span class="keywordflow">if</span> (llvm::dyn_cast&lt;VectorType&gt;(source.getType()))</div>
<div class="line"><a id="l03087" name="l03087"></a><span class="lineno"> 3087</span>      <span class="keywordflow">return</span> {};</div>
<div class="line"><a id="l03088" name="l03088"></a><span class="lineno"> 3088</span> </div>
<div class="line"><a id="l03089" name="l03089"></a><span class="lineno"> 3089</span>    <span class="keywordflow">return</span> source;</div>
<div class="line"><a id="l03090" name="l03090"></a><span class="lineno"> 3090</span>  }</div>
<div class="line"><a id="l03091" name="l03091"></a><span class="lineno"> 3091</span> </div>
<div class="line"><a id="l03092" name="l03092"></a><span class="lineno"> 3092</span>  <span class="comment">// 2. linalg.fill - use the scalar input value that used to fill the output</span></div>
<div class="line"><a id="l03093" name="l03093"></a><span class="lineno"> 3093</span>  <span class="comment">// tensor.</span></div>
<div class="line"><a id="l03094" name="l03094"></a><span class="lineno"> 3094</span>  <span class="keywordflow">if</span> (<span class="keyword">auto</span> fill = llvm::dyn_cast&lt;linalg::FillOp&gt;(op)) {</div>
<div class="line"><a id="l03095" name="l03095"></a><span class="lineno"> 3095</span>    <span class="keywordflow">return</span> fill.getInputs()[0];</div>
<div class="line"><a id="l03096" name="l03096"></a><span class="lineno"> 3096</span>  }</div>
<div class="line"><a id="l03097" name="l03097"></a><span class="lineno"> 3097</span> </div>
<div class="line"><a id="l03098" name="l03098"></a><span class="lineno"> 3098</span>  <span class="comment">// 3. tensor.generateOp - can&#39;t guarantee the value is fixed without</span></div>
<div class="line"><a id="l03099" name="l03099"></a><span class="lineno"> 3099</span>  <span class="comment">// analysing, bail out.</span></div>
<div class="line"><a id="l03100" name="l03100"></a><span class="lineno"> 3100</span>  <span class="keywordflow">if</span> (<span class="keyword">auto</span> generate = llvm::dyn_cast&lt;tensor::GenerateOp&gt;(op)) {</div>
<div class="line"><a id="l03101" name="l03101"></a><span class="lineno"> 3101</span>    <span class="keywordflow">return</span> {};</div>
<div class="line"><a id="l03102" name="l03102"></a><span class="lineno"> 3102</span>  }</div>
<div class="line"><a id="l03103" name="l03103"></a><span class="lineno"> 3103</span> </div>
<div class="line"><a id="l03104" name="l03104"></a><span class="lineno"> 3104</span>  <span class="comment">// 4. vector.transfer_write - inspect the input vector that&#39;s written from. If</span></div>
<div class="line"><a id="l03105" name="l03105"></a><span class="lineno"> 3105</span>  <span class="comment">// if contains a single value that has been broadcast (e.g. via</span></div>
<div class="line"><a id="l03106" name="l03106"></a><span class="lineno"> 3106</span>  <span class="comment">// vector.broadcast), extract it, fail otherwise.</span></div>
<div class="line"><a id="l03107" name="l03107"></a><span class="lineno"> 3107</span>  <span class="keywordflow">if</span> (<span class="keyword">auto</span> xferWrite = llvm::dyn_cast&lt;vector::TransferWriteOp&gt;(op))</div>
<div class="line"><a id="l03108" name="l03108"></a><span class="lineno"> 3108</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(xferWrite.getVector().getDefiningOp());</div>
<div class="line"><a id="l03109" name="l03109"></a><span class="lineno"> 3109</span> </div>
<div class="line"><a id="l03110" name="l03110"></a><span class="lineno"> 3110</span>  <span class="comment">// 5. tensor.insert_slice - inspect the destination tensor. If it&#39;s larger</span></div>
<div class="line"><a id="l03111" name="l03111"></a><span class="lineno"> 3111</span>  <span class="comment">// than the input tensor, then, provided it&#39;s constant, we&#39;ll extract the</span></div>
<div class="line"><a id="l03112" name="l03112"></a><span class="lineno"> 3112</span>  <span class="comment">// value that was used to generate it (via e.g. linalg.fill), fail otherwise.</span></div>
<div class="line"><a id="l03113" name="l03113"></a><span class="lineno"> 3113</span>  <span class="comment">// TODO: Clarify the semantics when the input tensor is larger than the</span></div>
<div class="line"><a id="l03114" name="l03114"></a><span class="lineno"> 3114</span>  <span class="comment">// destination.</span></div>
<div class="line"><a id="l03115" name="l03115"></a><span class="lineno"> 3115</span>  <span class="keywordflow">if</span> (<span class="keyword">auto</span> slice = llvm::dyn_cast&lt;tensor::InsertSliceOp&gt;(op))</div>
<div class="line"><a id="l03116" name="l03116"></a><span class="lineno"> 3116</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(slice.getDest().getDefiningOp());</div>
<div class="line"><a id="l03117" name="l03117"></a><span class="lineno"> 3117</span> </div>
<div class="line"><a id="l03118" name="l03118"></a><span class="lineno"> 3118</span>  <span class="keywordflow">return</span> {};</div>
<div class="line"><a id="l03119" name="l03119"></a><span class="lineno"> 3119</span>}</div>
<div class="line"><a id="l03120" name="l03120"></a><span class="lineno"> 3120</span> </div>
<div class="line"><a id="l03121" name="l03121"></a><span class="lineno"> 3121</span><span class="keyword">static</span> LogicalResult</div>
<div class="line"><a id="l03122" name="l03122"></a><span class="lineno"> 3122</span><a class="code hl_function" href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926">vectorizeAsInsertSliceOp</a>(RewriterBase &amp;rewriter, tensor::InsertSliceOp sliceOp,</div>
<div class="line"><a id="l03123" name="l03123"></a><span class="lineno"> 3123</span>                         ArrayRef&lt;int64_t&gt; inputVectorSizes,</div>
<div class="line"><a id="l03124" name="l03124"></a><span class="lineno"> 3124</span>                         SmallVectorImpl&lt;Value&gt; &amp;newResults) {</div>
<div class="line"><a id="l03125" name="l03125"></a><span class="lineno"> 3125</span>  <span class="comment">// TODO: Introduce a parent class that will handle the insertion point update.</span></div>
<div class="line"><a id="l03126" name="l03126"></a><span class="lineno"> 3126</span>  OpBuilder::InsertionGuard g(rewriter);</div>
<div class="line"><a id="l03127" name="l03127"></a><span class="lineno"> 3127</span>  rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(sliceOp);</div>
<div class="line"><a id="l03128" name="l03128"></a><span class="lineno"> 3128</span> </div>
<div class="line"><a id="l03129" name="l03129"></a><span class="lineno"> 3129</span>  <a class="code hl_typedef" href="namespacemlir.html#a864cb5eb1fea4a548c28cda535ba7213">TypedValue&lt;RankedTensorType&gt;</a> source = sliceOp.getSource();</div>
<div class="line"><a id="l03130" name="l03130"></a><span class="lineno"> 3130</span>  <span class="keyword">auto</span> sourceType = source.getType();</div>
<div class="line"><a id="l03131" name="l03131"></a><span class="lineno"> 3131</span>  <span class="keyword">auto</span> resultType = sliceOp.getResultType();</div>
<div class="line"><a id="l03132" name="l03132"></a><span class="lineno"> 3132</span> </div>
<div class="line"><a id="l03133" name="l03133"></a><span class="lineno"> 3133</span>  Value padValue = <a class="code hl_function" href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a>(sliceOp);</div>
<div class="line"><a id="l03134" name="l03134"></a><span class="lineno"> 3134</span> </div>
<div class="line"><a id="l03135" name="l03135"></a><span class="lineno"> 3135</span>  <span class="keywordflow">if</span> (!padValue) {</div>
<div class="line"><a id="l03136" name="l03136"></a><span class="lineno"> 3136</span>    <span class="keyword">auto</span> elemType = sourceType.getElementType();</div>
<div class="line"><a id="l03137" name="l03137"></a><span class="lineno"> 3137</span>    padValue = arith::ConstantOp::create(rewriter, sliceOp.getLoc(), elemType,</div>
<div class="line"><a id="l03138" name="l03138"></a><span class="lineno"> 3138</span>                                         rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#a8e943986e58a8b0c88fcd51b0f0afafb">getZeroAttr</a>(elemType));</div>
<div class="line"><a id="l03139" name="l03139"></a><span class="lineno"> 3139</span>  }</div>
<div class="line"><a id="l03140" name="l03140"></a><span class="lineno"> 3140</span> </div>
<div class="line"><a id="l03141" name="l03141"></a><span class="lineno"> 3141</span>  <span class="comment">// 2. Get the vector shape</span></div>
<div class="line"><a id="l03142" name="l03142"></a><span class="lineno"> 3142</span>  SmallVector&lt;int64_t&gt; vecShape;</div>
<div class="line"><a id="l03143" name="l03143"></a><span class="lineno"> 3143</span>  <span class="keywordtype">size_t</span> rankDiff = resultType.getRank() - sourceType.getRank();</div>
<div class="line"><a id="l03144" name="l03144"></a><span class="lineno"> 3144</span>  <span class="keywordflow">for</span> (int64_t i = 0, end = sourceType.getRank(); i &lt; end; ++i) {</div>
<div class="line"><a id="l03145" name="l03145"></a><span class="lineno"> 3145</span>    <span class="keywordflow">if</span> (!inputVectorSizes.empty()) {</div>
<div class="line"><a id="l03146" name="l03146"></a><span class="lineno"> 3146</span>      vecShape.push_back(inputVectorSizes[i]);</div>
<div class="line"><a id="l03147" name="l03147"></a><span class="lineno"> 3147</span>    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!sourceType.isDynamicDim(i)) {</div>
<div class="line"><a id="l03148" name="l03148"></a><span class="lineno"> 3148</span>      vecShape.push_back(sourceType.getDimSize(i));</div>
<div class="line"><a id="l03149" name="l03149"></a><span class="lineno"> 3149</span>    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!resultType.isDynamicDim(i)) {</div>
<div class="line"><a id="l03150" name="l03150"></a><span class="lineno"> 3150</span>      <span class="comment">// Source shape is not statically known, but result shape is.</span></div>
<div class="line"><a id="l03151" name="l03151"></a><span class="lineno"> 3151</span>      <span class="comment">// Vectorize with size of result shape. This may be larger than the</span></div>
<div class="line"><a id="l03152" name="l03152"></a><span class="lineno"> 3152</span>      <span class="comment">// source size.</span></div>
<div class="line"><a id="l03153" name="l03153"></a><span class="lineno"> 3153</span>      <span class="comment">// FIXME: Using rankDiff implies that the source tensor is inserted at</span></div>
<div class="line"><a id="l03154" name="l03154"></a><span class="lineno"> 3154</span>      <span class="comment">// the end of the destination tensor. However, that&#39;s not required.</span></div>
<div class="line"><a id="l03155" name="l03155"></a><span class="lineno"> 3155</span>      vecShape.push_back(resultType.getDimSize(rankDiff + i));</div>
<div class="line"><a id="l03156" name="l03156"></a><span class="lineno"> 3156</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l03157" name="l03157"></a><span class="lineno"> 3157</span>      <span class="comment">// Neither source nor result dim of padOp is static. Cannot vectorize</span></div>
<div class="line"><a id="l03158" name="l03158"></a><span class="lineno"> 3158</span>      <span class="comment">// the copy.</span></div>
<div class="line"><a id="l03159" name="l03159"></a><span class="lineno"> 3159</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l03160" name="l03160"></a><span class="lineno"> 3160</span>    }</div>
<div class="line"><a id="l03161" name="l03161"></a><span class="lineno"> 3161</span>  }</div>
<div class="line"><a id="l03162" name="l03162"></a><span class="lineno"> 3162</span>  <span class="keyword">auto</span> vecType = VectorType::get(vecShape, sourceType.getElementType());</div>
<div class="line"><a id="l03163" name="l03163"></a><span class="lineno"> 3163</span> </div>
<div class="line"><a id="l03164" name="l03164"></a><span class="lineno"> 3164</span>  <span class="comment">// 3. Generate TransferReadOp + TransferWriteOp</span></div>
<div class="line"><a id="l03165" name="l03165"></a><span class="lineno"> 3165</span>  <span class="keyword">auto</span> loc = sliceOp.getLoc();</div>
<div class="line"><a id="l03166" name="l03166"></a><span class="lineno"> 3166</span> </div>
<div class="line"><a id="l03167" name="l03167"></a><span class="lineno"> 3167</span>  <span class="comment">// Create read</span></div>
<div class="line"><a id="l03168" name="l03168"></a><span class="lineno"> 3168</span>  SmallVector&lt;Value&gt; readIndices(</div>
<div class="line"><a id="l03169" name="l03169"></a><span class="lineno"> 3169</span>      vecType.getRank(), <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0));</div>
<div class="line"><a id="l03170" name="l03170"></a><span class="lineno"> 3170</span>  Value read = <a class="code hl_function" href="namespacemlir_1_1vector.html#ac1f704d81959566caaf92245061960fb">mlir::vector::createReadOrMaskedRead</a>(</div>
<div class="line"><a id="l03171" name="l03171"></a><span class="lineno"> 3171</span>      rewriter, loc, source, vecType, padValue,</div>
<div class="line"><a id="l03172" name="l03172"></a><span class="lineno"> 3172</span>      <span class="comment">/*useInBoundsInsteadOfMasking=*/</span>inputVectorSizes.empty());</div>
<div class="line"><a id="l03173" name="l03173"></a><span class="lineno"> 3173</span> </div>
<div class="line"><a id="l03174" name="l03174"></a><span class="lineno"> 3174</span>  <span class="comment">// Create write</span></div>
<div class="line"><a id="l03175" name="l03175"></a><span class="lineno"> 3175</span>  <span class="keyword">auto</span> writeIndices =</div>
<div class="line"><a id="l03176" name="l03176"></a><span class="lineno"> 3176</span>      <a class="code hl_function" href="namespacemlir.html#aa058eb9c12d3b97deb073543c1372195">getValueOrCreateConstantIndexOp</a>(rewriter, loc, sliceOp.getMixedOffsets());</div>
<div class="line"><a id="l03177" name="l03177"></a><span class="lineno"> 3177</span>  Operation *write =</div>
<div class="line"><a id="l03178" name="l03178"></a><span class="lineno"> 3178</span>      <a class="code hl_function" href="Vectorization_8cpp.html#a2d04989901c1df355793bb8a71328797">createWriteOrMaskedWrite</a>(rewriter, loc, read, sliceOp.getDest(),</div>
<div class="line"><a id="l03179" name="l03179"></a><span class="lineno"> 3179</span>                               writeIndices, inputVectorSizes.empty());</div>
<div class="line"><a id="l03180" name="l03180"></a><span class="lineno"> 3180</span> </div>
<div class="line"><a id="l03181" name="l03181"></a><span class="lineno"> 3181</span>  <span class="comment">// 4. Finalize</span></div>
<div class="line"><a id="l03182" name="l03182"></a><span class="lineno"> 3182</span>  newResults.push_back(write-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a id="l03183" name="l03183"></a><span class="lineno"> 3183</span> </div>
<div class="line"><a id="l03184" name="l03184"></a><span class="lineno"> 3184</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l03185" name="l03185"></a><span class="lineno"> 3185</span>}</div>
<div class="line"><a id="l03186" name="l03186"></a><span class="lineno"> 3186</span><span class="comment"></span> </div>
<div class="line"><a id="l03187" name="l03187"></a><span class="lineno"> 3187</span><span class="comment">/// Rewrite use of tensor::PadOp result in InsertSliceOp. E.g.:</span></div>
<div class="line"><a id="l03188" name="l03188"></a><span class="lineno"> 3188</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03189" name="l03189"></a><span class="lineno"> 3189</span><span class="comment">/// %0 = tensor.pad %src ... : tensor&lt;?x?xf32&gt; to tensor&lt;17x5xf32&gt;</span></div>
<div class="line"><a id="l03190" name="l03190"></a><span class="lineno"> 3190</span><span class="comment">/// %r = tensor.insert_slice %0</span></div>
<div class="line"><a id="l03191" name="l03191"></a><span class="lineno"> 3191</span><span class="comment">///     into %dest[%a, %b, 0, 0] [1, 1, 17, 5] [1, 1, 1, 1]</span></div>
<div class="line"><a id="l03192" name="l03192"></a><span class="lineno"> 3192</span><span class="comment">///     : tensor&lt;17x5xf32&gt; into tensor&lt;?x?x17x5xf32&gt;</span></div>
<div class="line"><a id="l03193" name="l03193"></a><span class="lineno"> 3193</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03194" name="l03194"></a><span class="lineno"> 3194</span><span class="comment">/// is rewritten to:</span></div>
<div class="line"><a id="l03195" name="l03195"></a><span class="lineno"> 3195</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03196" name="l03196"></a><span class="lineno"> 3196</span><span class="comment">/// %0 = vector.transfer_read %src[%c0, %c0], %padding</span></div>
<div class="line"><a id="l03197" name="l03197"></a><span class="lineno"> 3197</span><span class="comment">///     : tensor&lt;?x?xf32&gt;, vector&lt;17x5xf32&gt;</span></div>
<div class="line"><a id="l03198" name="l03198"></a><span class="lineno"> 3198</span><span class="comment">/// %r = vector.transfer_write %0, %dest[%a, %b, %c0, %c0]</span></div>
<div class="line"><a id="l03199" name="l03199"></a><span class="lineno"> 3199</span><span class="comment">///     {in_bounds = [true, true]} : vector&lt;17x5xf32&gt;, tensor&lt;?x?x17x5xf32&gt;</span></div>
<div class="line"><a id="l03200" name="l03200"></a><span class="lineno"> 3200</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03201" name="l03201"></a><span class="lineno"> 3201</span><span class="comment">///</span></div>
<div class="line"><a id="l03202" name="l03202"></a><span class="lineno"> 3202</span><span class="comment">/// This rewrite is possible if:</span></div>
<div class="line"><a id="l03203" name="l03203"></a><span class="lineno"> 3203</span><span class="comment">/// - Low padding is static 0.</span></div>
<div class="line"><a id="l03204" name="l03204"></a><span class="lineno"> 3204</span><span class="comment">/// - `padOp` result shape is static.</span></div>
<div class="line"><a id="l03205" name="l03205"></a><span class="lineno"> 3205</span><span class="comment">/// - The entire padded tensor is inserted.</span></div>
<div class="line"><a id="l03206" name="l03206"></a><span class="lineno"> 3206</span><span class="comment">///   (Implies that sizes of `insertOp` are all static.)</span></div>
<div class="line"><a id="l03207" name="l03207"></a><span class="lineno"> 3207</span><span class="comment">/// - Only unit strides in `insertOp`.</span></div>
<div class="line"><a id="l03208" name="l03208"></a><span class="lineno"> 3208</span><span class="comment">/// - Single, scalar padding value.</span></div>
<div class="line"><a id="l03209" name="l03209"></a><span class="lineno"> 3209</span><span class="comment">/// - `padOp` result not used as destination.</span></div>
<div class="line"><a id="l03210" name="l03210"></a><span class="lineno"> 3210</span><span class="keyword">struct </span>PadOpVectorizationWithInsertSlicePattern</div>
<div class="line"><a id="l03211" name="l03211"></a><span class="lineno"> 3211</span>    : <span class="keyword">public</span> VectorizePadOpUserPattern&lt;tensor::InsertSliceOp&gt; {</div>
<div class="line"><a id="l03212" name="l03212"></a><span class="lineno"> 3212</span>  <span class="keyword">using </span>VectorizePadOpUserPattern&lt;</div>
<div class="line"><a id="l03213" name="l03213"></a><span class="lineno"> 3213</span>      tensor::InsertSliceOp&gt;::VectorizePadOpUserPattern;</div>
<div class="line"><a id="l03214" name="l03214"></a><span class="lineno"> 3214</span> </div>
<div class="line"><a id="l03215" name="l03215"></a><span class="lineno"> 3215</span>  LogicalResult rewriteUser(PatternRewriter &amp;rewriter, tensor::PadOp padOp,</div>
<div class="line"><a id="l03216" name="l03216"></a><span class="lineno"> 3216</span>                            tensor::InsertSliceOp insertOp)<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l03217" name="l03217"></a><span class="lineno"> 3217</span>    <span class="comment">// Low padding must be static 0.</span></div>
<div class="line"><a id="l03218" name="l03218"></a><span class="lineno"> 3218</span>    <span class="keywordflow">if</span> (!padOp.hasZeroLowPad())</div>
<div class="line"><a id="l03219" name="l03219"></a><span class="lineno"> 3219</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l03220" name="l03220"></a><span class="lineno"> 3220</span>    <span class="comment">// Only unit stride supported.</span></div>
<div class="line"><a id="l03221" name="l03221"></a><span class="lineno"> 3221</span>    <span class="keywordflow">if</span> (!insertOp.hasUnitStride())</div>
<div class="line"><a id="l03222" name="l03222"></a><span class="lineno"> 3222</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l03223" name="l03223"></a><span class="lineno"> 3223</span>    <span class="comment">// Pad value must be a constant.</span></div>
<div class="line"><a id="l03224" name="l03224"></a><span class="lineno"> 3224</span>    <span class="keyword">auto</span> padValue = padOp.getConstantPaddingValue();</div>
<div class="line"><a id="l03225" name="l03225"></a><span class="lineno"> 3225</span>    <span class="keywordflow">if</span> (!padValue)</div>
<div class="line"><a id="l03226" name="l03226"></a><span class="lineno"> 3226</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l03227" name="l03227"></a><span class="lineno"> 3227</span>    <span class="comment">// Dynamic shapes not supported.</span></div>
<div class="line"><a id="l03228" name="l03228"></a><span class="lineno"> 3228</span>    <span class="keywordflow">if</span> (!cast&lt;ShapedType&gt;(padOp.getResult().getType()).hasStaticShape())</div>
<div class="line"><a id="l03229" name="l03229"></a><span class="lineno"> 3229</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l03230" name="l03230"></a><span class="lineno"> 3230</span>    <span class="comment">// Pad result not used as destination.</span></div>
<div class="line"><a id="l03231" name="l03231"></a><span class="lineno"> 3231</span>    <span class="keywordflow">if</span> (insertOp.getDest() == padOp.getResult())</div>
<div class="line"><a id="l03232" name="l03232"></a><span class="lineno"> 3232</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l03233" name="l03233"></a><span class="lineno"> 3233</span> </div>
<div class="line"><a id="l03234" name="l03234"></a><span class="lineno"> 3234</span>    <span class="keyword">auto</span> vecType = VectorType::get(padOp.getType().getShape(),</div>
<div class="line"><a id="l03235" name="l03235"></a><span class="lineno"> 3235</span>                                   padOp.getType().getElementType());</div>
<div class="line"><a id="l03236" name="l03236"></a><span class="lineno"> 3236</span>    <span class="keywordtype">unsigned</span> vecRank = vecType.getRank();</div>
<div class="line"><a id="l03237" name="l03237"></a><span class="lineno"> 3237</span>    <span class="keywordtype">unsigned</span> tensorRank = insertOp.getType().getRank();</div>
<div class="line"><a id="l03238" name="l03238"></a><span class="lineno"> 3238</span> </div>
<div class="line"><a id="l03239" name="l03239"></a><span class="lineno"> 3239</span>    <span class="comment">// Check if sizes match: Insert the entire tensor into most minor dims.</span></div>
<div class="line"><a id="l03240" name="l03240"></a><span class="lineno"> 3240</span>    <span class="comment">// (No permutations allowed.)</span></div>
<div class="line"><a id="l03241" name="l03241"></a><span class="lineno"> 3241</span>    SmallVector&lt;int64_t&gt; expectedSizes(tensorRank - vecRank, 1);</div>
<div class="line"><a id="l03242" name="l03242"></a><span class="lineno"> 3242</span>    expectedSizes.append(vecType.getShape().begin(), vecType.getShape().end());</div>
<div class="line"><a id="l03243" name="l03243"></a><span class="lineno"> 3243</span>    <span class="keywordflow">if</span> (!llvm::all_of(</div>
<div class="line"><a id="l03244" name="l03244"></a><span class="lineno"> 3244</span>            llvm::zip(insertOp.getMixedSizes(), expectedSizes), [](<span class="keyword">auto</span> it) {</div>
<div class="line"><a id="l03245" name="l03245"></a><span class="lineno"> 3245</span>              return getConstantIntValue(std::get&lt;0&gt;(it)) == std::get&lt;1&gt;(it);</div>
<div class="line"><a id="l03246" name="l03246"></a><span class="lineno"> 3246</span>            }))</div>
<div class="line"><a id="l03247" name="l03247"></a><span class="lineno"> 3247</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l03248" name="l03248"></a><span class="lineno"> 3248</span> </div>
<div class="line"><a id="l03249" name="l03249"></a><span class="lineno"> 3249</span>    <span class="comment">// Insert the TransferReadOp and TransferWriteOp at the position of the</span></div>
<div class="line"><a id="l03250" name="l03250"></a><span class="lineno"> 3250</span>    <span class="comment">// InsertSliceOp.</span></div>
<div class="line"><a id="l03251" name="l03251"></a><span class="lineno"> 3251</span>    rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(insertOp);</div>
<div class="line"><a id="l03252" name="l03252"></a><span class="lineno"> 3252</span> </div>
<div class="line"><a id="l03253" name="l03253"></a><span class="lineno"> 3253</span>    <span class="comment">// Generate TransferReadOp: Read entire source tensor and add high</span></div>
<div class="line"><a id="l03254" name="l03254"></a><span class="lineno"> 3254</span>    <span class="comment">// padding.</span></div>
<div class="line"><a id="l03255" name="l03255"></a><span class="lineno"> 3255</span>    SmallVector&lt;Value&gt; readIndices(</div>
<div class="line"><a id="l03256" name="l03256"></a><span class="lineno"> 3256</span>        vecRank, <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, padOp.getLoc(), 0));</div>
<div class="line"><a id="l03257" name="l03257"></a><span class="lineno"> 3257</span>    <span class="keyword">auto</span> read = vector::TransferReadOp::create(rewriter, padOp.getLoc(),</div>
<div class="line"><a id="l03258" name="l03258"></a><span class="lineno"> 3258</span>                                               vecType, padOp.getSource(),</div>
<div class="line"><a id="l03259" name="l03259"></a><span class="lineno"> 3259</span>                                               readIndices, padValue);</div>
<div class="line"><a id="l03260" name="l03260"></a><span class="lineno"> 3260</span> </div>
<div class="line"><a id="l03261" name="l03261"></a><span class="lineno"> 3261</span>    <span class="comment">// Generate TransferWriteOp: Write to InsertSliceOp&#39;s dest tensor at</span></div>
<div class="line"><a id="l03262" name="l03262"></a><span class="lineno"> 3262</span>    <span class="comment">// specified offsets. Write is fully in-bounds because a InsertSliceOp&#39;s</span></div>
<div class="line"><a id="l03263" name="l03263"></a><span class="lineno"> 3263</span>    <span class="comment">// source must fit into the destination at the specified offsets.</span></div>
<div class="line"><a id="l03264" name="l03264"></a><span class="lineno"> 3264</span>    <span class="keyword">auto</span> writeIndices = <a class="code hl_function" href="namespacemlir.html#aa058eb9c12d3b97deb073543c1372195">getValueOrCreateConstantIndexOp</a>(</div>
<div class="line"><a id="l03265" name="l03265"></a><span class="lineno"> 3265</span>        rewriter, padOp.getLoc(), insertOp.getMixedOffsets());</div>
<div class="line"><a id="l03266" name="l03266"></a><span class="lineno"> 3266</span>    SmallVector&lt;bool&gt; inBounds(vecRank, <span class="keyword">true</span>);</div>
<div class="line"><a id="l03267" name="l03267"></a><span class="lineno"> 3267</span>    rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#afb1c910a57707f518d2b9c903c2bb5bc">replaceOpWithNewOp</a>&lt;vector::TransferWriteOp&gt;(</div>
<div class="line"><a id="l03268" name="l03268"></a><span class="lineno"> 3268</span>        insertOp, read, insertOp.getDest(), writeIndices,</div>
<div class="line"><a id="l03269" name="l03269"></a><span class="lineno"> 3269</span>        ArrayRef&lt;bool&gt;{inBounds});</div>
<div class="line"><a id="l03270" name="l03270"></a><span class="lineno"> 3270</span> </div>
<div class="line"><a id="l03271" name="l03271"></a><span class="lineno"> 3271</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l03272" name="l03272"></a><span class="lineno"> 3272</span>  }</div>
<div class="line"><a id="l03273" name="l03273"></a><span class="lineno"> 3273</span>};</div>
<div class="line"><a id="l03274" name="l03274"></a><span class="lineno"> 3274</span> </div>
<div class="line"><a id="l03275" name="l03275"></a><span class="lineno"> 3275</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacemlir_1_1linalg.html#a43c2ef8a778a33a17885475c11b50bdd">mlir::linalg::populatePadOpVectorizationPatterns</a>(</div>
<div class="line"><a id="l03276" name="l03276"></a><span class="lineno"> 3276</span>    RewritePatternSet &amp;<a class="code hl_variable" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>, PatternBenefit baseBenefit) {</div>
<div class="line"><a id="l03277" name="l03277"></a><span class="lineno"> 3277</span>  <a class="code hl_variable" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.add&lt;PadOpVectorizationWithTransferReadPattern,</div>
<div class="line"><a id="l03278" name="l03278"></a><span class="lineno"> 3278</span>               PadOpVectorizationWithTransferWritePattern,</div>
<div class="line"><a id="l03279" name="l03279"></a><span class="lineno"> 3279</span>               PadOpVectorizationWithInsertSlicePattern&gt;(</div>
<div class="line"><a id="l03280" name="l03280"></a><span class="lineno"> 3280</span>      <a class="code hl_variable" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.getContext(), baseBenefit.<a class="code hl_function" href="classmlir_1_1PatternBenefit.html#af19d7a934078c6de5512543eea299579">getBenefit</a>() + 1);</div>
<div class="line"><a id="l03281" name="l03281"></a><span class="lineno"> 3281</span>}</div>
<div class="line"><a id="l03282" name="l03282"></a><span class="lineno"> 3282</span> </div>
<div class="line"><a id="l03283" name="l03283"></a><span class="lineno"> 3283</span><span class="comment">//----------------------------------------------------------------------------//</span></div>
<div class="line"><a id="l03284" name="l03284"></a><span class="lineno"> 3284</span><span class="comment">// Forwarding patterns</span></div>
<div class="line"><a id="l03285" name="l03285"></a><span class="lineno"> 3285</span><span class="comment">//----------------------------------------------------------------------------//</span></div>
<div class="line"><a id="l03286" name="l03286"></a><span class="lineno"> 3286</span><span class="comment"></span> </div>
<div class="line"><a id="l03287" name="l03287"></a><span class="lineno"> 3287</span><span class="comment">/// Check whether there is any interleaved use of any `values` between</span></div>
<div class="line"><a id="l03288" name="l03288"></a><span class="lineno"> 3288</span><span class="comment">/// `firstOp` and `secondOp`. Conservatively return `true` if any op or value</span></div>
<div class="line"><a id="l03289" name="l03289"></a><span class="lineno"> 3289</span><span class="comment">/// is in a different block.</span></div>
<div class="line"><a id="l03290" name="l03290"></a><span class="lineno"> 3290</span><span class="keyword">static</span> <span class="keywordtype">bool</span> mayExistInterleavedUses(Operation *firstOp, Operation *secondOp,</div>
<div class="line"><a id="l03291" name="l03291"></a><span class="lineno"> 3291</span>                                    <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a4fa832087ed6d7798c173648e7541e60">ValueRange</a> values) {</div>
<div class="line"><a id="l03292" name="l03292"></a><span class="lineno"> 3292</span>  <span class="keywordflow">if</span> (firstOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a52ddd1dbf469abfbb77ab130119070f3">getBlock</a>() != secondOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a52ddd1dbf469abfbb77ab130119070f3">getBlock</a>() ||</div>
<div class="line"><a id="l03293" name="l03293"></a><span class="lineno"> 3293</span>      !firstOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a3cfc1046bad9638cf68c7add9efa6c33">isBeforeInBlock</a>(secondOp)) {</div>
<div class="line"><a id="l03294" name="l03294"></a><span class="lineno"> 3294</span>    LDBG() &lt;&lt; <span class="stringliteral">&quot;interleavedUses precondition failed, firstOp: &quot;</span> &lt;&lt; *firstOp</div>
<div class="line"><a id="l03295" name="l03295"></a><span class="lineno"> 3295</span>           &lt;&lt; <span class="stringliteral">&quot;, second op: &quot;</span> &lt;&lt; *secondOp;</div>
<div class="line"><a id="l03296" name="l03296"></a><span class="lineno"> 3296</span>    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l03297" name="l03297"></a><span class="lineno"> 3297</span>  }</div>
<div class="line"><a id="l03298" name="l03298"></a><span class="lineno"> 3298</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> v : values) {</div>
<div class="line"><a id="l03299" name="l03299"></a><span class="lineno"> 3299</span>    <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : v.getUses()) {</div>
<div class="line"><a id="l03300" name="l03300"></a><span class="lineno"> 3300</span>      Operation *owner = u.getOwner();</div>
<div class="line"><a id="l03301" name="l03301"></a><span class="lineno"> 3301</span>      <span class="keywordflow">if</span> (owner == firstOp || owner == secondOp)</div>
<div class="line"><a id="l03302" name="l03302"></a><span class="lineno"> 3302</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03303" name="l03303"></a><span class="lineno"> 3303</span>      <span class="comment">// TODO: this is too conservative, use dominance info in the future.</span></div>
<div class="line"><a id="l03304" name="l03304"></a><span class="lineno"> 3304</span>      <span class="keywordflow">if</span> (owner-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a52ddd1dbf469abfbb77ab130119070f3">getBlock</a>() == firstOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a52ddd1dbf469abfbb77ab130119070f3">getBlock</a>() &amp;&amp;</div>
<div class="line"><a id="l03305" name="l03305"></a><span class="lineno"> 3305</span>          (owner-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a3cfc1046bad9638cf68c7add9efa6c33">isBeforeInBlock</a>(firstOp) || secondOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a3cfc1046bad9638cf68c7add9efa6c33">isBeforeInBlock</a>(owner)))</div>
<div class="line"><a id="l03306" name="l03306"></a><span class="lineno"> 3306</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03307" name="l03307"></a><span class="lineno"> 3307</span>      LDBG() &lt;&lt; <span class="stringliteral">&quot; found interleaved op &quot;</span> &lt;&lt; *owner &lt;&lt; <span class="stringliteral">&quot;, firstOp: &quot;</span> &lt;&lt; *firstOp</div>
<div class="line"><a id="l03308" name="l03308"></a><span class="lineno"> 3308</span>             &lt;&lt; <span class="stringliteral">&quot;, second op: &quot;</span> &lt;&lt; *secondOp;</div>
<div class="line"><a id="l03309" name="l03309"></a><span class="lineno"> 3309</span>      <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><a id="l03310" name="l03310"></a><span class="lineno"> 3310</span>    }</div>
<div class="line"><a id="l03311" name="l03311"></a><span class="lineno"> 3311</span>  }</div>
<div class="line"><a id="l03312" name="l03312"></a><span class="lineno"> 3312</span>  <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a id="l03313" name="l03313"></a><span class="lineno"> 3313</span>}</div>
<div class="line"><a id="l03314" name="l03314"></a><span class="lineno"> 3314</span><span class="comment"></span> </div>
<div class="line"><a id="l03315" name="l03315"></a><span class="lineno"> 3315</span><span class="comment">/// Return the unique subview use of `v` if it is indeed unique, null</span></div>
<div class="line"><a id="l03316" name="l03316"></a><span class="lineno"> 3316</span><span class="comment">/// otherwise.</span></div>
<div class="line"><a id="l03317" name="l03317"></a><span class="lineno"> 3317</span><span class="keyword">static</span> memref::SubViewOp getSubViewUseIfUnique(Value v) {</div>
<div class="line"><a id="l03318" name="l03318"></a><span class="lineno"> 3318</span>  memref::SubViewOp subViewOp;</div>
<div class="line"><a id="l03319" name="l03319"></a><span class="lineno"> 3319</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : v.<a class="code hl_function" href="classmlir_1_1Value.html#a5adc50e42183f2f503143918a296da9d">getUses</a>()) {</div>
<div class="line"><a id="l03320" name="l03320"></a><span class="lineno"> 3320</span>    <span class="keywordflow">if</span> (<span class="keyword">auto</span> newSubViewOp = dyn_cast&lt;memref::SubViewOp&gt;(u.getOwner())) {</div>
<div class="line"><a id="l03321" name="l03321"></a><span class="lineno"> 3321</span>      <span class="keywordflow">if</span> (subViewOp)</div>
<div class="line"><a id="l03322" name="l03322"></a><span class="lineno"> 3322</span>        <span class="keywordflow">return</span> memref::SubViewOp();</div>
<div class="line"><a id="l03323" name="l03323"></a><span class="lineno"> 3323</span>      subViewOp = newSubViewOp;</div>
<div class="line"><a id="l03324" name="l03324"></a><span class="lineno"> 3324</span>    }</div>
<div class="line"><a id="l03325" name="l03325"></a><span class="lineno"> 3325</span>  }</div>
<div class="line"><a id="l03326" name="l03326"></a><span class="lineno"> 3326</span>  <span class="keywordflow">return</span> subViewOp;</div>
<div class="line"><a id="l03327" name="l03327"></a><span class="lineno"> 3327</span>}</div>
<div class="line"><a id="l03328" name="l03328"></a><span class="lineno"> 3328</span><span class="comment"></span> </div>
<div class="line"><a id="l03329" name="l03329"></a><span class="lineno"> 3329</span><span class="comment">/// TODO: use interfaces, side-effects and aliasing analysis as appropriate,</span></div>
<div class="line"><a id="l03330" name="l03330"></a><span class="lineno"> 3330</span><span class="comment">/// when available.</span></div>
<div class="line"><a id="l03331" name="l03331"></a><span class="lineno"> 3331</span>LogicalResult <a class="code hl_function" href="structmlir_1_1linalg_1_1LinalgCopyVTRForwardingPattern.html#a5be03b192efbaf3d0c6f4db1942432e8">LinalgCopyVTRForwardingPattern::matchAndRewrite</a>(</div>
<div class="line"><a id="l03332" name="l03332"></a><span class="lineno"> 3332</span>    vector::TransferReadOp xferOp, PatternRewriter &amp;rewriter)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l03333" name="l03333"></a><span class="lineno"> 3333</span> </div>
<div class="line"><a id="l03334" name="l03334"></a><span class="lineno"> 3334</span>  <span class="comment">// TODO: support mask.</span></div>
<div class="line"><a id="l03335" name="l03335"></a><span class="lineno"> 3335</span>  <span class="keywordflow">if</span> (xferOp.getMask())</div>
<div class="line"><a id="l03336" name="l03336"></a><span class="lineno"> 3336</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;unsupported mask&quot;</span>);</div>
<div class="line"><a id="l03337" name="l03337"></a><span class="lineno"> 3337</span> </div>
<div class="line"><a id="l03338" name="l03338"></a><span class="lineno"> 3338</span>  <span class="comment">// Transfer into `view`.</span></div>
<div class="line"><a id="l03339" name="l03339"></a><span class="lineno"> 3339</span>  Value viewOrAlloc = xferOp.getBase();</div>
<div class="line"><a id="l03340" name="l03340"></a><span class="lineno"> 3340</span>  <span class="keywordflow">if</span> (!viewOrAlloc.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;memref::ViewOp&gt;() &amp;&amp;</div>
<div class="line"><a id="l03341" name="l03341"></a><span class="lineno"> 3341</span>      !viewOrAlloc.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;memref::AllocOp&gt;())</div>
<div class="line"><a id="l03342" name="l03342"></a><span class="lineno"> 3342</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;source not a view or alloc&quot;</span>);</div>
<div class="line"><a id="l03343" name="l03343"></a><span class="lineno"> 3343</span> </div>
<div class="line"><a id="l03344" name="l03344"></a><span class="lineno"> 3344</span>  <span class="comment">// Ensure there is exactly one subview of `viewOrAlloc` defining `subView`.</span></div>
<div class="line"><a id="l03345" name="l03345"></a><span class="lineno"> 3345</span>  memref::SubViewOp subViewOp = getSubViewUseIfUnique(viewOrAlloc);</div>
<div class="line"><a id="l03346" name="l03346"></a><span class="lineno"> 3346</span>  <span class="keywordflow">if</span> (!subViewOp)</div>
<div class="line"><a id="l03347" name="l03347"></a><span class="lineno"> 3347</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;no subview found&quot;</span>);</div>
<div class="line"><a id="l03348" name="l03348"></a><span class="lineno"> 3348</span>  Value subView = subViewOp.getResult();</div>
<div class="line"><a id="l03349" name="l03349"></a><span class="lineno"> 3349</span> </div>
<div class="line"><a id="l03350" name="l03350"></a><span class="lineno"> 3350</span>  <span class="comment">// Find the copy into `subView` without interleaved uses.</span></div>
<div class="line"><a id="l03351" name="l03351"></a><span class="lineno"> 3351</span>  memref::CopyOp copyOp;</div>
<div class="line"><a id="l03352" name="l03352"></a><span class="lineno"> 3352</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : subView.<a class="code hl_function" href="classmlir_1_1Value.html#a5adc50e42183f2f503143918a296da9d">getUses</a>()) {</div>
<div class="line"><a id="l03353" name="l03353"></a><span class="lineno"> 3353</span>    <span class="keywordflow">if</span> (<span class="keyword">auto</span> newCopyOp = dyn_cast&lt;memref::CopyOp&gt;(u.getOwner())) {</div>
<div class="line"><a id="l03354" name="l03354"></a><span class="lineno"> 3354</span>      assert(isa&lt;MemRefType&gt;(newCopyOp.getTarget().getType()));</div>
<div class="line"><a id="l03355" name="l03355"></a><span class="lineno"> 3355</span>      <span class="keywordflow">if</span> (newCopyOp.getTarget() != subView)</div>
<div class="line"><a id="l03356" name="l03356"></a><span class="lineno"> 3356</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03357" name="l03357"></a><span class="lineno"> 3357</span>      <span class="keywordflow">if</span> (mayExistInterleavedUses(newCopyOp, xferOp, {viewOrAlloc, subView}))</div>
<div class="line"><a id="l03358" name="l03358"></a><span class="lineno"> 3358</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03359" name="l03359"></a><span class="lineno"> 3359</span>      copyOp = newCopyOp;</div>
<div class="line"><a id="l03360" name="l03360"></a><span class="lineno"> 3360</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03361" name="l03361"></a><span class="lineno"> 3361</span>    }</div>
<div class="line"><a id="l03362" name="l03362"></a><span class="lineno"> 3362</span>  }</div>
<div class="line"><a id="l03363" name="l03363"></a><span class="lineno"> 3363</span>  <span class="keywordflow">if</span> (!copyOp)</div>
<div class="line"><a id="l03364" name="l03364"></a><span class="lineno"> 3364</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;no copy found&quot;</span>);</div>
<div class="line"><a id="l03365" name="l03365"></a><span class="lineno"> 3365</span> </div>
<div class="line"><a id="l03366" name="l03366"></a><span class="lineno"> 3366</span>  <span class="comment">// Find the fill into `viewOrAlloc` without interleaved uses before the</span></div>
<div class="line"><a id="l03367" name="l03367"></a><span class="lineno"> 3367</span>  <span class="comment">// copy.</span></div>
<div class="line"><a id="l03368" name="l03368"></a><span class="lineno"> 3368</span>  FillOp maybeFillOp;</div>
<div class="line"><a id="l03369" name="l03369"></a><span class="lineno"> 3369</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : viewOrAlloc.<a class="code hl_function" href="classmlir_1_1Value.html#a5adc50e42183f2f503143918a296da9d">getUses</a>()) {</div>
<div class="line"><a id="l03370" name="l03370"></a><span class="lineno"> 3370</span>    <span class="keywordflow">if</span> (<span class="keyword">auto</span> newFillOp = dyn_cast&lt;FillOp&gt;(u.getOwner())) {</div>
<div class="line"><a id="l03371" name="l03371"></a><span class="lineno"> 3371</span>      assert(isa&lt;MemRefType&gt;(newFillOp.output().getType()));</div>
<div class="line"><a id="l03372" name="l03372"></a><span class="lineno"> 3372</span>      <span class="keywordflow">if</span> (newFillOp.output() != viewOrAlloc)</div>
<div class="line"><a id="l03373" name="l03373"></a><span class="lineno"> 3373</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03374" name="l03374"></a><span class="lineno"> 3374</span>      <span class="keywordflow">if</span> (mayExistInterleavedUses(newFillOp, copyOp, {viewOrAlloc, subView}))</div>
<div class="line"><a id="l03375" name="l03375"></a><span class="lineno"> 3375</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03376" name="l03376"></a><span class="lineno"> 3376</span>      maybeFillOp = newFillOp;</div>
<div class="line"><a id="l03377" name="l03377"></a><span class="lineno"> 3377</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03378" name="l03378"></a><span class="lineno"> 3378</span>    }</div>
<div class="line"><a id="l03379" name="l03379"></a><span class="lineno"> 3379</span>  }</div>
<div class="line"><a id="l03380" name="l03380"></a><span class="lineno"> 3380</span>  <span class="comment">// Ensure padding matches.</span></div>
<div class="line"><a id="l03381" name="l03381"></a><span class="lineno"> 3381</span>  <span class="keywordflow">if</span> (maybeFillOp &amp;&amp; xferOp.getPadding() != maybeFillOp.value())</div>
<div class="line"><a id="l03382" name="l03382"></a><span class="lineno"> 3382</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(xferOp,</div>
<div class="line"><a id="l03383" name="l03383"></a><span class="lineno"> 3383</span>                                       <span class="stringliteral">&quot;padding value does not match fill&quot;</span>);</div>
<div class="line"><a id="l03384" name="l03384"></a><span class="lineno"> 3384</span> </div>
<div class="line"><a id="l03385" name="l03385"></a><span class="lineno"> 3385</span>  <span class="comment">// `in` is the subview that memref.copy reads. Replace it.</span></div>
<div class="line"><a id="l03386" name="l03386"></a><span class="lineno"> 3386</span>  Value in = copyOp.getSource();</div>
<div class="line"><a id="l03387" name="l03387"></a><span class="lineno"> 3387</span> </div>
<div class="line"><a id="l03388" name="l03388"></a><span class="lineno"> 3388</span>  <span class="comment">// memref.copy + linalg.fill can be used to create a padded local buffer.</span></div>
<div class="line"><a id="l03389" name="l03389"></a><span class="lineno"> 3389</span>  <span class="comment">// The `masked` attribute is only valid on this padded buffer.</span></div>
<div class="line"><a id="l03390" name="l03390"></a><span class="lineno"> 3390</span>  <span class="comment">// When forwarding to vector.transfer_read, the attribute must be reset</span></div>
<div class="line"><a id="l03391" name="l03391"></a><span class="lineno"> 3391</span>  <span class="comment">// conservatively.</span></div>
<div class="line"><a id="l03392" name="l03392"></a><span class="lineno"> 3392</span>  <span class="keyword">auto</span> vectorType = xferOp.getVectorType();</div>
<div class="line"><a id="l03393" name="l03393"></a><span class="lineno"> 3393</span>  Value res = vector::TransferReadOp::create(</div>
<div class="line"><a id="l03394" name="l03394"></a><span class="lineno"> 3394</span>      rewriter, xferOp.getLoc(), vectorType, in, xferOp.getIndices(),</div>
<div class="line"><a id="l03395" name="l03395"></a><span class="lineno"> 3395</span>      xferOp.getPermutationMapAttr(), xferOp.getPadding(), xferOp.getMask(),</div>
<div class="line"><a id="l03396" name="l03396"></a><span class="lineno"> 3396</span>      rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(</div>
<div class="line"><a id="l03397" name="l03397"></a><span class="lineno"> 3397</span>          SmallVector&lt;bool&gt;(vectorType.getRank(), <span class="keyword">false</span>)));</div>
<div class="line"><a id="l03398" name="l03398"></a><span class="lineno"> 3398</span> </div>
<div class="line"><a id="l03399" name="l03399"></a><span class="lineno"> 3399</span>  <span class="keywordflow">if</span> (maybeFillOp)</div>
<div class="line"><a id="l03400" name="l03400"></a><span class="lineno"> 3400</span>    rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(maybeFillOp);</div>
<div class="line"><a id="l03401" name="l03401"></a><span class="lineno"> 3401</span>  rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(copyOp);</div>
<div class="line"><a id="l03402" name="l03402"></a><span class="lineno"> 3402</span>  rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(xferOp, res);</div>
<div class="line"><a id="l03403" name="l03403"></a><span class="lineno"> 3403</span> </div>
<div class="line"><a id="l03404" name="l03404"></a><span class="lineno"> 3404</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l03405" name="l03405"></a><span class="lineno"> 3405</span>}</div>
<div class="line"><a id="l03406" name="l03406"></a><span class="lineno"> 3406</span><span class="comment"></span> </div>
<div class="line"><a id="l03407" name="l03407"></a><span class="lineno"> 3407</span><span class="comment">/// TODO: use interfaces, side-effects and aliasing analysis as appropriate,</span></div>
<div class="line"><a id="l03408" name="l03408"></a><span class="lineno"> 3408</span><span class="comment">/// when available.</span></div>
<div class="line"><a id="l03409" name="l03409"></a><span class="lineno"> 3409</span>LogicalResult <a class="code hl_function" href="structmlir_1_1linalg_1_1LinalgCopyVTWForwardingPattern.html#a7d5ee3615456f09f4d7518e4d78e48f8">LinalgCopyVTWForwardingPattern::matchAndRewrite</a>(</div>
<div class="line"><a id="l03410" name="l03410"></a><span class="lineno"> 3410</span>    vector::TransferWriteOp xferOp, PatternRewriter &amp;rewriter)<span class="keyword"> const </span>{</div>
<div class="line"><a id="l03411" name="l03411"></a><span class="lineno"> 3411</span>  <span class="comment">// TODO: support mask.</span></div>
<div class="line"><a id="l03412" name="l03412"></a><span class="lineno"> 3412</span>  <span class="keywordflow">if</span> (xferOp.getMask())</div>
<div class="line"><a id="l03413" name="l03413"></a><span class="lineno"> 3413</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;unsupported mask&quot;</span>);</div>
<div class="line"><a id="l03414" name="l03414"></a><span class="lineno"> 3414</span> </div>
<div class="line"><a id="l03415" name="l03415"></a><span class="lineno"> 3415</span>  <span class="comment">// Transfer into `viewOrAlloc`.</span></div>
<div class="line"><a id="l03416" name="l03416"></a><span class="lineno"> 3416</span>  Value viewOrAlloc = xferOp.getBase();</div>
<div class="line"><a id="l03417" name="l03417"></a><span class="lineno"> 3417</span>  <span class="keywordflow">if</span> (!viewOrAlloc.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;memref::ViewOp&gt;() &amp;&amp;</div>
<div class="line"><a id="l03418" name="l03418"></a><span class="lineno"> 3418</span>      !viewOrAlloc.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;memref::AllocOp&gt;())</div>
<div class="line"><a id="l03419" name="l03419"></a><span class="lineno"> 3419</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;source not a view or alloc&quot;</span>);</div>
<div class="line"><a id="l03420" name="l03420"></a><span class="lineno"> 3420</span> </div>
<div class="line"><a id="l03421" name="l03421"></a><span class="lineno"> 3421</span>  <span class="comment">// Ensure there is exactly one subview of `viewOrAlloc` defining `subView`.</span></div>
<div class="line"><a id="l03422" name="l03422"></a><span class="lineno"> 3422</span>  memref::SubViewOp subViewOp = getSubViewUseIfUnique(viewOrAlloc);</div>
<div class="line"><a id="l03423" name="l03423"></a><span class="lineno"> 3423</span>  <span class="keywordflow">if</span> (!subViewOp)</div>
<div class="line"><a id="l03424" name="l03424"></a><span class="lineno"> 3424</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;no subview found&quot;</span>);</div>
<div class="line"><a id="l03425" name="l03425"></a><span class="lineno"> 3425</span>  Value subView = subViewOp.getResult();</div>
<div class="line"><a id="l03426" name="l03426"></a><span class="lineno"> 3426</span> </div>
<div class="line"><a id="l03427" name="l03427"></a><span class="lineno"> 3427</span>  <span class="comment">// Find the copy from `subView` without interleaved uses.</span></div>
<div class="line"><a id="l03428" name="l03428"></a><span class="lineno"> 3428</span>  memref::CopyOp copyOp;</div>
<div class="line"><a id="l03429" name="l03429"></a><span class="lineno"> 3429</span>  <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;u : subViewOp.getResult().getUses()) {</div>
<div class="line"><a id="l03430" name="l03430"></a><span class="lineno"> 3430</span>    <span class="keywordflow">if</span> (<span class="keyword">auto</span> newCopyOp = dyn_cast&lt;memref::CopyOp&gt;(u.getOwner())) {</div>
<div class="line"><a id="l03431" name="l03431"></a><span class="lineno"> 3431</span>      <span class="keywordflow">if</span> (newCopyOp.getSource() != subView)</div>
<div class="line"><a id="l03432" name="l03432"></a><span class="lineno"> 3432</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03433" name="l03433"></a><span class="lineno"> 3433</span>      <span class="keywordflow">if</span> (mayExistInterleavedUses(xferOp, newCopyOp, {viewOrAlloc, subView}))</div>
<div class="line"><a id="l03434" name="l03434"></a><span class="lineno"> 3434</span>        <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l03435" name="l03435"></a><span class="lineno"> 3435</span>      copyOp = newCopyOp;</div>
<div class="line"><a id="l03436" name="l03436"></a><span class="lineno"> 3436</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03437" name="l03437"></a><span class="lineno"> 3437</span>    }</div>
<div class="line"><a id="l03438" name="l03438"></a><span class="lineno"> 3438</span>  }</div>
<div class="line"><a id="l03439" name="l03439"></a><span class="lineno"> 3439</span>  <span class="keywordflow">if</span> (!copyOp)</div>
<div class="line"><a id="l03440" name="l03440"></a><span class="lineno"> 3440</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(xferOp, <span class="stringliteral">&quot;no copy found&quot;</span>);</div>
<div class="line"><a id="l03441" name="l03441"></a><span class="lineno"> 3441</span> </div>
<div class="line"><a id="l03442" name="l03442"></a><span class="lineno"> 3442</span>  <span class="comment">// `out` is the subview copied into that we replace.</span></div>
<div class="line"><a id="l03443" name="l03443"></a><span class="lineno"> 3443</span>  assert(isa&lt;MemRefType&gt;(copyOp.getTarget().getType()));</div>
<div class="line"><a id="l03444" name="l03444"></a><span class="lineno"> 3444</span>  Value out = copyOp.getTarget();</div>
<div class="line"><a id="l03445" name="l03445"></a><span class="lineno"> 3445</span> </div>
<div class="line"><a id="l03446" name="l03446"></a><span class="lineno"> 3446</span>  <span class="comment">// Forward vector.transfer into copy.</span></div>
<div class="line"><a id="l03447" name="l03447"></a><span class="lineno"> 3447</span>  <span class="comment">// memref.copy + linalg.fill can be used to create a padded local buffer.</span></div>
<div class="line"><a id="l03448" name="l03448"></a><span class="lineno"> 3448</span>  <span class="comment">// The `masked` attribute is only valid on this padded buffer.</span></div>
<div class="line"><a id="l03449" name="l03449"></a><span class="lineno"> 3449</span>  <span class="comment">// When forwarding to vector.transfer_write, the attribute must be reset</span></div>
<div class="line"><a id="l03450" name="l03450"></a><span class="lineno"> 3450</span>  <span class="comment">// conservatively.</span></div>
<div class="line"><a id="l03451" name="l03451"></a><span class="lineno"> 3451</span>  <span class="keyword">auto</span> vector = xferOp.getVector();</div>
<div class="line"><a id="l03452" name="l03452"></a><span class="lineno"> 3452</span>  vector::TransferWriteOp::create(</div>
<div class="line"><a id="l03453" name="l03453"></a><span class="lineno"> 3453</span>      rewriter, xferOp.getLoc(), vector, out, xferOp.getIndices(),</div>
<div class="line"><a id="l03454" name="l03454"></a><span class="lineno"> 3454</span>      xferOp.getPermutationMapAttr(), xferOp.getMask(),</div>
<div class="line"><a id="l03455" name="l03455"></a><span class="lineno"> 3455</span>      rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(SmallVector&lt;bool&gt;(</div>
<div class="line"><a id="l03456" name="l03456"></a><span class="lineno"> 3456</span>          dyn_cast&lt;VectorType&gt;(vector.getType()).getRank(), <span class="keyword">false</span>)));</div>
<div class="line"><a id="l03457" name="l03457"></a><span class="lineno"> 3457</span> </div>
<div class="line"><a id="l03458" name="l03458"></a><span class="lineno"> 3458</span>  rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(copyOp);</div>
<div class="line"><a id="l03459" name="l03459"></a><span class="lineno"> 3459</span>  rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(xferOp);</div>
<div class="line"><a id="l03460" name="l03460"></a><span class="lineno"> 3460</span> </div>
<div class="line"><a id="l03461" name="l03461"></a><span class="lineno"> 3461</span>  <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l03462" name="l03462"></a><span class="lineno"> 3462</span>}</div>
<div class="line"><a id="l03463" name="l03463"></a><span class="lineno"> 3463</span> </div>
<div class="line"><a id="l03464" name="l03464"></a><span class="lineno"> 3464</span><span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l03465" name="l03465"></a><span class="lineno"> 3465</span><span class="comment">// Convolution vectorization patterns</span></div>
<div class="line"><a id="l03466" name="l03466"></a><span class="lineno"> 3466</span><span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l03467" name="l03467"></a><span class="lineno"> 3467</span> </div>
<div class="line"><a id="l03468" name="l03468"></a><span class="lineno"> 3468</span><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> N&gt;</div>
<div class="line"><a id="l03469" name="l03469"></a><span class="lineno"> 3469</span><span class="keyword">static</span> <span class="keywordtype">void</span> bindShapeDims(ShapedType shapedType) {}</div>
<div class="line"><a id="l03470" name="l03470"></a><span class="lineno"> 3470</span> </div>
<div class="line"><a id="l03471" name="l03471"></a><span class="lineno"> 3471</span><span class="keyword">template</span> &lt;<span class="keywordtype">int</span> N, <span class="keyword">typename</span> IntTy, <span class="keyword">typename</span>... IntTy2&gt;</div>
<div class="line"><a id="l03472" name="l03472"></a><span class="lineno"> 3472</span><span class="keyword">static</span> <span class="keywordtype">void</span> bindShapeDims(ShapedType shapedType, IntTy &amp;val, IntTy2 &amp;...vals) {</div>
<div class="line"><a id="l03473" name="l03473"></a><span class="lineno"> 3473</span>  val = shapedType.getShape()[N];</div>
<div class="line"><a id="l03474" name="l03474"></a><span class="lineno"> 3474</span>  bindShapeDims&lt;N + 1, IntTy2 &amp;...&gt;(shapedType, vals...);</div>
<div class="line"><a id="l03475" name="l03475"></a><span class="lineno"> 3475</span>}</div>
<div class="line"><a id="l03476" name="l03476"></a><span class="lineno"> 3476</span><span class="comment"></span> </div>
<div class="line"><a id="l03477" name="l03477"></a><span class="lineno"> 3477</span><span class="comment">/// Bind a pack of int&amp; to the leading dimensions of shapedType.getShape().</span></div>
<div class="line"><a id="l03478" name="l03478"></a><span class="lineno"> 3478</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span>... IntTy&gt;</div>
<div class="line"><a id="l03479" name="l03479"></a><span class="lineno"> 3479</span><span class="keyword">static</span> <span class="keywordtype">void</span> bindShapeDims(ShapedType shapedType, IntTy &amp;...vals) {</div>
<div class="line"><a id="l03480" name="l03480"></a><span class="lineno"> 3480</span>  bindShapeDims&lt;0&gt;(shapedType, vals...);</div>
<div class="line"><a id="l03481" name="l03481"></a><span class="lineno"> 3481</span>}</div>
<div class="line"><a id="l03482" name="l03482"></a><span class="lineno"> 3482</span> </div>
<div class="line"><a id="l03483" name="l03483"></a><span class="lineno"> 3483</span><span class="keyword">namespace </span>{<span class="comment"></span></div>
<div class="line"><a id="l03484" name="l03484"></a><span class="lineno"> 3484</span><span class="comment">/// Generate a vector implementation for either:</span></div>
<div class="line"><a id="l03485" name="l03485"></a><span class="lineno"> 3485</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03486" name="l03486"></a><span class="lineno"> 3486</span><span class="comment">///   Op def: (     w,     kw  )</span></div>
<div class="line"><a id="l03487" name="l03487"></a><span class="lineno"> 3487</span><span class="comment">///    Iters: ({Par(), Red()})</span></div>
<div class="line"><a id="l03488" name="l03488"></a><span class="lineno"> 3488</span><span class="comment">///   Layout: {{w + kw}, {kw}, {w}}</span></div>
<div class="line"><a id="l03489" name="l03489"></a><span class="lineno"> 3489</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03490" name="l03490"></a><span class="lineno"> 3490</span><span class="comment">/// kw is unrolled.</span></div>
<div class="line"><a id="l03491" name="l03491"></a><span class="lineno"> 3491</span><span class="comment">///</span></div>
<div class="line"><a id="l03492" name="l03492"></a><span class="lineno"> 3492</span><span class="comment">/// or</span></div>
<div class="line"><a id="l03493" name="l03493"></a><span class="lineno"> 3493</span><span class="comment">///</span></div>
<div class="line"><a id="l03494" name="l03494"></a><span class="lineno"> 3494</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03495" name="l03495"></a><span class="lineno"> 3495</span><span class="comment">///   Op def: (     n,     w,     c,    kw,    f  )</span></div>
<div class="line"><a id="l03496" name="l03496"></a><span class="lineno"> 3496</span><span class="comment">///    Iters: ({Par(), Par(), Par(), Red(), Red()})</span></div>
<div class="line"><a id="l03497" name="l03497"></a><span class="lineno"> 3497</span><span class="comment">///   Layout: {{n, strideW * w + dilationW * kw, c}, {kw, c, f}, {n, w, f}}</span></div>
<div class="line"><a id="l03498" name="l03498"></a><span class="lineno"> 3498</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03499" name="l03499"></a><span class="lineno"> 3499</span><span class="comment">/// kw is unrolled, w is unrolled iff dilationW &gt; 1.</span></div>
<div class="line"><a id="l03500" name="l03500"></a><span class="lineno"> 3500</span><span class="comment">///</span></div>
<div class="line"><a id="l03501" name="l03501"></a><span class="lineno"> 3501</span><span class="comment">/// or</span></div>
<div class="line"><a id="l03502" name="l03502"></a><span class="lineno"> 3502</span><span class="comment">///</span></div>
<div class="line"><a id="l03503" name="l03503"></a><span class="lineno"> 3503</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03504" name="l03504"></a><span class="lineno"> 3504</span><span class="comment">///   Op def: (     n,     c,     w,    f,    kw )</span></div>
<div class="line"><a id="l03505" name="l03505"></a><span class="lineno"> 3505</span><span class="comment">///    Iters: ({Par(), Par(), Par(), Red(), Red()})</span></div>
<div class="line"><a id="l03506" name="l03506"></a><span class="lineno"> 3506</span><span class="comment">///   Layout: {{n, c, strideW * w + dilationW * kw}, {f, c, kw}, {n, f, w}}</span></div>
<div class="line"><a id="l03507" name="l03507"></a><span class="lineno"> 3507</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03508" name="l03508"></a><span class="lineno"> 3508</span><span class="comment">/// kw is unrolled, w is unrolled iff dilationW &gt; 1.</span></div>
<div class="line"><a id="l03509" name="l03509"></a><span class="lineno"> 3509</span><span class="comment">///</span></div>
<div class="line"><a id="l03510" name="l03510"></a><span class="lineno"> 3510</span><span class="comment">/// or</span></div>
<div class="line"><a id="l03511" name="l03511"></a><span class="lineno"> 3511</span><span class="comment">///</span></div>
<div class="line"><a id="l03512" name="l03512"></a><span class="lineno"> 3512</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03513" name="l03513"></a><span class="lineno"> 3513</span><span class="comment">///   Op def: (     n,     w,     c,    kw )</span></div>
<div class="line"><a id="l03514" name="l03514"></a><span class="lineno"> 3514</span><span class="comment">///    Iters: ({Par(), Par(), Par(), Red()})</span></div>
<div class="line"><a id="l03515" name="l03515"></a><span class="lineno"> 3515</span><span class="comment">///   Layout: {{n, strideW * w + dilationW * kw, c}, {kw, c}, {n, w, c}}</span></div>
<div class="line"><a id="l03516" name="l03516"></a><span class="lineno"> 3516</span><span class="comment">/// ```</span></div>
<div class="line"><a id="l03517" name="l03517"></a><span class="lineno"> 3517</span><span class="comment">/// kw is unrolled, w is unrolled iff dilationW &gt; 1.</span></div>
<div class="line"><a id="l03518" name="l03518"></a><span class="lineno"> 3518</span><span class="keyword">struct </span>Conv1DGenerator</div>
<div class="line"><a id="l03519" name="l03519"></a><span class="lineno"> 3519</span>    : <span class="keyword">public</span> StructuredGenerator&lt;LinalgOp, utils::IteratorType&gt; {</div>
<div class="line"><a id="l03520" name="l03520"></a><span class="lineno"> 3520</span>  Conv1DGenerator(RewriterBase &amp;rewriter, LinalgOp linalgOp)</div>
<div class="line"><a id="l03521" name="l03521"></a><span class="lineno"> 3521</span>      : StructuredGenerator&lt;LinalgOp, utils::IteratorType&gt;(rewriter, linalgOp) {</div>
<div class="line"><a id="l03522" name="l03522"></a><span class="lineno"> 3522</span> </div>
<div class="line"><a id="l03523" name="l03523"></a><span class="lineno"> 3523</span>    lhsShaped = linalgOp.getDpsInputOperand(0)-&gt;<a class="code hl_function" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">get</a>();</div>
<div class="line"><a id="l03524" name="l03524"></a><span class="lineno"> 3524</span>    rhsShaped = linalgOp.getDpsInputOperand(1)-&gt;<a class="code hl_function" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">get</a>();</div>
<div class="line"><a id="l03525" name="l03525"></a><span class="lineno"> 3525</span>    resShaped = linalgOp.getDpsInitOperand(0)-&gt;<a class="code hl_function" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">get</a>();</div>
<div class="line"><a id="l03526" name="l03526"></a><span class="lineno"> 3526</span>    lhsShapedType = dyn_cast&lt;ShapedType&gt;(lhsShaped.getType());</div>
<div class="line"><a id="l03527" name="l03527"></a><span class="lineno"> 3527</span>    rhsShapedType = dyn_cast&lt;ShapedType&gt;(rhsShaped.getType());</div>
<div class="line"><a id="l03528" name="l03528"></a><span class="lineno"> 3528</span>    resShapedType = dyn_cast&lt;ShapedType&gt;(resShaped.getType());</div>
<div class="line"><a id="l03529" name="l03529"></a><span class="lineno"> 3529</span> </div>
<div class="line"><a id="l03530" name="l03530"></a><span class="lineno"> 3530</span>    Operation *reduceOp = <a class="code hl_function" href="Vectorization_8cpp.html#a4c99d55a1274aa91b750b22a4a3c76e2">matchLinalgReduction</a>(linalgOp.getDpsInitOperand(0));</div>
<div class="line"><a id="l03531" name="l03531"></a><span class="lineno"> 3531</span>    redOp = reduceOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ab2e11ba83ff765eb7595554f97aaaa75">getName</a>().<a class="code hl_function" href="classmlir_1_1OperationName.html#a2c83cffa9a4c4fb68436d9ee3497c226">getIdentifier</a>();</div>
<div class="line"><a id="l03532" name="l03532"></a><span class="lineno"> 3532</span> </div>
<div class="line"><a id="l03533" name="l03533"></a><span class="lineno"> 3533</span>    setConvOperationKind(reduceOp);</div>
<div class="line"><a id="l03534" name="l03534"></a><span class="lineno"> 3534</span> </div>
<div class="line"><a id="l03535" name="l03535"></a><span class="lineno"> 3535</span>    <span class="keyword">auto</span> maybeKind = <a class="code hl_function" href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">getCombinerOpKind</a>(reduceOp);</div>
<div class="line"><a id="l03536" name="l03536"></a><span class="lineno"> 3536</span>    reductionKind = maybeKind.value();</div>
<div class="line"><a id="l03537" name="l03537"></a><span class="lineno"> 3537</span> </div>
<div class="line"><a id="l03538" name="l03538"></a><span class="lineno"> 3538</span>    <span class="comment">// The ConvolutionOpInterface gives us guarantees of existence for</span></div>
<div class="line"><a id="l03539" name="l03539"></a><span class="lineno"> 3539</span>    <span class="comment">// strides/dilations. However, we do not need to rely on those, we can</span></div>
<div class="line"><a id="l03540" name="l03540"></a><span class="lineno"> 3540</span>    <span class="comment">// simply use them if present, otherwise use the default and let the generic</span></div>
<div class="line"><a id="l03541" name="l03541"></a><span class="lineno"> 3541</span>    <span class="comment">// conv. matcher in the ConvGenerator succeed or fail.</span></div>
<div class="line"><a id="l03542" name="l03542"></a><span class="lineno"> 3542</span>    <span class="keyword">auto</span> strides = linalgOp-&gt;getAttrOfType&lt;DenseIntElementsAttr&gt;(<span class="stringliteral">&quot;strides&quot;</span>);</div>
<div class="line"><a id="l03543" name="l03543"></a><span class="lineno"> 3543</span>    <span class="keyword">auto</span> dilations = linalgOp-&gt;getAttrOfType&lt;DenseIntElementsAttr&gt;(<span class="stringliteral">&quot;dilations&quot;</span>);</div>
<div class="line"><a id="l03544" name="l03544"></a><span class="lineno"> 3544</span>    strideW = strides ? *strides.getValues&lt;uint64_t&gt;().begin() : 1;</div>
<div class="line"><a id="l03545" name="l03545"></a><span class="lineno"> 3545</span>    dilationW = dilations ? *dilations.getValues&lt;uint64_t&gt;().begin() : 1;</div>
<div class="line"><a id="l03546" name="l03546"></a><span class="lineno"> 3546</span>  }</div>
<div class="line"><a id="l03547" name="l03547"></a><span class="lineno"> 3547</span><span class="comment"></span> </div>
<div class="line"><a id="l03548" name="l03548"></a><span class="lineno"> 3548</span><span class="comment">  /// Generate a vector implementation for:</span></div>
<div class="line"><a id="l03549" name="l03549"></a><span class="lineno"> 3549</span><span class="comment">  /// ```</span></div>
<div class="line"><a id="l03550" name="l03550"></a><span class="lineno"> 3550</span><span class="comment">  ///   Op def: (     w,     kw  )</span></div>
<div class="line"><a id="l03551" name="l03551"></a><span class="lineno"> 3551</span><span class="comment">  ///    Iters: ({Par(), Red()})</span></div>
<div class="line"><a id="l03552" name="l03552"></a><span class="lineno"> 3552</span><span class="comment">  ///   Layout: {{w + kw}, {kw}, {w}}</span></div>
<div class="line"><a id="l03553" name="l03553"></a><span class="lineno"> 3553</span><span class="comment">  /// ```</span></div>
<div class="line"><a id="l03554" name="l03554"></a><span class="lineno"> 3554</span><span class="comment">  /// kw is always unrolled.</span></div>
<div class="line"><a id="l03555" name="l03555"></a><span class="lineno"> 3555</span><span class="comment">  ///</span></div>
<div class="line"><a id="l03556" name="l03556"></a><span class="lineno"> 3556</span><span class="comment">  /// or</span></div>
<div class="line"><a id="l03557" name="l03557"></a><span class="lineno"> 3557</span><span class="comment">  ///</span></div>
<div class="line"><a id="l03558" name="l03558"></a><span class="lineno"> 3558</span><span class="comment">  /// ```</span></div>
<div class="line"><a id="l03559" name="l03559"></a><span class="lineno"> 3559</span><span class="comment">  ///   Op def: (     n,     w,     c,    kw,    f  )</span></div>
<div class="line"><a id="l03560" name="l03560"></a><span class="lineno"> 3560</span><span class="comment">  ///    Iters: ({Par(), Par(), Par(), Red(), Red()})</span></div>
<div class="line"><a id="l03561" name="l03561"></a><span class="lineno"> 3561</span><span class="comment">  ///   Layout: {{n, strideW * w + dilationW * kw, c}, {kw, c, f}, {n, w, f}}</span></div>
<div class="line"><a id="l03562" name="l03562"></a><span class="lineno"> 3562</span><span class="comment">  /// ```</span></div>
<div class="line"><a id="l03563" name="l03563"></a><span class="lineno"> 3563</span><span class="comment">  /// kw is always unrolled.</span></div>
<div class="line"><a id="l03564" name="l03564"></a><span class="lineno"> 3564</span><span class="comment">  /// TODO: w (resp. kw) is unrolled when the strideW ( resp. dilationW) is</span></div>
<div class="line"><a id="l03565" name="l03565"></a><span class="lineno"> 3565</span><span class="comment">  /// &gt; 1.</span></div>
<div class="line"><a id="l03566" name="l03566"></a><span class="lineno"> 3566</span>  FailureOr&lt;Operation *&gt; conv(<a class="code hl_enumeration" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fec">Conv1DOpOrder</a> conv1DOpOrder) {</div>
<div class="line"><a id="l03567" name="l03567"></a><span class="lineno"> 3567</span>    int64_t nSize, wSize, cSize, kwSize, fSize;</div>
<div class="line"><a id="l03568" name="l03568"></a><span class="lineno"> 3568</span>    SmallVector&lt;int64_t, 3&gt; lhsShape, rhsShape, resShape;</div>
<div class="line"><a id="l03569" name="l03569"></a><span class="lineno"> 3569</span>    <span class="keywordtype">bool</span> isSingleChanneled = (conv1DOpOrder == <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>);</div>
<div class="line"><a id="l03570" name="l03570"></a><span class="lineno"> 3570</span>    <span class="keywordflow">switch</span> (conv1DOpOrder) {</div>
<div class="line"><a id="l03571" name="l03571"></a><span class="lineno"> 3571</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>:</div>
<div class="line"><a id="l03572" name="l03572"></a><span class="lineno"> 3572</span>      <span class="comment">// Initialize unused dimensions</span></div>
<div class="line"><a id="l03573" name="l03573"></a><span class="lineno"> 3573</span>      nSize = fSize = cSize = 0;</div>
<div class="line"><a id="l03574" name="l03574"></a><span class="lineno"> 3574</span>      <span class="comment">// out{W}</span></div>
<div class="line"><a id="l03575" name="l03575"></a><span class="lineno"> 3575</span>      bindShapeDims(resShapedType, wSize);</div>
<div class="line"><a id="l03576" name="l03576"></a><span class="lineno"> 3576</span>      <span class="comment">// kernel{kw}</span></div>
<div class="line"><a id="l03577" name="l03577"></a><span class="lineno"> 3577</span>      bindShapeDims(rhsShapedType, kwSize);</div>
<div class="line"><a id="l03578" name="l03578"></a><span class="lineno"> 3578</span>      lhsShape = {<span class="comment">// iw = ow + kw - 1</span></div>
<div class="line"><a id="l03579" name="l03579"></a><span class="lineno"> 3579</span>                  <span class="comment">//   (i.e. 16 convolved with 3 -&gt; 14)</span></div>
<div class="line"><a id="l03580" name="l03580"></a><span class="lineno"> 3580</span>                  (wSize + kwSize - 1)};</div>
<div class="line"><a id="l03581" name="l03581"></a><span class="lineno"> 3581</span>      rhsShape = {kwSize};</div>
<div class="line"><a id="l03582" name="l03582"></a><span class="lineno"> 3582</span>      resShape = {wSize};</div>
<div class="line"><a id="l03583" name="l03583"></a><span class="lineno"> 3583</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03584" name="l03584"></a><span class="lineno"> 3584</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>:</div>
<div class="line"><a id="l03585" name="l03585"></a><span class="lineno"> 3585</span>      <span class="comment">// out{n, w, f}</span></div>
<div class="line"><a id="l03586" name="l03586"></a><span class="lineno"> 3586</span>      bindShapeDims(resShapedType, nSize, wSize, fSize);</div>
<div class="line"><a id="l03587" name="l03587"></a><span class="lineno"> 3587</span>      <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a id="l03588" name="l03588"></a><span class="lineno"> 3588</span>      <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a id="l03589" name="l03589"></a><span class="lineno"> 3589</span>        <span class="comment">// kernel{kw, c, f}</span></div>
<div class="line"><a id="l03590" name="l03590"></a><span class="lineno"> 3590</span>        bindShapeDims(rhsShapedType, kwSize, cSize);</div>
<div class="line"><a id="l03591" name="l03591"></a><span class="lineno"> 3591</span>        <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03592" name="l03592"></a><span class="lineno"> 3592</span>      <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a id="l03593" name="l03593"></a><span class="lineno"> 3593</span>        <span class="comment">// kernel{kw}</span></div>
<div class="line"><a id="l03594" name="l03594"></a><span class="lineno"> 3594</span>        bindShapeDims(rhsShapedType, kwSize);</div>
<div class="line"><a id="l03595" name="l03595"></a><span class="lineno"> 3595</span>        cSize = fSize;</div>
<div class="line"><a id="l03596" name="l03596"></a><span class="lineno"> 3596</span>        <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03597" name="l03597"></a><span class="lineno"> 3597</span>      }</div>
<div class="line"><a id="l03598" name="l03598"></a><span class="lineno"> 3598</span>      lhsShape = {nSize,</div>
<div class="line"><a id="l03599" name="l03599"></a><span class="lineno"> 3599</span>                  <span class="comment">// iw = ow * sw + kw *  dw - 1</span></div>
<div class="line"><a id="l03600" name="l03600"></a><span class="lineno"> 3600</span>                  <span class="comment">//   (i.e. 16 convolved with 3 (@stride 1 dilation 1) -&gt; 14)</span></div>
<div class="line"><a id="l03601" name="l03601"></a><span class="lineno"> 3601</span>                  <span class="comment">// Perform the proper inclusive -&gt; exclusive -&gt; inclusive.</span></div>
<div class="line"><a id="l03602" name="l03602"></a><span class="lineno"> 3602</span>                  ((wSize - 1) * strideW + 1) + ((kwSize - 1) * dilationW + 1) -</div>
<div class="line"><a id="l03603" name="l03603"></a><span class="lineno"> 3603</span>                      1,</div>
<div class="line"><a id="l03604" name="l03604"></a><span class="lineno"> 3604</span>                  cSize};</div>
<div class="line"><a id="l03605" name="l03605"></a><span class="lineno"> 3605</span>      <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a id="l03606" name="l03606"></a><span class="lineno"> 3606</span>      <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a id="l03607" name="l03607"></a><span class="lineno"> 3607</span>        rhsShape = {kwSize, cSize, fSize};</div>
<div class="line"><a id="l03608" name="l03608"></a><span class="lineno"> 3608</span>        <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03609" name="l03609"></a><span class="lineno"> 3609</span>      <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a id="l03610" name="l03610"></a><span class="lineno"> 3610</span>        rhsShape = {kwSize};</div>
<div class="line"><a id="l03611" name="l03611"></a><span class="lineno"> 3611</span>        <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03612" name="l03612"></a><span class="lineno"> 3612</span>      }</div>
<div class="line"><a id="l03613" name="l03613"></a><span class="lineno"> 3613</span>      resShape = {nSize, wSize, fSize};</div>
<div class="line"><a id="l03614" name="l03614"></a><span class="lineno"> 3614</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03615" name="l03615"></a><span class="lineno"> 3615</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>:</div>
<div class="line"><a id="l03616" name="l03616"></a><span class="lineno"> 3616</span>      <span class="comment">// out{n, f, w}</span></div>
<div class="line"><a id="l03617" name="l03617"></a><span class="lineno"> 3617</span>      bindShapeDims(resShapedType, nSize, fSize, wSize);</div>
<div class="line"><a id="l03618" name="l03618"></a><span class="lineno"> 3618</span>      <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a id="l03619" name="l03619"></a><span class="lineno"> 3619</span>      <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a id="l03620" name="l03620"></a><span class="lineno"> 3620</span>        <span class="comment">// kernel{f, c, kw}</span></div>
<div class="line"><a id="l03621" name="l03621"></a><span class="lineno"> 3621</span>        bindShapeDims(rhsShapedType, fSize, cSize, kwSize);</div>
<div class="line"><a id="l03622" name="l03622"></a><span class="lineno"> 3622</span>        <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03623" name="l03623"></a><span class="lineno"> 3623</span>      <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a id="l03624" name="l03624"></a><span class="lineno"> 3624</span>        <span class="comment">// kernel{kw}</span></div>
<div class="line"><a id="l03625" name="l03625"></a><span class="lineno"> 3625</span>        bindShapeDims(rhsShapedType, kwSize);</div>
<div class="line"><a id="l03626" name="l03626"></a><span class="lineno"> 3626</span>        cSize = fSize;</div>
<div class="line"><a id="l03627" name="l03627"></a><span class="lineno"> 3627</span>        <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03628" name="l03628"></a><span class="lineno"> 3628</span>      }</div>
<div class="line"><a id="l03629" name="l03629"></a><span class="lineno"> 3629</span>      lhsShape = {nSize, cSize,</div>
<div class="line"><a id="l03630" name="l03630"></a><span class="lineno"> 3630</span>                  <span class="comment">// iw = ow * sw + kw *  dw - 1</span></div>
<div class="line"><a id="l03631" name="l03631"></a><span class="lineno"> 3631</span>                  <span class="comment">//   (i.e. 16 convolved with 3 (@stride 1 dilation 1) -&gt; 14)</span></div>
<div class="line"><a id="l03632" name="l03632"></a><span class="lineno"> 3632</span>                  <span class="comment">// Perform the proper inclusive -&gt; exclusive -&gt; inclusive.</span></div>
<div class="line"><a id="l03633" name="l03633"></a><span class="lineno"> 3633</span>                  ((wSize - 1) * strideW + 1) + ((kwSize - 1) * dilationW + 1) -</div>
<div class="line"><a id="l03634" name="l03634"></a><span class="lineno"> 3634</span>                      1};</div>
<div class="line"><a id="l03635" name="l03635"></a><span class="lineno"> 3635</span>      <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a id="l03636" name="l03636"></a><span class="lineno"> 3636</span>      <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a id="l03637" name="l03637"></a><span class="lineno"> 3637</span>        rhsShape = {fSize, cSize, kwSize};</div>
<div class="line"><a id="l03638" name="l03638"></a><span class="lineno"> 3638</span>        <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03639" name="l03639"></a><span class="lineno"> 3639</span>      <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a id="l03640" name="l03640"></a><span class="lineno"> 3640</span>        rhsShape = {kwSize};</div>
<div class="line"><a id="l03641" name="l03641"></a><span class="lineno"> 3641</span>        <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03642" name="l03642"></a><span class="lineno"> 3642</span>      }</div>
<div class="line"><a id="l03643" name="l03643"></a><span class="lineno"> 3643</span>      resShape = {nSize, fSize, wSize};</div>
<div class="line"><a id="l03644" name="l03644"></a><span class="lineno"> 3644</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03645" name="l03645"></a><span class="lineno"> 3645</span>    }</div>
<div class="line"><a id="l03646" name="l03646"></a><span class="lineno"> 3646</span> </div>
<div class="line"><a id="l03647" name="l03647"></a><span class="lineno"> 3647</span>    vector::TransferWriteOp write;</div>
<div class="line"><a id="l03648" name="l03648"></a><span class="lineno"> 3648</span>    Value zero = <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0);</div>
<div class="line"><a id="l03649" name="l03649"></a><span class="lineno"> 3649</span> </div>
<div class="line"><a id="l03650" name="l03650"></a><span class="lineno"> 3650</span>    <span class="comment">// w is unrolled (i.e. wSizeStep == 1) iff strideW &gt; 1.</span></div>
<div class="line"><a id="l03651" name="l03651"></a><span class="lineno"> 3651</span>    <span class="comment">// When strideW == 1, we can batch the contiguous loads and avoid</span></div>
<div class="line"><a id="l03652" name="l03652"></a><span class="lineno"> 3652</span>    <span class="comment">// unrolling</span></div>
<div class="line"><a id="l03653" name="l03653"></a><span class="lineno"> 3653</span>    int64_t wSizeStep = strideW == 1 ? wSize : 1;</div>
<div class="line"><a id="l03654" name="l03654"></a><span class="lineno"> 3654</span> </div>
<div class="line"><a id="l03655" name="l03655"></a><span class="lineno"> 3655</span>    Type lhsEltType = lhsShapedType.getElementType();</div>
<div class="line"><a id="l03656" name="l03656"></a><span class="lineno"> 3656</span>    Type rhsEltType = rhsShapedType.getElementType();</div>
<div class="line"><a id="l03657" name="l03657"></a><span class="lineno"> 3657</span>    Type resEltType = resShapedType.getElementType();</div>
<div class="line"><a id="l03658" name="l03658"></a><span class="lineno"> 3658</span>    <span class="keyword">auto</span> lhsType = VectorType::get(lhsShape, lhsEltType);</div>
<div class="line"><a id="l03659" name="l03659"></a><span class="lineno"> 3659</span>    <span class="keyword">auto</span> rhsType = VectorType::get(rhsShape, rhsEltType);</div>
<div class="line"><a id="l03660" name="l03660"></a><span class="lineno"> 3660</span>    <span class="keyword">auto</span> resType = VectorType::get(resShape, resEltType);</div>
<div class="line"><a id="l03661" name="l03661"></a><span class="lineno"> 3661</span>    <span class="comment">// Zero padding with the corresponding dimensions for lhs, rhs and res.</span></div>
<div class="line"><a id="l03662" name="l03662"></a><span class="lineno"> 3662</span>    SmallVector&lt;Value&gt; lhsPadding(lhsShape.size(), zero);</div>
<div class="line"><a id="l03663" name="l03663"></a><span class="lineno"> 3663</span>    SmallVector&lt;Value&gt; rhsPadding(rhsShape.size(), zero);</div>
<div class="line"><a id="l03664" name="l03664"></a><span class="lineno"> 3664</span>    SmallVector&lt;Value&gt; resPadding(resShape.size(), zero);</div>
<div class="line"><a id="l03665" name="l03665"></a><span class="lineno"> 3665</span> </div>
<div class="line"><a id="l03666" name="l03666"></a><span class="lineno"> 3666</span>    <span class="comment">// Read the whole lhs, rhs and res in one shot (with zero padding).</span></div>
<div class="line"><a id="l03667" name="l03667"></a><span class="lineno"> 3667</span>    Value <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a> = vector::TransferReadOp::create(</div>
<div class="line"><a id="l03668" name="l03668"></a><span class="lineno"> 3668</span>        rewriter, loc, lhsType, lhsShaped, lhsPadding,</div>
<div class="line"><a id="l03669" name="l03669"></a><span class="lineno"> 3669</span>        <span class="comment">/*padding=*/</span>arith::getZeroConstant(rewriter, loc, lhsEltType));</div>
<div class="line"><a id="l03670" name="l03670"></a><span class="lineno"> 3670</span>    <span class="comment">// This is needed only for Conv.</span></div>
<div class="line"><a id="l03671" name="l03671"></a><span class="lineno"> 3671</span>    Value <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a> = <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l03672" name="l03672"></a><span class="lineno"> 3672</span>    <span class="keywordflow">if</span> (oper == ConvOperationKind::Conv)</div>
<div class="line"><a id="l03673" name="l03673"></a><span class="lineno"> 3673</span>      <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a> = vector::TransferReadOp::create(</div>
<div class="line"><a id="l03674" name="l03674"></a><span class="lineno"> 3674</span>          rewriter, loc, rhsType, rhsShaped, rhsPadding,</div>
<div class="line"><a id="l03675" name="l03675"></a><span class="lineno"> 3675</span>          <span class="comment">/*padding=*/</span>arith::getZeroConstant(rewriter, loc, rhsEltType));</div>
<div class="line"><a id="l03676" name="l03676"></a><span class="lineno"> 3676</span>    Value res = vector::TransferReadOp::create(</div>
<div class="line"><a id="l03677" name="l03677"></a><span class="lineno"> 3677</span>        rewriter, loc, resType, resShaped, resPadding,</div>
<div class="line"><a id="l03678" name="l03678"></a><span class="lineno"> 3678</span>        <span class="comment">/*padding=*/</span>arith::getZeroConstant(rewriter, loc, resEltType));</div>
<div class="line"><a id="l03679" name="l03679"></a><span class="lineno"> 3679</span> </div>
<div class="line"><a id="l03680" name="l03680"></a><span class="lineno"> 3680</span>    <span class="comment">// The base vectorization case for channeled convolution is input:</span></div>
<div class="line"><a id="l03681" name="l03681"></a><span class="lineno"> 3681</span>    <span class="comment">// {n,w,c}, weight: {kw,c,f}, output: {n,w,f}. To reuse the base pattern</span></div>
<div class="line"><a id="l03682" name="l03682"></a><span class="lineno"> 3682</span>    <span class="comment">// vectorization case, we do pre transpose on input, weight, and output.</span></div>
<div class="line"><a id="l03683" name="l03683"></a><span class="lineno"> 3683</span>    <span class="keywordflow">switch</span> (conv1DOpOrder) {</div>
<div class="line"><a id="l03684" name="l03684"></a><span class="lineno"> 3684</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>:</div>
<div class="line"><a id="l03685" name="l03685"></a><span class="lineno"> 3685</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>:</div>
<div class="line"><a id="l03686" name="l03686"></a><span class="lineno"> 3686</span>      <span class="comment">// Base case, so no transposes necessary.</span></div>
<div class="line"><a id="l03687" name="l03687"></a><span class="lineno"> 3687</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03688" name="l03688"></a><span class="lineno"> 3688</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>: {</div>
<div class="line"><a id="l03689" name="l03689"></a><span class="lineno"> 3689</span>      <span class="comment">// To match base vectorization case, we pre-transpose current case.</span></div>
<div class="line"><a id="l03690" name="l03690"></a><span class="lineno"> 3690</span>      <span class="comment">// ncw -&gt; nwc</span></div>
<div class="line"><a id="l03691" name="l03691"></a><span class="lineno"> 3691</span>      <span class="keyword">static</span> <span class="keyword">constexpr</span> std::array&lt;int64_t, 3&gt; permLhs = {0, 2, 1};</div>
<div class="line"><a id="l03692" name="l03692"></a><span class="lineno"> 3692</span>      <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a> = vector::TransposeOp::create(rewriter, loc, <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, permLhs);</div>
<div class="line"><a id="l03693" name="l03693"></a><span class="lineno"> 3693</span>      <span class="comment">// fcw -&gt; wcf</span></div>
<div class="line"><a id="l03694" name="l03694"></a><span class="lineno"> 3694</span>      <span class="keyword">static</span> <span class="keyword">constexpr</span> std::array&lt;int64_t, 3&gt; permRhs = {2, 1, 0};</div>
<div class="line"><a id="l03695" name="l03695"></a><span class="lineno"> 3695</span> </div>
<div class="line"><a id="l03696" name="l03696"></a><span class="lineno"> 3696</span>      <span class="comment">// This is needed only for Conv.</span></div>
<div class="line"><a id="l03697" name="l03697"></a><span class="lineno"> 3697</span>      <span class="keywordflow">if</span> (oper == ConvOperationKind::Conv)</div>
<div class="line"><a id="l03698" name="l03698"></a><span class="lineno"> 3698</span>        <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a> = vector::TransposeOp::create(rewriter, loc, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, permRhs);</div>
<div class="line"><a id="l03699" name="l03699"></a><span class="lineno"> 3699</span>      <span class="comment">// nfw -&gt; nwf</span></div>
<div class="line"><a id="l03700" name="l03700"></a><span class="lineno"> 3700</span>      <span class="keyword">static</span> <span class="keyword">constexpr</span> std::array&lt;int64_t, 3&gt; permRes = {0, 2, 1};</div>
<div class="line"><a id="l03701" name="l03701"></a><span class="lineno"> 3701</span>      res = vector::TransposeOp::create(rewriter, loc, res, permRes);</div>
<div class="line"><a id="l03702" name="l03702"></a><span class="lineno"> 3702</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03703" name="l03703"></a><span class="lineno"> 3703</span>    }</div>
<div class="line"><a id="l03704" name="l03704"></a><span class="lineno"> 3704</span>    }</div>
<div class="line"><a id="l03705" name="l03705"></a><span class="lineno"> 3705</span> </div>
<div class="line"><a id="l03706" name="l03706"></a><span class="lineno"> 3706</span>    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l03707" name="l03707"></a><span class="lineno"> 3707</span>    <span class="comment">// Begin vector-only rewrite part</span></div>
<div class="line"><a id="l03708" name="l03708"></a><span class="lineno"> 3708</span>    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l03709" name="l03709"></a><span class="lineno"> 3709</span>    <span class="comment">// Unroll along kw and read slices of lhs and rhs.</span></div>
<div class="line"><a id="l03710" name="l03710"></a><span class="lineno"> 3710</span>    SmallVector&lt;Value&gt; lhsVals, rhsVals, resVals;</div>
<div class="line"><a id="l03711" name="l03711"></a><span class="lineno"> 3711</span>    lhsVals = <a class="code hl_function" href="Vectorization_8cpp.html#a200fa245f199890432efcd7596b5e672">extractConvInputSlices</a>(rewriter, loc, <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, nSize, wSize, cSize,</div>
<div class="line"><a id="l03712" name="l03712"></a><span class="lineno"> 3712</span>                                     kwSize, strideW, dilationW, wSizeStep,</div>
<div class="line"><a id="l03713" name="l03713"></a><span class="lineno"> 3713</span>                                     isSingleChanneled);</div>
<div class="line"><a id="l03714" name="l03714"></a><span class="lineno"> 3714</span>    <span class="comment">// Do not do for pooling.</span></div>
<div class="line"><a id="l03715" name="l03715"></a><span class="lineno"> 3715</span>    <span class="keywordflow">if</span> (oper == ConvOperationKind::Conv)</div>
<div class="line"><a id="l03716" name="l03716"></a><span class="lineno"> 3716</span>      rhsVals = <a class="code hl_function" href="Vectorization_8cpp.html#a5fd4201faa9fbc0aad08b5af06556cc8">extractConvFilterSlices</a>(rewriter, loc, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, kwSize);</div>
<div class="line"><a id="l03717" name="l03717"></a><span class="lineno"> 3717</span>    resVals = <a class="code hl_function" href="Vectorization_8cpp.html#af0d6a3da24bf08205af9661c55447701">extractConvResultSlices</a>(rewriter, loc, res, nSize, wSize, fSize,</div>
<div class="line"><a id="l03718" name="l03718"></a><span class="lineno"> 3718</span>                                      wSizeStep, isSingleChanneled);</div>
<div class="line"><a id="l03719" name="l03719"></a><span class="lineno"> 3719</span> </div>
<div class="line"><a id="l03720" name="l03720"></a><span class="lineno"> 3720</span>    <span class="keyword">auto</span> linearIndex = [&amp;](int64_t kw, int64_t w) {</div>
<div class="line"><a id="l03721" name="l03721"></a><span class="lineno"> 3721</span>      <span class="keywordflow">return</span> kw * (wSize / wSizeStep) + w;</div>
<div class="line"><a id="l03722" name="l03722"></a><span class="lineno"> 3722</span>    };</div>
<div class="line"><a id="l03723" name="l03723"></a><span class="lineno"> 3723</span> </div>
<div class="line"><a id="l03724" name="l03724"></a><span class="lineno"> 3724</span>    <span class="comment">// Compute contraction: O{n, w, f} += I{n, sw * w + dw * kw, c} * F{c, f}</span></div>
<div class="line"><a id="l03725" name="l03725"></a><span class="lineno"> 3725</span>    <span class="comment">// or perform outerproduct for non-channeled convolution or perform simple</span></div>
<div class="line"><a id="l03726" name="l03726"></a><span class="lineno"> 3726</span>    <span class="comment">// arith operation for pooling</span></div>
<div class="line"><a id="l03727" name="l03727"></a><span class="lineno"> 3727</span>    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a id="l03728" name="l03728"></a><span class="lineno"> 3728</span>      <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l03729" name="l03729"></a><span class="lineno"> 3729</span>        <span class="keywordflow">switch</span> (oper) {</div>
<div class="line"><a id="l03730" name="l03730"></a><span class="lineno"> 3730</span>        <span class="keywordflow">case</span> ConvOperationKind::Conv:</div>
<div class="line"><a id="l03731" name="l03731"></a><span class="lineno"> 3731</span>          <span class="keywordflow">if</span> (isSingleChanneled) {</div>
<div class="line"><a id="l03732" name="l03732"></a><span class="lineno"> 3732</span>            resVals[w] = conv1dSliceAsOuterProduct(rewriter, loc,</div>
<div class="line"><a id="l03733" name="l03733"></a><span class="lineno"> 3733</span>                                                   lhsVals[linearIndex(kw, w)],</div>
<div class="line"><a id="l03734" name="l03734"></a><span class="lineno"> 3734</span>                                                   rhsVals[kw], resVals[w]);</div>
<div class="line"><a id="l03735" name="l03735"></a><span class="lineno"> 3735</span>          } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l03736" name="l03736"></a><span class="lineno"> 3736</span>            resVals[w] = conv1dSliceAsContraction(rewriter, loc,</div>
<div class="line"><a id="l03737" name="l03737"></a><span class="lineno"> 3737</span>                                                  lhsVals[linearIndex(kw, w)],</div>
<div class="line"><a id="l03738" name="l03738"></a><span class="lineno"> 3738</span>                                                  rhsVals[kw], resVals[w]);</div>
<div class="line"><a id="l03739" name="l03739"></a><span class="lineno"> 3739</span>          }</div>
<div class="line"><a id="l03740" name="l03740"></a><span class="lineno"> 3740</span>          <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03741" name="l03741"></a><span class="lineno"> 3741</span>        <span class="keywordflow">case</span> ConvOperationKind::Pool:</div>
<div class="line"><a id="l03742" name="l03742"></a><span class="lineno"> 3742</span>          resVals[w] = pool1dSlice(rewriter, loc, lhsVals[linearIndex(kw, w)],</div>
<div class="line"><a id="l03743" name="l03743"></a><span class="lineno"> 3743</span>                                   resVals[w]);</div>
<div class="line"><a id="l03744" name="l03744"></a><span class="lineno"> 3744</span>          <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03745" name="l03745"></a><span class="lineno"> 3745</span>        }</div>
<div class="line"><a id="l03746" name="l03746"></a><span class="lineno"> 3746</span>      }</div>
<div class="line"><a id="l03747" name="l03747"></a><span class="lineno"> 3747</span>    }</div>
<div class="line"><a id="l03748" name="l03748"></a><span class="lineno"> 3748</span> </div>
<div class="line"><a id="l03749" name="l03749"></a><span class="lineno"> 3749</span>    res = <a class="code hl_function" href="Vectorization_8cpp.html#a110d1ed6891097419f0358bd63e974c8">insertConvResultSlices</a>(rewriter, loc, res, wSize, wSizeStep, resVals,</div>
<div class="line"><a id="l03750" name="l03750"></a><span class="lineno"> 3750</span>                                 isSingleChanneled);</div>
<div class="line"><a id="l03751" name="l03751"></a><span class="lineno"> 3751</span>    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l03752" name="l03752"></a><span class="lineno"> 3752</span>    <span class="comment">// End vector-only rewrite part</span></div>
<div class="line"><a id="l03753" name="l03753"></a><span class="lineno"> 3753</span>    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l03754" name="l03754"></a><span class="lineno"> 3754</span> </div>
<div class="line"><a id="l03755" name="l03755"></a><span class="lineno"> 3755</span>    <span class="comment">// The base vectorization case for channeled convolution is output:</span></div>
<div class="line"><a id="l03756" name="l03756"></a><span class="lineno"> 3756</span>    <span class="comment">// {n,w,f} To reuse the result from base pattern vectorization case, we</span></div>
<div class="line"><a id="l03757" name="l03757"></a><span class="lineno"> 3757</span>    <span class="comment">// post transpose the base case result.</span></div>
<div class="line"><a id="l03758" name="l03758"></a><span class="lineno"> 3758</span>    <span class="keywordflow">switch</span> (conv1DOpOrder) {</div>
<div class="line"><a id="l03759" name="l03759"></a><span class="lineno"> 3759</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>:</div>
<div class="line"><a id="l03760" name="l03760"></a><span class="lineno"> 3760</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>:</div>
<div class="line"><a id="l03761" name="l03761"></a><span class="lineno"> 3761</span>      <span class="comment">// Base case, so no transposes necessary.</span></div>
<div class="line"><a id="l03762" name="l03762"></a><span class="lineno"> 3762</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03763" name="l03763"></a><span class="lineno"> 3763</span>    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>: {</div>
<div class="line"><a id="l03764" name="l03764"></a><span class="lineno"> 3764</span>      <span class="comment">// nwf -&gt; nfw</span></div>
<div class="line"><a id="l03765" name="l03765"></a><span class="lineno"> 3765</span>      <span class="keyword">static</span> <span class="keyword">constexpr</span> std::array&lt;int64_t, 3&gt; perm = {0, 2, 1};</div>
<div class="line"><a id="l03766" name="l03766"></a><span class="lineno"> 3766</span>      res = vector::TransposeOp::create(rewriter, loc, res, perm);</div>
<div class="line"><a id="l03767" name="l03767"></a><span class="lineno"> 3767</span>      <span class="keywordflow">break</span>;</div>
<div class="line"><a id="l03768" name="l03768"></a><span class="lineno"> 3768</span>    }</div>
<div class="line"><a id="l03769" name="l03769"></a><span class="lineno"> 3769</span>    }</div>
<div class="line"><a id="l03770" name="l03770"></a><span class="lineno"> 3770</span> </div>
<div class="line"><a id="l03771" name="l03771"></a><span class="lineno"> 3771</span>    <span class="keywordflow">return</span> vector::TransferWriteOp::create(rewriter, loc, res, resShaped,</div>
<div class="line"><a id="l03772" name="l03772"></a><span class="lineno"> 3772</span>                                           resPadding)</div>
<div class="line"><a id="l03773" name="l03773"></a><span class="lineno"> 3773</span>        .getOperation();</div>
<div class="line"><a id="l03774" name="l03774"></a><span class="lineno"> 3774</span>  }</div>
<div class="line"><a id="l03775" name="l03775"></a><span class="lineno"> 3775</span> </div>
<div class="line"><a id="l03776" name="l03776"></a><span class="lineno"> 3776</span>  <span class="comment">// Take a value and widen to have the same element type as `ty`.</span></div>
<div class="line"><a id="l03777" name="l03777"></a><span class="lineno"> 3777</span>  Value <a class="code hl_function" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(RewriterBase &amp;rewriter, Location loc, Value val, Type ty) {</div>
<div class="line"><a id="l03778" name="l03778"></a><span class="lineno"> 3778</span>    <span class="keyword">const</span> Type srcElementType = <a class="code hl_function" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(val.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a id="l03779" name="l03779"></a><span class="lineno"> 3779</span>    <span class="keyword">const</span> Type dstElementType = <a class="code hl_function" href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">getElementTypeOrSelf</a>(ty);</div>
<div class="line"><a id="l03780" name="l03780"></a><span class="lineno"> 3780</span>    assert(isa&lt;IntegerType&gt;(dstElementType) || isa&lt;FloatType&gt;(dstElementType));</div>
<div class="line"><a id="l03781" name="l03781"></a><span class="lineno"> 3781</span>    <span class="keywordflow">if</span> (srcElementType == dstElementType)</div>
<div class="line"><a id="l03782" name="l03782"></a><span class="lineno"> 3782</span>      <span class="keywordflow">return</span> val;</div>
<div class="line"><a id="l03783" name="l03783"></a><span class="lineno"> 3783</span> </div>
<div class="line"><a id="l03784" name="l03784"></a><span class="lineno"> 3784</span>    <span class="keyword">const</span> int64_t srcWidth = srcElementType.<a class="code hl_function" href="classmlir_1_1Type.html#aeb142623709910125e07ecf1f9f2cdd5">getIntOrFloatBitWidth</a>();</div>
<div class="line"><a id="l03785" name="l03785"></a><span class="lineno"> 3785</span>    <span class="keyword">const</span> int64_t dstWidth = dstElementType.<a class="code hl_function" href="classmlir_1_1Type.html#aeb142623709910125e07ecf1f9f2cdd5">getIntOrFloatBitWidth</a>();</div>
<div class="line"><a id="l03786" name="l03786"></a><span class="lineno"> 3786</span>    <span class="keyword">const</span> Type dstType =</div>
<div class="line"><a id="l03787" name="l03787"></a><span class="lineno"> 3787</span>        cast&lt;ShapedType&gt;(val.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()).cloneWith(std::nullopt, dstElementType);</div>
<div class="line"><a id="l03788" name="l03788"></a><span class="lineno"> 3788</span> </div>
<div class="line"><a id="l03789" name="l03789"></a><span class="lineno"> 3789</span>    <span class="keywordflow">if</span> (isa&lt;IntegerType&gt;(srcElementType) &amp;&amp; isa&lt;FloatType&gt;(dstElementType)) {</div>
<div class="line"><a id="l03790" name="l03790"></a><span class="lineno"> 3790</span>      <span class="keywordflow">return</span> arith::SIToFPOp::create(rewriter, loc, dstType, val);</div>
<div class="line"><a id="l03791" name="l03791"></a><span class="lineno"> 3791</span>    }</div>
<div class="line"><a id="l03792" name="l03792"></a><span class="lineno"> 3792</span> </div>
<div class="line"><a id="l03793" name="l03793"></a><span class="lineno"> 3793</span>    <span class="keywordflow">if</span> (isa&lt;FloatType&gt;(srcElementType) &amp;&amp; isa&lt;FloatType&gt;(dstElementType) &amp;&amp;</div>
<div class="line"><a id="l03794" name="l03794"></a><span class="lineno"> 3794</span>        srcWidth &lt; dstWidth)</div>
<div class="line"><a id="l03795" name="l03795"></a><span class="lineno"> 3795</span>      <span class="keywordflow">return</span> arith::ExtFOp::create(rewriter, loc, dstType, val);</div>
<div class="line"><a id="l03796" name="l03796"></a><span class="lineno"> 3796</span> </div>
<div class="line"><a id="l03797" name="l03797"></a><span class="lineno"> 3797</span>    <span class="keywordflow">if</span> (isa&lt;IntegerType&gt;(srcElementType) &amp;&amp; isa&lt;IntegerType&gt;(dstElementType) &amp;&amp;</div>
<div class="line"><a id="l03798" name="l03798"></a><span class="lineno"> 3798</span>        srcWidth &lt; dstWidth)</div>
<div class="line"><a id="l03799" name="l03799"></a><span class="lineno"> 3799</span>      <span class="keywordflow">return</span> arith::ExtSIOp::create(rewriter, loc, dstType, val);</div>
<div class="line"><a id="l03800" name="l03800"></a><span class="lineno"> 3800</span> </div>
<div class="line"><a id="l03801" name="l03801"></a><span class="lineno"> 3801</span>    assert(<span class="keyword">false</span> &amp;&amp; <span class="stringliteral">&quot;unhandled promotion case&quot;</span>);</div>
<div class="line"><a id="l03802" name="l03802"></a><span class="lineno"> 3802</span>    <span class="keywordflow">return</span> <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l03803" name="l03803"></a><span class="lineno"> 3803</span>  }</div>
<div class="line"><a id="l03804" name="l03804"></a><span class="lineno"> 3804</span> </div>
<div class="line"><a id="l03805" name="l03805"></a><span class="lineno"> 3805</span>  <span class="comment">// Create a contraction: lhs{n, w, c} * rhs{c, f} -&gt; res{n, w, f}</span></div>
<div class="line"><a id="l03806" name="l03806"></a><span class="lineno"> 3806</span>  Value conv1dSliceAsContraction(RewriterBase &amp;rewriter, Location loc,</div>
<div class="line"><a id="l03807" name="l03807"></a><span class="lineno"> 3807</span>                                 Value <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, Value <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, Value res) {</div>
<div class="line"><a id="l03808" name="l03808"></a><span class="lineno"> 3808</span>    vector::IteratorType par = vector::IteratorType::parallel;</div>
<div class="line"><a id="l03809" name="l03809"></a><span class="lineno"> 3809</span>    vector::IteratorType red = vector::IteratorType::reduction;</div>
<div class="line"><a id="l03810" name="l03810"></a><span class="lineno"> 3810</span>    AffineExpr n, w, f, c;</div>
<div class="line"><a id="l03811" name="l03811"></a><span class="lineno"> 3811</span>    <a class="code hl_function" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, w, f, c);</div>
<div class="line"><a id="l03812" name="l03812"></a><span class="lineno"> 3812</span>    <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a> = <a class="code hl_function" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(rewriter, loc, <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, res.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a id="l03813" name="l03813"></a><span class="lineno"> 3813</span>    <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a> = <a class="code hl_function" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(rewriter, loc, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, res.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a id="l03814" name="l03814"></a><span class="lineno"> 3814</span>    <span class="keyword">auto</span> contrationOp = vector::ContractionOp::create(</div>
<div class="line"><a id="l03815" name="l03815"></a><span class="lineno"> 3815</span>        rewriter, loc, <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, res,</div>
<div class="line"><a id="l03816" name="l03816"></a><span class="lineno"> 3816</span>        <span class="comment">/*indexingMaps=*/</span>MapList{{n, w, c}, {c, f}, {n, w, f}},</div>
<div class="line"><a id="l03817" name="l03817"></a><span class="lineno"> 3817</span>        <span class="comment">/*iteratorTypes=*/</span>ArrayRef&lt;vector::IteratorType&gt;{par, par, par, red});</div>
<div class="line"><a id="l03818" name="l03818"></a><span class="lineno"> 3818</span>    contrationOp.setKind(reductionKind);</div>
<div class="line"><a id="l03819" name="l03819"></a><span class="lineno"> 3819</span>    <span class="keywordflow">return</span> contrationOp;</div>
<div class="line"><a id="l03820" name="l03820"></a><span class="lineno"> 3820</span>  }</div>
<div class="line"><a id="l03821" name="l03821"></a><span class="lineno"> 3821</span> </div>
<div class="line"><a id="l03822" name="l03822"></a><span class="lineno"> 3822</span>  <span class="comment">// Create an outerproduct: lhs{w} * rhs{1} -&gt; res{w} for single channel</span></div>
<div class="line"><a id="l03823" name="l03823"></a><span class="lineno"> 3823</span>  <span class="comment">// convolution.</span></div>
<div class="line"><a id="l03824" name="l03824"></a><span class="lineno"> 3824</span>  Value conv1dSliceAsOuterProduct(RewriterBase &amp;rewriter, Location loc,</div>
<div class="line"><a id="l03825" name="l03825"></a><span class="lineno"> 3825</span>                                  Value <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, Value <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, Value res) {</div>
<div class="line"><a id="l03826" name="l03826"></a><span class="lineno"> 3826</span>    <span class="keywordflow">return</span> vector::OuterProductOp::create(rewriter, loc, res.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>(), <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>,</div>
<div class="line"><a id="l03827" name="l03827"></a><span class="lineno"> 3827</span>                                          <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, res, vector::CombiningKind::ADD);</div>
<div class="line"><a id="l03828" name="l03828"></a><span class="lineno"> 3828</span>  }</div>
<div class="line"><a id="l03829" name="l03829"></a><span class="lineno"> 3829</span> </div>
<div class="line"><a id="l03830" name="l03830"></a><span class="lineno"> 3830</span>  <span class="comment">// Create a reduction: lhs{n, w, c} -&gt; res{n, w, c}</span></div>
<div class="line"><a id="l03831" name="l03831"></a><span class="lineno"> 3831</span>  Value pool1dSlice(RewriterBase &amp;rewriter, Location loc, Value <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>,</div>
<div class="line"><a id="l03832" name="l03832"></a><span class="lineno"> 3832</span>                    Value res) {</div>
<div class="line"><a id="l03833" name="l03833"></a><span class="lineno"> 3833</span>    <span class="keywordflow">if</span> (isPoolExt)</div>
<div class="line"><a id="l03834" name="l03834"></a><span class="lineno"> 3834</span>      <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a> = rewriter.<a class="code hl_function" href="classmlir_1_1OpBuilder.html#ac6a6edadd39800db410864ef06a004b2">create</a>(loc, poolExtOp, <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, res.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>())-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0);</div>
<div class="line"><a id="l03835" name="l03835"></a><span class="lineno"> 3835</span>    <span class="keywordflow">return</span> rewriter</div>
<div class="line"><a id="l03836" name="l03836"></a><span class="lineno"> 3836</span>        .<a class="code hl_function" href="classmlir_1_1OpBuilder.html#ac6a6edadd39800db410864ef06a004b2">create</a>(loc, redOp, ArrayRef&lt;Value&gt;{<a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, res}, res.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>())</div>
<div class="line"><a id="l03837" name="l03837"></a><span class="lineno"> 3837</span>        -&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0);</div>
<div class="line"><a id="l03838" name="l03838"></a><span class="lineno"> 3838</span>  }</div>
<div class="line"><a id="l03839" name="l03839"></a><span class="lineno"> 3839</span><span class="comment"></span> </div>
<div class="line"><a id="l03840" name="l03840"></a><span class="lineno"> 3840</span><span class="comment">  /// Generate a vector implementation for:</span></div>
<div class="line"><a id="l03841" name="l03841"></a><span class="lineno"> 3841</span><span class="comment">  /// ```</span></div>
<div class="line"><a id="l03842" name="l03842"></a><span class="lineno"> 3842</span><span class="comment">  ///   Op def: (     n,     w,     c,    kw)</span></div>
<div class="line"><a id="l03843" name="l03843"></a><span class="lineno"> 3843</span><span class="comment">  ///    Iters: ({Par(), Par(), Par(), Red()})</span></div>
<div class="line"><a id="l03844" name="l03844"></a><span class="lineno"> 3844</span><span class="comment">  ///   Layout: {{n, strideW * w + dilationW * kw, c}, {kw, c}, {n, w, c}}</span></div>
<div class="line"><a id="l03845" name="l03845"></a><span class="lineno"> 3845</span><span class="comment">  /// ```</span></div>
<div class="line"><a id="l03846" name="l03846"></a><span class="lineno"> 3846</span><span class="comment">  /// kw is always unrolled.</span></div>
<div class="line"><a id="l03847" name="l03847"></a><span class="lineno"> 3847</span><span class="comment">  /// TODO: w (resp. kw) is unrolled when the strideW ( resp. dilationW) is</span></div>
<div class="line"><a id="l03848" name="l03848"></a><span class="lineno"> 3848</span><span class="comment">  /// &gt; 1.</span></div>
<div class="line"><a id="l03849" name="l03849"></a><span class="lineno"> 3849</span>  FailureOr&lt;Operation *&gt; depthwiseConv(uint64_t channelDimVecSize,</div>
<div class="line"><a id="l03850" name="l03850"></a><span class="lineno"> 3850</span>                                       <span class="keywordtype">bool</span> channelDimScalableFlag,</div>
<div class="line"><a id="l03851" name="l03851"></a><span class="lineno"> 3851</span>                                       <span class="keywordtype">bool</span> flatten) {</div>
<div class="line"><a id="l03852" name="l03852"></a><span class="lineno"> 3852</span>    <span class="keywordtype">bool</span> scalableChDim = <span class="keyword">false</span>;</div>
<div class="line"><a id="l03853" name="l03853"></a><span class="lineno"> 3853</span>    <span class="keywordtype">bool</span> useMasking = <span class="keyword">false</span>;</div>
<div class="line"><a id="l03854" name="l03854"></a><span class="lineno"> 3854</span>    int64_t nSize, wSize, cSize, kwSize;</div>
<div class="line"><a id="l03855" name="l03855"></a><span class="lineno"> 3855</span>    <span class="comment">// kernel{kw, c}</span></div>
<div class="line"><a id="l03856" name="l03856"></a><span class="lineno"> 3856</span>    bindShapeDims(rhsShapedType, kwSize, cSize);</div>
<div class="line"><a id="l03857" name="l03857"></a><span class="lineno"> 3857</span>    <span class="keywordflow">if</span> (ShapedType::isDynamic(cSize)) {</div>
<div class="line"><a id="l03858" name="l03858"></a><span class="lineno"> 3858</span>      assert(channelDimVecSize != 0 &amp;&amp; <span class="stringliteral">&quot;Channel dim vec size must be &gt; 0&quot;</span>);</div>
<div class="line"><a id="l03859" name="l03859"></a><span class="lineno"> 3859</span>      cSize = channelDimVecSize;</div>
<div class="line"><a id="l03860" name="l03860"></a><span class="lineno"> 3860</span>      <span class="comment">// Scalable vectors are only used when both conditions are met:</span></div>
<div class="line"><a id="l03861" name="l03861"></a><span class="lineno"> 3861</span>      <span class="comment">//  1. channel dim is dynamic</span></div>
<div class="line"><a id="l03862" name="l03862"></a><span class="lineno"> 3862</span>      <span class="comment">//  2. channelDimScalableFlag is set</span></div>
<div class="line"><a id="l03863" name="l03863"></a><span class="lineno"> 3863</span>      scalableChDim = channelDimScalableFlag;</div>
<div class="line"><a id="l03864" name="l03864"></a><span class="lineno"> 3864</span>      useMasking = <span class="keyword">true</span>;</div>
<div class="line"><a id="l03865" name="l03865"></a><span class="lineno"> 3865</span>    }</div>
<div class="line"><a id="l03866" name="l03866"></a><span class="lineno"> 3866</span> </div>
<div class="line"><a id="l03867" name="l03867"></a><span class="lineno"> 3867</span>    assert(!(useMasking &amp;&amp; flatten) &amp;&amp;</div>
<div class="line"><a id="l03868" name="l03868"></a><span class="lineno"> 3868</span>           <span class="stringliteral">&quot;Unsupported flattened conv with dynamic shapes&quot;</span>);</div>
<div class="line"><a id="l03869" name="l03869"></a><span class="lineno"> 3869</span> </div>
<div class="line"><a id="l03870" name="l03870"></a><span class="lineno"> 3870</span>    <span class="comment">// out{n, w, c}</span></div>
<div class="line"><a id="l03871" name="l03871"></a><span class="lineno"> 3871</span>    bindShapeDims(resShapedType, nSize, wSize);</div>
<div class="line"><a id="l03872" name="l03872"></a><span class="lineno"> 3872</span> </div>
<div class="line"><a id="l03873" name="l03873"></a><span class="lineno"> 3873</span>    vector::TransferWriteOp write;</div>
<div class="line"><a id="l03874" name="l03874"></a><span class="lineno"> 3874</span>    Value zero = <a class="code hl_function" href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">arith::ConstantIndexOp::create</a>(rewriter, loc, 0);</div>
<div class="line"><a id="l03875" name="l03875"></a><span class="lineno"> 3875</span> </div>
<div class="line"><a id="l03876" name="l03876"></a><span class="lineno"> 3876</span>    <span class="comment">// w is unrolled (i.e. wSizeStep == 1) iff strideW &gt; 1.</span></div>
<div class="line"><a id="l03877" name="l03877"></a><span class="lineno"> 3877</span>    <span class="comment">// When strideW == 1, we can batch the contiguous loads and avoid</span></div>
<div class="line"><a id="l03878" name="l03878"></a><span class="lineno"> 3878</span>    <span class="comment">// unrolling</span></div>
<div class="line"><a id="l03879" name="l03879"></a><span class="lineno"> 3879</span>    int64_t wSizeStep = strideW == 1 ? wSize : 1;</div>
<div class="line"><a id="l03880" name="l03880"></a><span class="lineno"> 3880</span> </div>
<div class="line"><a id="l03881" name="l03881"></a><span class="lineno"> 3881</span>    Type lhsEltType = lhsShapedType.getElementType();</div>
<div class="line"><a id="l03882" name="l03882"></a><span class="lineno"> 3882</span>    Type rhsEltType = rhsShapedType.getElementType();</div>
<div class="line"><a id="l03883" name="l03883"></a><span class="lineno"> 3883</span>    Type resEltType = resShapedType.getElementType();</div>
<div class="line"><a id="l03884" name="l03884"></a><span class="lineno"> 3884</span>    VectorType lhsType = VectorType::get(</div>
<div class="line"><a id="l03885" name="l03885"></a><span class="lineno"> 3885</span>        {nSize,</div>
<div class="line"><a id="l03886" name="l03886"></a><span class="lineno"> 3886</span>         <span class="comment">// iw = ow * sw + kw *  dw - 1</span></div>
<div class="line"><a id="l03887" name="l03887"></a><span class="lineno"> 3887</span>         <span class="comment">//   (i.e. 16 convolved with 3 (@stride 1 dilation 1) -&gt; 14)</span></div>
<div class="line"><a id="l03888" name="l03888"></a><span class="lineno"> 3888</span>         ((wSize - 1) * strideW + 1) + ((kwSize - 1) * dilationW + 1) - 1,</div>
<div class="line"><a id="l03889" name="l03889"></a><span class="lineno"> 3889</span>         cSize},</div>
<div class="line"><a id="l03890" name="l03890"></a><span class="lineno"> 3890</span>        lhsEltType, <span class="comment">/*scalableDims=*/</span>{<span class="keyword">false</span>, <span class="keyword">false</span>, scalableChDim});</div>
<div class="line"><a id="l03891" name="l03891"></a><span class="lineno"> 3891</span>    VectorType rhsType =</div>
<div class="line"><a id="l03892" name="l03892"></a><span class="lineno"> 3892</span>        VectorType::get({kwSize, cSize}, rhsEltType,</div>
<div class="line"><a id="l03893" name="l03893"></a><span class="lineno"> 3893</span>                        <span class="comment">/*scalableDims=*/</span>{<span class="keyword">false</span>, scalableChDim});</div>
<div class="line"><a id="l03894" name="l03894"></a><span class="lineno"> 3894</span>    VectorType resType =</div>
<div class="line"><a id="l03895" name="l03895"></a><span class="lineno"> 3895</span>        VectorType::get({nSize, wSize, cSize}, resEltType,</div>
<div class="line"><a id="l03896" name="l03896"></a><span class="lineno"> 3896</span>                        <span class="comment">/*scalableDims=*/</span>{<span class="keyword">false</span>, <span class="keyword">false</span>, scalableChDim});</div>
<div class="line"><a id="l03897" name="l03897"></a><span class="lineno"> 3897</span> </div>
<div class="line"><a id="l03898" name="l03898"></a><span class="lineno"> 3898</span>    <span class="comment">// Masks the input xfer Op along the channel dim, iff the corresponding</span></div>
<div class="line"><a id="l03899" name="l03899"></a><span class="lineno"> 3899</span>    <span class="comment">// scalable flag is set.</span></div>
<div class="line"><a id="l03900" name="l03900"></a><span class="lineno"> 3900</span>    <span class="keyword">auto</span> maybeMaskXferOp = [&amp;](ArrayRef&lt;int64_t&gt; maskShape,</div>
<div class="line"><a id="l03901" name="l03901"></a><span class="lineno"> 3901</span>                               ArrayRef&lt;bool&gt; scalableDims,</div>
<div class="line"><a id="l03902" name="l03902"></a><span class="lineno"> 3902</span>                               Operation *opToMask) {</div>
<div class="line"><a id="l03903" name="l03903"></a><span class="lineno"> 3903</span>      <span class="keywordflow">if</span> (!useMasking)</div>
<div class="line"><a id="l03904" name="l03904"></a><span class="lineno"> 3904</span>        <span class="keywordflow">return</span> opToMask;</div>
<div class="line"><a id="l03905" name="l03905"></a><span class="lineno"> 3905</span>      <span class="keyword">auto</span> maskType =</div>
<div class="line"><a id="l03906" name="l03906"></a><span class="lineno"> 3906</span>          VectorType::get(maskShape, rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">getI1Type</a>(), scalableDims);</div>
<div class="line"><a id="l03907" name="l03907"></a><span class="lineno"> 3907</span> </div>
<div class="line"><a id="l03908" name="l03908"></a><span class="lineno"> 3908</span>      SmallVector&lt;bool&gt; inBounds(maskShape.size(), <span class="keyword">true</span>);</div>
<div class="line"><a id="l03909" name="l03909"></a><span class="lineno"> 3909</span>      <span class="keyword">auto</span> xferOp = cast&lt;VectorTransferOpInterface&gt;(opToMask);</div>
<div class="line"><a id="l03910" name="l03910"></a><span class="lineno"> 3910</span>      xferOp-&gt;setAttr(xferOp.getInBoundsAttrName(),</div>
<div class="line"><a id="l03911" name="l03911"></a><span class="lineno"> 3911</span>                      rewriter.<a class="code hl_function" href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">getBoolArrayAttr</a>(inBounds));</div>
<div class="line"><a id="l03912" name="l03912"></a><span class="lineno"> 3912</span> </div>
<div class="line"><a id="l03913" name="l03913"></a><span class="lineno"> 3913</span>      SmallVector&lt;OpFoldResult&gt; mixedDims = <a class="code hl_function" href="namespacemlir_1_1vector.html#ad910c130857e946d9d30b58ffb708f3a">vector::getMixedSizesXfer</a>(</div>
<div class="line"><a id="l03914" name="l03914"></a><span class="lineno"> 3914</span>          cast&lt;LinalgOp&gt;(op).hasPureTensorSemantics(), opToMask, rewriter);</div>
<div class="line"><a id="l03915" name="l03915"></a><span class="lineno"> 3915</span> </div>
<div class="line"><a id="l03916" name="l03916"></a><span class="lineno"> 3916</span>      Value maskOp =</div>
<div class="line"><a id="l03917" name="l03917"></a><span class="lineno"> 3917</span>          vector::CreateMaskOp::create(rewriter, loc, maskType, mixedDims);</div>
<div class="line"><a id="l03918" name="l03918"></a><span class="lineno"> 3918</span> </div>
<div class="line"><a id="l03919" name="l03919"></a><span class="lineno"> 3919</span>      <span class="keywordflow">return</span> <a class="code hl_function" href="namespacemlir_1_1vector.html#a21bfcee9196fe1a2cfa548b7df8193a9">mlir::vector::maskOperation</a>(rewriter, opToMask, maskOp);</div>
<div class="line"><a id="l03920" name="l03920"></a><span class="lineno"> 3920</span>    };</div>
<div class="line"><a id="l03921" name="l03921"></a><span class="lineno"> 3921</span> </div>
<div class="line"><a id="l03922" name="l03922"></a><span class="lineno"> 3922</span>    <span class="comment">// Read lhs slice of size {n, w * strideW + kw * dilationW, c} @ [0, 0,</span></div>
<div class="line"><a id="l03923" name="l03923"></a><span class="lineno"> 3923</span>    <span class="comment">// 0].</span></div>
<div class="line"><a id="l03924" name="l03924"></a><span class="lineno"> 3924</span>    Value <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a> = vector::TransferReadOp::create(</div>
<div class="line"><a id="l03925" name="l03925"></a><span class="lineno"> 3925</span>        rewriter, loc, lhsType, lhsShaped, <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a4fa832087ed6d7798c173648e7541e60">ValueRange</a>{zero, zero, zero},</div>
<div class="line"><a id="l03926" name="l03926"></a><span class="lineno"> 3926</span>        <span class="comment">/*padding=*/</span>arith::getZeroConstant(rewriter, loc, lhsEltType));</div>
<div class="line"><a id="l03927" name="l03927"></a><span class="lineno"> 3927</span>    <span class="keyword">auto</span> *maybeMaskedLhs = maybeMaskXferOp(</div>
<div class="line"><a id="l03928" name="l03928"></a><span class="lineno"> 3928</span>        lhsType.getShape(), lhsType.getScalableDims(), <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>.getDefiningOp());</div>
<div class="line"><a id="l03929" name="l03929"></a><span class="lineno"> 3929</span> </div>
<div class="line"><a id="l03930" name="l03930"></a><span class="lineno"> 3930</span>    <span class="comment">// Read rhs slice of size {kw, c} @ [0, 0].</span></div>
<div class="line"><a id="l03931" name="l03931"></a><span class="lineno"> 3931</span>    Value <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a> = vector::TransferReadOp::create(</div>
<div class="line"><a id="l03932" name="l03932"></a><span class="lineno"> 3932</span>        rewriter, loc, rhsType, rhsShaped, <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a4fa832087ed6d7798c173648e7541e60">ValueRange</a>{zero, zero},</div>
<div class="line"><a id="l03933" name="l03933"></a><span class="lineno"> 3933</span>        <span class="comment">/*padding=*/</span>arith::getZeroConstant(rewriter, loc, rhsEltType));</div>
<div class="line"><a id="l03934" name="l03934"></a><span class="lineno"> 3934</span>    <span class="keyword">auto</span> *maybeMaskedRhs = maybeMaskXferOp(</div>
<div class="line"><a id="l03935" name="l03935"></a><span class="lineno"> 3935</span>        rhsType.getShape(), rhsType.getScalableDims(), <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>.getDefiningOp());</div>
<div class="line"><a id="l03936" name="l03936"></a><span class="lineno"> 3936</span> </div>
<div class="line"><a id="l03937" name="l03937"></a><span class="lineno"> 3937</span>    <span class="comment">// Read res slice of size {n, w, c} @ [0, 0, 0].</span></div>
<div class="line"><a id="l03938" name="l03938"></a><span class="lineno"> 3938</span>    Value res = vector::TransferReadOp::create(</div>
<div class="line"><a id="l03939" name="l03939"></a><span class="lineno"> 3939</span>        rewriter, loc, resType, resShaped, <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a4fa832087ed6d7798c173648e7541e60">ValueRange</a>{zero, zero, zero},</div>
<div class="line"><a id="l03940" name="l03940"></a><span class="lineno"> 3940</span>        <span class="comment">/*padding=*/</span>arith::getZeroConstant(rewriter, loc, resEltType));</div>
<div class="line"><a id="l03941" name="l03941"></a><span class="lineno"> 3941</span>    <span class="keyword">auto</span> *maybeMaskedRes = maybeMaskXferOp(</div>
<div class="line"><a id="l03942" name="l03942"></a><span class="lineno"> 3942</span>        resType.getShape(), resType.getScalableDims(), res.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>());</div>
<div class="line"><a id="l03943" name="l03943"></a><span class="lineno"> 3943</span> </div>
<div class="line"><a id="l03944" name="l03944"></a><span class="lineno"> 3944</span>    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l03945" name="l03945"></a><span class="lineno"> 3945</span>    <span class="comment">// Begin vector-only rewrite part</span></div>
<div class="line"><a id="l03946" name="l03946"></a><span class="lineno"> 3946</span>    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l03947" name="l03947"></a><span class="lineno"> 3947</span>    <span class="comment">// Unroll along kw and read slices of lhs and rhs.</span></div>
<div class="line"><a id="l03948" name="l03948"></a><span class="lineno"> 3948</span>    SmallVector&lt;Value&gt; lhsVals, rhsVals, resVals;</div>
<div class="line"><a id="l03949" name="l03949"></a><span class="lineno"> 3949</span>    SmallVector&lt;int64_t&gt; inOutSliceSizes = {nSize, wSizeStep, cSize};</div>
<div class="line"><a id="l03950" name="l03950"></a><span class="lineno"> 3950</span>    SmallVector&lt;int64_t&gt; inOutStrides = {1, 1, 1};</div>
<div class="line"><a id="l03951" name="l03951"></a><span class="lineno"> 3951</span> </div>
<div class="line"><a id="l03952" name="l03952"></a><span class="lineno"> 3952</span>    <span class="comment">// Extract lhs slice of size {n, wSizeStep, c}</span></div>
<div class="line"><a id="l03953" name="l03953"></a><span class="lineno"> 3953</span>    <span class="comment">//   @ [0, sw * w + dw * kw, 0].</span></div>
<div class="line"><a id="l03954" name="l03954"></a><span class="lineno"> 3954</span>    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a id="l03955" name="l03955"></a><span class="lineno"> 3955</span>      <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l03956" name="l03956"></a><span class="lineno"> 3956</span>        lhsVals.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a id="l03957" name="l03957"></a><span class="lineno"> 3957</span>            rewriter, loc, maybeMaskedLhs-&gt;getResult(0),</div>
<div class="line"><a id="l03958" name="l03958"></a><span class="lineno"> 3958</span>            <span class="comment">/*offsets=*/</span>ArrayRef&lt;int64_t&gt;{0, w * strideW + kw * dilationW, 0},</div>
<div class="line"><a id="l03959" name="l03959"></a><span class="lineno"> 3959</span>            inOutSliceSizes, inOutStrides));</div>
<div class="line"><a id="l03960" name="l03960"></a><span class="lineno"> 3960</span>      }</div>
<div class="line"><a id="l03961" name="l03961"></a><span class="lineno"> 3961</span>    }</div>
<div class="line"><a id="l03962" name="l03962"></a><span class="lineno"> 3962</span>    <span class="comment">// Extract rhs slice of size {c} @ [kw].</span></div>
<div class="line"><a id="l03963" name="l03963"></a><span class="lineno"> 3963</span>    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a id="l03964" name="l03964"></a><span class="lineno"> 3964</span>      rhsVals.push_back(</div>
<div class="line"><a id="l03965" name="l03965"></a><span class="lineno"> 3965</span>          vector::ExtractOp::create(rewriter, loc, maybeMaskedRhs-&gt;getResult(0),</div>
<div class="line"><a id="l03966" name="l03966"></a><span class="lineno"> 3966</span>                                    <span class="comment">/*offsets=*/</span>ArrayRef&lt;int64_t&gt;{kw}));</div>
<div class="line"><a id="l03967" name="l03967"></a><span class="lineno"> 3967</span>    }</div>
<div class="line"><a id="l03968" name="l03968"></a><span class="lineno"> 3968</span>    <span class="comment">// Extract res slice: {n, wSizeStep, c} @ [0, w, 0].</span></div>
<div class="line"><a id="l03969" name="l03969"></a><span class="lineno"> 3969</span>    <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l03970" name="l03970"></a><span class="lineno"> 3970</span>      resVals.push_back(vector::ExtractStridedSliceOp::create(</div>
<div class="line"><a id="l03971" name="l03971"></a><span class="lineno"> 3971</span>          rewriter, loc, maybeMaskedRes-&gt;getResult(0),</div>
<div class="line"><a id="l03972" name="l03972"></a><span class="lineno"> 3972</span>          <span class="comment">/*offsets=*/</span>ArrayRef&lt;int64_t&gt;{0, w, 0}, inOutSliceSizes,</div>
<div class="line"><a id="l03973" name="l03973"></a><span class="lineno"> 3973</span>          inOutStrides));</div>
<div class="line"><a id="l03974" name="l03974"></a><span class="lineno"> 3974</span>    }</div>
<div class="line"><a id="l03975" name="l03975"></a><span class="lineno"> 3975</span> </div>
<div class="line"><a id="l03976" name="l03976"></a><span class="lineno"> 3976</span>    <span class="keyword">auto</span> linearIndex = [&amp;](int64_t kw, int64_t w) {</div>
<div class="line"><a id="l03977" name="l03977"></a><span class="lineno"> 3977</span>      <span class="keywordflow">return</span> kw * (wSize / wSizeStep) + w;</div>
<div class="line"><a id="l03978" name="l03978"></a><span class="lineno"> 3978</span>    };</div>
<div class="line"><a id="l03979" name="l03979"></a><span class="lineno"> 3979</span> </div>
<div class="line"><a id="l03980" name="l03980"></a><span class="lineno"> 3980</span>    <span class="comment">// Note - the scalable flags are ignored as flattening combined with</span></div>
<div class="line"><a id="l03981" name="l03981"></a><span class="lineno"> 3981</span>    <span class="comment">// scalable vectorization is not supported.</span></div>
<div class="line"><a id="l03982" name="l03982"></a><span class="lineno"> 3982</span>    SmallVector&lt;int64_t&gt; inOutFlattenSliceSizes = {nSize, wSizeStep * cSize};</div>
<div class="line"><a id="l03983" name="l03983"></a><span class="lineno"> 3983</span>    <span class="keyword">auto</span> lhsTypeAfterFlattening =</div>
<div class="line"><a id="l03984" name="l03984"></a><span class="lineno"> 3984</span>        VectorType::get(inOutFlattenSliceSizes, lhsEltType);</div>
<div class="line"><a id="l03985" name="l03985"></a><span class="lineno"> 3985</span>    <span class="keyword">auto</span> resTypeAfterFlattening =</div>
<div class="line"><a id="l03986" name="l03986"></a><span class="lineno"> 3986</span>        VectorType::get(inOutFlattenSliceSizes, resEltType);</div>
<div class="line"><a id="l03987" name="l03987"></a><span class="lineno"> 3987</span> </div>
<div class="line"><a id="l03988" name="l03988"></a><span class="lineno"> 3988</span>    <span class="comment">// Compute contraction: O{n, w, c} += I{n, sw * w + dw * kw, c} * F{c}</span></div>
<div class="line"><a id="l03989" name="l03989"></a><span class="lineno"> 3989</span>    <span class="keywordflow">for</span> (int64_t kw = 0; kw &lt; kwSize; ++kw) {</div>
<div class="line"><a id="l03990" name="l03990"></a><span class="lineno"> 3990</span>      <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l03991" name="l03991"></a><span class="lineno"> 3991</span>        Value lhsVal = lhsVals[linearIndex(kw, w)];</div>
<div class="line"><a id="l03992" name="l03992"></a><span class="lineno"> 3992</span>        Value resVal = resVals[w];</div>
<div class="line"><a id="l03993" name="l03993"></a><span class="lineno"> 3993</span>        <span class="keywordflow">if</span> (flatten) {</div>
<div class="line"><a id="l03994" name="l03994"></a><span class="lineno"> 3994</span>          <span class="comment">// Flatten the input and output vectors (collapse the channel</span></div>
<div class="line"><a id="l03995" name="l03995"></a><span class="lineno"> 3995</span>          <span class="comment">// dimension)</span></div>
<div class="line"><a id="l03996" name="l03996"></a><span class="lineno"> 3996</span>          lhsVal =</div>
<div class="line"><a id="l03997" name="l03997"></a><span class="lineno"> 3997</span>              vector::ShapeCastOp::create(rewriter, loc, lhsTypeAfterFlattening,</div>
<div class="line"><a id="l03998" name="l03998"></a><span class="lineno"> 3998</span>                                          lhsVals[linearIndex(kw, w)]);</div>
<div class="line"><a id="l03999" name="l03999"></a><span class="lineno"> 3999</span>          resVal = vector::ShapeCastOp::create(</div>
<div class="line"><a id="l04000" name="l04000"></a><span class="lineno"> 4000</span>              rewriter, loc, resTypeAfterFlattening, resVals[w]);</div>
<div class="line"><a id="l04001" name="l04001"></a><span class="lineno"> 4001</span>        }</div>
<div class="line"><a id="l04002" name="l04002"></a><span class="lineno"> 4002</span>        resVals[w] = depthwiseConv1dSliceAsMulAcc(rewriter, loc, lhsVal,</div>
<div class="line"><a id="l04003" name="l04003"></a><span class="lineno"> 4003</span>                                                  rhsVals[kw], resVal, flatten);</div>
<div class="line"><a id="l04004" name="l04004"></a><span class="lineno"> 4004</span>        <span class="keywordflow">if</span> (flatten) {</div>
<div class="line"><a id="l04005" name="l04005"></a><span class="lineno"> 4005</span>          <span class="comment">// Un-flatten the output vector (restore the channel dimension)</span></div>
<div class="line"><a id="l04006" name="l04006"></a><span class="lineno"> 4006</span>          resVals[w] = vector::ShapeCastOp::create(</div>
<div class="line"><a id="l04007" name="l04007"></a><span class="lineno"> 4007</span>              rewriter, loc, VectorType::get(inOutSliceSizes, resEltType),</div>
<div class="line"><a id="l04008" name="l04008"></a><span class="lineno"> 4008</span>              resVals[w]);</div>
<div class="line"><a id="l04009" name="l04009"></a><span class="lineno"> 4009</span>        }</div>
<div class="line"><a id="l04010" name="l04010"></a><span class="lineno"> 4010</span>      }</div>
<div class="line"><a id="l04011" name="l04011"></a><span class="lineno"> 4011</span>    }</div>
<div class="line"><a id="l04012" name="l04012"></a><span class="lineno"> 4012</span> </div>
<div class="line"><a id="l04013" name="l04013"></a><span class="lineno"> 4013</span>    <span class="comment">// Its possible we failed to create the Fma.</span></div>
<div class="line"><a id="l04014" name="l04014"></a><span class="lineno"> 4014</span>    <span class="keywordflow">if</span> (!llvm::all_of(resVals, [](Value v) { <span class="keywordflow">return</span> v; })) {</div>
<div class="line"><a id="l04015" name="l04015"></a><span class="lineno"> 4015</span>      <span class="comment">// Manually revert (in reverse order) to avoid leaving a bad IR state.</span></div>
<div class="line"><a id="l04016" name="l04016"></a><span class="lineno"> 4016</span>      <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;collection :</div>
<div class="line"><a id="l04017" name="l04017"></a><span class="lineno"> 4017</span>           {resVals, rhsVals, lhsVals, {res, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, zero}})</div>
<div class="line"><a id="l04018" name="l04018"></a><span class="lineno"> 4018</span>        <span class="keywordflow">for</span> (Value v : collection)</div>
<div class="line"><a id="l04019" name="l04019"></a><span class="lineno"> 4019</span>          rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(v.<a class="code hl_function" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>());</div>
<div class="line"><a id="l04020" name="l04020"></a><span class="lineno"> 4020</span>      <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;failed to create FMA&quot;</span>);</div>
<div class="line"><a id="l04021" name="l04021"></a><span class="lineno"> 4021</span>    }</div>
<div class="line"><a id="l04022" name="l04022"></a><span class="lineno"> 4022</span> </div>
<div class="line"><a id="l04023" name="l04023"></a><span class="lineno"> 4023</span>    <span class="comment">// Write back res slice: {n, wSizeStep, c} @ [0, w, 0].</span></div>
<div class="line"><a id="l04024" name="l04024"></a><span class="lineno"> 4024</span>    <span class="comment">// This does not depend on kw.</span></div>
<div class="line"><a id="l04025" name="l04025"></a><span class="lineno"> 4025</span>    <span class="keywordflow">for</span> (int64_t w = 0; w &lt; wSize; w += wSizeStep) {</div>
<div class="line"><a id="l04026" name="l04026"></a><span class="lineno"> 4026</span>      maybeMaskedRes = vector::InsertStridedSliceOp::create(</div>
<div class="line"><a id="l04027" name="l04027"></a><span class="lineno"> 4027</span>          rewriter, loc, resVals[w], maybeMaskedRes-&gt;getResult(0),</div>
<div class="line"><a id="l04028" name="l04028"></a><span class="lineno"> 4028</span>          <span class="comment">/*offsets=*/</span>ArrayRef&lt;int64_t&gt;{0, w, 0},</div>
<div class="line"><a id="l04029" name="l04029"></a><span class="lineno"> 4029</span>          <span class="comment">/*strides=*/</span>ArrayRef&lt;int64_t&gt;{1, 1, 1});</div>
<div class="line"><a id="l04030" name="l04030"></a><span class="lineno"> 4030</span>    }</div>
<div class="line"><a id="l04031" name="l04031"></a><span class="lineno"> 4031</span>    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l04032" name="l04032"></a><span class="lineno"> 4032</span>    <span class="comment">// End vector-only rewrite part</span></div>
<div class="line"><a id="l04033" name="l04033"></a><span class="lineno"> 4033</span>    <span class="comment">//===------------------------------------------------------------------===//</span></div>
<div class="line"><a id="l04034" name="l04034"></a><span class="lineno"> 4034</span> </div>
<div class="line"><a id="l04035" name="l04035"></a><span class="lineno"> 4035</span>    <span class="comment">// Write back res slice of size {n, w, c} @ [0, 0, 0].</span></div>
<div class="line"><a id="l04036" name="l04036"></a><span class="lineno"> 4036</span>    Operation *resOut = vector::TransferWriteOp::create(</div>
<div class="line"><a id="l04037" name="l04037"></a><span class="lineno"> 4037</span>        rewriter, loc, maybeMaskedRes-&gt;getResult(0), resShaped,</div>
<div class="line"><a id="l04038" name="l04038"></a><span class="lineno"> 4038</span>        <a class="code hl_variable" href="LinalgTransformOps_8cpp.html#a4fa832087ed6d7798c173648e7541e60">ValueRange</a>{zero, zero, zero});</div>
<div class="line"><a id="l04039" name="l04039"></a><span class="lineno"> 4039</span>    <span class="keywordflow">return</span> maybeMaskXferOp(resType.getShape(), resType.getScalableDims(),</div>
<div class="line"><a id="l04040" name="l04040"></a><span class="lineno"> 4040</span>                           resOut);</div>
<div class="line"><a id="l04041" name="l04041"></a><span class="lineno"> 4041</span>  }</div>
<div class="line"><a id="l04042" name="l04042"></a><span class="lineno"> 4042</span><span class="comment"></span> </div>
<div class="line"><a id="l04043" name="l04043"></a><span class="lineno"> 4043</span><span class="comment">  /// Lower:</span></div>
<div class="line"><a id="l04044" name="l04044"></a><span class="lineno"> 4044</span><span class="comment">  ///   *  lhs{n, w, c} * rhs{c} -&gt; res{n, w, c} (flatten = false)</span></div>
<div class="line"><a id="l04045" name="l04045"></a><span class="lineno"> 4045</span><span class="comment">  ///   *  lhs{n, w * c} * rhs{c} -&gt; res{n, w * c} (flatten = true)</span></div>
<div class="line"><a id="l04046" name="l04046"></a><span class="lineno"> 4046</span><span class="comment">  /// to MulAcc.</span></div>
<div class="line"><a id="l04047" name="l04047"></a><span class="lineno"> 4047</span>  Value depthwiseConv1dSliceAsMulAcc(RewriterBase &amp;rewriter, Location loc,</div>
<div class="line"><a id="l04048" name="l04048"></a><span class="lineno"> 4048</span>                                     Value <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, Value <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, Value res,</div>
<div class="line"><a id="l04049" name="l04049"></a><span class="lineno"> 4049</span>                                     <span class="keywordtype">bool</span> flatten) {</div>
<div class="line"><a id="l04050" name="l04050"></a><span class="lineno"> 4050</span>    <span class="keyword">auto</span> rhsTy = cast&lt;ShapedType&gt;(<a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>.getType());</div>
<div class="line"><a id="l04051" name="l04051"></a><span class="lineno"> 4051</span>    <span class="keyword">auto</span> resTy = cast&lt;ShapedType&gt;(res.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>());</div>
<div class="line"><a id="l04052" name="l04052"></a><span class="lineno"> 4052</span> </div>
<div class="line"><a id="l04053" name="l04053"></a><span class="lineno"> 4053</span>    <span class="comment">// TODO(suderman): Change this to use a vector.ima intrinsic.</span></div>
<div class="line"><a id="l04054" name="l04054"></a><span class="lineno"> 4054</span>    <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a> = <a class="code hl_function" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(rewriter, loc, <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, resTy);</div>
<div class="line"><a id="l04055" name="l04055"></a><span class="lineno"> 4055</span> </div>
<div class="line"><a id="l04056" name="l04056"></a><span class="lineno"> 4056</span>    <span class="keywordflow">if</span> (flatten) {</div>
<div class="line"><a id="l04057" name="l04057"></a><span class="lineno"> 4057</span>      <span class="comment">// NOTE: This following logic won&#39;t work for scalable vectors. For this</span></div>
<div class="line"><a id="l04058" name="l04058"></a><span class="lineno"> 4058</span>      <span class="comment">// reason, &quot;flattening&quot; is not supported when shapes are dynamic (this</span></div>
<div class="line"><a id="l04059" name="l04059"></a><span class="lineno"> 4059</span>      <span class="comment">// should be captured by one of the pre-conditions).</span></div>
<div class="line"><a id="l04060" name="l04060"></a><span class="lineno"> 4060</span> </div>
<div class="line"><a id="l04061" name="l04061"></a><span class="lineno"> 4061</span>      <span class="comment">// There are two options for handling the filter:</span></div>
<div class="line"><a id="l04062" name="l04062"></a><span class="lineno"> 4062</span>      <span class="comment">//  * shape_cast(broadcast(filter))</span></div>
<div class="line"><a id="l04063" name="l04063"></a><span class="lineno"> 4063</span>      <span class="comment">//  * broadcast(shuffle(filter))</span></div>
<div class="line"><a id="l04064" name="l04064"></a><span class="lineno"> 4064</span>      <span class="comment">// Opt for the option without shape_cast to simplify the codegen.</span></div>
<div class="line"><a id="l04065" name="l04065"></a><span class="lineno"> 4065</span>      <span class="keyword">auto</span> rhsSize = cast&lt;VectorType&gt;(<a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>.getType()).getShape()[0];</div>
<div class="line"><a id="l04066" name="l04066"></a><span class="lineno"> 4066</span>      <span class="keyword">auto</span> resSize = cast&lt;VectorType&gt;(res.<a class="code hl_function" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>()).getShape()[1];</div>
<div class="line"><a id="l04067" name="l04067"></a><span class="lineno"> 4067</span> </div>
<div class="line"><a id="l04068" name="l04068"></a><span class="lineno"> 4068</span>      SmallVector&lt;int64_t, 16&gt; <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>;</div>
<div class="line"><a id="l04069" name="l04069"></a><span class="lineno"> 4069</span>      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; resSize / rhsSize; ++i) {</div>
<div class="line"><a id="l04070" name="l04070"></a><span class="lineno"> 4070</span>        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; rhsSize; ++j)</div>
<div class="line"><a id="l04071" name="l04071"></a><span class="lineno"> 4071</span>          <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>.push_back(j);</div>
<div class="line"><a id="l04072" name="l04072"></a><span class="lineno"> 4072</span>      }</div>
<div class="line"><a id="l04073" name="l04073"></a><span class="lineno"> 4073</span> </div>
<div class="line"><a id="l04074" name="l04074"></a><span class="lineno"> 4074</span>      <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a> = vector::ShuffleOp::create(rewriter, loc, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, <a class="code hl_variable" href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a>);</div>
<div class="line"><a id="l04075" name="l04075"></a><span class="lineno"> 4075</span>    }</div>
<div class="line"><a id="l04076" name="l04076"></a><span class="lineno"> 4076</span>    <span class="comment">// Broadcast the filter to match the output vector</span></div>
<div class="line"><a id="l04077" name="l04077"></a><span class="lineno"> 4077</span>    <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a> = vector::BroadcastOp::create(rewriter, loc,</div>
<div class="line"><a id="l04078" name="l04078"></a><span class="lineno"> 4078</span>                                      resTy.clone(rhsTy.getElementType()), <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>);</div>
<div class="line"><a id="l04079" name="l04079"></a><span class="lineno"> 4079</span> </div>
<div class="line"><a id="l04080" name="l04080"></a><span class="lineno"> 4080</span>    <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a> = <a class="code hl_function" href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">promote</a>(rewriter, loc, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, resTy);</div>
<div class="line"><a id="l04081" name="l04081"></a><span class="lineno"> 4081</span> </div>
<div class="line"><a id="l04082" name="l04082"></a><span class="lineno"> 4082</span>    <span class="keywordflow">if</span> (!<a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a> || !<a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>)</div>
<div class="line"><a id="l04083" name="l04083"></a><span class="lineno"> 4083</span>      <span class="keywordflow">return</span> <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l04084" name="l04084"></a><span class="lineno"> 4084</span> </div>
<div class="line"><a id="l04085" name="l04085"></a><span class="lineno"> 4085</span>    <span class="keywordflow">if</span> (isa&lt;FloatType&gt;(resTy.getElementType()))</div>
<div class="line"><a id="l04086" name="l04086"></a><span class="lineno"> 4086</span>      <span class="keywordflow">return</span> vector::FMAOp::create(rewriter, loc, <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>, res);</div>
<div class="line"><a id="l04087" name="l04087"></a><span class="lineno"> 4087</span> </div>
<div class="line"><a id="l04088" name="l04088"></a><span class="lineno"> 4088</span>    <span class="keyword">auto</span> <a class="code hl_define" href="XeGPUDialect_8cpp.html#a0da29b54f1662523e9e9da60dde8b629">mul</a> = arith::MulIOp::create(rewriter, loc, <a class="code hl_variable" href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a>, <a class="code hl_variable" href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a>);</div>
<div class="line"><a id="l04089" name="l04089"></a><span class="lineno"> 4089</span>    <span class="keywordflow">return</span> arith::AddIOp::create(rewriter, loc, <a class="code hl_define" href="XeGPUDialect_8cpp.html#a0da29b54f1662523e9e9da60dde8b629">mul</a>, res);</div>
<div class="line"><a id="l04090" name="l04090"></a><span class="lineno"> 4090</span>  }</div>
<div class="line"><a id="l04091" name="l04091"></a><span class="lineno"> 4091</span><span class="comment"></span> </div>
<div class="line"><a id="l04092" name="l04092"></a><span class="lineno"> 4092</span><span class="comment">  /// Entry point for non-channeled convolution:</span></div>
<div class="line"><a id="l04093" name="l04093"></a><span class="lineno"> 4093</span><span class="comment">  ///   {{w + kw}, {kw}, {w}}</span></div>
<div class="line"><a id="l04094" name="l04094"></a><span class="lineno"> 4094</span>  FailureOr&lt;Operation *&gt; generateNonChanneledConv() {</div>
<div class="line"><a id="l04095" name="l04095"></a><span class="lineno"> 4095</span>    AffineExpr w, kw;</div>
<div class="line"><a id="l04096" name="l04096"></a><span class="lineno"> 4096</span>    <a class="code hl_function" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, w, kw);</div>
<div class="line"><a id="l04097" name="l04097"></a><span class="lineno"> 4097</span>    <span class="keywordflow">if</span> (!iters({Par(), Red()}))</div>
<div class="line"><a id="l04098" name="l04098"></a><span class="lineno"> 4098</span>      <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op,</div>
<div class="line"><a id="l04099" name="l04099"></a><span class="lineno"> 4099</span>                                         <span class="stringliteral">&quot;failed to match conv::W 1-par 1-red&quot;</span>);</div>
<div class="line"><a id="l04100" name="l04100"></a><span class="lineno"> 4100</span> </div>
<div class="line"><a id="l04101" name="l04101"></a><span class="lineno"> 4101</span>    <span class="comment">// No transposition needed.</span></div>
<div class="line"><a id="l04102" name="l04102"></a><span class="lineno"> 4102</span>    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {w + kw},</div>
<div class="line"><a id="l04103" name="l04103"></a><span class="lineno"> 4103</span>                <span class="comment">/*rhsIndex*/</span> {kw},</div>
<div class="line"><a id="l04104" name="l04104"></a><span class="lineno"> 4104</span>                <span class="comment">/*resIndex*/</span> {w}}))</div>
<div class="line"><a id="l04105" name="l04105"></a><span class="lineno"> 4105</span>      <span class="keywordflow">return</span> conv(<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a>);</div>
<div class="line"><a id="l04106" name="l04106"></a><span class="lineno"> 4106</span> </div>
<div class="line"><a id="l04107" name="l04107"></a><span class="lineno"> 4107</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a conv::W layout&quot;</span>);</div>
<div class="line"><a id="l04108" name="l04108"></a><span class="lineno"> 4108</span>  }</div>
<div class="line"><a id="l04109" name="l04109"></a><span class="lineno"> 4109</span><span class="comment"></span> </div>
<div class="line"><a id="l04110" name="l04110"></a><span class="lineno"> 4110</span><span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a id="l04111" name="l04111"></a><span class="lineno"> 4111</span><span class="comment">  ///   {{n, strideW * w + dilationW * kw, c}, {kw, c, f}, {n, w, f}}</span></div>
<div class="line"><a id="l04112" name="l04112"></a><span class="lineno"> 4112</span>  FailureOr&lt;Operation *&gt; generateNwcConv() {</div>
<div class="line"><a id="l04113" name="l04113"></a><span class="lineno"> 4113</span>    AffineExpr n, w, f, kw, c;</div>
<div class="line"><a id="l04114" name="l04114"></a><span class="lineno"> 4114</span>    <a class="code hl_function" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, w, f, kw, c);</div>
<div class="line"><a id="l04115" name="l04115"></a><span class="lineno"> 4115</span>    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red(), Red()}))</div>
<div class="line"><a id="l04116" name="l04116"></a><span class="lineno"> 4116</span>      <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(</div>
<div class="line"><a id="l04117" name="l04117"></a><span class="lineno"> 4117</span>          op, <span class="stringliteral">&quot;failed to match conv::Nwc 3-par 2-red&quot;</span>);</div>
<div class="line"><a id="l04118" name="l04118"></a><span class="lineno"> 4118</span> </div>
<div class="line"><a id="l04119" name="l04119"></a><span class="lineno"> 4119</span>    <span class="comment">// No transposition needed.</span></div>
<div class="line"><a id="l04120" name="l04120"></a><span class="lineno"> 4120</span>    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, strideW * w + dilationW * kw, c},</div>
<div class="line"><a id="l04121" name="l04121"></a><span class="lineno"> 4121</span>                <span class="comment">/*rhsIndex*/</span> {kw, c, f},</div>
<div class="line"><a id="l04122" name="l04122"></a><span class="lineno"> 4122</span>                <span class="comment">/*resIndex*/</span> {n, w, f}}))</div>
<div class="line"><a id="l04123" name="l04123"></a><span class="lineno"> 4123</span>      <span class="keywordflow">return</span> conv(<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>);</div>
<div class="line"><a id="l04124" name="l04124"></a><span class="lineno"> 4124</span> </div>
<div class="line"><a id="l04125" name="l04125"></a><span class="lineno"> 4125</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a conv::Nwc layout&quot;</span>);</div>
<div class="line"><a id="l04126" name="l04126"></a><span class="lineno"> 4126</span>  }</div>
<div class="line"><a id="l04127" name="l04127"></a><span class="lineno"> 4127</span><span class="comment"></span> </div>
<div class="line"><a id="l04128" name="l04128"></a><span class="lineno"> 4128</span><span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a id="l04129" name="l04129"></a><span class="lineno"> 4129</span><span class="comment">  ///   {{n, c, strideW * w + dilationW * kw}, {f, c, kw}, {n, f, w}}</span></div>
<div class="line"><a id="l04130" name="l04130"></a><span class="lineno"> 4130</span>  FailureOr&lt;Operation *&gt; generateNcwConv() {</div>
<div class="line"><a id="l04131" name="l04131"></a><span class="lineno"> 4131</span>    AffineExpr n, w, f, kw, c;</div>
<div class="line"><a id="l04132" name="l04132"></a><span class="lineno"> 4132</span>    <a class="code hl_function" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, f, w, c, kw);</div>
<div class="line"><a id="l04133" name="l04133"></a><span class="lineno"> 4133</span>    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red(), Red()}))</div>
<div class="line"><a id="l04134" name="l04134"></a><span class="lineno"> 4134</span>      <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(</div>
<div class="line"><a id="l04135" name="l04135"></a><span class="lineno"> 4135</span>          op, <span class="stringliteral">&quot;failed to match conv::Ncw 3-par 2-red&quot;</span>);</div>
<div class="line"><a id="l04136" name="l04136"></a><span class="lineno"> 4136</span> </div>
<div class="line"><a id="l04137" name="l04137"></a><span class="lineno"> 4137</span>    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, c, strideW * w + dilationW * kw},</div>
<div class="line"><a id="l04138" name="l04138"></a><span class="lineno"> 4138</span>                <span class="comment">/*rhsIndex*/</span> {f, c, kw},</div>
<div class="line"><a id="l04139" name="l04139"></a><span class="lineno"> 4139</span>                <span class="comment">/*resIndex*/</span> {n, f, w}}))</div>
<div class="line"><a id="l04140" name="l04140"></a><span class="lineno"> 4140</span>      <span class="keywordflow">return</span> conv(<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>);</div>
<div class="line"><a id="l04141" name="l04141"></a><span class="lineno"> 4141</span> </div>
<div class="line"><a id="l04142" name="l04142"></a><span class="lineno"> 4142</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a conv::Ncw layout&quot;</span>);</div>
<div class="line"><a id="l04143" name="l04143"></a><span class="lineno"> 4143</span>  }</div>
<div class="line"><a id="l04144" name="l04144"></a><span class="lineno"> 4144</span><span class="comment"></span> </div>
<div class="line"><a id="l04145" name="l04145"></a><span class="lineno"> 4145</span><span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a id="l04146" name="l04146"></a><span class="lineno"> 4146</span><span class="comment">  ///   {{n, strideW * w + dilationW * kw, c}, {kw}, {n, w, c}} for pooling</span></div>
<div class="line"><a id="l04147" name="l04147"></a><span class="lineno"> 4147</span>  FailureOr&lt;Operation *&gt; generateNwcPooling() {</div>
<div class="line"><a id="l04148" name="l04148"></a><span class="lineno"> 4148</span>    AffineExpr n, w, c, kw;</div>
<div class="line"><a id="l04149" name="l04149"></a><span class="lineno"> 4149</span>    <a class="code hl_function" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, w, c, kw);</div>
<div class="line"><a id="l04150" name="l04150"></a><span class="lineno"> 4150</span>    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red()}))</div>
<div class="line"><a id="l04151" name="l04151"></a><span class="lineno"> 4151</span>      <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op,</div>
<div class="line"><a id="l04152" name="l04152"></a><span class="lineno"> 4152</span>                                         <span class="stringliteral">&quot;failed to match pooling 3-par 1-red&quot;</span>);</div>
<div class="line"><a id="l04153" name="l04153"></a><span class="lineno"> 4153</span> </div>
<div class="line"><a id="l04154" name="l04154"></a><span class="lineno"> 4154</span>    <span class="comment">// No transposition needed.</span></div>
<div class="line"><a id="l04155" name="l04155"></a><span class="lineno"> 4155</span>    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, strideW * w + dilationW * kw, c},</div>
<div class="line"><a id="l04156" name="l04156"></a><span class="lineno"> 4156</span>                <span class="comment">/*rhsIndex*/</span> {kw},</div>
<div class="line"><a id="l04157" name="l04157"></a><span class="lineno"> 4157</span>                <span class="comment">/*resIndex*/</span> {n, w, c}}))</div>
<div class="line"><a id="l04158" name="l04158"></a><span class="lineno"> 4158</span>      <span class="keywordflow">return</span> conv(<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a>);</div>
<div class="line"><a id="l04159" name="l04159"></a><span class="lineno"> 4159</span> </div>
<div class="line"><a id="l04160" name="l04160"></a><span class="lineno"> 4160</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a pooling::Nwc layout&quot;</span>);</div>
<div class="line"><a id="l04161" name="l04161"></a><span class="lineno"> 4161</span>  }</div>
<div class="line"><a id="l04162" name="l04162"></a><span class="lineno"> 4162</span><span class="comment"></span> </div>
<div class="line"><a id="l04163" name="l04163"></a><span class="lineno"> 4163</span><span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a id="l04164" name="l04164"></a><span class="lineno"> 4164</span><span class="comment">  ///   {{n, c, strideW * w + dilationW * kw}, {kw}, {n, c, w}} for pooling</span></div>
<div class="line"><a id="l04165" name="l04165"></a><span class="lineno"> 4165</span>  FailureOr&lt;Operation *&gt; generateNcwPooling() {</div>
<div class="line"><a id="l04166" name="l04166"></a><span class="lineno"> 4166</span>    AffineExpr n, w, c, kw;</div>
<div class="line"><a id="l04167" name="l04167"></a><span class="lineno"> 4167</span>    <a class="code hl_function" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, c, w, kw);</div>
<div class="line"><a id="l04168" name="l04168"></a><span class="lineno"> 4168</span>    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red()}))</div>
<div class="line"><a id="l04169" name="l04169"></a><span class="lineno"> 4169</span>      <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op,</div>
<div class="line"><a id="l04170" name="l04170"></a><span class="lineno"> 4170</span>                                         <span class="stringliteral">&quot;failed to match pooling 3-par 1-red&quot;</span>);</div>
<div class="line"><a id="l04171" name="l04171"></a><span class="lineno"> 4171</span> </div>
<div class="line"><a id="l04172" name="l04172"></a><span class="lineno"> 4172</span>    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, c, strideW * w + dilationW * kw},</div>
<div class="line"><a id="l04173" name="l04173"></a><span class="lineno"> 4173</span>                <span class="comment">/*rhsIndex*/</span> {kw},</div>
<div class="line"><a id="l04174" name="l04174"></a><span class="lineno"> 4174</span>                <span class="comment">/*resIndex*/</span> {n, c, w}}))</div>
<div class="line"><a id="l04175" name="l04175"></a><span class="lineno"> 4175</span>      <span class="keywordflow">return</span> conv(<a class="code hl_enumvalue" href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a>);</div>
<div class="line"><a id="l04176" name="l04176"></a><span class="lineno"> 4176</span> </div>
<div class="line"><a id="l04177" name="l04177"></a><span class="lineno"> 4177</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a pooling::Ncw layout&quot;</span>);</div>
<div class="line"><a id="l04178" name="l04178"></a><span class="lineno"> 4178</span>  }</div>
<div class="line"><a id="l04179" name="l04179"></a><span class="lineno"> 4179</span><span class="comment"></span> </div>
<div class="line"><a id="l04180" name="l04180"></a><span class="lineno"> 4180</span><span class="comment">  /// Entry point that transposes into the common form:</span></div>
<div class="line"><a id="l04181" name="l04181"></a><span class="lineno"> 4181</span><span class="comment">  ///   {{n, strideW * w + dilationW * kw, c}, {kw, c}, {n, w, c}}</span></div>
<div class="line"><a id="l04182" name="l04182"></a><span class="lineno"> 4182</span>  FailureOr&lt;Operation *&gt; generateDilatedConv(uint64_t vecChDimSize = 0,</div>
<div class="line"><a id="l04183" name="l04183"></a><span class="lineno"> 4183</span>                                             <span class="keywordtype">bool</span> vecChDimScalableFlag = <span class="keyword">false</span>,</div>
<div class="line"><a id="l04184" name="l04184"></a><span class="lineno"> 4184</span>                                             <span class="keywordtype">bool</span> flatten = <span class="keyword">false</span>) {</div>
<div class="line"><a id="l04185" name="l04185"></a><span class="lineno"> 4185</span>    AffineExpr n, w, c, kw;</div>
<div class="line"><a id="l04186" name="l04186"></a><span class="lineno"> 4186</span>    <a class="code hl_function" href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">bindDims</a>(ctx, n, w, c, kw);</div>
<div class="line"><a id="l04187" name="l04187"></a><span class="lineno"> 4187</span>    <span class="keywordflow">if</span> (!iters({Par(), Par(), Par(), Red()}))</div>
<div class="line"><a id="l04188" name="l04188"></a><span class="lineno"> 4188</span>      <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(</div>
<div class="line"><a id="l04189" name="l04189"></a><span class="lineno"> 4189</span>          op, <span class="stringliteral">&quot;failed to match depthwise::Nwc conv 3-par 1-red&quot;</span>);</div>
<div class="line"><a id="l04190" name="l04190"></a><span class="lineno"> 4190</span> </div>
<div class="line"><a id="l04191" name="l04191"></a><span class="lineno"> 4191</span>    <span class="comment">// No transposition needed.</span></div>
<div class="line"><a id="l04192" name="l04192"></a><span class="lineno"> 4192</span>    <span class="keywordflow">if</span> (layout({<span class="comment">/*lhsIndex*/</span> {n, strideW * w + dilationW * kw, c},</div>
<div class="line"><a id="l04193" name="l04193"></a><span class="lineno"> 4193</span>                <span class="comment">/*rhsIndex*/</span> {kw, c},</div>
<div class="line"><a id="l04194" name="l04194"></a><span class="lineno"> 4194</span>                <span class="comment">/*resIndex*/</span> {n, w, c}}))</div>
<div class="line"><a id="l04195" name="l04195"></a><span class="lineno"> 4195</span>      <span class="keywordflow">return</span> depthwiseConv(vecChDimSize, vecChDimScalableFlag, flatten);</div>
<div class="line"><a id="l04196" name="l04196"></a><span class="lineno"> 4196</span> </div>
<div class="line"><a id="l04197" name="l04197"></a><span class="lineno"> 4197</span>    <span class="keywordflow">return</span> rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">notifyMatchFailure</a>(op, <span class="stringliteral">&quot;not a depthwise::Nwc layout&quot;</span>);</div>
<div class="line"><a id="l04198" name="l04198"></a><span class="lineno"> 4198</span>  }</div>
<div class="line"><a id="l04199" name="l04199"></a><span class="lineno"> 4199</span> </div>
<div class="line"><a id="l04200" name="l04200"></a><span class="lineno"> 4200</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l04201" name="l04201"></a><span class="lineno"> 4201</span>  ConvOperationKind oper = ConvOperationKind::Conv;</div>
<div class="line"><a id="l04202" name="l04202"></a><span class="lineno"> 4202</span>  StringAttr redOp;</div>
<div class="line"><a id="l04203" name="l04203"></a><span class="lineno"> 4203</span>  StringAttr poolExtOp;</div>
<div class="line"><a id="l04204" name="l04204"></a><span class="lineno"> 4204</span>  <span class="keywordtype">bool</span> isPoolExt = <span class="keyword">false</span>;</div>
<div class="line"><a id="l04205" name="l04205"></a><span class="lineno"> 4205</span>  <span class="keywordtype">int</span> strideW, dilationW;</div>
<div class="line"><a id="l04206" name="l04206"></a><span class="lineno"> 4206</span>  Value lhsShaped, rhsShaped, resShaped;</div>
<div class="line"><a id="l04207" name="l04207"></a><span class="lineno"> 4207</span>  ShapedType lhsShapedType, rhsShapedType, resShapedType;</div>
<div class="line"><a id="l04208" name="l04208"></a><span class="lineno"> 4208</span>  vector::CombiningKind reductionKind;</div>
<div class="line"><a id="l04209" name="l04209"></a><span class="lineno"> 4209</span> </div>
<div class="line"><a id="l04210" name="l04210"></a><span class="lineno"> 4210</span>  <span class="comment">// Sets oper, poolExtOp and isPoolExt for valid conv/pooling ops.</span></div>
<div class="line"><a id="l04211" name="l04211"></a><span class="lineno"> 4211</span>  <span class="keywordtype">void</span> setConvOperationKind(Operation *reduceOp) {</div>
<div class="line"><a id="l04212" name="l04212"></a><span class="lineno"> 4212</span>    <span class="keywordtype">int</span> numBlockArguments =</div>
<div class="line"><a id="l04213" name="l04213"></a><span class="lineno"> 4213</span>        llvm::count_if(reduceOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(), llvm::IsaPred&lt;BlockArgument&gt;);</div>
<div class="line"><a id="l04214" name="l04214"></a><span class="lineno"> 4214</span>    <span class="keywordflow">if</span> (numBlockArguments == 1) {</div>
<div class="line"><a id="l04215" name="l04215"></a><span class="lineno"> 4215</span>      <span class="comment">// Will be convolution if feeder is a MulOp.</span></div>
<div class="line"><a id="l04216" name="l04216"></a><span class="lineno"> 4216</span>      <span class="comment">// A strength reduced version of MulOp for i1 type is AndOp which is also</span></div>
<div class="line"><a id="l04217" name="l04217"></a><span class="lineno"> 4217</span>      <span class="comment">// supported. Otherwise, it can be pooling. This strength reduction logic</span></div>
<div class="line"><a id="l04218" name="l04218"></a><span class="lineno"> 4218</span>      <span class="comment">// is in `buildBinaryFn` helper in the Linalg dialect.</span></div>
<div class="line"><a id="l04219" name="l04219"></a><span class="lineno"> 4219</span>      <span class="keyword">auto</span> feedValIt = llvm::find_if_not(reduceOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">getOperands</a>(),</div>
<div class="line"><a id="l04220" name="l04220"></a><span class="lineno"> 4220</span>                                         llvm::IsaPred&lt;BlockArgument&gt;);</div>
<div class="line"><a id="l04221" name="l04221"></a><span class="lineno"> 4221</span>      Operation *feedOp = (*feedValIt).getDefiningOp();</div>
<div class="line"><a id="l04222" name="l04222"></a><span class="lineno"> 4222</span>      <span class="keywordflow">if</span> (isCastOfBlockArgument(feedOp)) {</div>
<div class="line"><a id="l04223" name="l04223"></a><span class="lineno"> 4223</span>        oper = ConvOperationKind::Pool;</div>
<div class="line"><a id="l04224" name="l04224"></a><span class="lineno"> 4224</span>        isPoolExt = <span class="keyword">true</span>;</div>
<div class="line"><a id="l04225" name="l04225"></a><span class="lineno"> 4225</span>        poolExtOp = feedOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#ab2e11ba83ff765eb7595554f97aaaa75">getName</a>().<a class="code hl_function" href="classmlir_1_1OperationName.html#a2c83cffa9a4c4fb68436d9ee3497c226">getIdentifier</a>();</div>
<div class="line"><a id="l04226" name="l04226"></a><span class="lineno"> 4226</span>        <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l04227" name="l04227"></a><span class="lineno"> 4227</span>      }</div>
<div class="line"><a id="l04228" name="l04228"></a><span class="lineno"> 4228</span>      oper = ConvOperationKind::Conv;</div>
<div class="line"><a id="l04229" name="l04229"></a><span class="lineno"> 4229</span>      <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l04230" name="l04230"></a><span class="lineno"> 4230</span>    }</div>
<div class="line"><a id="l04231" name="l04231"></a><span class="lineno"> 4231</span>    <span class="comment">// numBlockArugments == 2 and this is a pooling op.</span></div>
<div class="line"><a id="l04232" name="l04232"></a><span class="lineno"> 4232</span>    oper = ConvOperationKind::Pool;</div>
<div class="line"><a id="l04233" name="l04233"></a><span class="lineno"> 4233</span>    isPoolExt = <span class="keyword">false</span>;</div>
<div class="line"><a id="l04234" name="l04234"></a><span class="lineno"> 4234</span>  }</div>
<div class="line"><a id="l04235" name="l04235"></a><span class="lineno"> 4235</span>};</div>
<div class="line"><a id="l04236" name="l04236"></a><span class="lineno"> 4236</span>} <span class="comment">// namespace</span></div>
<div class="line"><a id="l04237" name="l04237"></a><span class="lineno"> 4237</span><span class="comment"></span> </div>
<div class="line"><a id="l04238" name="l04238"></a><span class="lineno"> 4238</span><span class="comment">/// Helper function to vectorize a LinalgOp with convolution semantics.</span></div>
<div class="line"><a id="l04239" name="l04239"></a><span class="lineno"> 4239</span><span class="comment">// TODO: extend the generic vectorization to support windows and drop this.</span></div>
<div class="line"><a id="l04240" name="l04240"></a><span class="lineno"> 4240</span><span class="keyword">static</span> FailureOr&lt;Operation *&gt; <a class="code hl_function" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a>(</div>
<div class="line"><a id="l04241" name="l04241"></a><span class="lineno"> 4241</span>    RewriterBase &amp;rewriter, LinalgOp op, ArrayRef&lt;int64_t&gt; inputVecSizes,</div>
<div class="line"><a id="l04242" name="l04242"></a><span class="lineno"> 4242</span>    ArrayRef&lt;bool&gt; inputScalableVecDims, <span class="keywordtype">bool</span> flatten1DDepthwiseConv) {</div>
<div class="line"><a id="l04243" name="l04243"></a><span class="lineno"> 4243</span>  Conv1DGenerator conv1dGen(rewriter, op);</div>
<div class="line"><a id="l04244" name="l04244"></a><span class="lineno"> 4244</span>  <span class="keyword">auto</span> res = conv1dGen.generateNonChanneledConv();</div>
<div class="line"><a id="l04245" name="l04245"></a><span class="lineno"> 4245</span>  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a id="l04246" name="l04246"></a><span class="lineno"> 4246</span>    <span class="keywordflow">return</span> res;</div>
<div class="line"><a id="l04247" name="l04247"></a><span class="lineno"> 4247</span>  res = conv1dGen.generateNwcConv();</div>
<div class="line"><a id="l04248" name="l04248"></a><span class="lineno"> 4248</span>  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a id="l04249" name="l04249"></a><span class="lineno"> 4249</span>    <span class="keywordflow">return</span> res;</div>
<div class="line"><a id="l04250" name="l04250"></a><span class="lineno"> 4250</span>  res = conv1dGen.generateNcwConv();</div>
<div class="line"><a id="l04251" name="l04251"></a><span class="lineno"> 4251</span>  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a id="l04252" name="l04252"></a><span class="lineno"> 4252</span>    <span class="keywordflow">return</span> res;</div>
<div class="line"><a id="l04253" name="l04253"></a><span class="lineno"> 4253</span>  res = conv1dGen.generateNwcPooling();</div>
<div class="line"><a id="l04254" name="l04254"></a><span class="lineno"> 4254</span>  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a id="l04255" name="l04255"></a><span class="lineno"> 4255</span>    <span class="keywordflow">return</span> res;</div>
<div class="line"><a id="l04256" name="l04256"></a><span class="lineno"> 4256</span>  res = conv1dGen.generateNcwPooling();</div>
<div class="line"><a id="l04257" name="l04257"></a><span class="lineno"> 4257</span>  <span class="keywordflow">if</span> (succeeded(res))</div>
<div class="line"><a id="l04258" name="l04258"></a><span class="lineno"> 4258</span>    <span class="keywordflow">return</span> res;</div>
<div class="line"><a id="l04259" name="l04259"></a><span class="lineno"> 4259</span> </div>
<div class="line"><a id="l04260" name="l04260"></a><span class="lineno"> 4260</span>  <span class="comment">// Only depthwise 1D NWC convs are left - these can be vectorized using masks</span></div>
<div class="line"><a id="l04261" name="l04261"></a><span class="lineno"> 4261</span>  <span class="comment">// and scalable vectors. Note that ATM the only dim that can be dynamic (i.e.</span></div>
<div class="line"><a id="l04262" name="l04262"></a><span class="lineno"> 4262</span>  <span class="comment">// masked/scalable) is the channel dim (i.e. the trailing dim).</span></div>
<div class="line"><a id="l04263" name="l04263"></a><span class="lineno"> 4263</span>  uint64_t vecChDimSize = ShapedType::kDynamic;</div>
<div class="line"><a id="l04264" name="l04264"></a><span class="lineno"> 4264</span>  <span class="keywordtype">bool</span> vecChDimScalableFlag = <span class="keyword">false</span>;</div>
<div class="line"><a id="l04265" name="l04265"></a><span class="lineno"> 4265</span>  <span class="keywordflow">if</span> (!inputVecSizes.empty()) {</div>
<div class="line"><a id="l04266" name="l04266"></a><span class="lineno"> 4266</span>    <span class="comment">// Only use the input vector size corresponding to the channel dim. Other</span></div>
<div class="line"><a id="l04267" name="l04267"></a><span class="lineno"> 4267</span>    <span class="comment">// vector dims will be inferred from the Ops.</span></div>
<div class="line"><a id="l04268" name="l04268"></a><span class="lineno"> 4268</span>    assert((isa&lt;linalg::DepthwiseConv1DNwcWcOp&gt;(*op) ||</div>
<div class="line"><a id="l04269" name="l04269"></a><span class="lineno"> 4269</span>            isa&lt;linalg::DepthwiseConv1DNcwCwOp&gt;(*op)) &amp;&amp;</div>
<div class="line"><a id="l04270" name="l04270"></a><span class="lineno"> 4270</span>           <span class="stringliteral">&quot;Not a 1D depthwise conv!&quot;</span>);</div>
<div class="line"><a id="l04271" name="l04271"></a><span class="lineno"> 4271</span>    <span class="keywordtype">size_t</span> chDimIdx =</div>
<div class="line"><a id="l04272" name="l04272"></a><span class="lineno"> 4272</span>        <a class="code hl_typedef" href="namespacemlir.html#a9eabc3974d2131e15fad199b34b2eaa0">TypeSwitch&lt;Operation *, size_t&gt;</a>(op)</div>
<div class="line"><a id="l04273" name="l04273"></a><span class="lineno"> 4273</span>            .Case&lt;linalg::DepthwiseConv1DNwcWcOp&gt;([](<span class="keyword">auto</span> conv) { <span class="keywordflow">return</span> 2; })</div>
<div class="line"><a id="l04274" name="l04274"></a><span class="lineno"> 4274</span>            .Case&lt;linalg::DepthwiseConv1DNcwCwOp&gt;([](<span class="keyword">auto</span> conv) { <span class="keywordflow">return</span> 1; });</div>
<div class="line"><a id="l04275" name="l04275"></a><span class="lineno"> 4275</span> </div>
<div class="line"><a id="l04276" name="l04276"></a><span class="lineno"> 4276</span>    vecChDimSize = inputVecSizes[chDimIdx];</div>
<div class="line"><a id="l04277" name="l04277"></a><span class="lineno"> 4277</span>    vecChDimScalableFlag = inputScalableVecDims[chDimIdx];</div>
<div class="line"><a id="l04278" name="l04278"></a><span class="lineno"> 4278</span>  }</div>
<div class="line"><a id="l04279" name="l04279"></a><span class="lineno"> 4279</span>  <span class="keywordflow">return</span> conv1dGen.generateDilatedConv(vecChDimSize, vecChDimScalableFlag,</div>
<div class="line"><a id="l04280" name="l04280"></a><span class="lineno"> 4280</span>                                       flatten1DDepthwiseConv);</div>
<div class="line"><a id="l04281" name="l04281"></a><span class="lineno"> 4281</span>}</div>
<div class="line"><a id="l04282" name="l04282"></a><span class="lineno"> 4282</span> </div>
<div class="line"><a id="l04283" name="l04283"></a><span class="lineno"> 4283</span><span class="keyword">struct </span>VectorizeConvolution : <span class="keyword">public</span> OpInterfaceRewritePattern&lt;LinalgOp&gt; {</div>
<div class="line"><a id="l04284" name="l04284"></a><span class="lineno"> 4284</span>  <span class="keyword">using </span><a class="code hl_function" href="structmlir_1_1OpInterfaceRewritePattern.html#a723a250f581dc2a0758fbe6b7c55f1c9">OpInterfaceRewritePattern::OpInterfaceRewritePattern</a>;</div>
<div class="line"><a id="l04285" name="l04285"></a><span class="lineno"> 4285</span> </div>
<div class="line"><a id="l04286" name="l04286"></a><span class="lineno"> 4286</span>  LogicalResult matchAndRewrite(LinalgOp op,</div>
<div class="line"><a id="l04287" name="l04287"></a><span class="lineno"> 4287</span>                                PatternRewriter &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a id="l04288" name="l04288"></a><span class="lineno"> 4288</span>    FailureOr&lt;Operation *&gt; resultOrFail = <a class="code hl_function" href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a>(rewriter, op);</div>
<div class="line"><a id="l04289" name="l04289"></a><span class="lineno"> 4289</span>    <span class="keywordflow">if</span> (<a class="code hl_function" href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">failed</a>(resultOrFail))</div>
<div class="line"><a id="l04290" name="l04290"></a><span class="lineno"> 4290</span>      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a id="l04291" name="l04291"></a><span class="lineno"> 4291</span>    Operation *newOp = *resultOrFail;</div>
<div class="line"><a id="l04292" name="l04292"></a><span class="lineno"> 4292</span>    <span class="keywordflow">if</span> (newOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#afeb237ab61bc6c18e133da3060a7fbfb">getNumResults</a>() == 0) {</div>
<div class="line"><a id="l04293" name="l04293"></a><span class="lineno"> 4293</span>      rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(op.getOperation());</div>
<div class="line"><a id="l04294" name="l04294"></a><span class="lineno"> 4294</span>      <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l04295" name="l04295"></a><span class="lineno"> 4295</span>    }</div>
<div class="line"><a id="l04296" name="l04296"></a><span class="lineno"> 4296</span>    assert(newOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#afeb237ab61bc6c18e133da3060a7fbfb">getNumResults</a>() == 1 &amp;&amp; <span class="stringliteral">&quot;expected single result&quot;</span>);</div>
<div class="line"><a id="l04297" name="l04297"></a><span class="lineno"> 4297</span>    rewriter.<a class="code hl_function" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(op.getOperation(), newOp-&gt;<a class="code hl_function" href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">getResult</a>(0));</div>
<div class="line"><a id="l04298" name="l04298"></a><span class="lineno"> 4298</span>    <span class="keywordflow">return</span> <a class="code hl_function" href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a>();</div>
<div class="line"><a id="l04299" name="l04299"></a><span class="lineno"> 4299</span>  }</div>
<div class="line"><a id="l04300" name="l04300"></a><span class="lineno"> 4300</span>};</div>
<div class="line"><a id="l04301" name="l04301"></a><span class="lineno"> 4301</span> </div>
<div class="line"><a id="l04302" name="l04302"></a><span class="lineno"> 4302</span><span class="keywordtype">void</span> <a class="code hl_function" href="namespacemlir_1_1linalg.html#a891b8f2d145dcc3327ba55c7a49d44e4">mlir::linalg::populateConvolutionVectorizationPatterns</a>(</div>
<div class="line"><a id="l04303" name="l04303"></a><span class="lineno"> 4303</span>    RewritePatternSet &amp;<a class="code hl_variable" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>, PatternBenefit benefit) {</div>
<div class="line"><a id="l04304" name="l04304"></a><span class="lineno"> 4304</span>  <a class="code hl_variable" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.add&lt;VectorizeConvolution&gt;(<a class="code hl_variable" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.getContext(), benefit);</div>
<div class="line"><a id="l04305" name="l04305"></a><span class="lineno"> 4305</span>}</div>
<div class="ttc" id="aAffineAnalysis_8cpp_html_a7b261d2d5f193015afc3427b0c0951ed"><div class="ttname"><a href="AffineAnalysis_8cpp.html#a7b261d2d5f193015afc3427b0c0951ed">indices</a></div><div class="ttdeci">indices</div><div class="ttdef"><b>Definition</b> <a href="AffineAnalysis_8cpp_source.html#l00263">AffineAnalysis.cpp:262</a></div></div>
<div class="ttc" id="aAffineAnalysis_8cpp_html_aa2afc59a21f80839c29f2812f75c36a4"><div class="ttname"><a href="AffineAnalysis_8cpp.html#aa2afc59a21f80839c29f2812f75c36a4">success</a></div><div class="ttdeci">return success()</div></div>
<div class="ttc" id="aAffineOps_8h_html"><div class="ttname"><a href="AffineOps_8h.html">AffineOps.h</a></div></div>
<div class="ttc" id="aBuilders_8h_html"><div class="ttname"><a href="Builders_8h.html">Builders.h</a></div></div>
<div class="ttc" id="aBuiltinTypeInterfaces_8h_html"><div class="ttname"><a href="BuiltinTypeInterfaces_8h.html">BuiltinTypeInterfaces.h</a></div></div>
<div class="ttc" id="aDialect_2Affine_2Utils_8h_html"><div class="ttname"><a href="Dialect_2Affine_2Utils_8h.html">Utils.h</a></div></div>
<div class="ttc" id="aDialect_2Linalg_2Utils_2Utils_8h_html"><div class="ttname"><a href="Dialect_2Linalg_2Utils_2Utils_8h.html">Utils.h</a></div></div>
<div class="ttc" id="aFuncOps_8h_html"><div class="ttname"><a href="FuncOps_8h.html">FuncOps.h</a></div></div>
<div class="ttc" id="aIR_2AffineExpr_8cpp_html_a204f446339af7929852f44df41484be5"><div class="ttname"><a href="IR_2AffineExpr_8cpp.html#a204f446339af7929852f44df41484be5">lhs</a></div><div class="ttdeci">lhs</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineExpr_8cpp_source.html#l00832">AffineExpr.cpp:832</a></div></div>
<div class="ttc" id="aIndexingUtils_8h_html"><div class="ttname"><a href="IndexingUtils_8h.html">IndexingUtils.h</a></div></div>
<div class="ttc" id="aLinalgTransformOps_8cpp_html_a21ad0bd836b90d08f4cf640b4c298e7c"><div class="ttname"><a href="LinalgTransformOps_8cpp.html#a21ad0bd836b90d08f4cf640b4c298e7c">b</a></div><div class="ttdeci">b</div><div class="ttdoc">Return true if permutation is a valid permutation of the outer_dims_perm (case OuterOrInnerPerm::Oute...</div><div class="ttdef"><b>Definition</b> <a href="LinalgTransformOps_8cpp_source.html#l02097">LinalgTransformOps.cpp:2097</a></div></div>
<div class="ttc" id="aLinalgTransformOps_8cpp_html_a4fa832087ed6d7798c173648e7541e60"><div class="ttname"><a href="LinalgTransformOps_8cpp.html#a4fa832087ed6d7798c173648e7541e60">ValueRange</a></div><div class="ttdeci">b ValueRange</div><div class="ttdef"><b>Definition</b> <a href="LinalgTransformOps_8cpp_source.html#l02103">LinalgTransformOps.cpp:2103</a></div></div>
<div class="ttc" id="aLinalgTransformOps_8cpp_html_a937d4dd628a8858b443a399410d2600b"><div class="ttname"><a href="LinalgTransformOps_8cpp.html#a937d4dd628a8858b443a399410d2600b">result</a></div><div class="ttdeci">result</div><div class="ttdef"><b>Definition</b> <a href="LinalgTransformOps_8cpp_source.html#l02098">LinalgTransformOps.cpp:2098</a></div></div>
<div class="ttc" id="aMaskableOpInterface_8h_html"><div class="ttname"><a href="MaskableOpInterface_8h.html">MaskableOpInterface.h</a></div></div>
<div class="ttc" id="aOpDefinition_8h_html"><div class="ttname"><a href="OpDefinition_8h.html">OpDefinition.h</a></div></div>
<div class="ttc" id="aPatternMatch_8h_html"><div class="ttname"><a href="PatternMatch_8h.html">PatternMatch.h</a></div></div>
<div class="ttc" id="aPolynomialApproximation_8cpp_html_ab923648d7590d36d942f588f686aa290"><div class="ttname"><a href="PolynomialApproximation_8cpp.html#ab923648d7590d36d942f588f686aa290">vectorShape</a></div><div class="ttdeci">static std::optional&lt; VectorShape &gt; vectorShape(Type type)</div><div class="ttdef"><b>Definition</b> <a href="PolynomialApproximation_8cpp_source.html#l00047">PolynomialApproximation.cpp:47</a></div></div>
<div class="ttc" id="aRegionUtils_8h_html"><div class="ttname"><a href="RegionUtils_8h.html">RegionUtils.h</a></div></div>
<div class="ttc" id="aSliceAnalysis_8h_html"><div class="ttname"><a href="SliceAnalysis_8h.html">SliceAnalysis.h</a></div></div>
<div class="ttc" id="aStructuredOpsUtils_8h_html"><div class="ttname"><a href="StructuredOpsUtils_8h.html">StructuredOpsUtils.h</a></div></div>
<div class="ttc" id="aValue_8h_html"><div class="ttname"><a href="Value_8h.html">Value.h</a></div></div>
<div class="ttc" id="aVectorOps_8h_html"><div class="ttname"><a href="VectorOps_8h.html">VectorOps.h</a></div></div>
<div class="ttc" id="aVectorTransforms_8cpp_html_a611c177776150f2e11f15c1cec5764c1"><div class="ttname"><a href="VectorTransforms_8cpp.html#a611c177776150f2e11f15c1cec5764c1">rhs</a></div><div class="ttdeci">*B rhs</div><div class="ttdef"><b>Definition</b> <a href="VectorTransforms_8cpp_source.html#l02249">VectorTransforms.cpp:2249</a></div></div>
<div class="ttc" id="aVectorUtils_8h_html"><div class="ttname"><a href="VectorUtils_8h.html">VectorUtils.h</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a0bcdc4b64d42010b23b271435831cb39"><div class="ttname"><a href="Vectorization_8cpp.html#a0bcdc4b64d42010b23b271435831cb39">isLoopInvariantIdx</a></div><div class="ttdeci">static bool isLoopInvariantIdx(LinalgOp &amp;linalgOp, Value &amp;val, VectorType resType)</div><div class="ttdoc">Checks whether val can be used for calculating a loop invariant index.</div><div class="ttdef"><b>Definition</b> <a href="#l00971">Vectorization.cpp:971</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a110d1ed6891097419f0358bd63e974c8"><div class="ttname"><a href="Vectorization_8cpp.html#a110d1ed6891097419f0358bd63e974c8">insertConvResultSlices</a></div><div class="ttdeci">static Value insertConvResultSlices(RewriterBase &amp;rewriter, Location loc, Value res, int64_t wSize, int64_t wSizeStep, SmallVectorImpl&lt; Value &gt; &amp;resVals, bool isSingleChanneled)</div><div class="ttdoc">Helper function to insert the computed result slices.</div><div class="ttdef"><b>Definition</b> <a href="#l00189">Vectorization.cpp:189</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a129f4ae5f0a8071a3f98c8f73ee729f9"><div class="ttname"><a href="Vectorization_8cpp.html#a129f4ae5f0a8071a3f98c8f73ee729f9">getDimsToReduce</a></div><div class="ttdeci">static SmallVector&lt; bool &gt; getDimsToReduce(LinalgOp linalgOp)</div><div class="ttdef"><b>Definition</b> <a href="#l00711">Vectorization.cpp:711</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a172594be3a7384cb03a833aed99dc03c"><div class="ttname"><a href="Vectorization_8cpp.html#a172594be3a7384cb03a833aed99dc03c">getTensorExtractMemoryAccessPattern</a></div><div class="ttdeci">static VectorMemoryAccessKind getTensorExtractMemoryAccessPattern(tensor::ExtractOp extractOp, LinalgOp &amp;linalgOp, VectorType resType)</div><div class="ttdoc">Infer the memory access pattern for the input ExtractOp.</div><div class="ttdef"><b>Definition</b> <a href="#l01085">Vectorization.cpp:1085</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a1bedce144a30ca3ef5eac6628b35d4a9"><div class="ttname"><a href="Vectorization_8cpp.html#a1bedce144a30ca3ef5eac6628b35d4a9">isMaskTriviallyFoldable</a></div><div class="ttdeci">static bool isMaskTriviallyFoldable(SmallVector&lt; OpFoldResult &gt; &amp;maskSizes, SmallVector&lt; Value &gt; &amp;writeIdxs, ArrayRef&lt; int64_t &gt; destShape, ArrayRef&lt; int64_t &gt; maskShape)</div><div class="ttdoc">Determines whether a mask for xfer_write is trivially &quot;all true&quot;.</div><div class="ttdef"><b>Definition</b> <a href="#l01613">Vectorization.cpp:1613</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a200fa245f199890432efcd7596b5e672"><div class="ttname"><a href="Vectorization_8cpp.html#a200fa245f199890432efcd7596b5e672">extractConvInputSlices</a></div><div class="ttdeci">static SmallVector&lt; Value &gt; extractConvInputSlices(RewriterBase &amp;rewriter, Location loc, Value input, int64_t nSize, int64_t wSize, int64_t cSize, int64_t kwSize, int strideW, int dilationW, int64_t wSizeStep, bool isSingleChanneled)</div><div class="ttdoc">Helper function to extract the input slices after filter is unrolled along kw.</div><div class="ttdef"><b>Definition</b> <a href="#l00109">Vectorization.cpp:109</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a224b215237fb8401f7031f2991266dcc"><div class="ttname"><a href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcc">VectorMemoryAccessKind</a></div><div class="ttdeci">VectorMemoryAccessKind</div><div class="ttdef"><b>Definition</b> <a href="#l00936">Vectorization.cpp:936</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea"><div class="ttname"><a href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dcca1910b77e1772ac1536cb49936f8c32ea">Contiguous</a></div><div class="ttdeci">@ Contiguous</div><div class="ttdef"><b>Definition</b> <a href="#l00936">Vectorization.cpp:936</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d"><div class="ttname"><a href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccaceba1db2e3b2f5aa1258aae0105e2a4d">Gather</a></div><div class="ttdeci">@ Gather</div><div class="ttdef"><b>Definition</b> <a href="#l00936">Vectorization.cpp:936</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca"><div class="ttname"><a href="Vectorization_8cpp.html#a224b215237fb8401f7031f2991266dccae08c87afc59477607178b88f356268ca">ScalarBroadcast</a></div><div class="ttdeci">@ ScalarBroadcast</div><div class="ttdef"><b>Definition</b> <a href="#l00936">Vectorization.cpp:936</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a26cb5e24425fdce30baaba6f7c0f5c84"><div class="ttname"><a href="Vectorization_8cpp.html#a26cb5e24425fdce30baaba6f7c0f5c84">vectorizeTensorExtract</a></div><div class="ttdeci">static VectorizationHookResult vectorizeTensorExtract(RewriterBase &amp;rewriter, VectorizationState &amp;state, Operation *op, LinalgOp linalgOp, const IRMapping &amp;bvm)</div><div class="ttdoc">Helper function to vectorize the tensor.extract operations.</div><div class="ttdef"><b>Definition</b> <a href="#l01166">Vectorization.cpp:1166</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a280bd1ab81d418cd32713eeb0a2dfffd"><div class="ttname"><a href="Vectorization_8cpp.html#a280bd1ab81d418cd32713eeb0a2dfffd">vectorizeLinalgIndex</a></div><div class="ttdeci">static VectorizationHookResult vectorizeLinalgIndex(RewriterBase &amp;rewriter, VectorizationState &amp;state, Operation *op, LinalgOp linalgOp)</div><div class="ttdoc">Helper function to vectorize the index operations of a linalgOp.</div><div class="ttdef"><b>Definition</b> <a href="#l00828">Vectorization.cpp:828</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a298ab89fe37b4d0e351c2d1619476926"><div class="ttname"><a href="Vectorization_8cpp.html#a298ab89fe37b4d0e351c2d1619476926">vectorizeAsInsertSliceOp</a></div><div class="ttdeci">static LogicalResult vectorizeAsInsertSliceOp(RewriterBase &amp;rewriter, tensor::InsertSliceOp sliceOp, ArrayRef&lt; int64_t &gt; inputVectorSizes, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Vectorize tensor::InsertSliceOp with:</div></div>
<div class="ttc" id="aVectorization_8cpp_html_a2d04989901c1df355793bb8a71328797"><div class="ttname"><a href="Vectorization_8cpp.html#a2d04989901c1df355793bb8a71328797">createWriteOrMaskedWrite</a></div><div class="ttdeci">static Operation * createWriteOrMaskedWrite(OpBuilder &amp;builder, Location loc, Value vecToStore, Value dest, SmallVector&lt; Value &gt; writeIndices={}, bool useInBoundsInsteadOfMasking=false)</div><div class="ttdoc">Creates an optionally masked TransferWriteOp.</div><div class="ttdef"><b>Definition</b> <a href="#l01690">Vectorization.cpp:1690</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a320b06f6c6f3905541d59f2c33ce5aea"><div class="ttname"><a href="Vectorization_8cpp.html#a320b06f6c6f3905541d59f2c33ce5aea">vectorizeConvolution</a></div><div class="ttdeci">static FailureOr&lt; Operation * &gt; vectorizeConvolution(RewriterBase &amp;rewriter, LinalgOp convOp, ArrayRef&lt; int64_t &gt; inputVecSizes={}, ArrayRef&lt; bool &gt; inputVecScalableFlags={}, bool flatten1DDepthwiseConv=false)</div><div class="ttdoc">Try to vectorize convOp as a convolution.</div></div>
<div class="ttc" id="aVectorization_8cpp_html_a35e1ec347850959af0bc7cbdf61b9da3"><div class="ttname"><a href="Vectorization_8cpp.html#a35e1ec347850959af0bc7cbdf61b9da3">vectorizeAsLinalgGeneric</a></div><div class="ttdeci">static LogicalResult vectorizeAsLinalgGeneric(RewriterBase &amp;rewriter, VectorizationState &amp;state, LinalgOp linalgOp, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Generic vectorization function that rewrites the body of a linalgOp into vector form.</div><div class="ttdef"><b>Definition</b> <a href="#l01452">Vectorization.cpp:1452</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a455f83de6534e53da06be057973f7e38"><div class="ttname"><a href="Vectorization_8cpp.html#a455f83de6534e53da06be057973f7e38">vectorizeOneOp</a></div><div class="ttdeci">static VectorizationHookResult vectorizeOneOp(RewriterBase &amp;rewriter, VectorizationState &amp;state, LinalgOp linalgOp, Operation *op, const IRMapping &amp;bvm, ArrayRef&lt; CustomVectorizationHook &gt; customVectorizationHooks)</div><div class="ttdoc">Generic vectorization for a single operation op, given already vectorized operands carried by bvm.</div><div class="ttdef"><b>Definition</b> <a href="#l01337">Vectorization.cpp:1337</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a4c99d55a1274aa91b750b22a4a3c76e2"><div class="ttname"><a href="Vectorization_8cpp.html#a4c99d55a1274aa91b750b22a4a3c76e2">matchLinalgReduction</a></div><div class="ttdeci">static Operation * matchLinalgReduction(OpOperand *outputOperand)</div><div class="ttdoc">Check whether outputOperand is a reduction with a single combiner operation.</div><div class="ttdef"><b>Definition</b> <a href="#l00669">Vectorization.cpp:669</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a4ffeefd6b3cba67afe11ecdc2b48fcef"><div class="ttname"><a href="Vectorization_8cpp.html#a4ffeefd6b3cba67afe11ecdc2b48fcef">buildVectorWrite</a></div><div class="ttdeci">static Value buildVectorWrite(RewriterBase &amp;rewriter, Value value, OpOperand *outputOperand, VectorizationState &amp;state)</div><div class="ttdoc">Build a vector.transfer_write of value into outputOperand at indices set to all 0; where outputOperan...</div><div class="ttdef"><b>Definition</b> <a href="#l00730">Vectorization.cpp:730</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a51c7625311de4f665ab3c2cde71709ec"><div class="ttname"><a href="Vectorization_8cpp.html#a51c7625311de4f665ab3c2cde71709ec">getStaticPadVal</a></div><div class="ttdeci">static Value getStaticPadVal(Operation *op)</div><div class="ttdoc">Returns the effective Pad value for the input op, provided it&#39;s a scalar.</div></div>
<div class="ttc" id="aVectorization_8cpp_html_a5fd4201faa9fbc0aad08b5af06556cc8"><div class="ttname"><a href="Vectorization_8cpp.html#a5fd4201faa9fbc0aad08b5af06556cc8">extractConvFilterSlices</a></div><div class="ttdeci">static SmallVector&lt; Value &gt; extractConvFilterSlices(RewriterBase &amp;rewriter, Location loc, Value filter, int64_t kwSize)</div><div class="ttdoc">Helper function to extract the filter slices after filter is unrolled along kw.</div><div class="ttdef"><b>Definition</b> <a href="#l00145">Vectorization.cpp:145</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a66021212cd375df8f87b79b0f01b7e19"><div class="ttname"><a href="Vectorization_8cpp.html#a66021212cd375df8f87b79b0f01b7e19">hasReductionIterator</a></div><div class="ttdeci">static bool hasReductionIterator(LinalgOp &amp;op)</div><div class="ttdoc">Check if op is a linalg.reduce or a linalg.generic that has at least one reduction iterator.</div><div class="ttdef"><b>Definition</b> <a href="#l00718">Vectorization.cpp:718</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a765387385c36b8245aca7e886c0e98fb"><div class="ttname"><a href="Vectorization_8cpp.html#a765387385c36b8245aca7e886c0e98fb">CustomVectorizationPrecondition</a></div><div class="ttdeci">std::function&lt; LogicalResult(Operation *, bool)&gt; CustomVectorizationPrecondition</div><div class="ttdef"><b>Definition</b> <a href="#l00787">Vectorization.cpp:787</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a7e9ce28bca426dd4de93ad09392b4ec1"><div class="ttname"><a href="Vectorization_8cpp.html#a7e9ce28bca426dd4de93ad09392b4ec1">getTrailingNonUnitLoopDimIdx</a></div><div class="ttdeci">static uint64_t getTrailingNonUnitLoopDimIdx(LinalgOp linalgOp)</div><div class="ttdoc">Find the index of the trailing non-unit dim in linalgOp.</div><div class="ttdef"><b>Definition</b> <a href="#l00953">Vectorization.cpp:953</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a8019302085ef04a05864f2bb3f198f5c"><div class="ttname"><a href="Vectorization_8cpp.html#a8019302085ef04a05864f2bb3f198f5c">getCollapsedVecType</a></div><div class="ttdeci">static VectorType getCollapsedVecType(VectorType type, ArrayRef&lt; AffineMap &gt; reassociation)</div><div class="ttdoc">Given the re-associations, &quot;collapses&quot; the input Vector type.</div><div class="ttdef"><b>Definition</b> <a href="#l01773">Vectorization.cpp:1773</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a88081210ed22e2f80c50dd07348f3fec"><div class="ttname"><a href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fec">Conv1DOpOrder</a></div><div class="ttdeci">Conv1DOpOrder</div><div class="ttdoc">Helper enum to represent conv1d input traversal order.</div><div class="ttdef"><b>Definition</b> <a href="#l00606">Vectorization.cpp:606</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276"><div class="ttname"><a href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca61e9c06ea9a85a5088a499df6458d276">Conv1DOpOrder::W</a></div><div class="ttdeci">@ W</div><div class="ttdef"><b>Definition</b> <a href="#l00607">Vectorization.cpp:607</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741"><div class="ttname"><a href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3feca93d1093d4ebc345b0e2d3520c41ca741">Conv1DOpOrder::Ncw</a></div><div class="ttdeci">@ Ncw</div><div class="ttdef"><b>Definition</b> <a href="#l00608">Vectorization.cpp:608</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3"><div class="ttname"><a href="Vectorization_8cpp.html#a88081210ed22e2f80c50dd07348f3fecacca9538f495516027540f166e6ca3ba3">Conv1DOpOrder::Nwc</a></div><div class="ttdeci">@ Nwc</div><div class="ttdef"><b>Definition</b> <a href="#l00609">Vectorization.cpp:609</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a894a3a33f4cfc348a3aced8a058b550a"><div class="ttname"><a href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550a">VectorizationHookStatus</a></div><div class="ttdeci">VectorizationHookStatus</div><div class="ttdoc">Helper data structure to represent the result of vectorization for a single operation.</div><div class="ttdef"><b>Definition</b> <a href="#l00615">Vectorization.cpp:615</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661"><div class="ttname"><a href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aa6fb01c5d76aa5b0825fd3c52dc5f3661">Failure</a></div><div class="ttdeci">@ Failure</div><div class="ttdoc">Op failed to vectorize.</div><div class="ttdef"><b>Definition</b> <a href="#l00617">Vectorization.cpp:617</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6"><div class="ttname"><a href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaaaf8d13847a58092eb64f52b2bed99c6">NewOp</a></div><div class="ttdeci">@ NewOp</div><div class="ttdoc">Op vectorized into a new Op whose results will replace original Op&#39;s results.</div><div class="ttdef"><b>Definition</b> <a href="#l00622">Vectorization.cpp:622</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f"><div class="ttname"><a href="Vectorization_8cpp.html#a894a3a33f4cfc348a3aced8a058b550aaf97b2f48071b6944652bfffb71351c8f">NoReplace</a></div><div class="ttdeci">@ NoReplace</div><div class="ttdoc">Op vectorized and custom function took care of replacement logic.</div><div class="ttdef"><b>Definition</b> <a href="#l00619">Vectorization.cpp:619</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_aae426acd0929292f99ebde650870d27b"><div class="ttname"><a href="Vectorization_8cpp.html#aae426acd0929292f99ebde650870d27b">reduceIfNeeded</a></div><div class="ttdeci">static Operation * reduceIfNeeded(OpBuilder &amp;b, LinalgOp linalgOp, Operation *op, Value reduceValue, Value initialValue, const IRMapping &amp;bvm)</div><div class="ttdoc">Emit reduction operations if the shapes of the value to reduce is different that the result shape.</div><div class="ttdef"><b>Definition</b> <a href="#l01301">Vectorization.cpp:1301</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ab37ae3178304b744d6b0249a60a6e7a3"><div class="ttname"><a href="Vectorization_8cpp.html#ab37ae3178304b744d6b0249a60a6e7a3">getSingleOpOfType</a></div><div class="ttdeci">static OpType getSingleOpOfType(Block &amp;block)</div><div class="ttdoc">Return the unique instance of OpType in block if it is indeed unique.</div><div class="ttdef"><b>Definition</b> <a href="#l00093">Vectorization.cpp:93</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ac9d5de1ac70bcbcc2f773e554a39bd1e"><div class="ttname"><a href="Vectorization_8cpp.html#ac9d5de1ac70bcbcc2f773e554a39bd1e">CustomVectorizationHook</a></div><div class="ttdeci">std::function&lt; VectorizationHookResult(Operation *, const IRMapping &amp;)&gt; CustomVectorizationHook</div><div class="ttdef"><b>Definition</b> <a href="#l00793">Vectorization.cpp:793</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ace2ca9537983c711e37b040688830950"><div class="ttname"><a href="Vectorization_8cpp.html#ace2ca9537983c711e37b040688830950">reindexIndexingMap</a></div><div class="ttdeci">static AffineMap reindexIndexingMap(AffineMap map)</div><div class="ttdoc">Given an indexing map coming from a LinalgOp indexing, restricted to a projectedPermutation,...</div><div class="ttdef"><b>Definition</b> <a href="#l00595">Vectorization.cpp:595</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ad09df73d48432e3de8291c7076164ba7"><div class="ttname"><a href="Vectorization_8cpp.html#ad09df73d48432e3de8291c7076164ba7">tensorExtractVectorizationPrecondition</a></div><div class="ttdeci">static LogicalResult tensorExtractVectorizationPrecondition(Operation *op, bool vectorizeNDExtract)</div><div class="ttdoc">Helper function to check if the tensor.extract can be vectorized by the custom hook vectorizeTensorEx...</div><div class="ttdef"><b>Definition</b> <a href="#l00872">Vectorization.cpp:872</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ae3a45e985a37cbb4db1c7c23ce0d9e9f"><div class="ttname"><a href="Vectorization_8cpp.html#ae3a45e985a37cbb4db1c7c23ce0d9e9f">broadcastIfNeeded</a></div><div class="ttdeci">static Value broadcastIfNeeded(OpBuilder &amp;b, Value value, Type dstType)</div><div class="ttdoc">Broadcast value to a vector of shape if possible.</div><div class="ttdef"><b>Definition</b> <a href="#l00685">Vectorization.cpp:685</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_ae4411a5d89520c86474035493a7da7c1"><div class="ttname"><a href="Vectorization_8cpp.html#ae4411a5d89520c86474035493a7da7c1">calculateGatherOffset</a></div><div class="ttdeci">static Value calculateGatherOffset(RewriterBase &amp;rewriter, VectorizationState &amp;state, tensor::ExtractOp extractOp, const IRMapping &amp;bvm)</div><div class="ttdoc">Calculates the offsets ($index_vec) for vector.gather operations generated from tensor....</div><div class="ttdef"><b>Definition</b> <a href="#l00905">Vectorization.cpp:905</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_af0d6a3da24bf08205af9661c55447701"><div class="ttname"><a href="Vectorization_8cpp.html#af0d6a3da24bf08205af9661c55447701">extractConvResultSlices</a></div><div class="ttdeci">static SmallVector&lt; Value &gt; extractConvResultSlices(RewriterBase &amp;rewriter, Location loc, Value res, int64_t nSize, int64_t wSize, int64_t fSize, int64_t wSizeStep, bool isSingleChanneled)</div><div class="ttdoc">Helper function to extract the result slices after filter is unrolled along kw.</div><div class="ttdef"><b>Definition</b> <a href="#l00161">Vectorization.cpp:161</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_af2f7690c564bae0d01129c661bfcb1f3"><div class="ttname"><a href="Vectorization_8cpp.html#af2f7690c564bae0d01129c661bfcb1f3">isContiguousLoadIdx</a></div><div class="ttdeci">static bool isContiguousLoadIdx(LinalgOp &amp;linalgOp, Value &amp;val, bool &amp;foundIndexOp, VectorType resType)</div><div class="ttdoc">Check whether val could be used for calculating the trailing index for a contiguous load operation.</div><div class="ttdef"><b>Definition</b> <a href="#l01030">Vectorization.cpp:1030</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_af85a26f7c1860388d0e83d22745a27aa"><div class="ttname"><a href="Vectorization_8cpp.html#af85a26f7c1860388d0e83d22745a27aa">vectorizeLinalgYield</a></div><div class="ttdeci">static VectorizationHookResult vectorizeLinalgYield(RewriterBase &amp;rewriter, Operation *op, const IRMapping &amp;bvm, VectorizationState &amp;state, LinalgOp linalgOp, SmallVectorImpl&lt; Value &gt; &amp;newResults)</div><div class="ttdoc">Helper function to vectorize the terminator of a linalgOp.</div><div class="ttdef"><b>Definition</b> <a href="#l00804">Vectorization.cpp:804</a></div></div>
<div class="ttc" id="aVectorization_8cpp_html_af936802591fc5ba398ba106887feac8f"><div class="ttname"><a href="Vectorization_8cpp.html#af936802591fc5ba398ba106887feac8f">buildMultiDimReduce</a></div><div class="ttdeci">static Operation * buildMultiDimReduce(OpBuilder &amp;b, Operation *reduceOp, Value valueToReduce, Value acc, ArrayRef&lt; bool &gt; dimsToMask)</div><div class="ttdoc">Create MultiDimReductionOp to compute the reduction for reductionOp.</div><div class="ttdef"><b>Definition</b> <a href="#l00702">Vectorization.cpp:702</a></div></div>
<div class="ttc" id="aXeGPUDialect_8cpp_html_a0da29b54f1662523e9e9da60dde8b629"><div class="ttname"><a href="XeGPUDialect_8cpp.html#a0da29b54f1662523e9e9da60dde8b629">mul</a></div><div class="ttdeci">#define mul(a, b)</div><div class="ttdef"><b>Definition</b> <a href="XeGPUDialect_8cpp_source.html#l00972">XeGPUDialect.cpp:972</a></div></div>
<div class="ttc" id="aclassint64__t_html"><div class="ttname"><a href="classint64__t.html">int64_t</a></div></div>
<div class="ttc" id="aclassllvm_1_1ArrayRef_html"><div class="ttname"><a href="classllvm_1_1ArrayRef.html">llvm::ArrayRef</a></div><div class="ttdef"><b>Definition</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00048">LLVM.h:48</a></div></div>
<div class="ttc" id="aclassllvm_1_1SmallVectorImpl_html"><div class="ttname"><a href="classllvm_1_1SmallVectorImpl.html">llvm::SmallVectorImpl</a></div><div class="ttdef"><b>Definition</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00074">LLVM.h:74</a></div></div>
<div class="ttc" id="aclassllvm_1_1SmallVector_html"><div class="ttname"><a href="classllvm_1_1SmallVector.html">llvm::SmallVector</a></div><div class="ttdef"><b>Definition</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00072">LLVM.h:72</a></div></div>
<div class="ttc" id="aclassllvm_1_1TypeSwitch_html"><div class="ttname"><a href="classllvm_1_1TypeSwitch.html">llvm::TypeSwitch</a></div><div class="ttdef"><b>Definition</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00082">LLVM.h:82</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineDimExpr_html"><div class="ttname"><a href="classmlir_1_1AffineDimExpr.html">mlir::AffineDimExpr</a></div><div class="ttdoc">A dimensional identifier appearing in an affine expression.</div><div class="ttdef"><b>Definition</b> <a href="mlir_2IR_2AffineExpr_8h_source.html#l00223">AffineExpr.h:223</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html"><div class="ttname"><a href="classmlir_1_1AffineMap.html">mlir::AffineMap</a></div><div class="ttdoc">A multi-dimensional affine map Affine map&#39;s are immutable like Type&#39;s, and they are uniqued.</div><div class="ttdef"><b>Definition</b> <a href="mlir_2IR_2AffineMap_8h_source.html#l00046">AffineMap.h:46</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a035fc7c93286e3aa0354f522f2cd885a"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a035fc7c93286e3aa0354f522f2cd885a">mlir::AffineMap::getMinorIdentityMap</a></div><div class="ttdeci">static AffineMap getMinorIdentityMap(unsigned dims, unsigned results, MLIRContext *context)</div><div class="ttdoc">Returns an identity affine map (d0, ..., dn) -&gt; (dp, ..., dn) on the most minor dimensions.</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00131">AffineMap.cpp:131</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a07ce6ee55edc21c008a3bf8d10a2d726"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a07ce6ee55edc21c008a3bf8d10a2d726">mlir::AffineMap::getContext</a></div><div class="ttdeci">MLIRContext * getContext() const</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00339">AffineMap.cpp:339</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a39ed2c2a4c743450a4a999fa6db1bf84"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a39ed2c2a4c743450a4a999fa6db1bf84">mlir::AffineMap::getMultiDimIdentityMap</a></div><div class="ttdeci">static AffineMap getMultiDimIdentityMap(unsigned numDims, MLIRContext *context)</div><div class="ttdoc">Returns an AffineMap with &#39;numDims&#39; identity result dim exprs.</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00330">AffineMap.cpp:330</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a3cfca2eb29fddf3c4bda714cccaa53f9"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a3cfca2eb29fddf3c4bda714cccaa53f9">mlir::AffineMap::get</a></div><div class="ttdeci">static AffineMap get(MLIRContext *context)</div><div class="ttdoc">Returns a zero result affine map with no dimensions or symbols: () -&gt; ().</div><div class="ttdef"><b>Definition</b> <a href="MLIRContext_8cpp_source.html#l01224">MLIRContext.cpp:1224</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a457a8530ceb03d15e3b171ea3a9fc4a6"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a457a8530ceb03d15e3b171ea3a9fc4a6">mlir::AffineMap::isProjectedPermutation</a></div><div class="ttdeci">bool isProjectedPermutation(bool allowZeroInResults=false) const</div><div class="ttdoc">Returns true if the AffineMap represents a subset (i.e.</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00611">AffineMap.cpp:611</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a96f194ae3b4baf33c67b10c9f795b564"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a96f194ae3b4baf33c67b10c9f795b564">mlir::AffineMap::getNumResults</a></div><div class="ttdeci">unsigned getNumResults() const</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00398">AffineMap.cpp:398</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_aa821f07143bcad97d6df532c232129a3"><div class="ttname"><a href="classmlir_1_1AffineMap.html#aa821f07143bcad97d6df532c232129a3">mlir::AffineMap::getNumInputs</a></div><div class="ttdeci">unsigned getNumInputs() const</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00399">AffineMap.cpp:399</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_ac60458b2cba87d765341cd6b2d41ed12"><div class="ttname"><a href="classmlir_1_1AffineMap.html#ac60458b2cba87d765341cd6b2d41ed12">mlir::AffineMap::getResult</a></div><div class="ttdeci">AffineExpr getResult(unsigned idx) const</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00407">AffineMap.cpp:407</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_ac64464574634cca5ffcd023227260414"><div class="ttname"><a href="classmlir_1_1AffineMap.html#ac64464574634cca5ffcd023227260414">mlir::AffineMap::getFilteredIdentityMap</a></div><div class="ttdeci">static AffineMap getFilteredIdentityMap(MLIRContext *ctx, unsigned numDims, llvm::function_ref&lt; bool(AffineDimExpr)&gt; keepDimFilter)</div><div class="ttdoc">Returns an identity affine map with numDims input dimensions and filtered results using keepDimFilter...</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00138">AffineMap.cpp:138</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_ac8532830efc67348905fd1e414beaebb"><div class="ttname"><a href="classmlir_1_1AffineMap.html#ac8532830efc67348905fd1e414beaebb">mlir::AffineMap::dropZeroResults</a></div><div class="ttdeci">AffineMap dropZeroResults()</div><div class="ttdoc">Returns the AffineMap resulting from removing &quot;zero&quot; results (constant values == 0) from this map.</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00600">AffineMap.cpp:600</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_acd08312b1039c20f008d2f6785c47816"><div class="ttname"><a href="classmlir_1_1AffineMap.html#acd08312b1039c20f008d2f6785c47816">mlir::AffineMap::getPermutationMap</a></div><div class="ttdeci">static AffineMap getPermutationMap(ArrayRef&lt; unsigned &gt; permutation, MLIRContext *context)</div><div class="ttdoc">Returns an AffineMap representing a permutation.</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00260">AffineMap.cpp:260</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_acf141c61521d9a40ba68c0b350a31836"><div class="ttname"><a href="classmlir_1_1AffineMap.html#acf141c61521d9a40ba68c0b350a31836">mlir::AffineMap::getBroadcastDims</a></div><div class="ttdeci">SmallVector&lt; unsigned &gt; getBroadcastDims() const</div><div class="ttdoc">Returns the list of broadcast dimensions (i.e.</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00157">AffineMap.cpp:157</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_af2baf4561cf7d74a9959fd9e875c9a82"><div class="ttname"><a href="classmlir_1_1AffineMap.html#af2baf4561cf7d74a9959fd9e875c9a82">mlir::AffineMap::compose</a></div><div class="ttdeci">AffineMap compose(AffineMap map) const</div><div class="ttdoc">Returns the AffineMap resulting from composing this with map.</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00552">AffineMap.cpp:552</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_af6e665372add0df0668e1ebd231488b4"><div class="ttname"><a href="classmlir_1_1AffineMap.html#af6e665372add0df0668e1ebd231488b4">mlir::AffineMap::isPermutation</a></div><div class="ttdeci">bool isPermutation() const</div><div class="ttdoc">Returns true if the AffineMap represents a symbol-less permutation map.</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00641">AffineMap.cpp:641</a></div></div>
<div class="ttc" id="aclassmlir_1_1BlockArgument_html"><div class="ttname"><a href="classmlir_1_1BlockArgument.html">mlir::BlockArgument</a></div><div class="ttdoc">This class represents an argument of a Block.</div><div class="ttdef"><b>Definition</b> <a href="Value_8h_source.html#l00309">Value.h:309</a></div></div>
<div class="ttc" id="aclassmlir_1_1BlockArgument_html_a5396ce59c00cd3ef7a8a500c59af295c"><div class="ttname"><a href="classmlir_1_1BlockArgument.html#a5396ce59c00cd3ef7a8a500c59af295c">mlir::BlockArgument::getArgNumber</a></div><div class="ttdeci">unsigned getArgNumber() const</div><div class="ttdoc">Returns the number of this argument.</div><div class="ttdef"><b>Definition</b> <a href="Value_8h_source.html#l00321">Value.h:321</a></div></div>
<div class="ttc" id="aclassmlir_1_1Block_html"><div class="ttname"><a href="classmlir_1_1Block.html">mlir::Block</a></div><div class="ttdoc">Block represents an ordered list of Operations.</div><div class="ttdef"><b>Definition</b> <a href="Block_8h_source.html#l00032">Block.h:33</a></div></div>
<div class="ttc" id="aclassmlir_1_1Block_html_a522e33225c6c47ffd8a36588483e0bd9"><div class="ttname"><a href="classmlir_1_1Block.html#a522e33225c6c47ffd8a36588483e0bd9">mlir::Block::getOperations</a></div><div class="ttdeci">OpListType &amp; getOperations()</div><div class="ttdef"><b>Definition</b> <a href="Block_8h_source.html#l00137">Block.h:137</a></div></div>
<div class="ttc" id="aclassmlir_1_1Block_html_a790af2827870ed217e85447b8ed8559c"><div class="ttname"><a href="classmlir_1_1Block.html#a790af2827870ed217e85447b8ed8559c">mlir::Block::walk</a></div><div class="ttdeci">RetT walk(FnT &amp;&amp;callback)</div><div class="ttdoc">Walk all nested operations, blocks (including this block) or regions, depending on the type of callba...</div><div class="ttdef"><b>Definition</b> <a href="Block_8h_source.html#l00308">Block.h:308</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_a422a9ab33af4134efcb4044fb81deab1"><div class="ttname"><a href="classmlir_1_1Builder.html#a422a9ab33af4134efcb4044fb81deab1">mlir::Builder::getMultiDimIdentityMap</a></div><div class="ttdeci">AffineMap getMultiDimIdentityMap(unsigned rank)</div><div class="ttdef"><b>Definition</b> <a href="Builders_8cpp_source.html#l00387">Builders.cpp:387</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_a8e943986e58a8b0c88fcd51b0f0afafb"><div class="ttname"><a href="classmlir_1_1Builder.html#a8e943986e58a8b0c88fcd51b0f0afafb">mlir::Builder::getZeroAttr</a></div><div class="ttdeci">TypedAttr getZeroAttr(Type type)</div><div class="ttdef"><b>Definition</b> <a href="Builders_8cpp_source.html#l00324">Builders.cpp:324</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_ac68228481d9deafab913889e4fb01886"><div class="ttname"><a href="classmlir_1_1Builder.html#ac68228481d9deafab913889e4fb01886">mlir::Builder::getI1Type</a></div><div class="ttdeci">IntegerType getI1Type()</div><div class="ttdef"><b>Definition</b> <a href="Builders_8cpp_source.html#l00053">Builders.cpp:53</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_ac9e0170e1b16f9c7464823b7b2fcb042"><div class="ttname"><a href="classmlir_1_1Builder.html#ac9e0170e1b16f9c7464823b7b2fcb042">mlir::Builder::getArrayAttr</a></div><div class="ttdeci">ArrayAttr getArrayAttr(ArrayRef&lt; Attribute &gt; value)</div><div class="ttdef"><b>Definition</b> <a href="Builders_8cpp_source.html#l00266">Builders.cpp:266</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_acbdddd0c6fa53e5605c93109ad00953b"><div class="ttname"><a href="classmlir_1_1Builder.html#acbdddd0c6fa53e5605c93109ad00953b">mlir::Builder::getContext</a></div><div class="ttdeci">MLIRContext * getContext() const</div><div class="ttdef"><b>Definition</b> <a href="Builders_8h_source.html#l00056">Builders.h:56</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_ace585fd315aa2ebcc7bb87e18483f5b4"><div class="ttname"><a href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">mlir::Builder::getIndexType</a></div><div class="ttdeci">IndexType getIndexType()</div><div class="ttdef"><b>Definition</b> <a href="Builders_8cpp_source.html#l00051">Builders.cpp:51</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_af40fe132a1059a68679775fa4c06666b"><div class="ttname"><a href="classmlir_1_1Builder.html#af40fe132a1059a68679775fa4c06666b">mlir::Builder::getBoolArrayAttr</a></div><div class="ttdeci">ArrayAttr getBoolArrayAttr(ArrayRef&lt; bool &gt; values)</div><div class="ttdef"><b>Definition</b> <a href="Builders_8cpp_source.html#l00270">Builders.cpp:270</a></div></div>
<div class="ttc" id="aclassmlir_1_1DenseIntElementsAttr_html_a9db4e0b61c851fb050659e8a3cd4f4a0"><div class="ttname"><a href="classmlir_1_1DenseIntElementsAttr.html#a9db4e0b61c851fb050659e8a3cd4f4a0">mlir::DenseIntElementsAttr::get</a></div><div class="ttdeci">static DenseIntElementsAttr get(const ShapedType &amp;type, Arg &amp;&amp;arg)</div><div class="ttdoc">Get an instance of a DenseIntElementsAttr with the given arguments.</div><div class="ttdef"><b>Definition</b> <a href="mlir_2IR_2BuiltinAttributes_8h_source.html#l00963">BuiltinAttributes.h:963</a></div></div>
<div class="ttc" id="aclassmlir_1_1IRMapping_html"><div class="ttname"><a href="classmlir_1_1IRMapping.html">mlir::IRMapping</a></div><div class="ttdoc">This is a utility class for mapping one set of IR entities to another.</div><div class="ttdef"><b>Definition</b> <a href="IRMapping_8h_source.html#l00026">IRMapping.h:26</a></div></div>
<div class="ttc" id="aclassmlir_1_1IRMapping_html_a3c0a75333d64669ef09490fc43218569"><div class="ttname"><a href="classmlir_1_1IRMapping.html#a3c0a75333d64669ef09490fc43218569">mlir::IRMapping::lookup</a></div><div class="ttdeci">auto lookup(T from) const</div><div class="ttdoc">Lookup a mapped value within the map.</div><div class="ttdef"><b>Definition</b> <a href="IRMapping_8h_source.html#l00072">IRMapping.h:72</a></div></div>
<div class="ttc" id="aclassmlir_1_1IRMapping_html_a9e4259707f73d5c85210c6c076a782bd"><div class="ttname"><a href="classmlir_1_1IRMapping.html#a9e4259707f73d5c85210c6c076a782bd">mlir::IRMapping::map</a></div><div class="ttdeci">void map(Value from, Value to)</div><div class="ttdoc">Inserts a new mapping for &#39;from&#39; to &#39;to&#39;.</div><div class="ttdef"><b>Definition</b> <a href="IRMapping_8h_source.html#l00030">IRMapping.h:30</a></div></div>
<div class="ttc" id="aclassmlir_1_1IROperand_html_a015cbc633653c0c763dca72a22b0e087"><div class="ttname"><a href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">mlir::IROperand::get</a></div><div class="ttdeci">IRValueT get() const</div><div class="ttdoc">Return the current value being used by this operand.</div><div class="ttdef"><b>Definition</b> <a href="UseDefLists_8h_source.html#l00160">UseDefLists.h:160</a></div></div>
<div class="ttc" id="aclassmlir_1_1Location_html"><div class="ttname"><a href="classmlir_1_1Location.html">mlir::Location</a></div><div class="ttdoc">This class defines the main interface for locations in MLIR and acts as a non-nullable wrapper around...</div><div class="ttdef"><b>Definition</b> <a href="Location_8h_source.html#l00076">Location.h:76</a></div></div>
<div class="ttc" id="aclassmlir_1_1MLIRContext_html"><div class="ttname"><a href="classmlir_1_1MLIRContext.html">mlir::MLIRContext</a></div><div class="ttdoc">MLIRContext is the top-level object for a collection of MLIR operations.</div><div class="ttdef"><b>Definition</b> <a href="MLIRContext_8h_source.html#l00063">MLIRContext.h:63</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html"><div class="ttname"><a href="classmlir_1_1OpBuilder.html">mlir::OpBuilder</a></div><div class="ttdoc">This class helps build Operations.</div><div class="ttdef"><b>Definition</b> <a href="Builders_8h_source.html#l00207">Builders.h:207</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_a394cad81296b42a24e1c37b045e15359"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#a394cad81296b42a24e1c37b045e15359">mlir::OpBuilder::clone</a></div><div class="ttdeci">Operation * clone(Operation &amp;op, IRMapping &amp;mapper)</div><div class="ttdoc">Creates a deep copy of the specified operation, remapping any operands that use values outside of the...</div><div class="ttdef"><b>Definition</b> <a href="Builders_8cpp_source.html#l00562">Builders.cpp:562</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_a4853433035d219e56febdb51d1b531cd"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">mlir::OpBuilder::setInsertionPoint</a></div><div class="ttdeci">void setInsertionPoint(Block *block, Block::iterator insertPoint)</div><div class="ttdoc">Set the insertion point to the specified location.</div><div class="ttdef"><b>Definition</b> <a href="Builders_8h_source.html#l00398">Builders.h:398</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_a9bfa9ca1c08777d5eba6276c24c0cf9a"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#a9bfa9ca1c08777d5eba6276c24c0cf9a">mlir::OpBuilder::createOrFold</a></div><div class="ttdeci">void createOrFold(SmallVectorImpl&lt; Value &gt; &amp;results, Location location, Args &amp;&amp;...args)</div><div class="ttdoc">Create an operation of specific op type at the current insertion point, and immediately try to fold i...</div><div class="ttdef"><b>Definition</b> <a href="Builders_8h_source.html#l00526">Builders.h:526</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_ac6a6edadd39800db410864ef06a004b2"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#ac6a6edadd39800db410864ef06a004b2">mlir::OpBuilder::create</a></div><div class="ttdeci">Operation * create(const OperationState &amp;state)</div><div class="ttdoc">Creates an operation given the fields represented as an OperationState.</div><div class="ttdef"><b>Definition</b> <a href="Builders_8cpp_source.html#l00457">Builders.cpp:457</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpOperand_html"><div class="ttname"><a href="classmlir_1_1OpOperand.html">mlir::OpOperand</a></div><div class="ttdoc">This class represents an operand of an operation.</div><div class="ttdef"><b>Definition</b> <a href="Value_8h_source.html#l00257">Value.h:257</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpOperand_html_a097f9026defd8afd19ab06b21aa11bdf"><div class="ttname"><a href="classmlir_1_1OpOperand.html#a097f9026defd8afd19ab06b21aa11bdf">mlir::OpOperand::getOperandNumber</a></div><div class="ttdeci">unsigned getOperandNumber()</div><div class="ttdoc">Return which operand this is in the OpOperand list of the Operation.</div><div class="ttdef"><b>Definition</b> <a href="Value_8cpp_source.html#l00226">Value.cpp:226</a></div></div>
<div class="ttc" id="aclassmlir_1_1OperationName_html_a2c83cffa9a4c4fb68436d9ee3497c226"><div class="ttname"><a href="classmlir_1_1OperationName.html#a2c83cffa9a4c4fb68436d9ee3497c226">mlir::OperationName::getIdentifier</a></div><div class="ttdeci">StringAttr getIdentifier() const</div><div class="ttdoc">Return the name of this operation as a StringAttr.</div><div class="ttdef"><b>Definition</b> <a href="OperationSupport_8h_source.html#l00476">OperationSupport.h:476</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html"><div class="ttname"><a href="classmlir_1_1Operation.html">mlir::Operation</a></div><div class="ttdoc">Operation is the basic unit of execution within MLIR.</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00084">Operation.h:88</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a1eecfffb7445e24f9fbdec2d619251ff"><div class="ttname"><a href="classmlir_1_1Operation.html#a1eecfffb7445e24f9fbdec2d619251ff">mlir::Operation::getOperand</a></div><div class="ttdeci">Value getOperand(unsigned idx)</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00350">Operation.h:350</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a3cfc1046bad9638cf68c7add9efa6c33"><div class="ttname"><a href="classmlir_1_1Operation.html#a3cfc1046bad9638cf68c7add9efa6c33">mlir::Operation::isBeforeInBlock</a></div><div class="ttdeci">bool isBeforeInBlock(Operation *other)</div><div class="ttdoc">Given an operation &#39;other&#39; that is within the same parent block, return whether the current operation...</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8cpp_source.html#l00383">Operation.cpp:383</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a49874022040c036fac50ce8f07668a76"><div class="ttname"><a href="classmlir_1_1Operation.html#a49874022040c036fac50ce8f07668a76">mlir::Operation::getAttrs</a></div><div class="ttdeci">ArrayRef&lt; NamedAttribute &gt; getAttrs()</div><div class="ttdoc">Return all of the attributes on this operation.</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00512">Operation.h:512</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a52ddd1dbf469abfbb77ab130119070f3"><div class="ttname"><a href="classmlir_1_1Operation.html#a52ddd1dbf469abfbb77ab130119070f3">mlir::Operation::getBlock</a></div><div class="ttdeci">Block * getBlock()</div><div class="ttdoc">Returns the operation block that contains this operation.</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00213">Operation.h:213</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a56f58b55c803b3313da7b4a04a3d542d"><div class="ttname"><a href="classmlir_1_1Operation.html#a56f58b55c803b3313da7b4a04a3d542d">mlir::Operation::getResult</a></div><div class="ttdeci">OpResult getResult(unsigned idx)</div><div class="ttdoc">Get the &#39;idx&#39;th result of this operation.</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00407">Operation.h:407</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a6c0b8ce5ff714a34f0192f3aa60dc7ea"><div class="ttname"><a href="classmlir_1_1Operation.html#a6c0b8ce5ff714a34f0192f3aa60dc7ea">mlir::Operation::getLoc</a></div><div class="ttdeci">Location getLoc()</div><div class="ttdoc">The source location the operation was defined or derived from.</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00223">Operation.h:223</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a80db2165a86e0837b30f5f3e0dc899df"><div class="ttname"><a href="classmlir_1_1Operation.html#a80db2165a86e0837b30f5f3e0dc899df">mlir::Operation::getNumOperands</a></div><div class="ttdeci">unsigned getNumOperands()</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00346">Operation.h:346</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a9d3b09f8e60b126070e82957d78d9fd0"><div class="ttname"><a href="classmlir_1_1Operation.html#a9d3b09f8e60b126070e82957d78d9fd0">mlir::Operation::operand_end</a></div><div class="ttdeci">operand_iterator operand_end()</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00375">Operation.h:375</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_ab2e11ba83ff765eb7595554f97aaaa75"><div class="ttname"><a href="classmlir_1_1Operation.html#ab2e11ba83ff765eb7595554f97aaaa75">mlir::Operation::getName</a></div><div class="ttdeci">OperationName getName()</div><div class="ttdoc">The name of an operation is the key identifier for it.</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00119">Operation.h:119</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_ac3095b4b7756a4974ba1c21b0e8ed762"><div class="ttname"><a href="classmlir_1_1Operation.html#ac3095b4b7756a4974ba1c21b0e8ed762">mlir::Operation::getResultTypes</a></div><div class="ttdeci">result_type_range getResultTypes()</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00428">Operation.h:428</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_ac632a7783f8ec353f79c4f17cb188454"><div class="ttname"><a href="classmlir_1_1Operation.html#ac632a7783f8ec353f79c4f17cb188454">mlir::Operation::getOperands</a></div><div class="ttdeci">operand_range getOperands()</div><div class="ttdoc">Returns an iterator on the underlying Value&#39;s.</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00378">Operation.h:378</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_ad79736dd29f14a220af56d7fb37d4bc3"><div class="ttname"><a href="classmlir_1_1Operation.html#ad79736dd29f14a220af56d7fb37d4bc3">mlir::Operation::getResults</a></div><div class="ttdeci">result_range getResults()</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00415">Operation.h:415</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_afeb237ab61bc6c18e133da3060a7fbfb"><div class="ttname"><a href="classmlir_1_1Operation.html#afeb237ab61bc6c18e133da3060a7fbfb">mlir::Operation::getNumResults</a></div><div class="ttdeci">unsigned getNumResults()</div><div class="ttdoc">Return the number of results held by this operation.</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8h_source.html#l00404">Operation.h:404</a></div></div>
<div class="ttc" id="aclassmlir_1_1PatternBenefit_html_af19d7a934078c6de5512543eea299579"><div class="ttname"><a href="classmlir_1_1PatternBenefit.html#af19d7a934078c6de5512543eea299579">mlir::PatternBenefit::getBenefit</a></div><div class="ttdeci">unsigned short getBenefit() const</div><div class="ttdoc">If the corresponding pattern can match, return its benefit. If the.</div><div class="ttdef"><b>Definition</b> <a href="PatternMatch_8cpp_source.html#l00025">PatternMatch.cpp:25</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html"><div class="ttname"><a href="classmlir_1_1RewriterBase.html">mlir::RewriterBase</a></div><div class="ttdoc">This class coordinates the application of a rewrite on a set of IR, providing a way for clients to tr...</div><div class="ttdef"><b>Definition</b> <a href="PatternMatch_8h_source.html#l00368">PatternMatch.h:368</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a53c88f3ce889be590b3801b4ddee627f"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">mlir::RewriterBase::replaceOp</a></div><div class="ttdeci">virtual void replaceOp(Operation *op, ValueRange newValues)</div><div class="ttdoc">Replace the results of the given (original) operation with the specified list of values (replacements...</div><div class="ttdef"><b>Definition</b> <a href="PatternMatch_8cpp_source.html#l00127">PatternMatch.cpp:127</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a786138ac6a91e0932da343ef5c6f1e70"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">mlir::RewriterBase::eraseOp</a></div><div class="ttdeci">virtual void eraseOp(Operation *op)</div><div class="ttdoc">This method erases an operation that is known to have no uses.</div><div class="ttdef"><b>Definition</b> <a href="PatternMatch_8cpp_source.html#l00155">PatternMatch.cpp:155</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a9bc0bf42591d2bf716733ed23bb8b6e6"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a9bc0bf42591d2bf716733ed23bb8b6e6">mlir::RewriterBase::replaceAllUsesExcept</a></div><div class="ttdeci">void replaceAllUsesExcept(Value from, Value to, Operation *exceptedUser)</div><div class="ttdoc">Find uses of from and replace them with to except if the user is exceptedUser.</div><div class="ttdef"><b>Definition</b> <a href="PatternMatch_8h_source.html#l00710">PatternMatch.h:710</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_ab8519ac3c220b4bb9674fdb368d36437"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#ab8519ac3c220b4bb9674fdb368d36437">mlir::RewriterBase::notifyMatchFailure</a></div><div class="ttdeci">std::enable_if_t&lt;!std::is_convertible&lt; CallbackT, Twine &gt;::value, LogicalResult &gt; notifyMatchFailure(Location loc, CallbackT &amp;&amp;reasonCallback)</div><div class="ttdoc">Used to notify the listener that the IR failed to be rewritten because of a match failure,...</div><div class="ttdef"><b>Definition</b> <a href="PatternMatch_8h_source.html#l00726">PatternMatch.h:726</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_abd8bae753b51386417536a36cf52d3f7"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#abd8bae753b51386417536a36cf52d3f7">mlir::RewriterBase::modifyOpInPlace</a></div><div class="ttdeci">void modifyOpInPlace(Operation *root, CallableT &amp;&amp;callable)</div><div class="ttdoc">This method is a utility wrapper around an in-place modification of an operation.</div><div class="ttdef"><b>Definition</b> <a href="PatternMatch_8h_source.html#l00638">PatternMatch.h:638</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_afb1c910a57707f518d2b9c903c2bb5bc"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#afb1c910a57707f518d2b9c903c2bb5bc">mlir::RewriterBase::replaceOpWithNewOp</a></div><div class="ttdeci">OpTy replaceOpWithNewOp(Operation *op, Args &amp;&amp;...args)</div><div class="ttdoc">Replace the results of the given (original) op with a new op that is created without verification (re...</div><div class="ttdef"><b>Definition</b> <a href="PatternMatch_8h_source.html#l00529">PatternMatch.h:529</a></div></div>
<div class="ttc" id="aclassmlir_1_1Type_html"><div class="ttname"><a href="classmlir_1_1Type.html">mlir::Type</a></div><div class="ttdoc">Instances of the Type class are uniqued, have an immutable identifier and an optional mutable compone...</div><div class="ttdef"><b>Definition</b> <a href="IR_2Types_8h_source.html#l00074">Types.h:74</a></div></div>
<div class="ttc" id="aclassmlir_1_1Type_html_a5d5d5335ce4fc906636a2690155a7d72"><div class="ttname"><a href="classmlir_1_1Type.html#a5d5d5335ce4fc906636a2690155a7d72">mlir::Type::isIndex</a></div><div class="ttdeci">bool isIndex() const</div><div class="ttdef"><b>Definition</b> <a href="IR_2Types_8cpp_source.html#l00054">Types.cpp:54</a></div></div>
<div class="ttc" id="aclassmlir_1_1Type_html_aeb142623709910125e07ecf1f9f2cdd5"><div class="ttname"><a href="classmlir_1_1Type.html#aeb142623709910125e07ecf1f9f2cdd5">mlir::Type::getIntOrFloatBitWidth</a></div><div class="ttdeci">unsigned getIntOrFloatBitWidth() const</div><div class="ttdoc">Return the bit width of an integer or a float type, assert failure on other types.</div><div class="ttdef"><b>Definition</b> <a href="IR_2Types_8cpp_source.html#l00122">Types.cpp:122</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html"><div class="ttname"><a href="classmlir_1_1Value.html">mlir::Value</a></div><div class="ttdoc">This class represents an instance of an SSA value in the MLIR system, representing a computable value...</div><div class="ttdef"><b>Definition</b> <a href="Value_8h_source.html#l00096">Value.h:96</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_a5348fc13d5201e2adf7ded6b4b2fb1ad"><div class="ttname"><a href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">mlir::Value::getType</a></div><div class="ttdeci">Type getType() const</div><div class="ttdoc">Return the type of this value.</div><div class="ttdef"><b>Definition</b> <a href="Value_8h_source.html#l00105">Value.h:105</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_a5adc50e42183f2f503143918a296da9d"><div class="ttname"><a href="classmlir_1_1Value.html#a5adc50e42183f2f503143918a296da9d">mlir::Value::getUses</a></div><div class="ttdeci">use_range getUses() const</div><div class="ttdoc">Returns a range of all uses, which is useful for iterating over all uses.</div><div class="ttdef"><b>Definition</b> <a href="Value_8h_source.html#l00188">Value.h:188</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_ae9df8c75072dbaab98cd4b7cd82b6ebc"><div class="ttname"><a href="classmlir_1_1Value.html#ae9df8c75072dbaab98cd4b7cd82b6ebc">mlir::Value::getLoc</a></div><div class="ttdeci">Location getLoc() const</div><div class="ttdoc">Return the location of this value.</div><div class="ttdef"><b>Definition</b> <a href="Value_8cpp_source.html#l00024">Value.cpp:24</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_aed80a742a36c5b3298467ce5d01738c8"><div class="ttname"><a href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">mlir::Value::getDefiningOp</a></div><div class="ttdeci">Operation * getDefiningOp() const</div><div class="ttdoc">If this value is the result of an operation, return the operation that defines it.</div><div class="ttdef"><b>Definition</b> <a href="Value_8cpp_source.html#l00018">Value.cpp:18</a></div></div>
<div class="ttc" id="aclassmlir_1_1WalkResult_html_a97a7015a793bb5d2a97f08e358f42797"><div class="ttname"><a href="classmlir_1_1WalkResult.html#a97a7015a793bb5d2a97f08e358f42797">mlir::WalkResult::advance</a></div><div class="ttdeci">static WalkResult advance()</div><div class="ttdef"><b>Definition</b> <a href="WalkResult_8h_source.html#l00047">WalkResult.h:47</a></div></div>
<div class="ttc" id="aclassmlir_1_1WalkResult_html_abab80dca5987e18f9abf08162cd3faaa"><div class="ttname"><a href="classmlir_1_1WalkResult.html#abab80dca5987e18f9abf08162cd3faaa">mlir::WalkResult::interrupt</a></div><div class="ttdeci">static WalkResult interrupt()</div><div class="ttdef"><b>Definition</b> <a href="WalkResult_8h_source.html#l00046">WalkResult.h:46</a></div></div>
<div class="ttc" id="aclassmlir_1_1arith_1_1ConstantIndexOp_html_af8e9cba912ba269664b71b920ba30e6d"><div class="ttname"><a href="classmlir_1_1arith_1_1ConstantIndexOp.html#af8e9cba912ba269664b71b920ba30e6d">mlir::arith::ConstantIndexOp::create</a></div><div class="ttdeci">static ConstantIndexOp create(OpBuilder &amp;builder, Location location, int64_t value)</div><div class="ttdef"><b>Definition</b> <a href="ArithOps_8cpp_source.html#l00359">ArithOps.cpp:359</a></div></div>
<div class="ttc" id="aclassmlir_1_1detail_1_1IROperandBase_html_a9ab8c68c85b92faa00c9df16a15ad1c0"><div class="ttname"><a href="classmlir_1_1detail_1_1IROperandBase.html#a9ab8c68c85b92faa00c9df16a15ad1c0">mlir::detail::IROperandBase::getOwner</a></div><div class="ttdeci">Operation * getOwner() const</div><div class="ttdoc">Return the owner of this operand.</div><div class="ttdef"><b>Definition</b> <a href="UseDefLists_8h_source.html#l00038">UseDefLists.h:38</a></div></div>
<div class="ttc" id="amlir_2Dialect_2Arith_2IR_2Arith_8h_html"><div class="ttname"><a href="mlir_2Dialect_2Arith_2IR_2Arith_8h.html">Arith.h</a></div></div>
<div class="ttc" id="amlir_2Dialect_2Linalg_2IR_2Linalg_8h_html"><div class="ttname"><a href="mlir_2Dialect_2Linalg_2IR_2Linalg_8h.html">Linalg.h</a></div></div>
<div class="ttc" id="amlir_2Dialect_2Linalg_2Transforms_2Transforms_8h_html"><div class="ttname"><a href="mlir_2Dialect_2Linalg_2Transforms_2Transforms_8h.html">Transforms.h</a></div></div>
<div class="ttc" id="amlir_2Dialect_2Tensor_2IR_2Tensor_8h_html"><div class="ttname"><a href="mlir_2Dialect_2Tensor_2IR_2Tensor_8h.html">Tensor.h</a></div></div>
<div class="ttc" id="amlir_2IR_2AffineExpr_8h_html"><div class="ttname"><a href="mlir_2IR_2AffineExpr_8h.html">AffineExpr.h</a></div></div>
<div class="ttc" id="amlir_2IR_2AffineMap_8h_html"><div class="ttname"><a href="mlir_2IR_2AffineMap_8h.html">AffineMap.h</a></div></div>
<div class="ttc" id="amlir_2IR_2BuiltinTypes_8h_html"><div class="ttname"><a href="mlir_2IR_2BuiltinTypes_8h.html">BuiltinTypes.h</a></div></div>
<div class="ttc" id="amlir_2Support_2LLVM_8h_html"><div class="ttname"><a href="mlir_2Support_2LLVM_8h.html">LLVM.h</a></div></div>
<div class="ttc" id="anamespacemlir_1_1OpTrait_html_a0c5480822c4898f287f588dfe98d1c85"><div class="ttname"><a href="namespacemlir_1_1OpTrait.html#a0c5480822c4898f287f588dfe98d1c85">mlir::OpTrait::hasElementwiseMappableTraits</a></div><div class="ttdeci">bool hasElementwiseMappableTraits(Operation *op)</div><div class="ttdoc">Together, Elementwise, Scalarizable, Vectorizable, and Tensorizable provide an easy way for scalar op...</div><div class="ttdef"><b>Definition</b> <a href="IR_2Operation_8cpp_source.html#l01390">Operation.cpp:1390</a></div></div>
<div class="ttc" id="anamespacemlir_1_1acc_html"><div class="ttname"><a href="namespacemlir_1_1acc.html">mlir::acc</a></div><div class="ttdef"><b>Definition</b> <a href="OpenACCSupport_8h_source.html#l00061">OpenACCSupport.h:61</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html"><div class="ttname"><a href="namespacemlir_1_1linalg.html">mlir::linalg</a></div><div class="ttdef"><b>Definition</b> <a href="LinalgToStandard_8h_source.html#l00024">LinalgToStandard.h:24</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a142a09c03dbaa0d795e44f62d4b6b395"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a142a09c03dbaa0d795e44f62d4b6b395">mlir::linalg::hasVectorizationImpl</a></div><div class="ttdeci">bool hasVectorizationImpl(Operation *)</div><div class="ttdoc">Return true if there&#39;s dedicated logic in the Linalg Vectorizer to vectorize this Op,...</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a1a3bb0a48c5e2778ea2bfd81a41db65d"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a1a3bb0a48c5e2778ea2bfd81a41db65d">mlir::linalg::getUnPackInverseSrcPerm</a></div><div class="ttdeci">SmallVector&lt; int64_t &gt; getUnPackInverseSrcPerm(linalg::UnPackOp, PackingMetadata &amp;metadata)</div><div class="ttdoc">Compute inverse permutation for the source tensor (i.e.</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a1eda2843cbf0dc5507bc64ec67f46f22"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a1eda2843cbf0dc5507bc64ec67f46f22">mlir::linalg::allIndexingsAreProjectedPermutation</a></div><div class="ttdeci">bool allIndexingsAreProjectedPermutation(LinalgOp op)</div><div class="ttdoc">Check if all indexing maps are projected permutations.</div><div class="ttdef"><b>Definition</b> <a href="Dialect_2Linalg_2Utils_2Utils_8cpp_source.html#l00195">Utils.cpp:195</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a303bb59c046a82276569e6b906002997"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a303bb59c046a82276569e6b906002997">mlir::linalg::vectorize</a></div><div class="ttdeci">FailureOr&lt; VectorizationResult &gt; vectorize(RewriterBase &amp;rewriter, Operation *op, ArrayRef&lt; int64_t &gt; inputVectorSizes={}, ArrayRef&lt; bool &gt; inputScalableVecDims={}, bool vectorizeNDExtract=false, bool flatten1DDepthwiseConv=false, bool assumeDynamicDimsMatchVecSizes=false, bool createNamedContraction=false)</div><div class="ttdoc">Returns a VectorizationResult containing the results of the vectorized op, or failure if the transfor...</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a43c2ef8a778a33a17885475c11b50bdd"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a43c2ef8a778a33a17885475c11b50bdd">mlir::linalg::populatePadOpVectorizationPatterns</a></div><div class="ttdeci">void populatePadOpVectorizationPatterns(RewritePatternSet &amp;patterns, PatternBenefit baseBenefit=1)</div><div class="ttdoc">Populates patterns with patterns that vectorize tensor.pad.</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a5377722f56e02541897c157260bd1eee"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a5377722f56e02541897c157260bd1eee">mlir::linalg::isReductionIterator</a></div><div class="ttdeci">bool isReductionIterator(utils::IteratorType iteratorType)</div><div class="ttdoc">Check if iterator type has &quot;reduction&quot; semantics.</div><div class="ttdef"><b>Definition</b> <a href="Dialect_2Linalg_2Utils_2Utils_8cpp_source.html#l00234">Utils.cpp:234</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a891b8f2d145dcc3327ba55c7a49d44e4"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a891b8f2d145dcc3327ba55c7a49d44e4">mlir::linalg::populateConvolutionVectorizationPatterns</a></div><div class="ttdeci">void populateConvolutionVectorizationPatterns(RewritePatternSet &amp;patterns, PatternBenefit benefit=1)</div><div class="ttdoc">Populate patterns for vectorizing low-D convolution ops.</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a8b1c347bc995910212c197f9f8728b12"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a8b1c347bc995910212c197f9f8728b12">mlir::linalg::isElementwise</a></div><div class="ttdeci">bool isElementwise(LinalgOp op)</div><div class="ttdoc">Check if a LinalgOp is an element-wise operation.</div><div class="ttdef"><b>Definition</b> <a href="Dialect_2Linalg_2Utils_2Utils_8cpp_source.html#l00215">Utils.cpp:215</a></div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a8c63bc9239511b70751c238a12f5b1da"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a8c63bc9239511b70751c238a12f5b1da">mlir::linalg::vectorizeCopy</a></div><div class="ttdeci">LogicalResult vectorizeCopy(RewriterBase &amp;builder, memref::CopyOp copyOp)</div><div class="ttdoc">Emit a suitable vector form for a Copy op with fully static shape.</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a8d0310adee4f127279f9147a71db0181"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a8d0310adee4f127279f9147a71db0181">mlir::linalg::vectorizeOpPrecondition</a></div><div class="ttdeci">LogicalResult vectorizeOpPrecondition(Operation *op, ArrayRef&lt; int64_t &gt; inputVectorSizes={}, ArrayRef&lt; bool &gt; inputScalableVecDims={}, bool vectorizeNDExtract=false, bool flatten1DDepthwiseConv=false)</div><div class="ttdoc">Return success if the operation can be vectorized.</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_a92b42ab91002d8c468cb54eaebdb3989"><div class="ttname"><a href="namespacemlir_1_1linalg.html#a92b42ab91002d8c468cb54eaebdb3989">mlir::linalg::getPackInverseDestPerm</a></div><div class="ttdeci">SmallVector&lt; int64_t &gt; getPackInverseDestPerm(linalg::PackOp packOp, PackingMetadata &amp;metadata)</div><div class="ttdoc">Compute inverse permutation for the destination tensor (i.e.</div></div>
<div class="ttc" id="anamespacemlir_1_1linalg_html_ae27267a4634c46beba8c9f55c14cdfa1"><div class="ttname"><a href="namespacemlir_1_1linalg.html#ae27267a4634c46beba8c9f55c14cdfa1">mlir::linalg::getCombinerOpKind</a></div><div class="ttdeci">std::optional&lt; vector::CombiningKind &gt; getCombinerOpKind(Operation *combinerOp)</div><div class="ttdoc">Return vector::CombiningKind for the given op.</div><div class="ttdef"><b>Definition</b> <a href="#l00638">Vectorization.cpp:638</a></div></div>
<div class="ttc" id="anamespacemlir_1_1memref_html_ab0c13e32e47a301b4ccac4b27404de51"><div class="ttname"><a href="namespacemlir_1_1memref.html#ab0c13e32e47a301b4ccac4b27404de51">mlir::memref::getMixedSizes</a></div><div class="ttdeci">SmallVector&lt; OpFoldResult &gt; getMixedSizes(OpBuilder &amp;builder, Location loc, Value value)</div><div class="ttdoc">Return the dimensions of the given memref value.</div><div class="ttdef"><b>Definition</b> <a href="MemRefOps_8cpp_source.html#l00077">MemRefOps.cpp:77</a></div></div>
<div class="ttc" id="anamespacemlir_1_1remark_html_a22dbf73b7357df7368ed0ba796a7d73f"><div class="ttname"><a href="namespacemlir_1_1remark.html#a22dbf73b7357df7368ed0ba796a7d73f">mlir::remark::failed</a></div><div class="ttdeci">detail::InFlightRemark failed(Location loc, RemarkOpts opts)</div><div class="ttdoc">Report an optimization remark that failed.</div><div class="ttdef"><b>Definition</b> <a href="Remarks_8h_source.html#l00573">Remarks.h:573</a></div></div>
<div class="ttc" id="anamespacemlir_1_1scf_html_a797e5365dbe74c07bf61e43ff8e6a796"><div class="ttname"><a href="namespacemlir_1_1scf.html#a797e5365dbe74c07bf61e43ff8e6a796">mlir::scf::promote</a></div><div class="ttdeci">void promote(RewriterBase &amp;rewriter, scf::ForallOp forallOp)</div><div class="ttdoc">Promotes the loop body of a scf::ForallOp to its containing block.</div><div class="ttdef"><b>Definition</b> <a href="Dialect_2SCF_2IR_2SCF_8cpp_source.html#l00793">SCF.cpp:793</a></div></div>
<div class="ttc" id="anamespacemlir_1_1shape_html"><div class="ttname"><a href="namespacemlir_1_1shape.html">mlir::shape</a></div><div class="ttdef"><b>Definition</b> <a href="ShapeMappingAnalysis_8h_source.html#l00020">ShapeMappingAnalysis.h:20</a></div></div>
<div class="ttc" id="anamespacemlir_1_1sparse__tensor_1_1detail_html_a44d6ca01c15a8cea3f63df24849cc449"><div class="ttname"><a href="namespacemlir_1_1sparse__tensor_1_1detail.html#a44d6ca01c15a8cea3f63df24849cc449">mlir::sparse_tensor::detail::readValue</a></div><div class="ttdeci">std::enable_if_t&lt;!is_complex&lt; V &gt;::value, V &gt; readValue(char **linePtr)</div><div class="ttdoc">Returns an element-value of non-complex type.</div><div class="ttdef"><b>Definition</b> <a href="File_8h_source.html#l00043">File.h:43</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_a21bfcee9196fe1a2cfa548b7df8193a9"><div class="ttname"><a href="namespacemlir_1_1vector.html#a21bfcee9196fe1a2cfa548b7df8193a9">mlir::vector::maskOperation</a></div><div class="ttdeci">Operation * maskOperation(OpBuilder &amp;builder, Operation *maskableOp, Value mask, Value passthru=Value())</div><div class="ttdoc">Creates a vector.mask operation around a maskable operation.</div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_a341516a4c95139534df7b424b2de2598"><div class="ttname"><a href="namespacemlir_1_1vector.html#a341516a4c95139534df7b424b2de2598">mlir::vector::isValidMaskedInputVector</a></div><div class="ttdeci">LogicalResult isValidMaskedInputVector(ArrayRef&lt; int64_t &gt; shape, ArrayRef&lt; int64_t &gt; inputVectorSizes)</div><div class="ttdoc">Returns success if inputVectorSizes is a valid masking configuraion for given shape,...</div><div class="ttdef"><b>Definition</b> <a href="VectorUtils_8cpp_source.html#l00387">VectorUtils.cpp:387</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_a4ba6d4a825dbd36205be5322733056efa822b19813c2556c566eec6864da1319f"><div class="ttname"><a href="namespacemlir_1_1vector.html#a4ba6d4a825dbd36205be5322733056efa822b19813c2556c566eec6864da1319f">mlir::vector::ConstantMaskKind::AllTrue</a></div><div class="ttdeci">@ AllTrue</div><div class="ttdef"><b>Definition</b> <a href="VectorOps_8h_source.html#l00064">VectorOps.h:64</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_a5150a3f7aa4857a1863bd10fb551442a"><div class="ttname"><a href="namespacemlir_1_1vector.html#a5150a3f7aa4857a1863bd10fb551442a">mlir::vector::isBroadcastableTo</a></div><div class="ttdeci">BroadcastableToResult isBroadcastableTo(Type srcType, VectorType dstVectorType, std::pair&lt; VectorDim, VectorDim &gt; *mismatchingDims=nullptr)</div><div class="ttdef"><b>Definition</b> <a href="VectorOps_8cpp_source.html#l02924">VectorOps.cpp:2924</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_ac1f704d81959566caaf92245061960fb"><div class="ttname"><a href="namespacemlir_1_1vector.html#ac1f704d81959566caaf92245061960fb">mlir::vector::createReadOrMaskedRead</a></div><div class="ttdeci">Value createReadOrMaskedRead(OpBuilder &amp;builder, Location loc, Value source, const VectorType &amp;vecToReadTy, std::optional&lt; Value &gt; padValue=std::nullopt, bool useInBoundsInsteadOfMasking=false)</div><div class="ttdoc">Creates a TransferReadOp from source.</div><div class="ttdef"><b>Definition</b> <a href="VectorUtils_8cpp_source.html#l00333">VectorUtils.cpp:333</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_acfee45e655b185bd625e2f7994dc2c50a505a83f220c02df2f85c3810cd9ceb38"><div class="ttname"><a href="namespacemlir_1_1vector.html#acfee45e655b185bd625e2f7994dc2c50a505a83f220c02df2f85c3810cd9ceb38">mlir::vector::BroadcastableToResult::Success</a></div><div class="ttdeci">@ Success</div><div class="ttdef"><b>Definition</b> <a href="VectorOps_8h_source.html#l00073">VectorOps.h:73</a></div></div>
<div class="ttc" id="anamespacemlir_1_1vector_html_ad910c130857e946d9d30b58ffb708f3a"><div class="ttname"><a href="namespacemlir_1_1vector.html#ad910c130857e946d9d30b58ffb708f3a">mlir::vector::getMixedSizesXfer</a></div><div class="ttdeci">SmallVector&lt; OpFoldResult &gt; getMixedSizesXfer(bool hasTensorSemantics, Operation *xfer, RewriterBase &amp;rewriter)</div><div class="ttdoc">A wrapper for getMixedSizes for vector.transfer_read and vector.transfer_write Ops (for source and de...</div><div class="ttdef"><b>Definition</b> <a href="VectorUtils_8cpp_source.html#l00298">VectorUtils.cpp:298</a></div></div>
<div class="ttc" id="anamespacemlir_html"><div class="ttname"><a href="namespacemlir.html">mlir</a></div><div class="ttdoc">Include the generated interface declarations.</div><div class="ttdef"><b>Definition</b> <a href="AliasAnalysis_8h_source.html#l00019">AliasAnalysis.h:19</a></div></div>
<div class="ttc" id="anamespacemlir_html_a0190228b09e7b51a4bc1e013c01d404c"><div class="ttname"><a href="namespacemlir.html#a0190228b09e7b51a4bc1e013c01d404c">mlir::matchPattern</a></div><div class="ttdeci">bool matchPattern(Value value, const Pattern &amp;pattern)</div><div class="ttdoc">Entry point for matching a pattern over a Value.</div><div class="ttdef"><b>Definition</b> <a href="Matchers_8h_source.html#l00490">Matchers.h:490</a></div></div>
<div class="ttc" id="anamespacemlir_html_a091c0686ba6d6f3ad4af9db1aea8063f"><div class="ttname"><a href="namespacemlir.html#a091c0686ba6d6f3ad4af9db1aea8063f">mlir::m_ConstantInt</a></div><div class="ttdeci">detail::constant_int_value_binder m_ConstantInt(IntegerAttr::ValueType *bind_value)</div><div class="ttdoc">Matches a constant holding a scalar/vector/tensor integer (splat) and writes the integer value to bin...</div><div class="ttdef"><b>Definition</b> <a href="Matchers_8h_source.html#l00527">Matchers.h:527</a></div></div>
<div class="ttc" id="anamespacemlir_html_a1c6ebcdda896c9a0316c2367d2843775"><div class="ttname"><a href="namespacemlir.html#a1c6ebcdda896c9a0316c2367d2843775">mlir::changed</a></div><div class="ttdeci">const FrozenRewritePatternSet GreedyRewriteConfig bool * changed</div><div class="ttdef"><b>Definition</b> <a href="GreedyPatternRewriteDriver_8h_source.html#l00285">GreedyPatternRewriteDriver.h:285</a></div></div>
<div class="ttc" id="anamespacemlir_html_a22bfcc5fa9deffb32e7c39183f732c90"><div class="ttname"><a href="namespacemlir.html#a22bfcc5fa9deffb32e7c39183f732c90">mlir::getConstantIntValue</a></div><div class="ttdeci">std::optional&lt; int64_t &gt; getConstantIntValue(OpFoldResult ofr)</div><div class="ttdoc">If ofr is a constant integer or an IntegerAttr, return the integer.</div><div class="ttdef"><b>Definition</b> <a href="StaticValueUtils_8cpp_source.html#l00134">StaticValueUtils.cpp:134</a></div></div>
<div class="ttc" id="anamespacemlir_html_a2ee77c6f0feb82212b1b817785f95f48"><div class="ttname"><a href="namespacemlir.html#a2ee77c6f0feb82212b1b817785f95f48">mlir::isEqualConstantIntOrValue</a></div><div class="ttdeci">bool isEqualConstantIntOrValue(OpFoldResult ofr1, OpFoldResult ofr2)</div><div class="ttdoc">Return true if ofr1 and ofr2 are the same integer constant attribute values or the same SSA value.</div><div class="ttdef"><b>Definition</b> <a href="StaticValueUtils_8cpp_source.html#l00176">StaticValueUtils.cpp:176</a></div></div>
<div class="ttc" id="anamespacemlir_html_a348ed9fcbefe1f5094cc571c346c7080"><div class="ttname"><a href="namespacemlir.html#a348ed9fcbefe1f5094cc571c346c7080">mlir::getType</a></div><div class="ttdeci">Type getType(OpFoldResult ofr)</div><div class="ttdoc">Returns the int type of the integer in ofr.</div><div class="ttdef"><b>Definition</b> <a href="Dialect_2Arith_2Utils_2Utils_8cpp_source.html#l00304">Utils.cpp:304</a></div></div>
<div class="ttc" id="anamespacemlir_html_a39612be2ef116102866d3bb9c6a8ca88"><div class="ttname"><a href="namespacemlir.html#a39612be2ef116102866d3bb9c6a8ca88">mlir::inverseAndBroadcastProjectedPermutation</a></div><div class="ttdeci">AffineMap inverseAndBroadcastProjectedPermutation(AffineMap map)</div><div class="ttdoc">Return the reverse map of a projected permutation where the projected dimensions are transformed into...</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00808">AffineMap.cpp:808</a></div></div>
<div class="ttc" id="anamespacemlir_html_a3d147ba82716614172eb7e9b5209d3eb"><div class="ttname"><a href="namespacemlir.html#a3d147ba82716614172eb7e9b5209d3eb">mlir::bindDims</a></div><div class="ttdeci">void bindDims(MLIRContext *ctx, AffineExprTy &amp;...exprs)</div><div class="ttdoc">Bind a list of AffineExpr references to DimExpr at positions: [0 .</div><div class="ttdef"><b>Definition</b> <a href="mlir_2IR_2AffineExpr_8h_source.html#l00311">AffineExpr.h:311</a></div></div>
<div class="ttc" id="anamespacemlir_html_a52b322818d83a2256d4e4391acbf78a2"><div class="ttname"><a href="namespacemlir.html#a52b322818d83a2256d4e4391acbf78a2">mlir::inversePermutation</a></div><div class="ttdeci">AffineMap inversePermutation(AffineMap map)</div><div class="ttdoc">Returns a map of codomain to domain dimensions such that the first codomain dimension for a particula...</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00784">AffineMap.cpp:784</a></div></div>
<div class="ttc" id="anamespacemlir_html_a561d5231fcefc471a4c9069fce2eaf87"><div class="ttname"><a href="namespacemlir.html#a561d5231fcefc471a4c9069fce2eaf87">mlir::getSymbolLessAffineMaps</a></div><div class="ttdeci">SmallVector&lt; AffineMap, 4 &gt; getSymbolLessAffineMaps(ArrayRef&lt; ReassociationExprs &gt; reassociation)</div><div class="ttdoc">Constructs affine maps out of Array&lt;Array&lt;AffineExpr&gt;&gt;.</div><div class="ttdef"><b>Definition</b> <a href="ReshapeOpsUtils_8cpp_source.html#l00447">ReshapeOpsUtils.cpp:447</a></div></div>
<div class="ttc" id="anamespacemlir_html_a676bc3fbf14bd5dba33f962b259d2034"><div class="ttname"><a href="namespacemlir.html#a676bc3fbf14bd5dba33f962b259d2034">mlir::ReifiedRankedShapedTypeDims</a></div><div class="ttdeci">SmallVector&lt; SmallVector&lt; OpFoldResult &gt; &gt; ReifiedRankedShapedTypeDims</div><div class="ttdef"><b>Definition</b> <a href="InferTypeOpInterface_8h_source.html#l00029">InferTypeOpInterface.h:29</a></div></div>
<div class="ttc" id="anamespacemlir_html_a6bc751bc8f30d71ad4cb771c0fcc788b"><div class="ttname"><a href="namespacemlir.html#a6bc751bc8f30d71ad4cb771c0fcc788b">mlir::matchReduction</a></div><div class="ttdeci">Value matchReduction(ArrayRef&lt; BlockArgument &gt; iterCarriedArgs, unsigned redPos, SmallVectorImpl&lt; Operation * &gt; &amp;combinerOps)</div><div class="ttdoc">Utility to match a generic reduction given a list of iteration-carried arguments, iterCarriedArgs and...</div><div class="ttdef"><b>Definition</b> <a href="SliceAnalysis_8cpp_source.html#l00290">SliceAnalysis.cpp:290</a></div></div>
<div class="ttc" id="anamespacemlir_html_a70f70d8c0fc9767c6d18b1592cd9a7ee"><div class="ttname"><a href="namespacemlir.html#a70f70d8c0fc9767c6d18b1592cd9a7ee">mlir::SetVector</a></div><div class="ttdeci">llvm::SetVector&lt; T, Vector, Set, N &gt; SetVector</div><div class="ttdef"><b>Definition</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00131">LLVM.h:131</a></div></div>
<div class="ttc" id="anamespacemlir_html_a82686ceb29eb0f78b59e29021f1b2cdd"><div class="ttname"><a href="namespacemlir.html#a82686ceb29eb0f78b59e29021f1b2cdd">mlir::getElementTypeOrSelf</a></div><div class="ttdeci">Type getElementTypeOrSelf(Type type)</div><div class="ttdoc">Return the element type or return the type itself.</div><div class="ttdef"><b>Definition</b> <a href="TypeUtilities_8cpp_source.html#l00023">TypeUtilities.cpp:23</a></div></div>
<div class="ttc" id="anamespacemlir_html_a864cb5eb1fea4a548c28cda535ba7213"><div class="ttname"><a href="namespacemlir.html#a864cb5eb1fea4a548c28cda535ba7213">mlir::TypedValue</a></div><div class="ttdeci">std::conditional_t&lt; std::is_same_v&lt; Ty, mlir::Type &gt;, mlir::Value, detail::TypedValue&lt; Ty &gt; &gt; TypedValue</div><div class="ttdoc">If Ty is mlir::Type this will select Value instead of having a wrapper around it.</div><div class="ttdef"><b>Definition</b> <a href="Value_8h_source.html#l00497">Value.h:497</a></div></div>
<div class="ttc" id="anamespacemlir_html_a8789c71249b4fcc3059f4ba4a9d27f26"><div class="ttname"><a href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">mlir::patterns</a></div><div class="ttdeci">const FrozenRewritePatternSet &amp; patterns</div><div class="ttdef"><b>Definition</b> <a href="GreedyPatternRewriteDriver_8h_source.html#l00283">GreedyPatternRewriteDriver.h:283</a></div></div>
<div class="ttc" id="anamespacemlir_html_a98f08e970a346cd42559db87f97f0b91"><div class="ttname"><a href="namespacemlir.html#a98f08e970a346cd42559db87f97f0b91">mlir::getUsedValuesDefinedAbove</a></div><div class="ttdeci">void getUsedValuesDefinedAbove(Region &amp;region, Region &amp;limit, SetVector&lt; Value &gt; &amp;values)</div><div class="ttdoc">Fill values with a list of values defined at the ancestors of the limit region and used within region...</div><div class="ttdef"><b>Definition</b> <a href="RegionUtils_8cpp_source.html#l00070">RegionUtils.cpp:70</a></div></div>
<div class="ttc" id="anamespacemlir_html_a99f84d2ce14eec6c85a20251582e5cc1"><div class="ttname"><a href="namespacemlir.html#a99f84d2ce14eec6c85a20251582e5cc1">mlir::compressUnusedDims</a></div><div class="ttdeci">AffineMap compressUnusedDims(AffineMap map)</div><div class="ttdoc">Drop the dims that are not used.</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00715">AffineMap.cpp:715</a></div></div>
<div class="ttc" id="anamespacemlir_html_a9b2799e8f52860dadc460b88a8f2df32"><div class="ttname"><a href="namespacemlir.html#a9b2799e8f52860dadc460b88a8f2df32">mlir::convertReassociationIndicesToExprs</a></div><div class="ttdeci">SmallVector&lt; SmallVector&lt; AffineExpr, 2 &gt;, 2 &gt; convertReassociationIndicesToExprs(MLIRContext *context, ArrayRef&lt; ReassociationIndices &gt; reassociationIndices)</div><div class="ttdoc">Convert reassociation indices to affine expressions.</div><div class="ttdef"><b>Definition</b> <a href="ReshapeOpsUtils_8cpp_source.html#l00396">ReshapeOpsUtils.cpp:396</a></div></div>
<div class="ttc" id="anamespacemlir_html_a9e3d6f94b6a941066c3e7e5535817a9b"><div class="ttname"><a href="namespacemlir.html#a9e3d6f94b6a941066c3e7e5535817a9b">mlir::isReassociationValid</a></div><div class="ttdeci">bool isReassociationValid(ArrayRef&lt; AffineMap &gt; reassociation, int *invalidIndex=nullptr)</div><div class="ttdoc">Return true if the reassociation specification is valid, false otherwise.</div><div class="ttdef"><b>Definition</b> <a href="ReshapeOpsUtils_8cpp_source.html#l00460">ReshapeOpsUtils.cpp:460</a></div></div>
<div class="ttc" id="anamespacemlir_html_a9eabc3974d2131e15fad199b34b2eaa0"><div class="ttname"><a href="namespacemlir.html#a9eabc3974d2131e15fad199b34b2eaa0">mlir::TypeSwitch</a></div><div class="ttdeci">llvm::TypeSwitch&lt; T, ResultT &gt; TypeSwitch</div><div class="ttdef"><b>Definition</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00144">LLVM.h:144</a></div></div>
<div class="ttc" id="anamespacemlir_html_aa058eb9c12d3b97deb073543c1372195"><div class="ttname"><a href="namespacemlir.html#aa058eb9c12d3b97deb073543c1372195">mlir::getValueOrCreateConstantIndexOp</a></div><div class="ttdeci">Value getValueOrCreateConstantIndexOp(OpBuilder &amp;b, Location loc, OpFoldResult ofr)</div><div class="ttdoc">Converts an OpFoldResult to a Value.</div><div class="ttdef"><b>Definition</b> <a href="Dialect_2Arith_2Utils_2Utils_8cpp_source.html#l00111">Utils.cpp:111</a></div></div>
<div class="ttc" id="anamespacemlir_html_ab26cdced424aa629fde4150cc8674d50"><div class="ttname"><a href="namespacemlir.html#ab26cdced424aa629fde4150cc8674d50">mlir::getAffineConstantExpr</a></div><div class="ttdeci">AffineExpr getAffineConstantExpr(int64_t constant, MLIRContext *context)</div></div>
<div class="ttc" id="anamespacemlir_html_ab4871db68c59a176135e0e35a3625e73"><div class="ttname"><a href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">mlir::get</a></div><div class="ttdeci">auto get(MLIRContext *context, Ts &amp;&amp;...params)</div><div class="ttdoc">Helper method that injects context only if needed, this helps unify some of the attribute constructio...</div><div class="ttdef"><b>Definition</b> <a href="BytecodeImplementation_8h_source.html#l00509">BytecodeImplementation.h:509</a></div></div>
<div class="ttc" id="anamespacemlir_html_abde461319ad5039ddbf5b4e70f47618b"><div class="ttname"><a href="namespacemlir.html#abde461319ad5039ddbf5b4e70f47618b">mlir::DenseMap</a></div><div class="ttdeci">llvm::DenseMap&lt; KeyT, ValueT, KeyInfoT, BucketT &gt; DenseMap</div><div class="ttdef"><b>Definition</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00126">LLVM.h:126</a></div></div>
<div class="ttc" id="anamespacemlir_html_abf34b5ae79f6561558887f2dd8254f94"><div class="ttname"><a href="namespacemlir.html#abf34b5ae79f6561558887f2dd8254f94">mlir::applyPermutationMap</a></div><div class="ttdeci">SmallVector&lt; T &gt; applyPermutationMap(AffineMap map, llvm::ArrayRef&lt; T &gt; source)</div><div class="ttdoc">Apply a permutation from map to source and return the result.</div><div class="ttdef"><b>Definition</b> <a href="mlir_2IR_2AffineMap_8h_source.html#l00675">AffineMap.h:675</a></div></div>
<div class="ttc" id="anamespacemlir_html_ac61c6bb6068af953a0711cf404a99645"><div class="ttname"><a href="namespacemlir.html#ac61c6bb6068af953a0711cf404a99645">mlir::getUnusedDimsBitVector</a></div><div class="ttdeci">llvm::SmallBitVector getUnusedDimsBitVector(ArrayRef&lt; AffineMap &gt; maps)</div><div class="ttdef"><b>Definition</b> <a href="IR_2AffineMap_8cpp_source.html#l00923">AffineMap.cpp:923</a></div></div>
<div class="ttc" id="anamespacemlir_html_ad402a86ee4c9000c6fa1fceaddab560b"><div class="ttname"><a href="namespacemlir.html#ad402a86ee4c9000c6fa1fceaddab560b">mlir::m_Constant</a></div><div class="ttdeci">detail::constant_op_matcher m_Constant()</div><div class="ttdoc">Matches a constant foldable operation.</div><div class="ttdef"><b>Definition</b> <a href="Matchers_8h_source.html#l00369">Matchers.h:369</a></div></div>
<div class="ttc" id="anamespacemlir_html_adbcff71555e8c1965e508f324f43a55a"><div class="ttname"><a href="namespacemlir.html#adbcff71555e8c1965e508f324f43a55a">mlir::applyPermutationToVector</a></div><div class="ttdeci">void applyPermutationToVector(SmallVector&lt; T, N &gt; &amp;inVec, ArrayRef&lt; int64_t &gt; permutation)</div><div class="ttdoc">Apply the permutation defined by permutation to inVec.</div><div class="ttdef"><b>Definition</b> <a href="IndexingUtils_8h_source.html#l00226">IndexingUtils.h:226</a></div></div>
<div class="ttc" id="anamespacemlir_html_afc254f56cba37671e1e5b2b933c6a090"><div class="ttname"><a href="namespacemlir.html#afc254f56cba37671e1e5b2b933c6a090">mlir::invertPermutationVector</a></div><div class="ttdeci">SmallVector&lt; int64_t &gt; invertPermutationVector(ArrayRef&lt; int64_t &gt; permutation)</div><div class="ttdoc">Helper method to apply to inverse a permutation.</div><div class="ttdef"><b>Definition</b> <a href="IndexingUtils_8cpp_source.html#l00187">IndexingUtils.cpp:187</a></div></div>
<div class="ttc" id="astructVectorizationHookResult_html"><div class="ttname"><a href="structVectorizationHookResult.html">VectorizationHookResult</a></div><div class="ttdoc">VectorizationHookResult contains the vectorized op returned from a CustomVectorizationHook.</div><div class="ttdef"><b>Definition</b> <a href="#l00629">Vectorization.cpp:629</a></div></div>
<div class="ttc" id="astructVectorizationHookResult_html_a325ec6cd37d3dcf718897f5e68a37b91"><div class="ttname"><a href="structVectorizationHookResult.html#a325ec6cd37d3dcf718897f5e68a37b91">VectorizationHookResult::status</a></div><div class="ttdeci">enum VectorizationHookStatus status</div><div class="ttdoc">Return status from vectorizing the current op.</div><div class="ttdef"><b>Definition</b> <a href="#l00631">Vectorization.cpp:631</a></div></div>
<div class="ttc" id="astructVectorizationHookResult_html_ab9025f3486cb1c8f0c6461db368c1a50"><div class="ttname"><a href="structVectorizationHookResult.html#ab9025f3486cb1c8f0c6461db368c1a50">VectorizationHookResult::newOp</a></div><div class="ttdeci">Operation * newOp</div><div class="ttdoc">New vectorized operation to replace the current op.</div><div class="ttdef"><b>Definition</b> <a href="#l00634">Vectorization.cpp:634</a></div></div>
<div class="ttc" id="astructVectorizationState_html_a01db79101b5db86d0de4c9e5d9b7e19b"><div class="ttname"><a href="structVectorizationState.html#a01db79101b5db86d0de4c9e5d9b7e19b">VectorizationState::getCanonicalVecShape</a></div><div class="ttdeci">ArrayRef&lt; int64_t &gt; getCanonicalVecShape() const</div><div class="ttdoc">Returns the canonical vector shape used to vectorize the iteration space.</div><div class="ttdef"><b>Definition</b> <a href="#l00229">Vectorization.cpp:229</a></div></div>
<div class="ttc" id="astructVectorizationState_html_a18a5831810f1beae1d2f37fb9f711b18"><div class="ttname"><a href="structVectorizationState.html#a18a5831810f1beae1d2f37fb9f711b18">VectorizationState::initState</a></div><div class="ttdeci">LogicalResult initState(RewriterBase &amp;rewriter, LinalgOp linalgOp, ArrayRef&lt; int64_t &gt; inputVectorSizes, ArrayRef&lt; bool &gt; inputScalableVecDims, bool assumeDynamicDimsMatchVecSizes=false)</div><div class="ttdoc">Initializes the vectorization state, including the computation of the canonical vector shape for vect...</div><div class="ttdef"><b>Definition</b> <a href="#l00380">Vectorization.cpp:380</a></div></div>
<div class="ttc" id="astructVectorizationState_html_a37816d928cc471a94c6ec113f60969a2"><div class="ttname"><a href="structVectorizationState.html#a37816d928cc471a94c6ec113f60969a2">VectorizationState::maskOperation</a></div><div class="ttdeci">Operation * maskOperation(RewriterBase &amp;rewriter, Operation *opToMask, LinalgOp linalgOp, std::optional&lt; AffineMap &gt; maybeIndexingMap=std::nullopt)</div><div class="ttdoc">Masks an operation with the canonical vector mask if the operation needs masking.</div><div class="ttdef"><b>Definition</b> <a href="#l00512">Vectorization.cpp:512</a></div></div>
<div class="ttc" id="astructVectorizationState_html_a5b0655951fd32179a5cfbd895109fd7a"><div class="ttname"><a href="structVectorizationState.html#a5b0655951fd32179a5cfbd895109fd7a">VectorizationState::getCanonicalVecType</a></div><div class="ttdeci">VectorType getCanonicalVecType(Type elementType, std::optional&lt; AffineMap &gt; dimPermutation=std::nullopt) const</div><div class="ttdoc">Returns a vector type of the provided elementType with the canonical vector shape and the correspondi...</div><div class="ttdef"><b>Definition</b> <a href="#l00239">Vectorization.cpp:239</a></div></div>
<div class="ttc" id="astructVectorizationState_html_a8eab28272149a7cac2bf97d99b199d20"><div class="ttname"><a href="structVectorizationState.html#a8eab28272149a7cac2bf97d99b199d20">VectorizationState::getScalableVecDims</a></div><div class="ttdeci">ArrayRef&lt; bool &gt; getScalableVecDims() const</div><div class="ttdoc">Returns the vector dimensions that are scalable in the canonical vector shape.</div><div class="ttdef"><b>Definition</b> <a href="#l00233">Vectorization.cpp:233</a></div></div>
<div class="ttc" id="astructVectorizationState_html_ac46e33dfa27baf34825d041264c2fd9c"><div class="ttname"><a href="structVectorizationState.html#ac46e33dfa27baf34825d041264c2fd9c">VectorizationState::VectorizationState</a></div><div class="ttdeci">VectorizationState(RewriterBase &amp;rewriter)</div><div class="ttdef"><b>Definition</b> <a href="#l00219">Vectorization.cpp:219</a></div></div>
<div class="ttc" id="astructmlir_1_1OpInterfaceRewritePattern_html_a723a250f581dc2a0758fbe6b7c55f1c9"><div class="ttname"><a href="structmlir_1_1OpInterfaceRewritePattern.html#a723a250f581dc2a0758fbe6b7c55f1c9">mlir::OpInterfaceRewritePattern::OpInterfaceRewritePattern</a></div><div class="ttdeci">OpInterfaceRewritePattern(MLIRContext *context, PatternBenefit benefit=1)</div><div class="ttdef"><b>Definition</b> <a href="PatternMatch_8h_source.html#l00338">PatternMatch.h:338</a></div></div>
<div class="ttc" id="astructmlir_1_1linalg_1_1LinalgCopyVTRForwardingPattern_html_a5be03b192efbaf3d0c6f4db1942432e8"><div class="ttname"><a href="structmlir_1_1linalg_1_1LinalgCopyVTRForwardingPattern.html#a5be03b192efbaf3d0c6f4db1942432e8">mlir::linalg::LinalgCopyVTRForwardingPattern::matchAndRewrite</a></div><div class="ttdeci">LogicalResult matchAndRewrite(vector::TransferReadOp xferOp, PatternRewriter &amp;rewriter) const override</div></div>
<div class="ttc" id="astructmlir_1_1linalg_1_1LinalgCopyVTWForwardingPattern_html_a7d5ee3615456f09f4d7518e4d78e48f8"><div class="ttname"><a href="structmlir_1_1linalg_1_1LinalgCopyVTWForwardingPattern.html#a7d5ee3615456f09f4d7518e4d78e48f8">mlir::linalg::LinalgCopyVTWForwardingPattern::matchAndRewrite</a></div><div class="ttdeci">LogicalResult matchAndRewrite(vector::TransferWriteOp xferOp, PatternRewriter &amp;rewriter) const override</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on <span class="timestamp"></span> for MLIR by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.14.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
