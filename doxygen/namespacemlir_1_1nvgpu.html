<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MLIR: mlir::nvgpu Namespace Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MLIR
   &#160;<span id="projectnumber">22.0.0git</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacemlir.html">mlir</a></li><li class="navelem"><a class="el" href="namespacemlir_1_1nvgpu.html">nvgpu</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">mlir::nvgpu Namespace Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Collects information about a warp-level matrix operand represented by a VectorType.  <a href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html">FragmentElementInfo</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Specifies information about the registers which compose a matrix fragment according to the PTX documentation.  <a href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">LdMatrixParams</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Encapsulates the parameters needed to lower a <code>nvgpu.ldmatrix</code> operation to <code>nvvm.ldmatrix</code>.  <a href="structmlir_1_1nvgpu_1_1LdMatrixParams.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:a2cd481d969335c7faee4833fd989f8ed"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">MmaSyncF32Lowering</a> { <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8eda7af37e98489130cf59da22f2f9b3c2d6">TF32</a> = 0
, <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8edab0496676569bf2251989f4011ec01965">TF32x3</a> = 1
, <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8eda777358f6554241fd6bb9110bf267b3ac">Unkown</a> = 2
 }</td></tr>
<tr class="memdesc:a2cd481d969335c7faee4833fd989f8ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">Rewrites patterns.  <a href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">More...</a><br /></td></tr>
<tr class="separator:a2cd481d969335c7faee4833fd989f8ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4c82fd5e3500e2d345d723829e09efe"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efe">MatMulOperandRole</a> : int32_t { <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea7fc56270e7a70fa81a5935b72eacbe29">A</a> = 0
, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea9d5ed678fe57bcca610140957afab571">B</a>
, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea0d61f8370cad1d412f80b84d143e1257">C</a>
 }</td></tr>
<tr class="memdesc:ae4c82fd5e3500e2d345d723829e09efe"><td class="mdescLeft">&#160;</td><td class="mdescRight">Represents the role of an operand in an MMA instruction: <code>result := matmul(A, B) + C</code>  <a href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efe">More...</a><br /></td></tr>
<tr class="separator:ae4c82fd5e3500e2d345d723829e09efe"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a68e2eb7a214f699ea849b6f2f25555ce"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1Attribute.html">Attribute</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a68e2eb7a214f699ea849b6f2f25555ce">getMbarrierMemorySpace</a> (<a class="el" href="classmlir_1_1MLIRContext.html">MLIRContext</a> *context, MBarrierGroupType barrierType)</td></tr>
<tr class="memdesc:a68e2eb7a214f699ea849b6f2f25555ce"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the memory space attribute of the mbarrier object.  <a href="namespacemlir_1_1nvgpu.html#a68e2eb7a214f699ea849b6f2f25555ce">More...</a><br /></td></tr>
<tr class="separator:a68e2eb7a214f699ea849b6f2f25555ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3e30fabfef9dd0964a957cbc3baa7b9c"><td class="memItemLeft" align="right" valign="top">MemRefType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a3e30fabfef9dd0964a957cbc3baa7b9c">getMBarrierMemrefType</a> (<a class="el" href="classmlir_1_1MLIRContext.html">MLIRContext</a> *context, MBarrierGroupType barrierType)</td></tr>
<tr class="memdesc:a3e30fabfef9dd0964a957cbc3baa7b9c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return the memref type that can be used to represent an mbarrier object.  <a href="namespacemlir_1_1nvgpu.html#a3e30fabfef9dd0964a957cbc3baa7b9c">More...</a><br /></td></tr>
<tr class="separator:a3e30fabfef9dd0964a957cbc3baa7b9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae64270d2058ef5fd99281df6e7de4464"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#ae64270d2058ef5fd99281df6e7de4464">registerTransformDialectExtension</a> (<a class="el" href="classmlir_1_1DialectRegistry.html">DialectRegistry</a> &amp;registry)</td></tr>
<tr class="separator:ae64270d2058ef5fd99281df6e7de4464"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6783845748d4e0a1c685d19edbf53314"><td class="memItemLeft" align="right" valign="top">std::unique_ptr&lt; <a class="el" href="classmlir_1_1Pass.html">Pass</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a6783845748d4e0a1c685d19edbf53314">createOptimizeSharedMemoryPass</a> ()</td></tr>
<tr class="memdesc:a6783845748d4e0a1c685d19edbf53314"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a pass to optimize shared memory reads and writes.  <a href="namespacemlir_1_1nvgpu.html#a6783845748d4e0a1c685d19edbf53314">More...</a><br /></td></tr>
<tr class="separator:a6783845748d4e0a1c685d19edbf53314"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a481b33225aab10fb527d43e21693576c"><td class="memItemLeft" align="right" valign="top">llvm::LogicalResult&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a481b33225aab10fb527d43e21693576c">optimizeSharedMemoryReadsAndWrites</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *parentOp, <a class="el" href="classmlir_1_1Value.html">Value</a> memrefValue)</td></tr>
<tr class="memdesc:a481b33225aab10fb527d43e21693576c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Passes.  <a href="namespacemlir_1_1nvgpu.html#a481b33225aab10fb527d43e21693576c">More...</a><br /></td></tr>
<tr class="separator:a481b33225aab10fb527d43e21693576c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d4c259957fcb36c77d32413688cd447"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a7d4c259957fcb36c77d32413688cd447">populateMmaSyncF32ToTF32Patterns</a> (<a class="el" href="classmlir_1_1RewritePatternSet.html">RewritePatternSet</a> &amp;<a class="el" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>, <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">nvgpu::MmaSyncF32Lowering</a> precision=<a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8eda7af37e98489130cf59da22f2f9b3c2d6">nvgpu::MmaSyncF32Lowering::TF32</a>)</td></tr>
<tr class="memdesc:a7d4c259957fcb36c77d32413688cd447"><td class="mdescLeft">&#160;</td><td class="mdescRight">Collect patterns to convert mma.sync on f32 input and rewrite to use tensor cores with user provided level of accuracy: (a) tf32 (1 mma.sync per warp-level matrix-multiply-accumulate) (b) tf32x3 (3 mma.sync per warp-level matrix-multiply-accumulate) Typically, tf32 tensor core acceleration comes at a cost of accuracy from missing precision bits.  <a href="namespacemlir_1_1nvgpu.html#a7d4c259957fcb36c77d32413688cd447">More...</a><br /></td></tr>
<tr class="separator:a7d4c259957fcb36c77d32413688cd447"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af0ddf8062abd0432231a7d36838e208a"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#af0ddf8062abd0432231a7d36838e208a">createAsyncGroups</a> (<a class="el" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;rewriter, <a class="el" href="classmlir_1_1Operation.html">Operation</a> *op, bool bypassL1)</td></tr>
<tr class="memdesc:af0ddf8062abd0432231a7d36838e208a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convert global-&gt;shared vector transfers to async device copies.  <a href="namespacemlir_1_1nvgpu.html#af0ddf8062abd0432231a7d36838e208a">More...</a><br /></td></tr>
<tr class="separator:af0ddf8062abd0432231a7d36838e208a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad59722c33205a25c3184235b9519c8bc"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1Operation.html#a8fc63f3d33e11994ab3330eb6e8990b9">Operation::operand_range</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#ad59722c33205a25c3184235b9519c8bc">getIndices</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op)</td></tr>
<tr class="memdesc:ad59722c33205a25c3184235b9519c8bc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the indices that the given load/store operation is operating on.  <a href="namespacemlir_1_1nvgpu.html#ad59722c33205a25c3184235b9519c8bc">More...</a><br /></td></tr>
<tr class="separator:ad59722c33205a25c3184235b9519c8bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab0258fd3dfe2db8a9b1c2c2206e6fb89"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#ab0258fd3dfe2db8a9b1c2c2206e6fb89">setIndices</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op, <a class="el" href="classllvm_1_1ArrayRef.html">ArrayRef</a>&lt; <a class="el" href="classmlir_1_1Value.html">Value</a> &gt; indices)</td></tr>
<tr class="memdesc:ab0258fd3dfe2db8a9b1c2c2206e6fb89"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the indices that the given load/store operation is operating on.  <a href="namespacemlir_1_1nvgpu.html#ab0258fd3dfe2db8a9b1c2c2206e6fb89">More...</a><br /></td></tr>
<tr class="separator:ab0258fd3dfe2db8a9b1c2c2206e6fb89"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad3cfa52d974ad6a649c45c740364cf10"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1Value.html">Value</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#ad3cfa52d974ad6a649c45c740364cf10">getValueStored</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op)</td></tr>
<tr class="memdesc:ad3cfa52d974ad6a649c45c740364cf10"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the value that is stored by the given store operation.  <a href="namespacemlir_1_1nvgpu.html#ad3cfa52d974ad6a649c45c740364cf10">More...</a><br /></td></tr>
<tr class="separator:ad3cfa52d974ad6a649c45c740364cf10"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3cdfe05b617a4a8ad03a9aa649a740f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classmlir_1_1Value.html">Value</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#ab3cdfe05b617a4a8ad03a9aa649a740f">getMemrefOperand</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op)</td></tr>
<tr class="memdesc:ab3cdfe05b617a4a8ad03a9aa649a740f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the memref that is loaded from/stored into by the given load/store operation.  <a href="namespacemlir_1_1nvgpu.html#ab3cdfe05b617a4a8ad03a9aa649a740f">More...</a><br /></td></tr>
<tr class="separator:ab3cdfe05b617a4a8ad03a9aa649a740f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5e5e9578e2fea736fe8b33cdbb846a75"><td class="memItemLeft" align="right" valign="top">FailureOr&lt; vector::ContractionOp &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a5e5e9578e2fea736fe8b33cdbb846a75">getUserContract</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op)</td></tr>
<tr class="memdesc:a5e5e9578e2fea736fe8b33cdbb846a75"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the first user of the <code>op</code> that is vector.contract.  <a href="namespacemlir_1_1nvgpu.html#a5e5e9578e2fea736fe8b33cdbb846a75">More...</a><br /></td></tr>
<tr class="separator:a5e5e9578e2fea736fe8b33cdbb846a75"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a833cda849d4c16ca9e572b561a3d7c8c"><td class="memItemLeft" align="right" valign="top">FailureOr&lt; <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a833cda849d4c16ca9e572b561a3d7c8c">getWarpMatrixInfo</a> (<a class="el" href="classmlir_1_1Operation.html">Operation</a> *op)</td></tr>
<tr class="memdesc:a833cda849d4c16ca9e572b561a3d7c8c"><td class="mdescLeft">&#160;</td><td class="mdescRight">If <code>op</code> is a <code>vector.transfer_write</code>, return the <code><a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html" title="Collects information about a warp-level matrix operand represented by a VectorType.">WarpMatrixInfo</a></code> for the vector operand.  <a href="namespacemlir_1_1nvgpu.html#a833cda849d4c16ca9e572b561a3d7c8c">More...</a><br /></td></tr>
<tr class="separator:a833cda849d4c16ca9e572b561a3d7c8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c7d221188b7c25a9615d098a69a8961"><td class="memItemLeft" align="right" valign="top">int64_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a5c7d221188b7c25a9615d098a69a8961">inferTileWidthInBits</a> (const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;type)</td></tr>
<tr class="memdesc:a5c7d221188b7c25a9615d098a69a8961"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the number of bits in a single tile row.  <a href="namespacemlir_1_1nvgpu.html#a5c7d221188b7c25a9615d098a69a8961">More...</a><br /></td></tr>
<tr class="separator:a5c7d221188b7c25a9615d098a69a8961"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afc4ec5365767add53c11a004b407c2c8"><td class="memItemLeft" align="right" valign="top">FailureOr&lt; <a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html">FragmentElementInfo</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#afc4ec5365767add53c11a004b407c2c8">getMmaSyncRegisterType</a> (const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;type)</td></tr>
<tr class="memdesc:afc4ec5365767add53c11a004b407c2c8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns a <a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html" title="Specifies information about the registers which compose a matrix fragment according to the PTX docume...">FragmentElementInfo</a> struct describing the register types for the given matrix fragment type.  <a href="namespacemlir_1_1nvgpu.html#afc4ec5365767add53c11a004b407c2c8">More...</a><br /></td></tr>
<tr class="separator:afc4ec5365767add53c11a004b407c2c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a654920e24c40c316f956cf1b720ddebd"><td class="memItemLeft" align="right" valign="top">FailureOr&lt; <a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#a654920e24c40c316f956cf1b720ddebd">getLaneIdAndValueIdToOperandCoord</a> (<a class="el" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;builder, <a class="el" href="classmlir_1_1Location.html">Location</a> loc, const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;fragmentType)</td></tr>
<tr class="memdesc:a654920e24c40c316f956cf1b720ddebd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns an <a class="el" href="classmlir_1_1AffineMap.html" title="A multi-dimensional affine map Affine map&#39;s are immutable like Type&#39;s, and they are uniqued.">AffineMap</a> which maps a two dimensions representing (laneId, logicalValueId) and returns two results representing offsets within a matrix operand.  <a href="namespacemlir_1_1nvgpu.html#a654920e24c40c316f956cf1b720ddebd">More...</a><br /></td></tr>
<tr class="separator:a654920e24c40c316f956cf1b720ddebd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aedec27c25c18f9d99a07975a272e45b7"><td class="memItemLeft" align="right" valign="top">FailureOr&lt; <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">LdMatrixParams</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#aedec27c25c18f9d99a07975a272e45b7">getLdMatrixParams</a> (const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;type, bool transpose)</td></tr>
<tr class="memdesc:aedec27c25c18f9d99a07975a272e45b7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given <code>type</code> that contains info for a warp-matrix operand and whether or not the load is a transposed load, return the <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html" title="Encapsulates the parameters needed to lower a nvgpu.ldmatrix operation to nvvm.ldmatrix.">LdMatrixParams</a>.  <a href="namespacemlir_1_1nvgpu.html#aedec27c25c18f9d99a07975a272e45b7">More...</a><br /></td></tr>
<tr class="separator:aedec27c25c18f9d99a07975a272e45b7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc1d62ff394c612ca3be7b74b8dda3a3"><td class="memItemLeft" align="right" valign="top">FailureOr&lt; <a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#adc1d62ff394c612ca3be7b74b8dda3a3">getLaneIdToLdMatrixMatrixCoord</a> (<a class="el" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;builder, <a class="el" href="classmlir_1_1Location.html">Location</a> loc, const <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">LdMatrixParams</a> &amp;params)</td></tr>
<tr class="memdesc:adc1d62ff394c612ca3be7b74b8dda3a3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns an <a class="el" href="classmlir_1_1AffineMap.html" title="A multi-dimensional affine map Affine map&#39;s are immutable like Type&#39;s, and they are uniqued.">AffineMap</a> which maps a single dimension representing the laneId to two results representing offsets within the matrix operand that should be the pointer locations a thread should pass to the ldmatrix instruction.  <a href="namespacemlir_1_1nvgpu.html#adc1d62ff394c612ca3be7b74b8dda3a3">More...</a><br /></td></tr>
<tr class="separator:adc1d62ff394c612ca3be7b74b8dda3a3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:affa842f2088a7be660fd6767867f9630"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#affa842f2088a7be660fd6767867f9630">canLowerToWarpMatrixOperation</a> (vector::TransferReadOp op)</td></tr>
<tr class="memdesc:affa842f2088a7be660fd6767867f9630"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns whether the <code>vector.transfer_read</code> instruction can be interpreted as a warp-level cooperative matrix load operation.  <a href="namespacemlir_1_1nvgpu.html#affa842f2088a7be660fd6767867f9630">More...</a><br /></td></tr>
<tr class="separator:affa842f2088a7be660fd6767867f9630"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adf5434a8a66a6334b2c049e206356873"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespacemlir_1_1nvgpu.html#adf5434a8a66a6334b2c049e206356873">canLowerToWarpMatrixOperation</a> (vector::TransferWriteOp op)</td></tr>
<tr class="memdesc:adf5434a8a66a6334b2c049e206356873"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns whether the <code>vector.transfer_write</code> instruction can be interpreted as a warp-level cooperative matrix store operation.  <a href="namespacemlir_1_1nvgpu.html#adf5434a8a66a6334b2c049e206356873">More...</a><br /></td></tr>
<tr class="separator:adf5434a8a66a6334b2c049e206356873"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a id="ae4c82fd5e3500e2d345d723829e09efe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4c82fd5e3500e2d345d723829e09efe">&#9670;&nbsp;</a></span>MatMulOperandRole</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efe">mlir::nvgpu::MatMulOperandRole</a> : int32_t</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Represents the role of an operand in an MMA instruction: <code>result := matmul(A, B) + C</code> </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="ae4c82fd5e3500e2d345d723829e09efea7fc56270e7a70fa81a5935b72eacbe29"></a>A&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="ae4c82fd5e3500e2d345d723829e09efea9d5ed678fe57bcca610140957afab571"></a>B&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="ae4c82fd5e3500e2d345d723829e09efea0d61f8370cad1d412f80b84d143e1257"></a>C&#160;</td><td class="fielddoc"></td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8h_source.html#l00026">26</a> of file <a class="el" href="MMAUtils_8h_source.html">MMAUtils.h</a>.</p>

</div>
</div>
<a id="a2cd481d969335c7faee4833fd989f8ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2cd481d969335c7faee4833fd989f8ed">&#9670;&nbsp;</a></span>MmaSyncF32Lowering</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">mlir::nvgpu::MmaSyncF32Lowering</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Rewrites patterns. </p>
<p>Enum to control the lowering of <code>nvgpu.mmasync</code>. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a2cd481d969335c7faee4833fd989f8eda7af37e98489130cf59da22f2f9b3c2d6"></a>TF32&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a2cd481d969335c7faee4833fd989f8edab0496676569bf2251989f4011ec01965"></a>TF32x3&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a2cd481d969335c7faee4833fd989f8eda777358f6554241fd6bb9110bf267b3ac"></a>Unkown&#160;</td><td class="fielddoc"></td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="mlir_2Dialect_2NVGPU_2Transforms_2Transforms_8h_source.html#l00057">57</a> of file <a class="el" href="mlir_2Dialect_2NVGPU_2Transforms_2Transforms_8h_source.html">Transforms.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a id="affa842f2088a7be660fd6767867f9630"></a>
<h2 class="memtitle"><span class="permalink"><a href="#affa842f2088a7be660fd6767867f9630">&#9670;&nbsp;</a></span>canLowerToWarpMatrixOperation() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool mlir::nvgpu::canLowerToWarpMatrixOperation </td>
          <td>(</td>
          <td class="paramtype">vector::TransferReadOp&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns whether the <code>vector.transfer_read</code> instruction can be interpreted as a warp-level cooperative matrix load operation. </p>
<p>This function is meant to be used to establish whether <code>op</code> is part of a chain of such warp-level operations. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00270">270</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00272">supportsMMaMatrixType()</a>.</p>

</div>
</div>
<a id="adf5434a8a66a6334b2c049e206356873"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adf5434a8a66a6334b2c049e206356873">&#9670;&nbsp;</a></span>canLowerToWarpMatrixOperation() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool mlir::nvgpu::canLowerToWarpMatrixOperation </td>
          <td>(</td>
          <td class="paramtype">vector::TransferWriteOp&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns whether the <code>vector.transfer_write</code> instruction can be interpreted as a warp-level cooperative matrix store operation. </p>
<p>This function is meant to be used to establish whether <code>op</code> is part of a chain of such warp-level operations. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00297">297</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

</div>
</div>
<a id="af0ddf8062abd0432231a7d36838e208a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af0ddf8062abd0432231a7d36838e208a">&#9670;&nbsp;</a></span>createAsyncGroups()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void mlir::nvgpu::createAsyncGroups </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1RewriterBase.html">RewriterBase</a> &amp;&#160;</td>
          <td class="paramname"><em>rewriter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>bypassL1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Convert global-&gt;shared vector transfers to async device copies. </p>
<p>This function looks for suitable vector transfers within the specified op and converts them to "nvgpu.device_async_copy" ops. Consecutive copies are put into the same sync group. If <code>bypassL1</code> is set, the "bypassL1" attribute is set for suitable (i.e., transfer size 16 bytes) transfers. </p>

<p class="definition">Definition at line <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00152">152</a> of file <a class="el" href="CreateAsyncGroups_8cpp_source.html">CreateAsyncGroups.cpp</a>.</p>

<p class="reference">References <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00083">buildNumReadElements()</a>, <a class="el" href="PatternMatch_8cpp_source.html#l00155">mlir::RewriterBase::eraseOp()</a>, <a class="el" href="Remarks_8h_source.html#l00491">mlir::remark::failed()</a>, <a class="el" href="BytecodeImplementation_8h_source.html#l00509">mlir::get()</a>, <a class="el" href="StaticValueUtils_8cpp_source.html#l00134">mlir::getConstantIntValue()</a>, <a class="el" href="IR_2Operation_8h_source.html#l00216">mlir::Operation::getContext()</a>, <a class="el" href="Value_8cpp_source.html#l00018">mlir::Value::getDefiningOp()</a>, <a class="el" href="Builders_8cpp_source.html#l00108">mlir::Builder::getIndexAttr()</a>, <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html#l00018">getIndices()</a>, <a class="el" href="IR_2Operation_8h_source.html#l00223">mlir::Operation::getLoc()</a>, <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00058">getMaskOp()</a>, <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html#l00068">getMemrefOperand()</a>, <a class="el" href="Value_8h_source.html#l00105">mlir::Value::getType()</a>, <a class="el" href="Builders_8cpp_source.html#l00098">mlir::Builder::getUnitAttr()</a>, <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html#l00058">getValueStored()</a>, <a class="el" href="IR_2Operation_8h_source.html#l00749">mlir::Operation::hasTrait()</a>, <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00041">isContiguousRead()</a>, <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00032">isContiguousStore()</a>, <a class="el" href="IR_2Operation_8cpp_source.html#l00546">mlir::Operation::remove()</a>, <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00126">resultsInSupportedAsyncCopy()</a>, <a class="el" href="Builders_8h_source.html#l00398">mlir::OpBuilder::setInsertionPoint()</a>, and <a class="el" href="IR_2Operation_8h_source.html#l00797">mlir::Operation::walk()</a>.</p>

</div>
</div>
<a id="a6783845748d4e0a1c685d19edbf53314"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6783845748d4e0a1c685d19edbf53314">&#9670;&nbsp;</a></span>createOptimizeSharedMemoryPass()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::unique_ptr&lt; <a class="el" href="classmlir_1_1Pass.html">Pass</a> &gt; mlir::nvgpu::createOptimizeSharedMemoryPass </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a pass to optimize shared memory reads and writes. </p>

<p class="definition">Definition at line <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00245">245</a> of file <a class="el" href="OptimizeSharedMemory_8cpp_source.html">OptimizeSharedMemory.cpp</a>.</p>

</div>
</div>
<a id="ad59722c33205a25c3184235b9519c8bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad59722c33205a25c3184235b9519c8bc">&#9670;&nbsp;</a></span>getIndices()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1Operation.html#a8fc63f3d33e11994ab3330eb6e8990b9">Operation::operand_range</a> mlir::nvgpu::getIndices </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Get the indices that the given load/store operation is operating on. </p>

<p class="definition">Definition at line <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html#l00018">18</a> of file <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html">Utils.cpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00152">createAsyncGroups()</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00113">getShmReadAndWriteOps()</a>, <a class="el" href="CAPI_2IR_2BuiltinAttributes_8cpp_source.html#l00957">mlirSparseElementsAttrGetIndices()</a>, and <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00149">optimizeSharedMemoryReadsAndWrites()</a>.</p>

</div>
</div>
<a id="a654920e24c40c316f956cf1b720ddebd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a654920e24c40c316f956cf1b720ddebd">&#9670;&nbsp;</a></span>getLaneIdAndValueIdToOperandCoord()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FailureOr&lt; <a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a> &gt; mlir::nvgpu::getLaneIdAndValueIdToOperandCoord </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;&#160;</td>
          <td class="paramname"><em>builder</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Location.html">Location</a>&#160;</td>
          <td class="paramname"><em>loc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>fragmentType</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns an <a class="el" href="classmlir_1_1AffineMap.html" title="A multi-dimensional affine map Affine map&#39;s are immutable like Type&#39;s, and they are uniqued.">AffineMap</a> which maps a two dimensions representing (laneId, logicalValueId) and returns two results representing offsets within a matrix operand. </p>
<p>The offsets point to the values the thread is responsible for (AKA the matrix fragment values) during a warp-collective matrix operation. For a visual reference of this LaneId -&gt; (row, col) mapping, please see NVIDIA's PTX documentation: <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-for-mma">https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-for-mma</a> </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00167">167</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="mlir_2IR_2AffineExpr_8h_source.html#l00311">mlir::bindDims()</a>, <a class="el" href="Remarks_8h_source.html#l00491">mlir::remark::failed()</a>, <a class="el" href="IR_2AffineExpr_8cpp_source.html#l00959">mlir::AffineExpr::floorDiv()</a>, <a class="el" href="MLIRContext_8cpp_source.html#l01221">mlir::AffineMap::get()</a>, <a class="el" href="Builders_8h_source.html#l00056">mlir::Builder::getContext()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00122">mlir::Type::getIntOrFloatBitWidth()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00098">getMmaSyncRegisterType()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00148">getRegisterIndexToTileOffsetMap()</a>, <a class="el" href="IR_2AffineMap_8cpp_source.html#l00407">mlir::AffineMap::getResult()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00085">inferTileWidthInBits()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00021">isAccumulatorOrResult()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00018">kThreadsPerRow</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00897">convertTransferWriteToStores()</a>, and <a class="el" href="VectorToGPU_8cpp_source.html#l00766">createNonLdMatrixLoads()</a>.</p>

</div>
</div>
<a id="adc1d62ff394c612ca3be7b74b8dda3a3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc1d62ff394c612ca3be7b74b8dda3a3">&#9670;&nbsp;</a></span>getLaneIdToLdMatrixMatrixCoord()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FailureOr&lt; <a class="el" href="classmlir_1_1AffineMap.html">AffineMap</a> &gt; mlir::nvgpu::getLaneIdToLdMatrixMatrixCoord </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;&#160;</td>
          <td class="paramname"><em>builder</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Location.html">Location</a>&#160;</td>
          <td class="paramname"><em>loc</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">LdMatrixParams</a> &amp;&#160;</td>
          <td class="paramname"><em>params</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns an <a class="el" href="classmlir_1_1AffineMap.html" title="A multi-dimensional affine map Affine map&#39;s are immutable like Type&#39;s, and they are uniqued.">AffineMap</a> which maps a single dimension representing the laneId to two results representing offsets within the matrix operand that should be the pointer locations a thread should pass to the ldmatrix instruction. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00232">232</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="MMAUtils_8h_source.html#l00081">mlir::nvgpu::LdMatrixParams::contiguousDimType</a>, <a class="el" href="IR_2AffineExpr_8cpp_source.html#l00959">mlir::AffineExpr::floorDiv()</a>, <a class="el" href="MMAUtils_8h_source.html#l00078">mlir::nvgpu::LdMatrixParams::fragmentType</a>, <a class="el" href="MLIRContext_8cpp_source.html#l01221">mlir::AffineMap::get()</a>, <a class="el" href="IR_2AffineExpr_8cpp_source.html#l00619">mlir::getAffineDimExpr()</a>, and <a class="el" href="Builders_8h_source.html#l00056">mlir::Builder::getContext()</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00705">creatLdMatrixCompatibleLoads()</a>.</p>

</div>
</div>
<a id="aedec27c25c18f9d99a07975a272e45b7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aedec27c25c18f9d99a07975a272e45b7">&#9670;&nbsp;</a></span>getLdMatrixParams()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FailureOr&lt; <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html">nvgpu::LdMatrixParams</a> &gt; mlir::nvgpu::getLdMatrixParams </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>transpose</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Given <code>type</code> that contains info for a warp-matrix operand and whether or not the load is a transposed load, return the <a class="el" href="structmlir_1_1nvgpu_1_1LdMatrixParams.html" title="Encapsulates the parameters needed to lower a nvgpu.ldmatrix operation to nvvm.ldmatrix.">LdMatrixParams</a>. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00203">203</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea7fc56270e7a70fa81a5935b72eacbe29">A</a>, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea0d61f8370cad1d412f80b84d143e1257">C</a>, <a class="el" href="MMAUtils_8h_source.html#l00081">mlir::nvgpu::LdMatrixParams::contiguousDimType</a>, <a class="el" href="MMAUtils_8h_source.html#l00078">mlir::nvgpu::LdMatrixParams::fragmentType</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00122">mlir::Type::getIntOrFloatBitWidth()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00019">kNumRowsPerTile</a>, <a class="el" href="MMAUtils_8h_source.html#l00080">mlir::nvgpu::LdMatrixParams::numTiles</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, <a class="el" href="MMAUtils_8h_source.html#l00082">mlir::nvgpu::LdMatrixParams::targetLayout</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00705">creatLdMatrixCompatibleLoads()</a>.</p>

</div>
</div>
<a id="a68e2eb7a214f699ea849b6f2f25555ce"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68e2eb7a214f699ea849b6f2f25555ce">&#9670;&nbsp;</a></span>getMbarrierMemorySpace()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1Attribute.html">Attribute</a> mlir::nvgpu::getMbarrierMemorySpace </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1MLIRContext.html">MLIRContext</a> *&#160;</td>
          <td class="paramname"><em>context</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MBarrierGroupType&#160;</td>
          <td class="paramname"><em>barrierType</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the memory space attribute of the mbarrier object. </p>

</div>
</div>
<a id="a3e30fabfef9dd0964a957cbc3baa7b9c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3e30fabfef9dd0964a957cbc3baa7b9c">&#9670;&nbsp;</a></span>getMBarrierMemrefType()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">MemRefType mlir::nvgpu::getMBarrierMemrefType </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1MLIRContext.html">MLIRContext</a> *&#160;</td>
          <td class="paramname"><em>context</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">MBarrierGroupType&#160;</td>
          <td class="paramname"><em>barrierType</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Return the memref type that can be used to represent an mbarrier object. </p>

</div>
</div>
<a id="ab3cdfe05b617a4a8ad03a9aa649a740f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3cdfe05b617a4a8ad03a9aa649a740f">&#9670;&nbsp;</a></span>getMemrefOperand()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1Value.html">Value</a> mlir::nvgpu::getMemrefOperand </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Get the memref that is loaded from/stored into by the given load/store operation. </p>

<p class="definition">Definition at line <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html#l00068">68</a> of file <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html">Utils.cpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00152">createAsyncGroups()</a>, and <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00023">isContiguousXferOp()</a>.</p>

</div>
</div>
<a id="afc4ec5365767add53c11a004b407c2c8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afc4ec5365767add53c11a004b407c2c8">&#9670;&nbsp;</a></span>getMmaSyncRegisterType()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FailureOr&lt; <a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html">FragmentElementInfo</a> &gt; mlir::nvgpu::getMmaSyncRegisterType </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>type</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns a <a class="el" href="structmlir_1_1nvgpu_1_1FragmentElementInfo.html" title="Specifies information about the registers which compose a matrix fragment according to the PTX docume...">FragmentElementInfo</a> struct describing the register types for the given matrix fragment type. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00098">98</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="BytecodeImplementation_8h_source.html#l00509">mlir::get()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00027">inferNumRegistersPerMatrixFragment()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00021">isAccumulatorOrResult()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00038">mlir::Type::isF16()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00040">mlir::Type::isF32()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00041">mlir::Type::isF64()</a>, <a class="el" href="IR_2Types_8cpp_source.html#l00056">mlir::Type::isInteger()</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00638">convertConstantOpMmaSync()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00949">convertExtractStridedSlice()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00897">convertTransferWriteToStores()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00766">createNonLdMatrixLoads()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00705">creatLdMatrixCompatibleLoads()</a>, and <a class="el" href="MMAUtils_8cpp_source.html#l00167">getLaneIdAndValueIdToOperandCoord()</a>.</p>

</div>
</div>
<a id="a5e5e9578e2fea736fe8b33cdbb846a75"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5e5e9578e2fea736fe8b33cdbb846a75">&#9670;&nbsp;</a></span>getUserContract()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FailureOr&lt; vector::ContractionOp &gt; mlir::nvgpu::getUserContract </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the first user of the <code>op</code> that is vector.contract. </p>
<p>If no vector.contract user exists, return failure. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00048">48</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="IR_2Operation_8h_source.html#l00873">mlir::Operation::getUsers()</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00248">extractStridedSliceSupportsMMAMatrixType()</a>, and <a class="el" href="MMAUtils_8cpp_source.html#l00056">getWarpMatrixInfo()</a>.</p>

</div>
</div>
<a id="ad3cfa52d974ad6a649c45c740364cf10"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad3cfa52d974ad6a649c45c740364cf10">&#9670;&nbsp;</a></span>getValueStored()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classmlir_1_1Value.html">Value</a> mlir::nvgpu::getValueStored </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Get the value that is stored by the given store operation. </p>

<p class="definition">Definition at line <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html#l00058">58</a> of file <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html">Utils.cpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="CreateAsyncGroups_8cpp_source.html#l00152">createAsyncGroups()</a>.</p>

</div>
</div>
<a id="a833cda849d4c16ca9e572b561a3d7c8c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a833cda849d4c16ca9e572b561a3d7c8c">&#9670;&nbsp;</a></span>getWarpMatrixInfo()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">FailureOr&lt; <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &gt; mlir::nvgpu::getWarpMatrixInfo </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>If <code>op</code> is a <code>vector.transfer_write</code>, return the <code><a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html" title="Collects information about a warp-level matrix operand represented by a VectorType.">WarpMatrixInfo</a></code> for the vector operand. </p>
<p>If op is a <code>vector.transfer_read</code>, <code>vector.contraction</code>, or <code>arith.constant</code>, return the <code><a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html" title="Collects information about a warp-level matrix operand represented by a VectorType.">WarpMatrixInfo</a></code> corresponding to the result. Otherwise, return failure. </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00056">56</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea7fc56270e7a70fa81a5935b72eacbe29">A</a>, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea9d5ed678fe57bcca610140957afab571">B</a>, <a class="el" href="namespacemlir_1_1nvgpu.html#ae4c82fd5e3500e2d345d723829e09efea0d61f8370cad1d412f80b84d143e1257">C</a>, <a class="el" href="IR_2Operation_8cpp_source.html#l00267">mlir::Operation::emitError()</a>, <a class="el" href="Remarks_8h_source.html#l00491">mlir::remark::failed()</a>, <a class="el" href="IR_2Operation_8h_source.html#l00407">mlir::Operation::getResult()</a>, <a class="el" href="Value_8h_source.html#l00105">mlir::Value::getType()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00048">getUserContract()</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00638">convertConstantOpMmaSync()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00949">convertExtractStridedSlice()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00865">convertTransferReadToLoads()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00897">convertTransferWriteToStores()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00766">createNonLdMatrixLoads()</a>, <a class="el" href="VectorToGPU_8cpp_source.html#l00705">creatLdMatrixCompatibleLoads()</a>, and <a class="el" href="VectorToGPU_8cpp_source.html#l00248">extractStridedSliceSupportsMMAMatrixType()</a>.</p>

</div>
</div>
<a id="a5c7d221188b7c25a9615d098a69a8961"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5c7d221188b7c25a9615d098a69a8961">&#9670;&nbsp;</a></span>inferTileWidthInBits()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int64_t mlir::nvgpu::inferTileWidthInBits </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structmlir_1_1nvgpu_1_1WarpMatrixInfo.html">WarpMatrixInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>type</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the number of bits in a single tile row. </p>
<p>It is either 128, 256, or 512 bits depending on the data type and` whether the operand is an accumulator/result operand </p>

<p class="definition">Definition at line <a class="el" href="MMAUtils_8cpp_source.html#l00085">85</a> of file <a class="el" href="MMAUtils_8cpp_source.html">MMAUtils.cpp</a>.</p>

<p class="reference">References <a class="el" href="IR_2Types_8cpp_source.html#l00122">mlir::Type::getIntOrFloatBitWidth()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00021">isAccumulatorOrResult()</a>, <a class="el" href="MMAUtils_8h_source.html#l00036">mlir::nvgpu::WarpMatrixInfo::operandRole</a>, and <a class="el" href="MMAUtils_8h_source.html#l00035">mlir::nvgpu::WarpMatrixInfo::vectorType</a>.</p>

<p class="reference">Referenced by <a class="el" href="VectorToGPU_8cpp_source.html#l00865">convertTransferReadToLoads()</a>, <a class="el" href="MMAUtils_8cpp_source.html#l00167">getLaneIdAndValueIdToOperandCoord()</a>, and <a class="el" href="MMAUtils_8cpp_source.html#l00027">inferNumRegistersPerMatrixFragment()</a>.</p>

</div>
</div>
<a id="a481b33225aab10fb527d43e21693576c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a481b33225aab10fb527d43e21693576c">&#9670;&nbsp;</a></span>optimizeSharedMemoryReadsAndWrites()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">llvm::LogicalResult mlir::nvgpu::optimizeSharedMemoryReadsAndWrites </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>parentOp</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Value.html">Value</a>&#160;</td>
          <td class="paramname"><em>memrefValue</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Passes. </p>
<p>Optimizes vectorized accesses to a shared memory buffer specified by memrefValue. This transformation assumes the following: 1) All relevant accesses to <code>memrefValue</code> are contained with <code>parentOp</code>. 2) The function will fail precondition checks if any subviews are taken of <code>memrefValue</code>. All reads/writes to <code>memrefValue</code> should occur through <code>memrefValue</code> directly.</p>
<p>Shared memory bank conflicts occur when multiple threads attempt to read or write locations assigned to the same shared memory bank. For <code>2^N</code> byte vectorized accesses, we need to be concerned with conflicts among threads identified as <code>(tid) -&gt; tid.floordiv(2^{7-N})</code>. As such, this transformation changes any indexed memory access (vector.load, memref.load, nvgpu.ldmatrix, etc) such that the final dimension's index value is permuted such that <code>newColIndex = oldColIndex % vectorSize + perm[rowIndex](oldColIndex/vectorSize, rowIndex)</code> where <code>rowIndex</code> is the index for the second-to last dimension and <code>perm[rowIndex]</code> is a permutation function that depends on the row Index. The permutation function is chosen to ensure that sequential distributed+vectorized reads/writes down a single dimension of the memref have minimal conflicts. </p>

<p class="definition">Definition at line <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00149">149</a> of file <a class="el" href="OptimizeSharedMemory_8cpp_source.html">OptimizeSharedMemory.cpp</a>.</p>

<p class="reference">References <a class="el" href="Remarks_8h_source.html#l00491">mlir::remark::failed()</a>, <a class="el" href="IR_2Operation_8h_source.html#l00216">mlir::Operation::getContext()</a>, <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html#l00018">getIndices()</a>, <a class="el" href="IR_2Operation_8h_source.html#l00223">mlir::Operation::getLoc()</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00113">getShmReadAndWriteOps()</a>, <a class="el" href="Value_8h_source.html#l00105">mlir::Value::getType()</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00039">kDefaultVectorSizeBits</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00036">kSharedMemoryLineSizeBytes</a>, <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html#l00038">setIndices()</a>, <a class="el" href="Builders_8h_source.html#l00398">mlir::OpBuilder::setInsertionPoint()</a>, <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00102">transformIndices()</a>, and <a class="el" href="IR_2Operation_8h_source.html#l00797">mlir::Operation::walk()</a>.</p>

</div>
</div>
<a id="a7d4c259957fcb36c77d32413688cd447"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d4c259957fcb36c77d32413688cd447">&#9670;&nbsp;</a></span>populateMmaSyncF32ToTF32Patterns()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void mlir::nvgpu::populateMmaSyncF32ToTF32Patterns </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1RewritePatternSet.html">RewritePatternSet</a> &amp;&#160;</td>
          <td class="paramname"><em>patterns</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8ed">nvgpu::MmaSyncF32Lowering</a>&#160;</td>
          <td class="paramname"><em>precision</em> = <code><a class="el" href="namespacemlir_1_1nvgpu.html#a2cd481d969335c7faee4833fd989f8eda7af37e98489130cf59da22f2f9b3c2d6">nvgpu::MmaSyncF32Lowering::TF32</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Collect patterns to convert mma.sync on f32 input and rewrite to use tensor cores with user provided level of accuracy: (a) tf32 (1 mma.sync per warp-level matrix-multiply-accumulate) (b) tf32x3 (3 mma.sync per warp-level matrix-multiply-accumulate) Typically, tf32 tensor core acceleration comes at a cost of accuracy from missing precision bits. </p>
<p>While f32 has 23 precision bits, tf32 has only 10 precision bits. tf32x3 aims to recover the precision bits by spliting each operand into two tf32 values and issue three mma.sync tensor core operations. </p>

<p class="definition">Definition at line <a class="el" href="MmaSyncTF32Transform_8cpp_source.html#l00065">65</a> of file <a class="el" href="MmaSyncTF32Transform_8cpp_source.html">MmaSyncTF32Transform.cpp</a>.</p>

<p class="reference">References <a class="el" href="GreedyPatternRewriteDriver_8h_source.html#l00283">mlir::patterns</a>.</p>

</div>
</div>
<a id="ae64270d2058ef5fd99281df6e7de4464"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae64270d2058ef5fd99281df6e7de4464">&#9670;&nbsp;</a></span>registerTransformDialectExtension()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void mlir::nvgpu::registerTransformDialectExtension </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1DialectRegistry.html">DialectRegistry</a> &amp;&#160;</td>
          <td class="paramname"><em>registry</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="ab0258fd3dfe2db8a9b1c2c2206e6fb89"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab0258fd3dfe2db8a9b1c2c2206e6fb89">&#9670;&nbsp;</a></span>setIndices()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void mlir::nvgpu::setIndices </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classmlir_1_1Operation.html">Operation</a> *&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classllvm_1_1ArrayRef.html">ArrayRef</a>&lt; <a class="el" href="classmlir_1_1Value.html">Value</a> &gt;&#160;</td>
          <td class="paramname"><em>indices</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Set the indices that the given load/store operation is operating on. </p>

<p class="definition">Definition at line <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html#l00038">38</a> of file <a class="el" href="Dialect_2NVGPU_2Transforms_2Utils_8cpp_source.html">Utils.cpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="OptimizeSharedMemory_8cpp_source.html#l00149">optimizeSharedMemoryReadsAndWrites()</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sat Sep 27 2025 16:33:11 for MLIR by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
