<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>MLIR: lib/Dialect/XeGPU/Transforms/XeGPUSubgroupDistribute.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">MLIR
   &#160;<span id="projectnumber">22.0.0git</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_97aefd0d527b934f1d99a682da8fe6a9.html">lib</a></li><li class="navelem"><a class="el" href="dir_1a25ec519b6c1121408b67cc33ce3f15.html">Dialect</a></li><li class="navelem"><a class="el" href="dir_4450d9c2fe676127035a85de624b54cb.html">XeGPU</a></li><li class="navelem"><a class="el" href="dir_2c7c141a96fa7a5cbbd680608daa3825.html">Transforms</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">XeGPUSubgroupDistribute.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="XeGPUSubgroupDistribute_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">//===- XeGPUSubgroupDistribute.cpp - XeGPU Subgroup Distribute Pass -------===//</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.</span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment">// See https://llvm.org/LICENSE.txt for license information.</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">//</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="GPUDialect_8h.html">mlir/Dialect/GPU/IR/GPUDialect.h</a>&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="DistributionUtils_8h.html">mlir/Dialect/GPU/Utils/DistributionUtils.h</a>&quot;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2MemRef_2IR_2MemRef_8h.html">mlir/Dialect/MemRef/IR/MemRef.h</a>&quot;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="VectorOps_8h.html">mlir/Dialect/Vector/IR/VectorOps.h</a>&quot;</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="VectorDistribution_8h.html">mlir/Dialect/Vector/Transforms/VectorDistribution.h</a>&quot;</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="XeGPU_8h.html">mlir/Dialect/XeGPU/IR/XeGPU.h</a>&quot;</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="XeGPUTargetInfo_8h.html">mlir/Dialect/XeGPU/IR/XeGPUTargetInfo.h</a>&quot;</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Dialect_2XeGPU_2Transforms_2Passes_8h.html">mlir/Dialect/XeGPU/Transforms/Passes.h</a>&quot;</span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2Dialect_2XeGPU_2Transforms_2Transforms_8h.html">mlir/Dialect/XeGPU/Transforms/Transforms.h</a>&quot;</span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="XeGPUUtils_8h.html">mlir/Dialect/XeGPU/Utils/XeGPUUtils.h</a>&quot;</span></div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2IR_2AffineMap_8h.html">mlir/IR/AffineMap.h</a>&quot;</span></div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Attributes_8h.html">mlir/IR/Attributes.h</a>&quot;</span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Builders_8h.html">mlir/IR/Builders.h</a>&quot;</span></div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2IR_2BuiltinAttributes_8h.html">mlir/IR/BuiltinAttributes.h</a>&quot;</span></div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="BuiltinOps_8h.html">mlir/IR/BuiltinOps.h</a>&quot;</span></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2IR_2BuiltinTypes_8h.html">mlir/IR/BuiltinTypes.h</a>&quot;</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="IR_2Operation_8h.html">mlir/IR/Operation.h</a>&quot;</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="PatternMatch_8h.html">mlir/IR/PatternMatch.h</a>&quot;</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="TypeRange_8h.html">mlir/IR/TypeRange.h</a>&quot;</span></div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Value_8h.html">mlir/IR/Value.h</a>&quot;</span></div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Visitors_8h.html">mlir/IR/Visitors.h</a>&quot;</span></div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="FunctionInterfaces_8h.html">mlir/Interfaces/FunctionInterfaces.h</a>&quot;</span></div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="mlir_2Support_2LLVM_8h.html">mlir/Support/LLVM.h</a>&quot;</span></div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="DialectConversion_8h.html">mlir/Transforms/DialectConversion.h</a>&quot;</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="GreedyPatternRewriteDriver_8h.html">mlir/Transforms/GreedyPatternRewriteDriver.h</a>&quot;</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="InliningUtils_8h.html">mlir/Transforms/InliningUtils.h</a>&quot;</span></div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="preprocessor">#include &quot;llvm/ADT/ArrayRef.h&quot;</span></div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="preprocessor">#include &quot;llvm/ADT/STLExtras.h&quot;</span></div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="preprocessor">#include &quot;llvm/ADT/SmallVector.h&quot;</span></div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160; </div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacemlir.html">mlir</a> {</div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="keyword">namespace </span>xegpu {</div>
<div class="line"><a name="l00040"></a><span class="lineno"><a class="line" href="XeGPUSubgroupDistribute_8cpp.html#a031bf161a336d459c60a0b9e692e58a3">   40</a></span>&#160;<span class="preprocessor">#define GEN_PASS_DEF_XEGPUSUBGROUPDISTRIBUTE</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="preprocessor">#include &quot;mlir/Dialect/XeGPU/Transforms/Passes.h.inc&quot;</span></div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;} <span class="comment">// namespace xegpu</span></div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;} <span class="comment">// namespace mlir</span></div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160; </div>
<div class="line"><a name="l00045"></a><span class="lineno"><a class="line" href="XeGPUSubgroupDistribute_8cpp.html#ad78e062f62e0d6e453941fb4ca843e4d">   45</a></span>&#160;<span class="preprocessor">#define DEBUG_TYPE &quot;xegpu-subgroup-distribute&quot;</span></div>
<div class="line"><a name="l00046"></a><span class="lineno"><a class="line" href="XeGPUSubgroupDistribute_8cpp.html#ae0bb487c37194ac844a13205a7edcefc">   46</a></span>&#160;<span class="preprocessor">#define DBGS() (llvm::dbgs() &lt;&lt; &quot;[&quot;</span> DEBUG_TYPE &quot;]: &quot;)</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160; </div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="keyword">using namespace </span><a class="code" href="namespacemlir.html">mlir</a>;</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160; </div>
<div class="line"><a name="l00050"></a><span class="lineno"><a class="line" href="XeGPUSubgroupDistribute_8cpp.html#a908e16bf69a72db5cd2045bc016ac3fe">   50</a></span>&#160;<span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">char</span> *<span class="keyword">const</span> <a class="code" href="XeGPUSubgroupDistribute_8cpp.html#a908e16bf69a72db5cd2045bc016ac3fe">resolveSIMTTypeMismatch</a> =</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    <span class="stringliteral">&quot;resolve_simt_type_mismatch&quot;</span>; <span class="comment">// Attribute name for identifying</span></div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;                                  <span class="comment">// UnrelizedConversionCastOp added to resolve</span></div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;                                  <span class="comment">// SIMT type mismatches.</span></div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160; </div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="keyword">namespace </span>{</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160; </div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment">// SIMT Distribution Patterns</span></div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="comment">//===----------------------------------------------------------------------===//</span></div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="comment">/// Helper function to get  distributed vector type for a source vector type</span></div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="comment">/// according to the lane_layout. We simply divide each dimension of tensor</span></div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="comment">/// descriptor shape by corresponding lane_layout dimension. If</span></div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="comment">/// array_length &gt; 1, that is appended to the front of the ditributed shape.</span></div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="comment">/// NOTE: This is the vector type that will be returned by the</span></div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="comment">/// gpu.warp_execute_on_lane0 op.</span></div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="comment">/// Examples:</span></div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="comment">/// | original vector shape | lane_layout | distributed vector shape |</span></div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="comment">/// |-----------------------|-------------|--------------------------|</span></div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;<span class="comment">/// | 32x16                 | [1, 16]     | 32x1                     |</span></div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="comment">/// | 32x16                 | [2, 8]      | 16x2                     |</span></div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment">/// | 2x32x16               | [1, 16]     | 2x32x1                   |</span></div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="comment"></span><span class="keyword">static</span> FailureOr&lt;VectorType&gt;</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;getDistVecTypeBasedOnLaneLayout(xegpu::LayoutAttr layout,</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;                                VectorType originalType) {</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;  <span class="keywordflow">if</span> (!layout)</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;    <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160; </div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;  <span class="keyword">auto</span> laneLayout = layout.getLaneLayout().asArrayRef();</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;  assert(originalType.getShape().size() &gt;= laneLayout.size() &amp;&amp;</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;         <span class="stringliteral">&quot;Rank of the original vector type should be greater or equal to the &quot;</span></div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;         <span class="stringliteral">&quot;size of the lane layout to distribute the vector type.&quot;</span>);</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;  <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;int64_t&gt;</a> distributedShape(originalType.getShape());</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;  <span class="comment">// Only distribute the last `laneLayout.size()` dimensions. The remaining</span></div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;  <span class="comment">// dimensions are not distributed.</span></div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;  <span class="keywordtype">unsigned</span> distributionStart = originalType.getRank() - laneLayout.size();</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> [i, dim] : <a class="code" href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">llvm::enumerate</a>(originalType.getShape())) {</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;    <span class="keywordflow">if</span> (i &lt; distributionStart)</div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;      <span class="keywordflow">continue</span>;</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160; </div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    <span class="comment">// Check if the dimension can be distributed evenly.</span></div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    <span class="keywordflow">if</span> (dim % laneLayout[i - distributionStart] != 0)</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;    distributedShape[i] = dim / laneLayout[i - distributionStart];</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;  }</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">VectorType::get</a>(distributedShape, originalType.getElementType());</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;}</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;<span class="comment">/// Helper function to resolve types if the distributed type out of</span></div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;<span class="comment">/// gpu.warp_execute_on_lane0 is different from the expected xegpu SIMT type.</span></div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;<span class="comment">/// Example 1:</span></div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;<span class="comment">///   distributed type: vector&lt;8x1xf32&gt;</span></div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;<span class="comment">///   expected type: vector&lt;8xf32&gt;</span></div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;<span class="comment">///   resolved using,</span></div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;<span class="comment">///   %0 = vector.shape_cast %1 : vector&lt;8x1xf32&gt; to vector&lt;8xf32&gt;</span></div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;<span class="comment">/// Example 2:</span></div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;<span class="comment">///   distributed type: xegpu.tensor_desc&lt;8x16xf32, #xegpu.layout&lt;...&gt;&gt;</span></div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;<span class="comment">///   expected type: xegpu.tensor_desc&lt;8x16xf32&gt;</span></div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="comment">///   resolved using,</span></div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;<span class="comment">///   %0 = unrealized_conversion_cast %1 :</span></div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;<span class="comment">///      xegpu.tensor_desc&lt;8x16xf32, #xegpu.layout&lt;..&gt;&gt; -&gt;</span></div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="comment">///      xegpu.tensor_desc&lt;8x16xf32&gt;</span></div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;<span class="comment"></span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;<span class="keyword">static</span> <a class="code" href="classmlir_1_1Value.html">Value</a> resolveDistributedTy(<a class="code" href="classmlir_1_1Value.html">Value</a> orig, T expected,</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;                                  <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter) {</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;  <span class="comment">// If orig and expected types are the same, return orig.</span></div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;  <span class="keywordflow">if</span> (orig.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>() == expected)</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    <span class="keywordflow">return</span> orig;</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;  <span class="comment">// If orig is a vector type, create a shape cast op to reconcile the types.</span></div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;  <span class="keywordflow">if</span> (isa&lt;VectorType&gt;(orig.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>())) {</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    <span class="keyword">auto</span> castOp =</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;        vector::ShapeCastOp::create(rewriter, orig.<a class="code" href="classmlir_1_1Value.html#ae9df8c75072dbaab98cd4b7cd82b6ebc">getLoc</a>(), expected, orig);</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;    <span class="keywordflow">return</span> castOp.getResult();</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;  }</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;  <span class="comment">// If orig is a tensor descriptor type, create an unrealized conversion cast</span></div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;  <span class="comment">// op to reconcile the types.</span></div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;  <span class="keywordflow">if</span> (isa&lt;xegpu::TensorDescType&gt;(orig.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>())) {</div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;    <span class="keyword">auto</span> castOp = UnrealizedConversionCastOp::create(rewriter, orig.<a class="code" href="classmlir_1_1Value.html#ae9df8c75072dbaab98cd4b7cd82b6ebc">getLoc</a>(),</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;                                                     expected, orig);</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;    castOp-&gt;setAttr(<a class="code" href="XeGPUSubgroupDistribute_8cpp.html#a908e16bf69a72db5cd2045bc016ac3fe">resolveSIMTTypeMismatch</a>, rewriter.<a class="code" href="classmlir_1_1Builder.html#a0ba94155c8438c805c7bf379d79d36c5">getUnitAttr</a>());</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;    <span class="keywordflow">return</span> castOp.getResult(0);</div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;  }</div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;  llvm_unreachable(<span class="stringliteral">&quot;Unsupported type for reconciliation&quot;</span>);</div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;  <span class="keywordflow">return</span> orig;</div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;}</div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="comment">/// Helper function to check if the layout is packed. Layout is packed if it is</span></div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;<span class="comment">/// 2D and lane_data[0] != 1 (data packed from col dimension).</span></div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;<span class="comment"></span><span class="keyword">static</span> <span class="keywordtype">bool</span> hasPackedLayout(xegpu::LayoutAttr layout) {</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;  <span class="keywordflow">if</span> (layout == xegpu::LayoutAttr())</div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;  <a class="code" href="classmlir_1_1detail_1_1DenseArrayAttrImpl.html">DenseI32ArrayAttr</a> laneData = layout.getLaneData();</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;  <span class="keywordflow">if</span> (!laneData || laneData.size() != 2)</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;  <span class="keywordflow">return</span> laneData.<a class="code" href="classmlir_1_1detail_1_1DenseArrayAttrImpl.html#a289ce16b280c7eaf247d7d8413f87e82">asArrayRef</a>()[0] != 1;</div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;}</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;<span class="comment">/// Given a GPUFuncOp, this pattern creates a new GPUFuncOp and moves the body</span></div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;<span class="comment">/// of the original GPUFuncOp to the new GPUFuncOp such that entire body is</span></div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;<span class="comment">/// contained within a WarpExecuteOnLane0Op.</span></div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;<span class="comment">/// Example:</span></div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;<span class="comment">///   gpu.func @foo(%arg0: memref&lt;*xf16&gt;) -&gt; vector&lt;8x16xf32&gt; {</span></div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment">///     gpu.return %result: vector&lt;8x16xf32&gt;</span></div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;<span class="comment">/// To</span></div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;<span class="comment">///   gpu.func @foo(%arg0: memref&lt;*xf16&gt;) -&gt; vector&lt;8x16xf32&gt; {</span></div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;<span class="comment">///     %laneid = gpu.lane_id : index</span></div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="comment">///     %0 = gpu.warp_execute_on_lane_0(%laneid) -&gt; vector&lt;8x16xf32&gt; {</span></div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="comment">///       ...</span></div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;<span class="comment">///       ...</span></div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="comment">///       gpu.yield %result: vector&lt;8x16xf32&gt;</span></div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;<span class="comment">///     }</span></div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;<span class="comment">///     return %0</span></div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;<span class="comment"></span><span class="keyword">struct </span>MoveFuncBodyToWarpExecuteOnLane0</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;    : <span class="keyword">public</span> <a class="code" href="structmlir_1_1OpRewritePattern.html">OpRewritePattern</a>&lt;gpu::GPUFuncOp&gt; {</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;  <span class="keyword">using</span> <a class="code" href="structmlir_1_1OpRewritePattern.html">OpRewritePattern&lt;gpu::GPUFuncOp&gt;::OpRewritePattern</a>;</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;  LogicalResult matchAndRewrite(gpu::GPUFuncOp gpuFuncOp,</div>
<div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;    <span class="comment">// If the function only contains a single void return, skip.</span></div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;    <span class="keywordflow">if</span> (llvm::all_of(gpuFuncOp.getBody().getOps(), [](<a class="code" href="classmlir_1_1Operation.html">Operation</a> &amp;op) {</div>
<div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;          return isa&lt;gpu::ReturnOp&gt;(op) &amp;&amp; !op.getNumOperands();</div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;        }))</div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;    <span class="comment">// If the function already moved inside a warp_execute_on_lane0, skip.</span></div>
<div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;    <span class="keywordflow">if</span> (llvm::any_of(gpuFuncOp.getBody().getOps(), [](<a class="code" href="classmlir_1_1Operation.html">Operation</a> &amp;op) {</div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;          return isa&lt;gpu::WarpExecuteOnLane0Op&gt;(op);</div>
<div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;        }))</div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;    <span class="comment">// Create a new function with the same signature and same attributes.</span></div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Type&gt;</a> workgroupAttributionsTypes =</div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;        llvm::map_to_vector(gpuFuncOp.getWorkgroupAttributions(),</div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;                            [](<a class="code" href="classmlir_1_1BlockArgument.html">BlockArgument</a> arg) { return arg.getType(); });</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Type&gt;</a> privateAttributionsTypes =</div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;        llvm::map_to_vector(gpuFuncOp.getPrivateAttributions(),</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;                            [](<a class="code" href="classmlir_1_1BlockArgument.html">BlockArgument</a> arg) { return arg.getType(); });</div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;    <span class="keyword">auto</span> newGpuFunc = gpu::GPUFuncOp::create(</div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;        rewriter, gpuFuncOp.getLoc(), gpuFuncOp.getName(),</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;        gpuFuncOp.<a class="code" href="classmlir_1_1Builder.html#a5e44a1083e200c0aea501f30f4ddc62c">getFunctionType</a>(), workgroupAttributionsTypes,</div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;        privateAttributionsTypes);</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;    newGpuFunc-&gt;setAttrs(gpuFuncOp-&gt;getAttrs());</div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;    <span class="comment">// Create a WarpExecuteOnLane0Op with same arguments and results as the</span></div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;    <span class="comment">// original gpuFuncOp.</span></div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a5ff4c0abb5c98e53a3de90a8593026a9">setInsertionPointToEnd</a>(&amp;newGpuFunc.getFunctionBody().front());</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;    <span class="keyword">auto</span> laneId = gpu::LaneIdOp::create(</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;        rewriter, newGpuFunc.getLoc(), rewriter.<a class="code" href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">getIndexType</a>(),<span class="comment"></span></div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;<span class="comment">        /** upperBound = **/</span> mlir::IntegerAttr());</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;Type&gt;</a> gpuFuncResultType = gpuFuncOp.getFunctionType().getResults();</div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;    <span class="keyword">auto</span> warpOp = gpu::WarpExecuteOnLane0Op::create(</div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;        rewriter, laneId.getLoc(), gpuFuncResultType, laneId,</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;        <a class="code" href="namespacemlir_1_1xegpu_1_1targetinfo.html#aaa6e551ae63fe8b67d4a54868d9d797b">xegpu::targetinfo::subgroupSize</a>, newGpuFunc.getArguments(),</div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;        newGpuFunc.getArgumentTypes());</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;    <a class="code" href="classmlir_1_1Block.html">Block</a> &amp;warpBodyBlock = warpOp.getBodyRegion().<a class="code" href="classmlir_1_1Block.html#aa904889345bf1bf23a54076768158c94">front</a>();</div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;    <span class="comment">// Replace the ReturnOp of the original gpu function with a YieldOp.</span></div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;    <span class="keyword">auto</span> origRetunOp =</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;        cast&lt;gpu::ReturnOp&gt;(gpuFuncOp.getBlocks().back().getTerminator());</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">setInsertionPointAfter</a>(origRetunOp);</div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;    gpu::YieldOp::create(rewriter, origRetunOp.getLoc(),</div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;                         origRetunOp.getOperands());</div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(origRetunOp);</div>
<div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;    <span class="comment">// Move the original function body to the WarpExecuteOnLane0Op body.</span></div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#adaf2b23302d524eeb5643dcff7668ebf">inlineRegionBefore</a>(gpuFuncOp.getBody(), warpOp.getBodyRegion(),</div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;                                warpOp.getBodyRegion().begin());</div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a286510e5cc47983e5b6017bad6aa6335">eraseBlock</a>(&amp;warpBodyBlock);</div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;    <span class="comment">// Insert a new ReturnOp after the WarpExecuteOnLane0Op.</span></div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">setInsertionPointAfter</a>(warpOp);</div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;    gpu::ReturnOp::create(rewriter, newGpuFunc.getLoc(), warpOp.getResults());</div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">replaceOp</a>(gpuFuncOp, newGpuFunc);</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;  }</div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;};</div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;<span class="comment">/// Distribute a create_nd_tdesc feeding into vector.yield op of the enclosing</span></div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;<span class="comment">/// `gpu.warp_execute_on_lane_0` region. After the sinking, the warp op will</span></div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;<span class="comment">/// still contain the original op that will not be used by the yield op (and</span></div>
<div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;<span class="comment">/// should be cleaned up later). The yield op will bypass the create_nd_tdesc&#39;s</span></div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;<span class="comment">/// arguments. Tensor descriptor shape is not distributed because it is a</span></div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;<span class="comment">/// uniform value across all work items within the subgroup. However, the</span></div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;<span class="comment">/// layout information is dropped in the new tensor descriptor type.</span></div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;<span class="comment">/// Example:</span></div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;<span class="comment">///   #layout0 = #xegpu.layout&lt;wi_layout = [1, 8], wi_data = [1, 1]&gt;</span></div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;<span class="comment">///   %r = gpu.warp_execute_on_lane_0(%laneid) -&gt;</span></div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;<span class="comment">///                   (!xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;) {</span></div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;<span class="comment">///     %td = xegpu.create_nd_tdesc %arg0[0, 0]</span></div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;<span class="comment">///               : memref&lt;4x8xf32&gt; -&gt; !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;</span></div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;<span class="comment">///     vector.yield %td</span></div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;<span class="comment">/// To</span></div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;<span class="comment">///   %r:2 = gpu.warp_execute_on_lane_0(%laneid) -&gt; (...) {</span></div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;<span class="comment">///     %dead = xegpu.create_nd_tdesc %arg0[0, 0]</span></div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;<span class="comment">///               : memref&lt;4x8xf32&gt; -&gt; !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;</span></div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;<span class="comment">///     vector.yield %arg0, %dead</span></div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;<span class="comment">///   %td = xegpu.create_nd_tdesc %r#0[0, 0]: memref&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;<span class="comment">///                                 -&gt; !xegpu.tensor_desc&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;<span class="comment"></span><span class="keyword">struct </span>CreateNdDescDistribution final : <span class="keyword">public</span> <a class="code" href="structmlir_1_1gpu_1_1WarpDistributionPattern.html">gpu::WarpDistributionPattern</a> {</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;  <span class="keyword">using</span> gpu::WarpDistributionPattern::WarpDistributionPattern;</div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;  LogicalResult matchAndRewrite(gpu::WarpExecuteOnLane0Op warpOp,</div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;    <a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> *operand =</div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;        getWarpResult(warpOp, llvm::IsaPred&lt;xegpu::CreateNdDescOp&gt;);</div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;    <span class="keywordflow">if</span> (!operand)</div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;          warpOp, <span class="stringliteral">&quot;warp result is not a xegpu::CreateNdDesc op&quot;</span>);</div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;    <span class="keyword">auto</span> descOp = operand-&gt;<a class="code" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>().<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;xegpu::CreateNdDescOp&gt;();</div>
<div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;    <span class="keywordtype">unsigned</span> operandIdx = operand-&gt;<a class="code" href="classmlir_1_1OpOperand.html#a097f9026defd8afd19ab06b21aa11bdf">getOperandNumber</a>();</div>
<div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160; </div>
<div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;    xegpu::LayoutAttr layout = descOp.getType().getLayoutAttr();</div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;    <span class="keywordflow">if</span> (!layout)</div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;          descOp, <span class="stringliteral">&quot;the tensor descriptor lacks layout attribute&quot;</span>);</div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160; </div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;size_t&gt;</a> newRetIndices;</div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> newYieldValues;</div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Type&gt;</a> newYieldTypes;</div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160; </div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;    <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1Value.html">Value</a> operand : descOp-&gt;getOperands()) {</div>
<div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;      newYieldValues.push_back(operand);</div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;      newYieldTypes.push_back(operand.getType());</div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;    }</div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">setInsertionPoint</a>(warpOp);</div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;    gpu::WarpExecuteOnLane0Op newWarpOp = moveRegionToNewWarpOpAndAppendReturns(</div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;        rewriter, warpOp, <span class="comment">/* new yieled values = */</span> newYieldValues,</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;        <span class="comment">/* new yielded types = */</span> newYieldTypes, newRetIndices);</div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160; </div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> newDescOperands;</div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i : newRetIndices) {</div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;      newDescOperands.push_back(newWarpOp.getResult(i));</div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;    }</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">setInsertionPointAfter</a>(newWarpOp);</div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;    xegpu::TensorDescType distributedTensorDescTy =</div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;        descOp.getType().dropLayouts(); <span class="comment">// Distributed tensor descriptor type</span></div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;                                        <span class="comment">// does not contain layout info.</span></div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> newDescOp = xegpu::CreateNdDescOp::create(</div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;        rewriter, newWarpOp.getLoc(), distributedTensorDescTy, newDescOperands,</div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;        descOp-&gt;getAttrs());</div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160; </div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> distributedVal = newWarpOp.getResult(operandIdx);</div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;    <span class="comment">// Resolve the distributed type to the expected type.</span></div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;    newDescOp =</div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;        resolveDistributedTy(newDescOp, distributedVal.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>(), rewriter);</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a61b4cea69baed7a36d0cd02f5b44c176">replaceAllUsesWith</a>(distributedVal, newDescOp);</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;  }</div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;};</div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;<span class="comment">/// Distribute a store_nd op at the end of enclosing</span></div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;<span class="comment">/// `gpu.warp_execute_on_lane_0`. In case arguments for the store are passed</span></div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;<span class="comment">/// through the warp op interface they would be propagated as returned values.</span></div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;<span class="comment">/// Source vector is distributed based on lane layout. Appropriate cast ops are</span></div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;<span class="comment">/// inserted if the distributed types does not match expected xegpu SIMT types.</span></div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;<span class="comment">/// Example:</span></div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;<span class="comment">///   #layout0 = #xegpu.layout&lt;wi_layout = [1, 8], wi_data = [1, 1]&gt;</span></div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;<span class="comment">///   gpu.warp_execute_on_lane_0(%laneid) -&gt; () {</span></div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;<span class="comment">///     xegpu.store_nd %arg0, %arg1: vector&lt;4x8xf32&gt;,</span></div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;<span class="comment">///                                 !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;</span></div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;<span class="comment">/// To</span></div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;<span class="comment">///   %r:2 = gpu.warp_execute_on_lane_0(%laneid) -&gt; (vector&lt;4x1xf32&gt;,</span></div>
<div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;<span class="comment">///   !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;) {</span></div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;<span class="comment">///     gpu.yield %arg0, %arg1: vector&lt;4x8xf32&gt;, !xegpu.tensor_desc&lt;4x8xf32,</span></div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;<span class="comment">///     #layout0&gt;</span></div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;<span class="comment">///   %0 = vector.shape_cast %r#0: vector&lt;4x1xf32&gt; to vector&lt;4xf32&gt;</span></div>
<div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;<span class="comment">///   %1 = unrealized_conversion_cast %r#1: !xegpu.tensor_desc&lt;4x8xf32,</span></div>
<div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;<span class="comment">///   #layout0&gt;</span></div>
<div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;<span class="comment">///     -&gt; !xegpu.tensor_desc&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;<span class="comment">///   xegpu.store_nd %0, %1: vector&lt;4xf32&gt;,</span></div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;<span class="comment">///     !xegpu.tensor_desc&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;<span class="comment"></span><span class="keyword">struct </span>StoreNdDistribution final : <span class="keyword">public</span> <a class="code" href="structmlir_1_1gpu_1_1WarpDistributionPattern.html">gpu::WarpDistributionPattern</a> {</div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;  <span class="keyword">using</span> gpu::WarpDistributionPattern::WarpDistributionPattern;</div>
<div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;  LogicalResult matchAndRewrite(gpu::WarpExecuteOnLane0Op warpOp,</div>
<div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;    <span class="keyword">auto</span> yield = cast&lt;gpu::YieldOp&gt;(</div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;        warpOp.getBodyRegion().getBlocks().begin()-&gt;getTerminator());</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *lastNode = yield-&gt;getPrevNode();</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;    <span class="keyword">auto</span> storeOp = dyn_cast_or_null&lt;xegpu::StoreNdOp&gt;(lastNode);</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;    <span class="keywordflow">if</span> (!storeOp)</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160; </div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;    int64_t offsetSize = <span class="keyword">static_cast&lt;</span>int64_t<span class="keyword">&gt;</span>(storeOp.getOffsets().size());</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;    <span class="keywordflow">if</span> ((offsetSize != 0) || storeOp.getConstOffsetsAttr())</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160; </div>
<div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;    xegpu::TensorDescType tensorDescTy = storeOp.getTensorDescType();</div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;    xegpu::LayoutAttr layout = tensorDescTy.getLayoutAttr();</div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;    <span class="keywordflow">if</span> (!layout)</div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;          storeOp, <span class="stringliteral">&quot;the source tensor descriptor lacks layout attribute&quot;</span>);</div>
<div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160; </div>
<div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;    FailureOr&lt;VectorType&gt; distributedTypeByWarpOpOrFailure =</div>
<div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;        getDistVecTypeBasedOnLaneLayout(layout, storeOp.getValueType());</div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;    <span class="keywordflow">if</span> (failed(distributedTypeByWarpOpOrFailure))</div>
<div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(storeOp,</div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;                                         <span class="stringliteral">&quot;Failed to distribute the type&quot;</span>);</div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;    VectorType distributedTypeByWarpOp =</div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;        distributedTypeByWarpOpOrFailure.value();</div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160; </div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;size_t&gt;</a> newRetIndices;</div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;    gpu::WarpExecuteOnLane0Op newWarpOp = moveRegionToNewWarpOpAndAppendReturns(</div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;        rewriter, warpOp,</div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;        <span class="comment">/* new yielded values = */</span></div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;        <a class="code" href="classmlir_1_1ValueRange.html">ValueRange</a>{storeOp.getValue(), storeOp.getTensorDesc()},</div>
<div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;        <span class="comment">/* new yielded types = */</span></div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;        <a class="code" href="classmlir_1_1TypeRange.html">TypeRange</a>{distributedTypeByWarpOp, storeOp.getTensorDescType()},</div>
<div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;        newRetIndices);</div>
<div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;    <span class="comment">// Create a new store op outside the warp op with the distributed vector</span></div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;    <span class="comment">// type. Tensor descriptor is not distributed.</span></div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">setInsertionPointAfter</a>(newWarpOp);</div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> newStoreOperands;</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160; </div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;    <span class="comment">// For the value operand, there can be a mismatch between the vector type</span></div>
<div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;    <span class="comment">// distributed by the warp op and (xegpu-specific) distributed type</span></div>
<div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;    <span class="comment">// supported by the store op. Type mismatch must be resolved using</span></div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;    <span class="comment">// appropriate cast op.</span></div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;    FailureOr&lt;VectorType&gt; storeNdDistributedValueTyOrFailure =</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;        <a class="code" href="namespacemlir_1_1xegpu.html#af95421174e54b5dfc990dfb4357fa13c">xegpu::getDistributedVectorType</a>(storeOp.getTensorDescType());</div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;    <span class="keywordflow">if</span> (failed(storeNdDistributedValueTyOrFailure))</div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;          storeOp, <span class="stringliteral">&quot;Failed to get distributed vector type for the store op&quot;</span>);</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;    newStoreOperands.push_back(resolveDistributedTy(</div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;        newWarpOp.getResult(newRetIndices[0]),</div>
<div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;        storeNdDistributedValueTyOrFailure.value(), rewriter));</div>
<div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;    <span class="comment">// For the tensor descriptor operand, the layout attribute is dropped after</span></div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;    <span class="comment">// distribution. Types needs to be resolved in this case also.</span></div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;    xegpu::TensorDescType distributedTensorDescTy =</div>
<div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;        storeOp.getTensorDescType().dropLayouts();</div>
<div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;    newStoreOperands.push_back(</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;        resolveDistributedTy(newWarpOp.getResult(newRetIndices[1]),</div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;                             distributedTensorDescTy, rewriter));</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160; </div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;    <span class="keyword">auto</span> newStoreOp =</div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;        xegpu::StoreNdOp::create(rewriter, newWarpOp.getLoc(), <a class="code" href="classmlir_1_1TypeRange.html">TypeRange</a>{},</div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;                                 newStoreOperands, storeOp-&gt;getAttrs());</div>
<div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;    <a class="code" href="namespacemlir_1_1xegpu.html#ace8e74148db06970f9e51f8da0a7066d">xegpu::removeLayoutAttrs</a>(newStoreOp);</div>
<div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(storeOp);</div>
<div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;  }</div>
<div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;};</div>
<div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;<span class="comment">/// Distribute a load_nd op feeding into vector.yield op for the enclosing</span></div>
<div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;<span class="comment">/// `gpu.warp_execute_on_lane_0` and put it after the warp op.</span></div>
<div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;<span class="comment">/// The warp op will still contain the original op that will not be used by</span></div>
<div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;<span class="comment">/// the yield op (and should be cleaned up later). The yield op will</span></div>
<div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;<span class="comment">/// bypass the load&#39;s arguments. Only the loaded vector is distributed</span></div>
<div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;<span class="comment">/// according to lane layout and, tensor descriptor types is not</span></div>
<div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;<span class="comment">/// distributed. Appropriate cast ops are inserted if the distributed types does</span></div>
<div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;<span class="comment">/// not match expected xegpu SIMT types.</span></div>
<div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;<span class="comment">/// Example:</span></div>
<div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;<span class="comment">///   #layout0 = #xegpu.layout&lt;wi_layout = [1, 8], wi_data = [1, 1]&gt;</span></div>
<div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;<span class="comment">///   %r = gpu.warp_execute_on_lane_0(%laneid) -&gt;</span></div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;<span class="comment">///                   (vector&lt;4x1xf32&gt;) {</span></div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;<span class="comment">///     %ld = xegpu.load_nd %arg0, %arg1: !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;</span></div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;<span class="comment">///     -&gt;</span></div>
<div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;<span class="comment">///       vector&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;<span class="comment">///     gpu.yield %ld</span></div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;<span class="comment">/// To</span></div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;<span class="comment">///   %r:2 = gpu.warp_execute_on_lane_0(%laneid) -&gt; (vector&lt;4x1xf32&gt;,</span></div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;<span class="comment">///   !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;) {</span></div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;<span class="comment">///     %dead = xegpu.load_nd %arg0: !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt; -&gt;</span></div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;<span class="comment">///     vector&lt;4x8xf32&gt; gpu.yield %dead, %arg0</span></div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;<span class="comment">///   %0 = unrealized_conversion_cast %r#1: !xegpu.tensor_desc&lt;4x8xf32,</span></div>
<div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;<span class="comment">///        #layout0&gt; -&gt; !xegpu.tensor_desc&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;<span class="comment">///   %1 = xegpu.load_nd %0: !xegpu.tensor_desc&lt;4x8xf32&gt; -&gt; vector&lt;4xf32&gt;</span></div>
<div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;<span class="comment">///   %2 = vector.shape_cast %r#0: vector&lt;4xf32&gt; to vector&lt;4x1xf32&gt;</span></div>
<div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;<span class="comment"></span><span class="keyword">struct </span>LoadNdDistribution final : <span class="keyword">public</span> <a class="code" href="structmlir_1_1gpu_1_1WarpDistributionPattern.html">gpu::WarpDistributionPattern</a> {</div>
<div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;  <span class="keyword">using</span> gpu::WarpDistributionPattern::WarpDistributionPattern;</div>
<div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;  LogicalResult matchAndRewrite(gpu::WarpExecuteOnLane0Op warpOp,</div>
<div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;    <a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> *operand = getWarpResult(warpOp, [&amp;](<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op) {</div>
<div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;      <span class="keywordflow">if</span> (!isa&lt;xegpu::LoadNdOp&gt;(op))</div>
<div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;      <span class="comment">// Make sure the same load op is the last operation in the warp op body.</span></div>
<div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;      <span class="comment">// This ensure that load op is not sinked earlier violating any barrier</span></div>
<div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;      <span class="comment">// synchronizations.</span></div>
<div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;      <span class="keyword">auto</span> yield = cast&lt;gpu::YieldOp&gt;(</div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;          warpOp.getBodyRegion().getBlocks().begin()-&gt;getTerminator());</div>
<div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;      <span class="keywordflow">return</span> yield-&gt;getPrevNode() == op;</div>
<div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;    });</div>
<div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160; </div>
<div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;    <span class="keywordflow">if</span> (!operand)</div>
<div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;          warpOp, <span class="stringliteral">&quot;warp result is not a xegpu::LoadNd op&quot;</span>);</div>
<div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160; </div>
<div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;    <span class="keyword">auto</span> loadOp = operand-&gt;<a class="code" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>().<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;xegpu::LoadNdOp&gt;();</div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160; </div>
<div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;    int64_t offsetSize = <span class="keyword">static_cast&lt;</span>int64_t<span class="keyword">&gt;</span>(loadOp.getOffsets().size());</div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;    <span class="keywordflow">if</span> ((offsetSize != 0) || loadOp.getConstOffsetsAttr())</div>
<div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160; </div>
<div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;    xegpu::TensorDescType tensorDescTy = loadOp.getTensorDescType();</div>
<div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;    xegpu::LayoutAttr layout = tensorDescTy.getLayoutAttr();</div>
<div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;    <span class="keywordflow">if</span> (!layout)</div>
<div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;          loadOp, <span class="stringliteral">&quot;the source tensor descriptor lacks layout attribute&quot;</span>);</div>
<div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160; </div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;    <span class="keywordtype">unsigned</span> operandIdx = operand-&gt;<a class="code" href="classmlir_1_1OpOperand.html#a097f9026defd8afd19ab06b21aa11bdf">getOperandNumber</a>();</div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;    VectorType distributedTypeByWarpOp =</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;        cast&lt;VectorType&gt;(warpOp.getResult(operandIdx).getType());</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160; </div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;size_t&gt;</a> newRetIndices;</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;    gpu::WarpExecuteOnLane0Op newWarpOp = moveRegionToNewWarpOpAndAppendReturns(</div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;        rewriter, warpOp,</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;        <span class="comment">/* new yielded values = */</span> loadOp.getTensorDesc(),</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;        <span class="comment">/* new yielded types = */</span> tensorDescTy, newRetIndices);</div>
<div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160; </div>
<div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;    <span class="comment">// Create a new load op outside the warp op with the distributed vector</span></div>
<div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;    <span class="comment">// type.</span></div>
<div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">setInsertionPointAfter</a>(newWarpOp);</div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;    FailureOr&lt;VectorType&gt; loadNdDistValueTyOrFailure =</div>
<div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;        <a class="code" href="namespacemlir_1_1xegpu.html#af95421174e54b5dfc990dfb4357fa13c">xegpu::getDistributedVectorType</a>(loadOp.getTensorDescType());</div>
<div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;    <span class="keywordflow">if</span> (failed(loadNdDistValueTyOrFailure))</div>
<div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;          loadOp, <span class="stringliteral">&quot;Failed to get distributed vector type for the load op&quot;</span>);</div>
<div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;    xegpu::TensorDescType distributedTensorDescTy =</div>
<div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;        loadOp.getTensorDescType().dropLayouts(); <span class="comment">// Distributed tensor</span></div>
<div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;                                                  <span class="comment">// descriptor type does not</span></div>
<div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;                                                  <span class="comment">// contain layout info.</span></div>
<div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;    <span class="keyword">auto</span> newLoadOp = xegpu::LoadNdOp::create(</div>
<div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;        rewriter, newWarpOp.getLoc(), loadNdDistValueTyOrFailure.value(),</div>
<div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;        resolveDistributedTy(newWarpOp-&gt;getResult(newRetIndices[0]),</div>
<div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;                             distributedTensorDescTy, rewriter),</div>
<div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;        loadOp-&gt;getAttrs());</div>
<div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;    <a class="code" href="namespacemlir_1_1xegpu.html#ace8e74148db06970f9e51f8da0a7066d">xegpu::removeLayoutAttrs</a>(newLoadOp);</div>
<div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;    <span class="comment">// Set the packed attribute if the layout requires it.</span></div>
<div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;    newLoadOp.setPacked(hasPackedLayout(layout));</div>
<div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> distributedVal = newWarpOp.getResult(operandIdx);</div>
<div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;    <span class="comment">// There can be a conflict between the vector type distributed by the</span></div>
<div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;    <span class="comment">// warp op and (xegpu-specific) distributed type supported by the load</span></div>
<div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;    <span class="comment">// op. Resolve these mismatches by inserting a cast.</span></div>
<div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> tyResolvedVal = resolveDistributedTy(</div>
<div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;        newLoadOp.getResult(), distributedTypeByWarpOp, rewriter);</div>
<div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a61b4cea69baed7a36d0cd02f5b44c176">replaceAllUsesWith</a>(distributedVal, tyResolvedVal);</div>
<div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;  }</div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;};</div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;<span class="comment">/// Distribute a dpas op feeding into vector.yield op for the enclosing</span></div>
<div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;<span class="comment">/// `gpu.warp_execute_on_lane_0` and put it after the warp op.</span></div>
<div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;<span class="comment">/// The warp op will still contain the original op that will not be used by</span></div>
<div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;<span class="comment">/// the yield op (and should be cleaned up later). The yield op will</span></div>
<div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;<span class="comment">/// bypass the dpas&#39;s arguments. Appropriate cast ops are inserted if the</span></div>
<div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;<span class="comment">/// distributed types does not match expected xegpu SIMT types.</span></div>
<div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;<span class="comment">/// Example:</span></div>
<div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;<span class="comment">///   #lo_a = #xegpu.layout&lt;wi_layout = [1, 16], wi_data = [1, 1]&gt;</span></div>
<div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;<span class="comment">///   #lo_b = #xegpu.layout&lt;wi_layout = [1, 16], wi_data = [2, 1]&gt;</span></div>
<div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;<span class="comment">///   #lo_c = #xegpu.layout&lt;wi_layout = [1, 16], wi_data = [1, 1]&gt;</span></div>
<div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;<span class="comment">///   %r = gpu.warp_execute_on_lane_0(%laneid) -&gt;</span></div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;<span class="comment">///                   (vector&lt;8x1xf32&gt;) {</span></div>
<div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;<span class="comment">///     %dpas = xegpu.dpas %arg0, %arg1: vector&lt;8x16xf16&gt;, vector&lt;16x16xf16&gt; -&gt;</span></div>
<div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;<span class="comment">///       vector&lt;8x16xf32&gt;</span></div>
<div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;<span class="comment">///     gpu.yield %dpas</span></div>
<div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;<span class="comment">/// To</span></div>
<div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;<span class="comment">///   %r:2 = gpu.warp_execute_on_lane_0(%laneid) -&gt; (vector&lt;8x1xf32&gt;,</span></div>
<div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;<span class="comment">///   vector&lt;8x1xf16&gt;, vector&lt;16x1xf16&gt;) {</span></div>
<div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;<span class="comment">///     %dead = xegpu.dpas %arg0, %arg1: vector&lt;8x16xf16&gt;, vector&lt;16x16xf16&gt;</span></div>
<div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;<span class="comment">///       -&gt; vector&lt;8x16xf32&gt;</span></div>
<div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;<span class="comment">///     gpu.yield %dead, %arg0, %arg1</span></div>
<div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;<span class="comment">///   %0 = vector.shape_cast %r#1: vector&lt;8x1xf16&gt; to vector&lt;8xf16&gt;</span></div>
<div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;<span class="comment">///   %1 = vector.shape_cast %r#2: vector&lt;16x1xf16&gt; to vector&lt;16xf16&gt;</span></div>
<div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;<span class="comment">///   %2 = xegpu.dpas %0, %1: vector&lt;8xf16&gt;, vector&lt;16xf16&gt; -&gt;</span></div>
<div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;<span class="comment">///     vector&lt;8xf32&gt;</span></div>
<div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;<span class="comment">///   %dpas = vector.shape_cast %2: vector&lt;8xf32&gt; to vector&lt;8x1xf32&gt;</span></div>
<div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;<span class="comment"></span><span class="keyword">struct </span>DpasDistribution final : <span class="keyword">public</span> <a class="code" href="structmlir_1_1gpu_1_1WarpDistributionPattern.html">gpu::WarpDistributionPattern</a> {</div>
<div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;  <span class="keyword">using</span> gpu::WarpDistributionPattern::WarpDistributionPattern;</div>
<div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;  LogicalResult matchAndRewrite(gpu::WarpExecuteOnLane0Op warpOp,</div>
<div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;    <a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> *operand = getWarpResult(warpOp, llvm::IsaPred&lt;xegpu::DpasOp&gt;);</div>
<div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;    <span class="keywordflow">if</span> (!operand)</div>
<div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(warpOp,</div>
<div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;                                         <span class="stringliteral">&quot;warp result is not a xegpu::Dpas op&quot;</span>);</div>
<div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160; </div>
<div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;    <span class="keyword">auto</span> dpasOp = operand-&gt;<a class="code" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>().<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;xegpu::DpasOp&gt;();</div>
<div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;    <span class="keywordtype">unsigned</span> operandIdx = operand-&gt;<a class="code" href="classmlir_1_1OpOperand.html#a097f9026defd8afd19ab06b21aa11bdf">getOperandNumber</a>();</div>
<div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;    std::string layoutAName = <a class="code" href="namespacemlir_1_1xegpu.html#a672ad62c985a7ae405189e62c203dd64">xegpu::getLayoutName</a>(dpasOp-&gt;getOpOperand(0));</div>
<div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;    std::string layoutBName = <a class="code" href="namespacemlir_1_1xegpu.html#a672ad62c985a7ae405189e62c203dd64">xegpu::getLayoutName</a>(dpasOp-&gt;getOpOperand(1));</div>
<div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;    std::string layoutCName = <a class="code" href="namespacemlir_1_1xegpu.html#a672ad62c985a7ae405189e62c203dd64">xegpu::getLayoutName</a>(dpasOp-&gt;getOpResult(0));</div>
<div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160; </div>
<div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;    xegpu::LayoutAttr layoutA =</div>
<div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;        dpasOp-&gt;getAttrOfType&lt;xegpu::LayoutAttr&gt;(layoutAName);</div>
<div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;    xegpu::LayoutAttr layoutB =</div>
<div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;        dpasOp-&gt;getAttrOfType&lt;xegpu::LayoutAttr&gt;(layoutBName);</div>
<div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;    xegpu::LayoutAttr layoutOut =</div>
<div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;        dpasOp-&gt;getAttrOfType&lt;xegpu::LayoutAttr&gt;(layoutCName);</div>
<div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;    <span class="keywordflow">if</span> (!layoutA || !layoutB || !layoutOut)</div>
<div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;          dpasOp,</div>
<div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;          <span class="stringliteral">&quot;the xegpu::Dpas op lacks layout attribute for A, B or output&quot;</span>);</div>
<div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160; </div>
<div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;    FailureOr&lt;VectorType&gt; distLhsTypeByWarpOpOrFailure =</div>
<div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;        getDistVecTypeBasedOnLaneLayout(layoutA, dpasOp.getLhsType());</div>
<div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;    FailureOr&lt;VectorType&gt; distRhsTypeByWarpOpOrFailure =</div>
<div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;        getDistVecTypeBasedOnLaneLayout(layoutB, dpasOp.getRhsType());</div>
<div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;    FailureOr&lt;VectorType&gt; distResultTypeByWarpOpOrFailure =</div>
<div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;        getDistVecTypeBasedOnLaneLayout(layoutOut, dpasOp.getResultType());</div>
<div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;    <span class="keywordflow">if</span> (failed(distLhsTypeByWarpOpOrFailure) ||</div>
<div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;        failed(distRhsTypeByWarpOpOrFailure) ||</div>
<div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;        failed(distResultTypeByWarpOpOrFailure))</div>
<div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;          dpasOp,</div>
<div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;          <span class="stringliteral">&quot;Failed to distribute the A, B or output types in xegpu::Dpas op&quot;</span>);</div>
<div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160; </div>
<div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">llvm::SmallVector&lt;Value, 3&gt;</a> newYieldValues{dpasOp.getLhs(),</div>
<div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;                                               dpasOp.getRhs()};</div>
<div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">llvm::SmallVector&lt;Type, 3&gt;</a> newYieldTypes{</div>
<div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;        distLhsTypeByWarpOpOrFailure.value(),</div>
<div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;        distRhsTypeByWarpOpOrFailure.value()};</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;    <span class="comment">// Dpas acc operand is optional.</span></div>
<div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;    <span class="keywordflow">if</span> (dpasOp.getAcc()) {</div>
<div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;      newYieldValues.push_back(dpasOp.getAcc());</div>
<div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;      newYieldTypes.push_back(distResultTypeByWarpOpOrFailure.value());</div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;    }</div>
<div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;    <span class="comment">// Create a new warp op without the dpas.</span></div>
<div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;size_t&gt;</a> newRetIndices;</div>
<div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;    gpu::WarpExecuteOnLane0Op newWarpOp = moveRegionToNewWarpOpAndAppendReturns(</div>
<div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;        rewriter, warpOp, newYieldValues, newYieldTypes, newRetIndices);</div>
<div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160; </div>
<div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;    FailureOr&lt;VectorType&gt; expectedDistLhsTyOrFailure =</div>
<div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;        <a class="code" href="namespacemlir_1_1xegpu.html#af95421174e54b5dfc990dfb4357fa13c">xegpu::getDistributedVectorType</a>(dpasOp.getLhsType(), layoutA);</div>
<div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;    FailureOr&lt;VectorType&gt; expectedDistRhsTyOrFailure =</div>
<div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;        <a class="code" href="namespacemlir_1_1xegpu.html#af95421174e54b5dfc990dfb4357fa13c">xegpu::getDistributedVectorType</a>(dpasOp.getRhsType(), layoutB);</div>
<div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;    FailureOr&lt;VectorType&gt; expectedDistResultTyOrFailure =</div>
<div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;        <a class="code" href="namespacemlir_1_1xegpu.html#af95421174e54b5dfc990dfb4357fa13c">xegpu::getDistributedVectorType</a>(dpasOp.getResultType(), layoutOut);</div>
<div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;    <span class="keywordflow">if</span> (failed(expectedDistLhsTyOrFailure) ||</div>
<div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;        failed(expectedDistRhsTyOrFailure) ||</div>
<div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;        failed(expectedDistResultTyOrFailure))</div>
<div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;          dpasOp,</div>
<div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;          <span class="stringliteral">&quot;Failed to get distributed vector type for the dpas operands.&quot;</span>);</div>
<div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;    <span class="comment">// Create a new dpas op outside the warp op.</span></div>
<div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">setInsertionPointAfter</a>(newWarpOp);</div>
<div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> newDpasOperands;</div>
<div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;VectorType&gt;</a> newDpasOperandExpectedTypes;</div>
<div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160; </div>
<div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;    <span class="comment">// Resolve the distributed types with the original types.</span></div>
<div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;    newDpasOperandExpectedTypes.push_back(expectedDistLhsTyOrFailure.value());</div>
<div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;    newDpasOperandExpectedTypes.push_back(expectedDistRhsTyOrFailure.value());</div>
<div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;    VectorType distributedResultTy = expectedDistResultTyOrFailure.value();</div>
<div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;    <span class="keywordflow">if</span> (dpasOp.getAcc())</div>
<div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;      newDpasOperandExpectedTypes.push_back(distributedResultTy);</div>
<div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160; </div>
<div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; newRetIndices.size(); i++) {</div>
<div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;      newDpasOperands.push_back(</div>
<div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;          resolveDistributedTy(newWarpOp.getResult(newRetIndices[i]),</div>
<div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;                               newDpasOperandExpectedTypes[i], rewriter));</div>
<div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;    }</div>
<div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160;    <span class="keyword">auto</span> newDpasOp = xegpu::DpasOp::create(rewriter, newWarpOp-&gt;getLoc(),</div>
<div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;                                           distributedResultTy, newDpasOperands,</div>
<div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;                                           dpasOp-&gt;getAttrs());</div>
<div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;    <a class="code" href="namespacemlir_1_1xegpu.html#ace8e74148db06970f9e51f8da0a7066d">xegpu::removeLayoutAttrs</a>(newDpasOp);</div>
<div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> distributedVal = newWarpOp.getResult(operandIdx);</div>
<div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;    <span class="comment">// Resolve the output type.</span></div>
<div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> typeResolved =</div>
<div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;        resolveDistributedTy(newDpasOp.getResult(),</div>
<div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;                             distResultTypeByWarpOpOrFailure.value(), rewriter);</div>
<div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a61b4cea69baed7a36d0cd02f5b44c176">replaceAllUsesWith</a>(distributedVal, typeResolved);</div>
<div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;  }</div>
<div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;};</div>
<div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;<span class="comment">/// Sink an update_nd_offset op feeding into yield op of an enclosing</span></div>
<div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;<span class="comment">/// `gpu.warp_execute_on_lane_0` region. The warp op will still contain the</span></div>
<div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;<span class="comment">/// original op that will not be used by the yield op (and should be cleaned</span></div>
<div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;<span class="comment">/// up later). The yield op will bypass the updateOp&#39;s arguments. The tensor</span></div>
<div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;<span class="comment">/// descriptor type is not distributed. Appropriate cast ops are inserted if</span></div>
<div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;<span class="comment">/// the distributed types does not match expected xegpu SIMT types.</span></div>
<div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160;<span class="comment">/// Example:</span></div>
<div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;<span class="comment">///   #layout0 = #xegpu.layout&lt;wi_layout = [1, 8], wi_data = [1, 1]&gt;</span></div>
<div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;<span class="comment">///   %r = gpu.warp_execute_on_lane_0(%laneid) -&gt;</span></div>
<div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;<span class="comment">///                   (!xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;) {</span></div>
<div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;<span class="comment">///     %update = xegpu.update_nd_offset %arg0, [%c32, %c16]:</span></div>
<div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;<span class="comment">///       !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;</span></div>
<div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160;<span class="comment">///     gpu.yield %update</span></div>
<div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;<span class="comment">///   ...</span></div>
<div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;<span class="comment">/// To</span></div>
<div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;<span class="comment">///   %r:2 = gpu.warp_execute_on_lane_0(%laneid) -&gt; (</span></div>
<div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;<span class="comment">///     !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;,</span></div>
<div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;<span class="comment">///     !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;, index, index) {</span></div>
<div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;<span class="comment">///     %dead = xegpu.update_nd_offset %arg0, [%c32, %c16]:</span></div>
<div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;<span class="comment">///       !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt; gpu.yield %dead, %arg0</span></div>
<div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;<span class="comment">///     gpu.yield %dead, %arg0, %c32, %c16</span></div>
<div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;<span class="comment">///   %0 = xegpu.unrealized_conversion_cast %r#1: !xegpu.tensor_desc&lt;4x8xf32,</span></div>
<div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;<span class="comment">///        #layout0&gt; -&gt; !xegpu.tensor_desc&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;<span class="comment">///   %1 = xegpu.update_nd_offset %0, [%r#2, %r#3]:</span></div>
<div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;<span class="comment">///     !xegpu.tensor_desc&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;<span class="comment">///   ...</span></div>
<div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;<span class="comment"></span><span class="keyword">struct </span>UpdateNdOffsetDistribution final : <span class="keyword">public</span> <a class="code" href="structmlir_1_1gpu_1_1WarpDistributionPattern.html">gpu::WarpDistributionPattern</a> {</div>
<div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;  <span class="keyword">using</span> gpu::WarpDistributionPattern::WarpDistributionPattern;</div>
<div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;  LogicalResult matchAndRewrite(gpu::WarpExecuteOnLane0Op warpOp,</div>
<div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;    <a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> *operand =</div>
<div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;        getWarpResult(warpOp, llvm::IsaPred&lt;xegpu::UpdateNdOffsetOp&gt;);</div>
<div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;    <span class="keywordflow">if</span> (!operand)</div>
<div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;          warpOp, <span class="stringliteral">&quot;warp result is not a xegpu::UpdateNdOffset op&quot;</span>);</div>
<div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;    <span class="keyword">auto</span> <a class="code" href="XeGPUPropagateLayout_8cpp.html#abc382893a51ad62af8afb28f74ba0555">updateOp</a> = operand-&gt;<a class="code" href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">get</a>().<a class="code" href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">getDefiningOp</a>&lt;xegpu::UpdateNdOffsetOp&gt;();</div>
<div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;    <span class="keywordtype">unsigned</span> operandIdx = operand-&gt;<a class="code" href="classmlir_1_1OpOperand.html#a097f9026defd8afd19ab06b21aa11bdf">getOperandNumber</a>();</div>
<div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;    <span class="comment">// new update op does not have layout attribute.</span></div>
<div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;    xegpu::TensorDescType newTensorDescTy =</div>
<div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;        <a class="code" href="XeGPUPropagateLayout_8cpp.html#abc382893a51ad62af8afb28f74ba0555">updateOp</a>.getTensorDescType().dropLayouts();</div>
<div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160; </div>
<div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value, 3&gt;</a> newYieldValues;</div>
<div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Type, 3&gt;</a> newYieldTypes;</div>
<div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;    <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1Value.html">Value</a> operand : <a class="code" href="XeGPUPropagateLayout_8cpp.html#abc382893a51ad62af8afb28f74ba0555">updateOp</a>-&gt;getOperands()) {</div>
<div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;      newYieldValues.push_back(operand);</div>
<div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;      <span class="keywordflow">if</span> (isa&lt;xegpu::TensorDescType&gt;(operand.getType())) {</div>
<div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;        newYieldTypes.push_back(newTensorDescTy);</div>
<div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;      } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;        newYieldTypes.push_back(operand.getType());</div>
<div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;      }</div>
<div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;    }</div>
<div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;size_t&gt;</a> newRetIndices;</div>
<div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;    gpu::WarpExecuteOnLane0Op newWarpOp = moveRegionToNewWarpOpAndAppendReturns(</div>
<div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;        rewriter, warpOp, newYieldValues, newYieldTypes, newRetIndices);</div>
<div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">setInsertionPointAfter</a>(newWarpOp);</div>
<div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> newUpdateOperands;</div>
<div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i : newRetIndices) {</div>
<div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;      <span class="comment">// For the tensor descriptor operand, the layout attribute is dropped</span></div>
<div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;      <span class="comment">// after distribution. Types needs to be resolved in this case.</span></div>
<div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;      <span class="keywordflow">if</span> (isa&lt;xegpu::TensorDescType&gt;(newWarpOp.getResult(i).getType())) {</div>
<div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;        newUpdateOperands.push_back(resolveDistributedTy(</div>
<div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160;            newWarpOp.getResult(i), newTensorDescTy, rewriter));</div>
<div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;      } <span class="keywordflow">else</span> {</div>
<div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160;        newUpdateOperands.push_back(newWarpOp.getResult(i));</div>
<div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;      }</div>
<div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;    }</div>
<div class="line"><a name="l00728"></a><span class="lineno">  728</span>&#160;    <span class="comment">// Create a new update op outside the warp op.</span></div>
<div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;    <span class="keyword">auto</span> newUpdateOp = xegpu::UpdateNdOffsetOp::create(</div>
<div class="line"><a name="l00730"></a><span class="lineno">  730</span>&#160;        rewriter, newWarpOp.getLoc(), newTensorDescTy, newUpdateOperands,</div>
<div class="line"><a name="l00731"></a><span class="lineno">  731</span>&#160;        <a class="code" href="XeGPUPropagateLayout_8cpp.html#abc382893a51ad62af8afb28f74ba0555">updateOp</a>-&gt;getAttrs());</div>
<div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160;    <a class="code" href="namespacemlir_1_1xegpu.html#ace8e74148db06970f9e51f8da0a7066d">xegpu::removeLayoutAttrs</a>(newUpdateOp);</div>
<div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> distributedVal = newWarpOp.getResult(operandIdx);</div>
<div class="line"><a name="l00734"></a><span class="lineno">  734</span>&#160;    <span class="comment">// Resolve the distributed type with the original type.</span></div>
<div class="line"><a name="l00735"></a><span class="lineno">  735</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> typeResolved = resolveDistributedTy(</div>
<div class="line"><a name="l00736"></a><span class="lineno">  736</span>&#160;        newUpdateOp.getResult(), distributedVal.<a class="code" href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">getType</a>(), rewriter);</div>
<div class="line"><a name="l00737"></a><span class="lineno">  737</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a61b4cea69baed7a36d0cd02f5b44c176">replaceAllUsesWith</a>(distributedVal, typeResolved);</div>
<div class="line"><a name="l00738"></a><span class="lineno">  738</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00739"></a><span class="lineno">  739</span>&#160;  }</div>
<div class="line"><a name="l00740"></a><span class="lineno">  740</span>&#160;};</div>
<div class="line"><a name="l00741"></a><span class="lineno">  741</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;<span class="comment">/// Distribute a prefetch_nd op at the end of enclosing</span></div>
<div class="line"><a name="l00743"></a><span class="lineno">  743</span>&#160;<span class="comment">/// `gpu.warp_execute_on_lane_0`. In case arguments for the prefetch are passed</span></div>
<div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;<span class="comment">/// through the warp op interface they would be propagated as returned values.</span></div>
<div class="line"><a name="l00745"></a><span class="lineno">  745</span>&#160;<span class="comment">/// Tensor descriptor shape is not distributed because it is a uniform value</span></div>
<div class="line"><a name="l00746"></a><span class="lineno">  746</span>&#160;<span class="comment">/// across all work items within the subgroup. Appropriate cast ops are inserted</span></div>
<div class="line"><a name="l00747"></a><span class="lineno">  747</span>&#160;<span class="comment">/// if the distributed types does not match expected xegpu SIMT types.</span></div>
<div class="line"><a name="l00748"></a><span class="lineno">  748</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00749"></a><span class="lineno">  749</span>&#160;<span class="comment">/// Example:</span></div>
<div class="line"><a name="l00750"></a><span class="lineno">  750</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160;<span class="comment">///   #layout0 = #xegpu.layout&lt;wi_layout = [1, 8], wi_data = [1, 1]&gt;</span></div>
<div class="line"><a name="l00753"></a><span class="lineno">  753</span>&#160;<span class="comment">///   gpu.warp_execute_on_lane_0(%laneid) -&gt; () {</span></div>
<div class="line"><a name="l00754"></a><span class="lineno">  754</span>&#160;<span class="comment">///     ...</span></div>
<div class="line"><a name="l00755"></a><span class="lineno">  755</span>&#160;<span class="comment">///     xegpu.prefetch_nd %arg0 : !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;</span></div>
<div class="line"><a name="l00756"></a><span class="lineno">  756</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00757"></a><span class="lineno">  757</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00758"></a><span class="lineno">  758</span>&#160;<span class="comment">/// To</span></div>
<div class="line"><a name="l00759"></a><span class="lineno">  759</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00760"></a><span class="lineno">  760</span>&#160;<span class="comment">///   %r:1 = gpu.warp_execute_on_lane_0(%laneid) -&gt; (</span></div>
<div class="line"><a name="l00761"></a><span class="lineno">  761</span>&#160;<span class="comment">///    !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;) {</span></div>
<div class="line"><a name="l00762"></a><span class="lineno">  762</span>&#160;<span class="comment">///     gpu.yield %arg0: !xegpu.tensor_desc&lt;4x8xf32, #layout0&gt;</span></div>
<div class="line"><a name="l00763"></a><span class="lineno">  763</span>&#160;<span class="comment">///   }</span></div>
<div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;<span class="comment">///   %1 = unrealized_conversion_cast %r#0: !xegpu.tensor_desc&lt;4x8xf32,</span></div>
<div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;<span class="comment">///     #layout0&gt; -&gt; !xegpu.tensor_desc&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;<span class="comment">///   xegpu.prefetch_nd %1 : !xegpu.tensor_desc&lt;4x8xf32&gt;</span></div>
<div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;<span class="comment">///</span></div>
<div class="line"><a name="l00768"></a><span class="lineno">  768</span>&#160;<span class="comment">/// ```</span></div>
<div class="line"><a name="l00769"></a><span class="lineno">  769</span>&#160;<span class="comment"></span><span class="keyword">struct </span>PrefetchNdDistribution final : <span class="keyword">public</span> <a class="code" href="structmlir_1_1gpu_1_1WarpDistributionPattern.html">gpu::WarpDistributionPattern</a> {</div>
<div class="line"><a name="l00770"></a><span class="lineno">  770</span>&#160;  <span class="keyword">using</span> gpu::WarpDistributionPattern::WarpDistributionPattern;</div>
<div class="line"><a name="l00771"></a><span class="lineno">  771</span>&#160;  LogicalResult matchAndRewrite(gpu::WarpExecuteOnLane0Op warpOp,</div>
<div class="line"><a name="l00772"></a><span class="lineno">  772</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l00773"></a><span class="lineno">  773</span>&#160;    <span class="keyword">auto</span> yield = cast&lt;gpu::YieldOp&gt;(</div>
<div class="line"><a name="l00774"></a><span class="lineno">  774</span>&#160;        warpOp.getBodyRegion().getBlocks().begin()-&gt;getTerminator());</div>
<div class="line"><a name="l00775"></a><span class="lineno">  775</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *lastNode = yield-&gt;getPrevNode();</div>
<div class="line"><a name="l00776"></a><span class="lineno">  776</span>&#160;    <span class="keyword">auto</span> prefetchOp = dyn_cast_or_null&lt;xegpu::PrefetchNdOp&gt;(lastNode);</div>
<div class="line"><a name="l00777"></a><span class="lineno">  777</span>&#160;    <span class="keywordflow">if</span> (!prefetchOp)</div>
<div class="line"><a name="l00778"></a><span class="lineno">  778</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00779"></a><span class="lineno">  779</span>&#160; </div>
<div class="line"><a name="l00780"></a><span class="lineno">  780</span>&#160;    int64_t offsetSize = <span class="keyword">static_cast&lt;</span>int64_t<span class="keyword">&gt;</span>(prefetchOp.getOffsets().size());</div>
<div class="line"><a name="l00781"></a><span class="lineno">  781</span>&#160;    <span class="keywordflow">if</span> ((offsetSize != 0) || prefetchOp.getConstOffsetsAttr())</div>
<div class="line"><a name="l00782"></a><span class="lineno">  782</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00783"></a><span class="lineno">  783</span>&#160; </div>
<div class="line"><a name="l00784"></a><span class="lineno">  784</span>&#160;    xegpu::LayoutAttr layout = prefetchOp.getTensorDescType().getLayoutAttr();</div>
<div class="line"><a name="l00785"></a><span class="lineno">  785</span>&#160;    <span class="keywordflow">if</span> (!layout)</div>
<div class="line"><a name="l00786"></a><span class="lineno">  786</span>&#160;      <span class="keywordflow">return</span> rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">notifyMatchFailure</a>(</div>
<div class="line"><a name="l00787"></a><span class="lineno">  787</span>&#160;          prefetchOp, <span class="stringliteral">&quot;the source tensor descriptor lacks layout attribute&quot;</span>);</div>
<div class="line"><a name="l00788"></a><span class="lineno">  788</span>&#160; </div>
<div class="line"><a name="l00789"></a><span class="lineno">  789</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value, 1&gt;</a> newYieldValues = {prefetchOp.getTensorDesc()};</div>
<div class="line"><a name="l00790"></a><span class="lineno">  790</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Type, 1&gt;</a> newYieldTypes = {prefetchOp.getTensorDescType()};</div>
<div class="line"><a name="l00791"></a><span class="lineno">  791</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;size_t&gt;</a> newRetIndices;</div>
<div class="line"><a name="l00792"></a><span class="lineno">  792</span>&#160;    gpu::WarpExecuteOnLane0Op newWarpOp = moveRegionToNewWarpOpAndAppendReturns(</div>
<div class="line"><a name="l00793"></a><span class="lineno">  793</span>&#160;        rewriter, warpOp, newYieldValues, newYieldTypes, newRetIndices);</div>
<div class="line"><a name="l00794"></a><span class="lineno">  794</span>&#160;    <span class="comment">// Create a new prefetch op outside the warp op with updated tensor</span></div>
<div class="line"><a name="l00795"></a><span class="lineno">  795</span>&#160;    <span class="comment">// descriptor type. Source tensor descriptor require type resolution.</span></div>
<div class="line"><a name="l00796"></a><span class="lineno">  796</span>&#160;    xegpu::TensorDescType newTensorDescTy =</div>
<div class="line"><a name="l00797"></a><span class="lineno">  797</span>&#160;        prefetchOp.getTensorDescType().dropLayouts();</div>
<div class="line"><a name="l00798"></a><span class="lineno">  798</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">setInsertionPointAfter</a>(newWarpOp);</div>
<div class="line"><a name="l00799"></a><span class="lineno">  799</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;Value&gt;</a> newPrefetchOperands = {resolveDistributedTy(</div>
<div class="line"><a name="l00800"></a><span class="lineno">  800</span>&#160;        newWarpOp.getResult(newRetIndices[0]), newTensorDescTy, rewriter)};</div>
<div class="line"><a name="l00801"></a><span class="lineno">  801</span>&#160;    xegpu::PrefetchNdOp::create(rewriter, newWarpOp.getLoc(), <a class="code" href="classmlir_1_1TypeRange.html">TypeRange</a>{},</div>
<div class="line"><a name="l00802"></a><span class="lineno">  802</span>&#160;                                newPrefetchOperands, prefetchOp-&gt;getAttrs());</div>
<div class="line"><a name="l00803"></a><span class="lineno">  803</span>&#160;    <a class="code" href="namespacemlir_1_1xegpu.html#ace8e74148db06970f9e51f8da0a7066d">xegpu::removeLayoutAttrs</a>(prefetchOp);</div>
<div class="line"><a name="l00804"></a><span class="lineno">  804</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(prefetchOp);</div>
<div class="line"><a name="l00805"></a><span class="lineno">  805</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00806"></a><span class="lineno">  806</span>&#160;  }</div>
<div class="line"><a name="l00807"></a><span class="lineno">  807</span>&#160;};</div>
<div class="line"><a name="l00808"></a><span class="lineno">  808</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00809"></a><span class="lineno">  809</span>&#160;<span class="comment">/// Sink a gpu::BarrierOp at the end of enclosing `gpu.warp_execute_on_lane_0`</span></div>
<div class="line"><a name="l00810"></a><span class="lineno">  810</span>&#160;<span class="comment">/// region. This will simply move the barrier op outside of the warp op.</span></div>
<div class="line"><a name="l00811"></a><span class="lineno">  811</span>&#160;<span class="comment"></span><span class="keyword">struct </span>GpuBarrierDistribution final : <span class="keyword">public</span> <a class="code" href="structmlir_1_1gpu_1_1WarpDistributionPattern.html">gpu::WarpDistributionPattern</a> {</div>
<div class="line"><a name="l00812"></a><span class="lineno">  812</span>&#160;  <span class="keyword">using</span> gpu::WarpDistributionPattern::WarpDistributionPattern;</div>
<div class="line"><a name="l00813"></a><span class="lineno">  813</span>&#160;  LogicalResult matchAndRewrite(gpu::WarpExecuteOnLane0Op warpOp,</div>
<div class="line"><a name="l00814"></a><span class="lineno">  814</span>&#160;                                <a class="code" href="classmlir_1_1PatternRewriter.html">PatternRewriter</a> &amp;rewriter)<span class="keyword"> const override </span>{</div>
<div class="line"><a name="l00815"></a><span class="lineno">  815</span>&#160;    <span class="keyword">auto</span> yield = cast&lt;gpu::YieldOp&gt;(</div>
<div class="line"><a name="l00816"></a><span class="lineno">  816</span>&#160;        warpOp.getBodyRegion().getBlocks().begin()-&gt;getTerminator());</div>
<div class="line"><a name="l00817"></a><span class="lineno">  817</span>&#160;    <a class="code" href="classmlir_1_1Operation.html">Operation</a> *lastNode = yield-&gt;getPrevNode();</div>
<div class="line"><a name="l00818"></a><span class="lineno">  818</span>&#160;    <span class="comment">// The last node must be a gpu::BarrierOp.</span></div>
<div class="line"><a name="l00819"></a><span class="lineno">  819</span>&#160;    <span class="keyword">auto</span> barrierOp = dyn_cast_or_null&lt;gpu::BarrierOp&gt;(lastNode);</div>
<div class="line"><a name="l00820"></a><span class="lineno">  820</span>&#160;    <span class="keywordflow">if</span> (!barrierOp)</div>
<div class="line"><a name="l00821"></a><span class="lineno">  821</span>&#160;      <span class="keywordflow">return</span> failure();</div>
<div class="line"><a name="l00822"></a><span class="lineno">  822</span>&#160;    <span class="comment">// Move the barrier op outside of the warp op.</span></div>
<div class="line"><a name="l00823"></a><span class="lineno">  823</span>&#160;    rewriter.<a class="code" href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">setInsertionPointAfter</a>(warpOp);</div>
<div class="line"><a name="l00824"></a><span class="lineno">  824</span>&#160;    gpu::BarrierOp::create(rewriter, barrierOp.getLoc(),</div>
<div class="line"><a name="l00825"></a><span class="lineno">  825</span>&#160;                           barrierOp-&gt;getResultTypes(),</div>
<div class="line"><a name="l00826"></a><span class="lineno">  826</span>&#160;                           barrierOp-&gt;getOperands(), barrierOp-&gt;getAttrs());</div>
<div class="line"><a name="l00827"></a><span class="lineno">  827</span>&#160;    rewriter.<a class="code" href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">eraseOp</a>(barrierOp);</div>
<div class="line"><a name="l00828"></a><span class="lineno">  828</span>&#160;    <span class="keywordflow">return</span> success();</div>
<div class="line"><a name="l00829"></a><span class="lineno">  829</span>&#160;  }</div>
<div class="line"><a name="l00830"></a><span class="lineno">  830</span>&#160;};</div>
<div class="line"><a name="l00831"></a><span class="lineno">  831</span>&#160; </div>
<div class="line"><a name="l00832"></a><span class="lineno">  832</span>&#160;} <span class="comment">// namespace</span></div>
<div class="line"><a name="l00833"></a><span class="lineno">  833</span>&#160; </div>
<div class="line"><a name="l00834"></a><span class="lineno">  834</span>&#160;<span class="keyword">namespace </span>{</div>
<div class="line"><a name="l00835"></a><span class="lineno">  835</span>&#160;<span class="keyword">struct </span>XeGPUSubgroupDistributePass final</div>
<div class="line"><a name="l00836"></a><span class="lineno">  836</span>&#160;    : <span class="keyword">public</span> xegpu::impl::XeGPUSubgroupDistributeBase&lt;</div>
<div class="line"><a name="l00837"></a><span class="lineno">  837</span>&#160;          XeGPUSubgroupDistributePass&gt; {</div>
<div class="line"><a name="l00838"></a><span class="lineno">  838</span>&#160;  <span class="keywordtype">void</span> runOnOperation() <span class="keyword">override</span>;</div>
<div class="line"><a name="l00839"></a><span class="lineno">  839</span>&#160;};</div>
<div class="line"><a name="l00840"></a><span class="lineno">  840</span>&#160;} <span class="comment">// namespace</span></div>
<div class="line"><a name="l00841"></a><span class="lineno">  841</span>&#160; </div>
<div class="line"><a name="l00842"></a><span class="lineno"><a class="line" href="namespacemlir_1_1xegpu.html#af39a7d1520005ea372b9b513a1d7b442">  842</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="namespacemlir_1_1xegpu.html#af39a7d1520005ea372b9b513a1d7b442">xegpu::populateXeGPUSubgroupDistributePatterns</a>(</div>
<div class="line"><a name="l00843"></a><span class="lineno">  843</span>&#160;    <a class="code" href="classmlir_1_1RewritePatternSet.html">RewritePatternSet</a> &amp;<a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>) {</div>
<div class="line"><a name="l00844"></a><span class="lineno">  844</span>&#160;  <a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.add&lt;CreateNdDescDistribution, StoreNdDistribution,</div>
<div class="line"><a name="l00845"></a><span class="lineno">  845</span>&#160;               LoadNdDistribution, DpasDistribution, PrefetchNdDistribution,</div>
<div class="line"><a name="l00846"></a><span class="lineno">  846</span>&#160;               UpdateNdOffsetDistribution, GpuBarrierDistribution&gt;(</div>
<div class="line"><a name="l00847"></a><span class="lineno">  847</span>&#160;      <a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.getContext());</div>
<div class="line"><a name="l00848"></a><span class="lineno">  848</span>&#160;}</div>
<div class="line"><a name="l00849"></a><span class="lineno">  849</span>&#160; </div>
<div class="line"><a name="l00850"></a><span class="lineno">  850</span>&#160;<span class="keywordtype">void</span> XeGPUSubgroupDistributePass::runOnOperation() {</div>
<div class="line"><a name="l00851"></a><span class="lineno">  851</span>&#160;  <span class="comment">// Step 1: Attach layouts to op operands.</span></div>
<div class="line"><a name="l00852"></a><span class="lineno">  852</span>&#160;  <span class="comment">// TODO: Following assumptions are made:</span></div>
<div class="line"><a name="l00853"></a><span class="lineno">  853</span>&#160;  <span class="comment">// 1) It is assumed that there are no layout conflicts.</span></div>
<div class="line"><a name="l00854"></a><span class="lineno">  854</span>&#160;  <span class="comment">// 2) Any existing layout attributes attached to the operands are ignored.</span></div>
<div class="line"><a name="l00855"></a><span class="lineno">  855</span>&#160;  <a class="code" href="classmlir_1_1Operation.html">Operation</a> *op = getOperation();</div>
<div class="line"><a name="l00856"></a><span class="lineno">  856</span>&#160;  op-&gt;<a class="code" href="classmlir_1_1Operation.html#a59740592240b950b8c8afcf4a2eb4113">walk</a>([&amp;](<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op) {</div>
<div class="line"><a name="l00857"></a><span class="lineno">  857</span>&#160;    <span class="keywordflow">for</span> (<a class="code" href="classmlir_1_1OpOperand.html">OpOperand</a> &amp;operand : op-&gt;<a class="code" href="classmlir_1_1Operation.html#ac289fff433e2845845692b02922d119a">getOpOperands</a>()) {</div>
<div class="line"><a name="l00858"></a><span class="lineno">  858</span>&#160;      <span class="comment">// Layouts are needed for vector type only.</span></div>
<div class="line"><a name="l00859"></a><span class="lineno">  859</span>&#160;      if (!isa&lt;VectorType&gt;(operand.get().getType()))</div>
<div class="line"><a name="l00860"></a><span class="lineno">  860</span>&#160;        continue;</div>
<div class="line"><a name="l00861"></a><span class="lineno">  861</span>&#160; </div>
<div class="line"><a name="l00862"></a><span class="lineno">  862</span>&#160;      xegpu::LayoutAttr layout = xegpu::getLayoutAttr(operand);</div>
<div class="line"><a name="l00863"></a><span class="lineno">  863</span>&#160;      if (!layout) {</div>
<div class="line"><a name="l00864"></a><span class="lineno">  864</span>&#160;        op-&gt;emitError(<span class="stringliteral">&quot;Could not find layout attribute for operand &quot;</span>)</div>
<div class="line"><a name="l00865"></a><span class="lineno">  865</span>&#160;            &lt;&lt; operand.getOperandNumber() &lt;&lt; <span class="stringliteral">&quot; of operation &quot;</span> &lt;&lt; op-&gt;getName();</div>
<div class="line"><a name="l00866"></a><span class="lineno">  866</span>&#160;        signalPassFailure();</div>
<div class="line"><a name="l00867"></a><span class="lineno">  867</span>&#160;        return;</div>
<div class="line"><a name="l00868"></a><span class="lineno">  868</span>&#160;      }</div>
<div class="line"><a name="l00869"></a><span class="lineno">  869</span>&#160;      <a class="code" href="namespacemlir_1_1xegpu.html#a2d061472bfed55c12960494849bbd863">xegpu::setLayoutAttr</a>(operand, layout);</div>
<div class="line"><a name="l00870"></a><span class="lineno">  870</span>&#160;    }</div>
<div class="line"><a name="l00871"></a><span class="lineno">  871</span>&#160;  });</div>
<div class="line"><a name="l00872"></a><span class="lineno">  872</span>&#160;  <span class="comment">// Step 2: Move all operations of a GPU function inside</span></div>
<div class="line"><a name="l00873"></a><span class="lineno">  873</span>&#160;  <span class="comment">// gpu.warp_execute_on_lane_0 operation.</span></div>
<div class="line"><a name="l00874"></a><span class="lineno">  874</span>&#160;  {</div>
<div class="line"><a name="l00875"></a><span class="lineno">  875</span>&#160;    <a class="code" href="classmlir_1_1RewritePatternSet.html">RewritePatternSet</a> <a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>(&amp;<a class="code" href="IndexingUtils_8cpp.html#a4261c9783e78bdc09e762f2aeda95e17">getContext</a>());</div>
<div class="line"><a name="l00876"></a><span class="lineno">  876</span>&#160;    <a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>.add&lt;MoveFuncBodyToWarpExecuteOnLane0&gt;(&amp;<a class="code" href="IndexingUtils_8cpp.html#a4261c9783e78bdc09e762f2aeda95e17">getContext</a>());</div>
<div class="line"><a name="l00877"></a><span class="lineno">  877</span>&#160; </div>
<div class="line"><a name="l00878"></a><span class="lineno">  878</span>&#160;    <span class="keywordflow">if</span> (failed(<a class="code" href="namespacemlir.html#a40136aee562026e1f4503e32fb71fa2d">applyPatternsGreedily</a>(getOperation(), std::move(<a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>)))) {</div>
<div class="line"><a name="l00879"></a><span class="lineno">  879</span>&#160;      signalPassFailure();</div>
<div class="line"><a name="l00880"></a><span class="lineno">  880</span>&#160;      <span class="keywordflow">return</span>;</div>
<div class="line"><a name="l00881"></a><span class="lineno">  881</span>&#160;    }</div>
<div class="line"><a name="l00882"></a><span class="lineno">  882</span>&#160;    <span class="comment">// At this point, we have moved the entire function body inside the</span></div>
<div class="line"><a name="l00883"></a><span class="lineno">  883</span>&#160;    <span class="comment">// warpOp. Now move any scalar uniform code outside of the warpOp (like</span></div>
<div class="line"><a name="l00884"></a><span class="lineno">  884</span>&#160;    <span class="comment">// GPU index ops, scalar constants, etc.). This will simplify the</span></div>
<div class="line"><a name="l00885"></a><span class="lineno">  885</span>&#160;    <span class="comment">// later lowering and avoid custom patterns for these ops.</span></div>
<div class="line"><a name="l00886"></a><span class="lineno">  886</span>&#160;    getOperation()-&gt;walk([&amp;](<a class="code" href="classmlir_1_1Operation.html">Operation</a> *op) {</div>
<div class="line"><a name="l00887"></a><span class="lineno">  887</span>&#160;      <span class="keywordflow">if</span> (<span class="keyword">auto</span> warpOp = dyn_cast&lt;gpu::WarpExecuteOnLane0Op&gt;(op))</div>
<div class="line"><a name="l00888"></a><span class="lineno">  888</span>&#160;        vector::moveScalarUniformCode(warpOp);</div>
<div class="line"><a name="l00889"></a><span class="lineno">  889</span>&#160;    });</div>
<div class="line"><a name="l00890"></a><span class="lineno">  890</span>&#160;  }</div>
<div class="line"><a name="l00891"></a><span class="lineno">  891</span>&#160;  <span class="comment">// Step 3: Apply subgroup to workitem distribution patterns.</span></div>
<div class="line"><a name="l00892"></a><span class="lineno">  892</span>&#160;  <a class="code" href="classmlir_1_1RewritePatternSet.html">RewritePatternSet</a> <a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>(&amp;<a class="code" href="IndexingUtils_8cpp.html#a4261c9783e78bdc09e762f2aeda95e17">getContext</a>());</div>
<div class="line"><a name="l00893"></a><span class="lineno">  893</span>&#160;  <a class="code" href="namespacemlir_1_1xegpu.html#af39a7d1520005ea372b9b513a1d7b442">xegpu::populateXeGPUSubgroupDistributePatterns</a>(<a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>);</div>
<div class="line"><a name="l00894"></a><span class="lineno">  894</span>&#160;  <span class="comment">// distributionFn is used by vector distribution patterns to determine the</span></div>
<div class="line"><a name="l00895"></a><span class="lineno">  895</span>&#160;  <span class="comment">// distributed vector type for a given vector value. In XeGPU subgroup</span></div>
<div class="line"><a name="l00896"></a><span class="lineno">  896</span>&#160;  <span class="comment">// distribution context, we compute this based on lane layout.</span></div>
<div class="line"><a name="l00897"></a><span class="lineno">  897</span>&#160;  <span class="keyword">auto</span> distributionFn = [](<a class="code" href="classmlir_1_1Value.html">Value</a> val) {</div>
<div class="line"><a name="l00898"></a><span class="lineno">  898</span>&#160;    VectorType vecType = dyn_cast&lt;VectorType&gt;(val.getType());</div>
<div class="line"><a name="l00899"></a><span class="lineno">  899</span>&#160;    int64_t vecRank = vecType ? vecType.getRank() : 0;</div>
<div class="line"><a name="l00900"></a><span class="lineno">  900</span>&#160;    <span class="keywordflow">if</span> (vecRank == 0)</div>
<div class="line"><a name="l00901"></a><span class="lineno">  901</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1AffineMap.html#a3cfca2eb29fddf3c4bda714cccaa53f9">AffineMap::get</a>(val.getContext());</div>
<div class="line"><a name="l00902"></a><span class="lineno">  902</span>&#160;    <span class="comment">// Get the layout of the vector type.</span></div>
<div class="line"><a name="l00903"></a><span class="lineno">  903</span>&#160;    xegpu::LayoutAttr layout = <a class="code" href="namespacemlir_1_1xegpu.html#a2ae68d0f2a6c692c9665306ebed7e851">xegpu::getLayoutAttr</a>(val);</div>
<div class="line"><a name="l00904"></a><span class="lineno">  904</span>&#160;    <span class="comment">// If no layout is specified, assume the inner most dimension is distributed</span></div>
<div class="line"><a name="l00905"></a><span class="lineno">  905</span>&#160;    <span class="comment">// for now.</span></div>
<div class="line"><a name="l00906"></a><span class="lineno">  906</span>&#160;    <span class="keywordflow">if</span> (!layout)</div>
<div class="line"><a name="l00907"></a><span class="lineno">  907</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1AffineMap.html#ada21d48618f194b336889ce9a549925e">AffineMap::getMultiDimMapWithTargets</a>(</div>
<div class="line"><a name="l00908"></a><span class="lineno">  908</span>&#160;          vecRank, {<span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span> <span class="keywordtype">int</span><span class="keyword">&gt;</span>(vecRank - 1)}, val.getContext());</div>
<div class="line"><a name="l00909"></a><span class="lineno">  909</span>&#160;    <a class="code" href="classllvm_1_1SmallVector.html">SmallVector&lt;unsigned int&gt;</a> distributedDims;</div>
<div class="line"><a name="l00910"></a><span class="lineno">  910</span>&#160;    <span class="comment">// Get the distributed dimensions based on the layout.</span></div>
<div class="line"><a name="l00911"></a><span class="lineno">  911</span>&#160;    <a class="code" href="classllvm_1_1ArrayRef.html">ArrayRef&lt;int&gt;</a> laneLayout = layout.getLaneLayout().asArrayRef();</div>
<div class="line"><a name="l00912"></a><span class="lineno">  912</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; laneLayout.size(); ++i) {</div>
<div class="line"><a name="l00913"></a><span class="lineno">  913</span>&#160;      <span class="keywordflow">if</span> (laneLayout[i] &gt; 1)</div>
<div class="line"><a name="l00914"></a><span class="lineno">  914</span>&#160;        distributedDims.push_back(i);</div>
<div class="line"><a name="l00915"></a><span class="lineno">  915</span>&#160;    }</div>
<div class="line"><a name="l00916"></a><span class="lineno">  916</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1AffineMap.html#ada21d48618f194b336889ce9a549925e">AffineMap::getMultiDimMapWithTargets</a>(vecRank, distributedDims,</div>
<div class="line"><a name="l00917"></a><span class="lineno">  917</span>&#160;                                                val.getContext());</div>
<div class="line"><a name="l00918"></a><span class="lineno">  918</span>&#160;  };</div>
<div class="line"><a name="l00919"></a><span class="lineno">  919</span>&#160;  <span class="comment">// TODO: shuffleFn is not used.</span></div>
<div class="line"><a name="l00920"></a><span class="lineno">  920</span>&#160;  <span class="keyword">auto</span> shuffleFn = [](<a class="code" href="classmlir_1_1Location.html">Location</a> loc, <a class="code" href="classmlir_1_1OpBuilder.html">OpBuilder</a> &amp;builder, <a class="code" href="classmlir_1_1Value.html">Value</a> val, <a class="code" href="classmlir_1_1Value.html">Value</a> srcIdx,</div>
<div class="line"><a name="l00921"></a><span class="lineno">  921</span>&#160;                      int64_t warpSz) { <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1Value.html">Value</a>(); };</div>
<div class="line"><a name="l00922"></a><span class="lineno">  922</span>&#160;  vector::populatePropagateWarpVectorDistributionPatterns(</div>
<div class="line"><a name="l00923"></a><span class="lineno">  923</span>&#160;      <a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>, distributionFn, shuffleFn);</div>
<div class="line"><a name="l00924"></a><span class="lineno">  924</span>&#160;  <span class="keywordflow">if</span> (failed(<a class="code" href="namespacemlir.html#a40136aee562026e1f4503e32fb71fa2d">applyPatternsGreedily</a>(getOperation(), std::move(<a class="code" href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">patterns</a>)))) {</div>
<div class="line"><a name="l00925"></a><span class="lineno">  925</span>&#160;    signalPassFailure();</div>
<div class="line"><a name="l00926"></a><span class="lineno">  926</span>&#160;    <span class="keywordflow">return</span>;</div>
<div class="line"><a name="l00927"></a><span class="lineno">  927</span>&#160;  }</div>
<div class="line"><a name="l00928"></a><span class="lineno">  928</span>&#160; </div>
<div class="line"><a name="l00929"></a><span class="lineno">  929</span>&#160;  <span class="comment">// Step 4: Finllay, clean up UnrealizedConversionCastOps that were inserted</span></div>
<div class="line"><a name="l00930"></a><span class="lineno">  930</span>&#160;  <span class="comment">// due to tensor desc type mismatches created by using upstream distribution</span></div>
<div class="line"><a name="l00931"></a><span class="lineno">  931</span>&#160;  <span class="comment">// patterns (scf.for)</span></div>
<div class="line"><a name="l00932"></a><span class="lineno">  932</span>&#160;  getOperation()-&gt;walk([&amp;](mlir::UnrealizedConversionCastOp op) {</div>
<div class="line"><a name="l00933"></a><span class="lineno">  933</span>&#160;    <span class="comment">// We are only interested in UnrealizedConversionCastOps there were added</span></div>
<div class="line"><a name="l00934"></a><span class="lineno">  934</span>&#160;    <span class="comment">// for resolving SIMT type mismatches.</span></div>
<div class="line"><a name="l00935"></a><span class="lineno">  935</span>&#160;    <span class="keywordflow">if</span> (!op-&gt;getAttr(<a class="code" href="XeGPUSubgroupDistribute_8cpp.html#a908e16bf69a72db5cd2045bc016ac3fe">resolveSIMTTypeMismatch</a>))</div>
<div class="line"><a name="l00936"></a><span class="lineno">  936</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1WalkResult.html#a693d2ecca6f15d4d492c6ff2bea148d0">WalkResult::skip</a>();</div>
<div class="line"><a name="l00937"></a><span class="lineno">  937</span>&#160; </div>
<div class="line"><a name="l00938"></a><span class="lineno">  938</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> input = op.getOperand(0);</div>
<div class="line"><a name="l00939"></a><span class="lineno">  939</span>&#160;    <a class="code" href="classmlir_1_1Value.html">Value</a> output = op.getResult(0);</div>
<div class="line"><a name="l00940"></a><span class="lineno">  940</span>&#160; </div>
<div class="line"><a name="l00941"></a><span class="lineno">  941</span>&#160;    <span class="comment">// Both input and output must have tensor descriptor types.</span></div>
<div class="line"><a name="l00942"></a><span class="lineno">  942</span>&#160;    xegpu::TensorDescType inputDescType =</div>
<div class="line"><a name="l00943"></a><span class="lineno">  943</span>&#160;        mlir::dyn_cast&lt;xegpu::TensorDescType&gt;(input.getType());</div>
<div class="line"><a name="l00944"></a><span class="lineno">  944</span>&#160;    xegpu::TensorDescType outputDescType =</div>
<div class="line"><a name="l00945"></a><span class="lineno">  945</span>&#160;        mlir::dyn_cast&lt;xegpu::TensorDescType&gt;(output.getType());</div>
<div class="line"><a name="l00946"></a><span class="lineno">  946</span>&#160;    assert(inputDescType &amp;&amp; outputDescType &amp;&amp;</div>
<div class="line"><a name="l00947"></a><span class="lineno">  947</span>&#160;           <span class="stringliteral">&quot;Unrealized conversion cast must have tensor descriptor types&quot;</span>);</div>
<div class="line"><a name="l00948"></a><span class="lineno">  948</span>&#160; </div>
<div class="line"><a name="l00949"></a><span class="lineno">  949</span>&#160;    <span class="comment">// tensor_desc&lt;shape, layout&gt; -&gt; tensor_desc&lt;shape&gt; Type of conversions.</span></div>
<div class="line"><a name="l00950"></a><span class="lineno">  950</span>&#160;    <span class="comment">// This occurs iside scf.for body to resolve the block argument type to</span></div>
<div class="line"><a name="l00951"></a><span class="lineno">  951</span>&#160;    <span class="comment">// SIMT type.</span></div>
<div class="line"><a name="l00952"></a><span class="lineno">  952</span>&#160;    <span class="keywordflow">if</span> (inputDescType.getLayout()) {</div>
<div class="line"><a name="l00953"></a><span class="lineno">  953</span>&#160;      auto argument = mlir::dyn_cast&lt;mlir::BlockArgument&gt;(input);</div>
<div class="line"><a name="l00954"></a><span class="lineno">  954</span>&#160;      if (argument) {</div>
<div class="line"><a name="l00955"></a><span class="lineno">  955</span>&#160;        argument.setType(output.getType());</div>
<div class="line"><a name="l00956"></a><span class="lineno">  956</span>&#160;        output.replaceAllUsesWith(argument);</div>
<div class="line"><a name="l00957"></a><span class="lineno">  957</span>&#160;        if (auto loopOp = mlir::dyn_cast&lt;mlir::LoopLikeOpInterface&gt;(</div>
<div class="line"><a name="l00958"></a><span class="lineno">  958</span>&#160;                argument.getOwner()-&gt;getParentOp())) {</div>
<div class="line"><a name="l00959"></a><span class="lineno">  959</span>&#160;          auto result = loopOp.getTiedLoopResult(argument);</div>
<div class="line"><a name="l00960"></a><span class="lineno">  960</span>&#160;          result.setType(output.getType());</div>
<div class="line"><a name="l00961"></a><span class="lineno">  961</span>&#160;        }</div>
<div class="line"><a name="l00962"></a><span class="lineno">  962</span>&#160;      }</div>
<div class="line"><a name="l00963"></a><span class="lineno">  963</span>&#160;    }</div>
<div class="line"><a name="l00964"></a><span class="lineno">  964</span>&#160; </div>
<div class="line"><a name="l00965"></a><span class="lineno">  965</span>&#160;    <span class="comment">// tensor_desc&lt;shape&gt; -&gt; tensor_desc&lt;shape, layout&gt; Type of</span></div>
<div class="line"><a name="l00966"></a><span class="lineno">  966</span>&#160;    <span class="comment">// conversions. This occurs at the yield op of scf.for body to go back</span></div>
<div class="line"><a name="l00967"></a><span class="lineno">  967</span>&#160;    <span class="comment">// from SIMT type to original type.</span></div>
<div class="line"><a name="l00968"></a><span class="lineno">  968</span>&#160;    <span class="keywordflow">if</span> (outputDescType.getLayout())</div>
<div class="line"><a name="l00969"></a><span class="lineno">  969</span>&#160;      output.<a class="code" href="classmlir_1_1Value.html#ac56b0fdb6246bcf7fa1805ba0eb71aa2">replaceAllUsesWith</a>(input);</div>
<div class="line"><a name="l00970"></a><span class="lineno">  970</span>&#160; </div>
<div class="line"><a name="l00971"></a><span class="lineno">  971</span>&#160;    if (op-&gt;use_empty())</div>
<div class="line"><a name="l00972"></a><span class="lineno">  972</span>&#160;      op-&gt;erase();</div>
<div class="line"><a name="l00973"></a><span class="lineno">  973</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classmlir_1_1WalkResult.html#a97a7015a793bb5d2a97f08e358f42797">WalkResult::advance</a>();</div>
<div class="line"><a name="l00974"></a><span class="lineno">  974</span>&#160;  });</div>
<div class="line"><a name="l00975"></a><span class="lineno">  975</span>&#160;}</div>
<div class="ttc" id="aAttributes_8h_html"><div class="ttname"><a href="Attributes_8h.html">Attributes.h</a></div></div>
<div class="ttc" id="aBuilders_8h_html"><div class="ttname"><a href="Builders_8h.html">Builders.h</a></div></div>
<div class="ttc" id="aBuiltinOps_8h_html"><div class="ttname"><a href="BuiltinOps_8h.html">BuiltinOps.h</a></div></div>
<div class="ttc" id="aDialectConversion_8h_html"><div class="ttname"><a href="DialectConversion_8h.html">DialectConversion.h</a></div></div>
<div class="ttc" id="aDialect_2XeGPU_2Transforms_2Passes_8h_html"><div class="ttname"><a href="Dialect_2XeGPU_2Transforms_2Passes_8h.html">Passes.h</a></div></div>
<div class="ttc" id="aDistributionUtils_8h_html"><div class="ttname"><a href="DistributionUtils_8h.html">DistributionUtils.h</a></div></div>
<div class="ttc" id="aFunctionInterfaces_8h_html"><div class="ttname"><a href="FunctionInterfaces_8h.html">FunctionInterfaces.h</a></div></div>
<div class="ttc" id="aGPUDialect_8h_html"><div class="ttname"><a href="GPUDialect_8h.html">GPUDialect.h</a></div></div>
<div class="ttc" id="aGreedyPatternRewriteDriver_8h_html"><div class="ttname"><a href="GreedyPatternRewriteDriver_8h.html">GreedyPatternRewriteDriver.h</a></div></div>
<div class="ttc" id="aIR_2Operation_8h_html"><div class="ttname"><a href="IR_2Operation_8h.html">Operation.h</a></div></div>
<div class="ttc" id="aIndexingUtils_8cpp_html_a4261c9783e78bdc09e762f2aeda95e17"><div class="ttname"><a href="IndexingUtils_8cpp.html#a4261c9783e78bdc09e762f2aeda95e17">getContext</a></div><div class="ttdeci">static MLIRContext * getContext(OpFoldResult val)</div><div class="ttdef"><b>Definition:</b> <a href="IndexingUtils_8cpp_source.html#l00296">IndexingUtils.cpp:296</a></div></div>
<div class="ttc" id="aInliningUtils_8h_html"><div class="ttname"><a href="InliningUtils_8h.html">InliningUtils.h</a></div></div>
<div class="ttc" id="aPatternMatch_8h_html"><div class="ttname"><a href="PatternMatch_8h.html">PatternMatch.h</a></div></div>
<div class="ttc" id="aTypeRange_8h_html"><div class="ttname"><a href="TypeRange_8h.html">TypeRange.h</a></div></div>
<div class="ttc" id="aValue_8h_html"><div class="ttname"><a href="Value_8h.html">Value.h</a></div></div>
<div class="ttc" id="aVectorDistribution_8h_html"><div class="ttname"><a href="VectorDistribution_8h.html">VectorDistribution.h</a></div></div>
<div class="ttc" id="aVectorOps_8h_html"><div class="ttname"><a href="VectorOps_8h.html">VectorOps.h</a></div></div>
<div class="ttc" id="aVisitors_8h_html"><div class="ttname"><a href="Visitors_8h.html">Visitors.h</a></div></div>
<div class="ttc" id="aXeGPUPropagateLayout_8cpp_html_abc382893a51ad62af8afb28f74ba0555"><div class="ttname"><a href="XeGPUPropagateLayout_8cpp.html#abc382893a51ad62af8afb28f74ba0555">updateOp</a></div><div class="ttdeci">static LogicalResult updateOp(mlir::OpBuilder &amp;builder, mlir::Operation *op, GetLayoutFnTy getLayoutOfValue)</div><div class="ttdoc">Update an operation with the layout of its results.</div><div class="ttdef"><b>Definition:</b> <a href="XeGPUPropagateLayout_8cpp_source.html#l00692">XeGPUPropagateLayout.cpp:692</a></div></div>
<div class="ttc" id="aXeGPUSubgroupDistribute_8cpp_html_a908e16bf69a72db5cd2045bc016ac3fe"><div class="ttname"><a href="XeGPUSubgroupDistribute_8cpp.html#a908e16bf69a72db5cd2045bc016ac3fe">resolveSIMTTypeMismatch</a></div><div class="ttdeci">static const char *const resolveSIMTTypeMismatch</div><div class="ttdef"><b>Definition:</b> <a href="XeGPUSubgroupDistribute_8cpp_source.html#l00050">XeGPUSubgroupDistribute.cpp:50</a></div></div>
<div class="ttc" id="aXeGPUTargetInfo_8h_html"><div class="ttname"><a href="XeGPUTargetInfo_8h.html">XeGPUTargetInfo.h</a></div></div>
<div class="ttc" id="aXeGPUUtils_8h_html"><div class="ttname"><a href="XeGPUUtils_8h.html">XeGPUUtils.h</a></div></div>
<div class="ttc" id="aXeGPU_8h_html"><div class="ttname"><a href="XeGPU_8h.html">XeGPU.h</a></div></div>
<div class="ttc" id="aclassllvm_1_1ArrayRef_html"><div class="ttname"><a href="classllvm_1_1ArrayRef.html">llvm::ArrayRef</a></div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00048">LLVM.h:48</a></div></div>
<div class="ttc" id="aclassllvm_1_1SmallVector_html"><div class="ttname"><a href="classllvm_1_1SmallVector.html">llvm::SmallVector</a></div><div class="ttdef"><b>Definition:</b> <a href="mlir_2Support_2LLVM_8h_source.html#l00072">LLVM.h:72</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_a3cfca2eb29fddf3c4bda714cccaa53f9"><div class="ttname"><a href="classmlir_1_1AffineMap.html#a3cfca2eb29fddf3c4bda714cccaa53f9">mlir::AffineMap::get</a></div><div class="ttdeci">static AffineMap get(MLIRContext *context)</div><div class="ttdoc">Returns a zero result affine map with no dimensions or symbols: () -&gt; ().</div><div class="ttdef"><b>Definition:</b> <a href="MLIRContext_8cpp_source.html#l01203">MLIRContext.cpp:1203</a></div></div>
<div class="ttc" id="aclassmlir_1_1AffineMap_html_ada21d48618f194b336889ce9a549925e"><div class="ttname"><a href="classmlir_1_1AffineMap.html#ada21d48618f194b336889ce9a549925e">mlir::AffineMap::getMultiDimMapWithTargets</a></div><div class="ttdeci">static AffineMap getMultiDimMapWithTargets(unsigned numDims, ArrayRef&lt; unsigned &gt; targets, MLIRContext *context)</div><div class="ttdoc">Returns an affine map with numDims input dimensions and results specified by targets.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2AffineMap_8cpp_source.html#l00276">AffineMap.cpp:276</a></div></div>
<div class="ttc" id="aclassmlir_1_1BlockArgument_html"><div class="ttname"><a href="classmlir_1_1BlockArgument.html">mlir::BlockArgument</a></div><div class="ttdoc">This class represents an argument of a Block.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00309">Value.h:309</a></div></div>
<div class="ttc" id="aclassmlir_1_1Block_html"><div class="ttname"><a href="classmlir_1_1Block.html">mlir::Block</a></div><div class="ttdoc">Block represents an ordered list of Operations.</div><div class="ttdef"><b>Definition:</b> <a href="Block_8h_source.html#l00032">Block.h:33</a></div></div>
<div class="ttc" id="aclassmlir_1_1Block_html_aa904889345bf1bf23a54076768158c94"><div class="ttname"><a href="classmlir_1_1Block.html#aa904889345bf1bf23a54076768158c94">mlir::Block::front</a></div><div class="ttdeci">Operation &amp; front()</div><div class="ttdef"><b>Definition:</b> <a href="Block_8h_source.html#l00153">Block.h:153</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_a0ba94155c8438c805c7bf379d79d36c5"><div class="ttname"><a href="classmlir_1_1Builder.html#a0ba94155c8438c805c7bf379d79d36c5">mlir::Builder::getUnitAttr</a></div><div class="ttdeci">UnitAttr getUnitAttr()</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00093">Builders.cpp:93</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_a5e44a1083e200c0aea501f30f4ddc62c"><div class="ttname"><a href="classmlir_1_1Builder.html#a5e44a1083e200c0aea501f30f4ddc62c">mlir::Builder::getFunctionType</a></div><div class="ttdeci">FunctionType getFunctionType(TypeRange inputs, TypeRange results)</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00075">Builders.cpp:75</a></div></div>
<div class="ttc" id="aclassmlir_1_1Builder_html_ace585fd315aa2ebcc7bb87e18483f5b4"><div class="ttname"><a href="classmlir_1_1Builder.html#ace585fd315aa2ebcc7bb87e18483f5b4">mlir::Builder::getIndexType</a></div><div class="ttdeci">IndexType getIndexType()</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8cpp_source.html#l00050">Builders.cpp:50</a></div></div>
<div class="ttc" id="aclassmlir_1_1IROperand_html_a015cbc633653c0c763dca72a22b0e087"><div class="ttname"><a href="classmlir_1_1IROperand.html#a015cbc633653c0c763dca72a22b0e087">mlir::IROperand::get</a></div><div class="ttdeci">IRValueT get() const</div><div class="ttdoc">Return the current value being used by this operand.</div><div class="ttdef"><b>Definition:</b> <a href="UseDefLists_8h_source.html#l00160">UseDefLists.h:160</a></div></div>
<div class="ttc" id="aclassmlir_1_1Location_html"><div class="ttname"><a href="classmlir_1_1Location.html">mlir::Location</a></div><div class="ttdoc">This class defines the main interface for locations in MLIR and acts as a non-nullable wrapper around...</div><div class="ttdef"><b>Definition:</b> <a href="Location_8h_source.html#l00076">Location.h:76</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html"><div class="ttname"><a href="classmlir_1_1OpBuilder.html">mlir::OpBuilder</a></div><div class="ttdoc">This class helps build Operations.</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00205">Builders.h:205</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_a4853433035d219e56febdb51d1b531cd"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#a4853433035d219e56febdb51d1b531cd">mlir::OpBuilder::setInsertionPoint</a></div><div class="ttdeci">void setInsertionPoint(Block *block, Block::iterator insertPoint)</div><div class="ttdoc">Set the insertion point to the specified location.</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00396">Builders.h:396</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_a5ff4c0abb5c98e53a3de90a8593026a9"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#a5ff4c0abb5c98e53a3de90a8593026a9">mlir::OpBuilder::setInsertionPointToEnd</a></div><div class="ttdeci">void setInsertionPointToEnd(Block *block)</div><div class="ttdoc">Sets the insertion point to the end of the specified block.</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00434">Builders.h:434</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpBuilder_html_acd2bfec2b8f9c2a505a98da5252196b0"><div class="ttname"><a href="classmlir_1_1OpBuilder.html#acd2bfec2b8f9c2a505a98da5252196b0">mlir::OpBuilder::setInsertionPointAfter</a></div><div class="ttdeci">void setInsertionPointAfter(Operation *op)</div><div class="ttdoc">Sets the insertion point to the node after the specified operation, which will cause subsequent inser...</div><div class="ttdef"><b>Definition:</b> <a href="Builders_8h_source.html#l00410">Builders.h:410</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpOperand_html"><div class="ttname"><a href="classmlir_1_1OpOperand.html">mlir::OpOperand</a></div><div class="ttdoc">This class represents an operand of an operation.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00257">Value.h:257</a></div></div>
<div class="ttc" id="aclassmlir_1_1OpOperand_html_a097f9026defd8afd19ab06b21aa11bdf"><div class="ttname"><a href="classmlir_1_1OpOperand.html#a097f9026defd8afd19ab06b21aa11bdf">mlir::OpOperand::getOperandNumber</a></div><div class="ttdeci">unsigned getOperandNumber()</div><div class="ttdoc">Return which operand this is in the OpOperand list of the Operation.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8cpp_source.html#l00226">Value.cpp:226</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html"><div class="ttname"><a href="classmlir_1_1Operation.html">mlir::Operation</a></div><div class="ttdoc">Operation is the basic unit of execution within MLIR.</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00084">Operation.h:88</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_a59740592240b950b8c8afcf4a2eb4113"><div class="ttname"><a href="classmlir_1_1Operation.html#a59740592240b950b8c8afcf4a2eb4113">mlir::Operation::walk</a></div><div class="ttdeci">std::enable_if_t&lt; llvm::function_traits&lt; std::decay_t&lt; FnT &gt; &gt;::num_args==1, RetT &gt; walk(FnT &amp;&amp;callback)</div><div class="ttdoc">Walk the operation by calling the callback for each nested operation (including this one),...</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00797">Operation.h:797</a></div></div>
<div class="ttc" id="aclassmlir_1_1Operation_html_ac289fff433e2845845692b02922d119a"><div class="ttname"><a href="classmlir_1_1Operation.html#ac289fff433e2845845692b02922d119a">mlir::Operation::getOpOperands</a></div><div class="ttdeci">MutableArrayRef&lt; OpOperand &gt; getOpOperands()</div><div class="ttdef"><b>Definition:</b> <a href="IR_2Operation_8h_source.html#l00383">Operation.h:383</a></div></div>
<div class="ttc" id="aclassmlir_1_1PatternRewriter_html"><div class="ttname"><a href="classmlir_1_1PatternRewriter.html">mlir::PatternRewriter</a></div><div class="ttdoc">A special type of RewriterBase that coordinates the application of a rewrite pattern on the current I...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00783">PatternMatch.h:783</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewritePatternSet_html"><div class="ttname"><a href="classmlir_1_1RewritePatternSet.html">mlir::RewritePatternSet</a></div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00806">PatternMatch.h:806</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a032aa8fe5345a286681688ef10f5cb84"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a032aa8fe5345a286681688ef10f5cb84">mlir::RewriterBase::notifyMatchFailure</a></div><div class="ttdeci">std::enable_if_t&lt;!std::is_convertible&lt; CallbackT, Twine &gt;::value, LogicalResult &gt; notifyMatchFailure(Location loc, CallbackT &amp;&amp;reasonCallback)</div><div class="ttdoc">Used to notify the listener that the IR failed to be rewritten because of a match failure,...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00716">PatternMatch.h:716</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a286510e5cc47983e5b6017bad6aa6335"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a286510e5cc47983e5b6017bad6aa6335">mlir::RewriterBase::eraseBlock</a></div><div class="ttdeci">virtual void eraseBlock(Block *block)</div><div class="ttdoc">This method erases all operations in a block.</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8cpp_source.html#l00232">PatternMatch.cpp:232</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a53c88f3ce889be590b3801b4ddee627f"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a53c88f3ce889be590b3801b4ddee627f">mlir::RewriterBase::replaceOp</a></div><div class="ttdeci">virtual void replaceOp(Operation *op, ValueRange newValues)</div><div class="ttdoc">Replace the results of the given (original) operation with the specified list of values (replacements...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8cpp_source.html#l00127">PatternMatch.cpp:127</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a61b4cea69baed7a36d0cd02f5b44c176"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a61b4cea69baed7a36d0cd02f5b44c176">mlir::RewriterBase::replaceAllUsesWith</a></div><div class="ttdeci">void replaceAllUsesWith(Value from, Value to)</div><div class="ttdoc">Find uses of from and replace them with to.</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00636">PatternMatch.h:636</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_a786138ac6a91e0932da343ef5c6f1e70"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#a786138ac6a91e0932da343ef5c6f1e70">mlir::RewriterBase::eraseOp</a></div><div class="ttdeci">virtual void eraseOp(Operation *op)</div><div class="ttdoc">This method erases an operation that is known to have no uses.</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8cpp_source.html#l00155">PatternMatch.cpp:155</a></div></div>
<div class="ttc" id="aclassmlir_1_1RewriterBase_html_adaf2b23302d524eeb5643dcff7668ebf"><div class="ttname"><a href="classmlir_1_1RewriterBase.html#adaf2b23302d524eeb5643dcff7668ebf">mlir::RewriterBase::inlineRegionBefore</a></div><div class="ttdeci">void inlineRegionBefore(Region &amp;region, Region &amp;parent, Region::iterator before)</div><div class="ttdoc">Move the blocks that belong to &quot;region&quot; before the given position in another region &quot;parent&quot;.</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8cpp_source.html#l00376">PatternMatch.cpp:376</a></div></div>
<div class="ttc" id="aclassmlir_1_1TypeRange_html"><div class="ttname"><a href="classmlir_1_1TypeRange.html">mlir::TypeRange</a></div><div class="ttdoc">This class provides an abstraction over the various different ranges of value types.</div><div class="ttdef"><b>Definition:</b> <a href="TypeRange_8h_source.html#l00033">TypeRange.h:37</a></div></div>
<div class="ttc" id="aclassmlir_1_1ValueRange_html"><div class="ttname"><a href="classmlir_1_1ValueRange.html">mlir::ValueRange</a></div><div class="ttdoc">This class provides an abstraction over the different types of ranges over Values.</div><div class="ttdef"><b>Definition:</b> <a href="ValueRange_8h_source.html#l00383">ValueRange.h:387</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html"><div class="ttname"><a href="classmlir_1_1Value.html">mlir::Value</a></div><div class="ttdoc">This class represents an instance of an SSA value in the MLIR system, representing a computable value...</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00096">Value.h:96</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_a5348fc13d5201e2adf7ded6b4b2fb1ad"><div class="ttname"><a href="classmlir_1_1Value.html#a5348fc13d5201e2adf7ded6b4b2fb1ad">mlir::Value::getType</a></div><div class="ttdeci">Type getType() const</div><div class="ttdoc">Return the type of this value.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00105">Value.h:105</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_ac56b0fdb6246bcf7fa1805ba0eb71aa2"><div class="ttname"><a href="classmlir_1_1Value.html#ac56b0fdb6246bcf7fa1805ba0eb71aa2">mlir::Value::replaceAllUsesWith</a></div><div class="ttdeci">void replaceAllUsesWith(Value newValue)</div><div class="ttdoc">Replace all uses of 'this' value with the new value, updating anything in the IR that uses 'this' to ...</div><div class="ttdef"><b>Definition:</b> <a href="Value_8h_source.html#l00149">Value.h:149</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_ae9df8c75072dbaab98cd4b7cd82b6ebc"><div class="ttname"><a href="classmlir_1_1Value.html#ae9df8c75072dbaab98cd4b7cd82b6ebc">mlir::Value::getLoc</a></div><div class="ttdeci">Location getLoc() const</div><div class="ttdoc">Return the location of this value.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8cpp_source.html#l00024">Value.cpp:24</a></div></div>
<div class="ttc" id="aclassmlir_1_1Value_html_aed80a742a36c5b3298467ce5d01738c8"><div class="ttname"><a href="classmlir_1_1Value.html#aed80a742a36c5b3298467ce5d01738c8">mlir::Value::getDefiningOp</a></div><div class="ttdeci">Operation * getDefiningOp() const</div><div class="ttdoc">If this value is the result of an operation, return the operation that defines it.</div><div class="ttdef"><b>Definition:</b> <a href="Value_8cpp_source.html#l00018">Value.cpp:18</a></div></div>
<div class="ttc" id="aclassmlir_1_1WalkResult_html_a693d2ecca6f15d4d492c6ff2bea148d0"><div class="ttname"><a href="classmlir_1_1WalkResult.html#a693d2ecca6f15d4d492c6ff2bea148d0">mlir::WalkResult::skip</a></div><div class="ttdeci">static WalkResult skip()</div><div class="ttdef"><b>Definition:</b> <a href="WalkResult_8h_source.html#l00048">WalkResult.h:48</a></div></div>
<div class="ttc" id="aclassmlir_1_1WalkResult_html_a97a7015a793bb5d2a97f08e358f42797"><div class="ttname"><a href="classmlir_1_1WalkResult.html#a97a7015a793bb5d2a97f08e358f42797">mlir::WalkResult::advance</a></div><div class="ttdeci">static WalkResult advance()</div><div class="ttdef"><b>Definition:</b> <a href="WalkResult_8h_source.html#l00047">WalkResult.h:47</a></div></div>
<div class="ttc" id="aclassmlir_1_1detail_1_1DenseArrayAttrImpl_html"><div class="ttname"><a href="classmlir_1_1detail_1_1DenseArrayAttrImpl.html">mlir::detail::DenseArrayAttrImpl&lt; int32_t &gt;</a></div></div>
<div class="ttc" id="aclassmlir_1_1detail_1_1DenseArrayAttrImpl_html_a289ce16b280c7eaf247d7d8413f87e82"><div class="ttname"><a href="classmlir_1_1detail_1_1DenseArrayAttrImpl.html#a289ce16b280c7eaf247d7d8413f87e82">mlir::detail::DenseArrayAttrImpl::asArrayRef</a></div><div class="ttdeci">ArrayRef&lt; T &gt; asArrayRef() const</div><div class="ttdef"><b>Definition:</b> <a href="mlir_2IR_2BuiltinAttributes_8h_source.html#l00732">BuiltinAttributes.h:732</a></div></div>
<div class="ttc" id="amlir_2Dialect_2MemRef_2IR_2MemRef_8h_html"><div class="ttname"><a href="mlir_2Dialect_2MemRef_2IR_2MemRef_8h.html">MemRef.h</a></div></div>
<div class="ttc" id="amlir_2Dialect_2XeGPU_2Transforms_2Transforms_8h_html"><div class="ttname"><a href="mlir_2Dialect_2XeGPU_2Transforms_2Transforms_8h.html">Transforms.h</a></div></div>
<div class="ttc" id="amlir_2IR_2AffineMap_8h_html"><div class="ttname"><a href="mlir_2IR_2AffineMap_8h.html">AffineMap.h</a></div></div>
<div class="ttc" id="amlir_2IR_2BuiltinAttributes_8h_html"><div class="ttname"><a href="mlir_2IR_2BuiltinAttributes_8h.html">BuiltinAttributes.h</a></div></div>
<div class="ttc" id="amlir_2IR_2BuiltinTypes_8h_html"><div class="ttname"><a href="mlir_2IR_2BuiltinTypes_8h.html">BuiltinTypes.h</a></div></div>
<div class="ttc" id="amlir_2Support_2LLVM_8h_html"><div class="ttname"><a href="mlir_2Support_2LLVM_8h.html">LLVM.h</a></div></div>
<div class="ttc" id="anamespacemlir_1_1detail_html_a7146031ab7f6bb4cdacc53c4f1e96aac"><div class="ttname"><a href="namespacemlir_1_1detail.html#a7146031ab7f6bb4cdacc53c4f1e96aac">mlir::detail::enumerate</a></div><div class="ttdeci">constexpr void enumerate(std::tuple&lt; Tys... &gt; &amp;tuple, CallbackT &amp;&amp;callback)</div><div class="ttdef"><b>Definition:</b> <a href="Matchers_8h_source.html#l00344">Matchers.h:344</a></div></div>
<div class="ttc" id="anamespacemlir_1_1xegpu_1_1targetinfo_html_aaa6e551ae63fe8b67d4a54868d9d797b"><div class="ttname"><a href="namespacemlir_1_1xegpu_1_1targetinfo.html#aaa6e551ae63fe8b67d4a54868d9d797b">mlir::xegpu::targetinfo::subgroupSize</a></div><div class="ttdeci">constexpr unsigned subgroupSize</div><div class="ttdef"><b>Definition:</b> <a href="XeGPUTargetInfo_8h_source.html#l00017">XeGPUTargetInfo.h:17</a></div></div>
<div class="ttc" id="anamespacemlir_1_1xegpu_html_a2ae68d0f2a6c692c9665306ebed7e851"><div class="ttname"><a href="namespacemlir_1_1xegpu.html#a2ae68d0f2a6c692c9665306ebed7e851">mlir::xegpu::getLayoutAttr</a></div><div class="ttdeci">LayoutAttr getLayoutAttr(const Value value)</div><div class="ttdoc">Retrieves the LayoutAttr associated with a given Value.</div><div class="ttdef"><b>Definition:</b> <a href="XeGPUUtils_8cpp_source.html#l00114">XeGPUUtils.cpp:114</a></div></div>
<div class="ttc" id="anamespacemlir_1_1xegpu_html_a2d061472bfed55c12960494849bbd863"><div class="ttname"><a href="namespacemlir_1_1xegpu.html#a2d061472bfed55c12960494849bbd863">mlir::xegpu::setLayoutAttr</a></div><div class="ttdeci">void setLayoutAttr(const T &amp;operandOrResult, const LayoutAttr layout)</div><div class="ttdoc">Sets the LayoutAttr for a given OpOperand or OpResult by attaching it to the owner's dictionary attri...</div><div class="ttdef"><b>Definition:</b> <a href="XeGPUUtils_8cpp_source.html#l00160">XeGPUUtils.cpp:160</a></div></div>
<div class="ttc" id="anamespacemlir_1_1xegpu_html_a672ad62c985a7ae405189e62c203dd64"><div class="ttname"><a href="namespacemlir_1_1xegpu.html#a672ad62c985a7ae405189e62c203dd64">mlir::xegpu::getLayoutName</a></div><div class="ttdeci">std::string getLayoutName(const OpOperand &amp;operand)</div><div class="ttdoc">Return the attribute name for the OpOperand to attach LayoutAttr.</div><div class="ttdef"><b>Definition:</b> <a href="XeGPUUtils_8cpp_source.html#l00103">XeGPUUtils.cpp:103</a></div></div>
<div class="ttc" id="anamespacemlir_1_1xegpu_html_ace8e74148db06970f9e51f8da0a7066d"><div class="ttname"><a href="namespacemlir_1_1xegpu.html#ace8e74148db06970f9e51f8da0a7066d">mlir::xegpu::removeLayoutAttrs</a></div><div class="ttdeci">void removeLayoutAttrs(Operation *op)</div><div class="ttdoc">Removes the LayoutAttr for each OpOperand and OpResult of the given operation if they exist.</div><div class="ttdef"><b>Definition:</b> <a href="XeGPUUtils_8cpp_source.html#l00207">XeGPUUtils.cpp:207</a></div></div>
<div class="ttc" id="anamespacemlir_1_1xegpu_html_af39a7d1520005ea372b9b513a1d7b442"><div class="ttname"><a href="namespacemlir_1_1xegpu.html#af39a7d1520005ea372b9b513a1d7b442">mlir::xegpu::populateXeGPUSubgroupDistributePatterns</a></div><div class="ttdeci">void populateXeGPUSubgroupDistributePatterns(RewritePatternSet &amp;patterns)</div><div class="ttdoc">Appends patterns for XeGPU SIMT distribution into patterns.</div><div class="ttdef"><b>Definition:</b> <a href="XeGPUSubgroupDistribute_8cpp_source.html#l00842">XeGPUSubgroupDistribute.cpp:842</a></div></div>
<div class="ttc" id="anamespacemlir_1_1xegpu_html_af95421174e54b5dfc990dfb4357fa13c"><div class="ttname"><a href="namespacemlir_1_1xegpu.html#af95421174e54b5dfc990dfb4357fa13c">mlir::xegpu::getDistributedVectorType</a></div><div class="ttdeci">FailureOr&lt; VectorType &gt; getDistributedVectorType(xegpu::TensorDescType tdescTy)</div><div class="ttdoc">If tensor descriptor has a layout attribute it is used in SIMT mode.</div><div class="ttdef"><b>Definition:</b> <a href="XeGPUUtils_8cpp_source.html#l00037">XeGPUUtils.cpp:37</a></div></div>
<div class="ttc" id="anamespacemlir_html"><div class="ttname"><a href="namespacemlir.html">mlir</a></div><div class="ttdoc">Include the generated interface declarations.</div><div class="ttdef"><b>Definition:</b> <a href="LocalAliasAnalysis_8h_source.html#l00020">LocalAliasAnalysis.h:20</a></div></div>
<div class="ttc" id="anamespacemlir_html_a40136aee562026e1f4503e32fb71fa2d"><div class="ttname"><a href="namespacemlir.html#a40136aee562026e1f4503e32fb71fa2d">mlir::applyPatternsGreedily</a></div><div class="ttdeci">LogicalResult applyPatternsGreedily(Region &amp;region, const FrozenRewritePatternSet &amp;patterns, GreedyRewriteConfig config=GreedyRewriteConfig(), bool *changed=nullptr)</div><div class="ttdoc">Rewrite ops in the given region, which must be isolated from above, by repeatedly applying the highes...</div><div class="ttdef"><b>Definition:</b> <a href="GreedyPatternRewriteDriver_8cpp_source.html#l00897">GreedyPatternRewriteDriver.cpp:897</a></div></div>
<div class="ttc" id="anamespacemlir_html_a8789c71249b4fcc3059f4ba4a9d27f26"><div class="ttname"><a href="namespacemlir.html#a8789c71249b4fcc3059f4ba4a9d27f26">mlir::patterns</a></div><div class="ttdeci">const FrozenRewritePatternSet &amp; patterns</div><div class="ttdef"><b>Definition:</b> <a href="GreedyPatternRewriteDriver_8h_source.html#l00283">GreedyPatternRewriteDriver.h:283</a></div></div>
<div class="ttc" id="anamespacemlir_html_ab4871db68c59a176135e0e35a3625e73"><div class="ttname"><a href="namespacemlir.html#ab4871db68c59a176135e0e35a3625e73">mlir::get</a></div><div class="ttdeci">auto get(MLIRContext *context, Ts &amp;&amp;...params)</div><div class="ttdoc">Helper method that injects context only if needed, this helps unify some of the attribute constructio...</div><div class="ttdef"><b>Definition:</b> <a href="BytecodeImplementation_8h_source.html#l00509">BytecodeImplementation.h:509</a></div></div>
<div class="ttc" id="astructmlir_1_1OpRewritePattern_html"><div class="ttname"><a href="structmlir_1_1OpRewritePattern.html">mlir::OpRewritePattern</a></div><div class="ttdoc">OpRewritePattern is a wrapper around RewritePattern that allows for matching and rewriting against an...</div><div class="ttdef"><b>Definition:</b> <a href="PatternMatch_8h_source.html#l00313">PatternMatch.h:314</a></div></div>
<div class="ttc" id="astructmlir_1_1gpu_1_1WarpDistributionPattern_html"><div class="ttname"><a href="structmlir_1_1gpu_1_1WarpDistributionPattern.html">mlir::gpu::WarpDistributionPattern</a></div><div class="ttdef"><b>Definition:</b> <a href="DistributionUtils_8h_source.html#l00019">DistributionUtils.h:19</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Aug 1 2025 16:33:26 for MLIR by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
