<!doctype html>
<html class="no-js" lang="en" data-content_root="../../../../">
  <head><meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../../../../genindex.html"><link rel="search" title="Search" href="../../../../search.html"><link rel="next" title="mlir.dialects.tosa" href="../tosa/index.html"><link rel="prev" title="mlir.dialects.spirv" href="../spirv/index.html">

    <!-- Generated with Sphinx 8.1.3 and Furo 2025.09.25 -->
        <title>mlir.dialects.tensor - MLIR Python bindings documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=d111a655" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/furo.css?v=580074bf" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/furo-extensions.css?v=8dab3a3b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/ignore_highlight_err.css?v=07bcfcf5" />
    
    


<style>
  body {
    --color-code-background: #f2f2f2;
  --color-code-foreground: #1e1e1e;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle site navigation sidebar">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc" aria-label="Toggle table of contents sidebar">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <span class="icon"><svg><use href="#svg-menu"></use></svg></span>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../../index.html"><div class="brand">MLIR Python bindings  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../../index.html">
  
  <span class="sidebar-brand-text">MLIR Python bindings  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1 current has-children"><a class="reference internal" href="../../index.html">mlir namespace</a><input aria-label="Toggle navigation of mlir namespace" checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../_mlir_libs/_mlir/dialects/pdl/index.html">mlir._mlir_libs._mlir.dialects.pdl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_mlir_libs/_mlir/dialects/quant/index.html">mlir._mlir_libs._mlir.dialects.quant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_mlir_libs/_mlir/dialects/transform/index.html">mlir._mlir_libs._mlir.dialects.transform</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../_mlir_libs/_mlir/index.html">mlir._mlir_libs._mlir</a><input aria-label="Toggle navigation of mlir._mlir_libs._mlir" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../_mlir_libs/_mlir/ir/index.html">mlir._mlir_libs._mlir.ir</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_mlir_libs/_mlir/passmanager/index.html">mlir._mlir_libs._mlir.passmanager</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_mlir_libs/_mlir/rewrite/index.html">mlir._mlir_libs._mlir.rewrite</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../_mlir_libs/_mlir/ir/index.html">mlir._mlir_libs._mlir.ir</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_mlir_libs/_mlir/passmanager/index.html">mlir._mlir_libs._mlir.passmanager</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_mlir_libs/_mlir/rewrite/index.html">mlir._mlir_libs._mlir.rewrite</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_mlir_libs/_mlirExecutionEngine/index.html">mlir._mlir_libs._mlirExecutionEngine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_mlir_libs/_mlirPythonTestNanobind/index.html">mlir._mlir_libs._mlirPythonTestNanobind</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../_mlir_libs/index.html">mlir._mlir_libs</a><input aria-label="Toggle navigation of mlir._mlir_libs" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../_mlir_libs/_mlir/index.html">mlir._mlir_libs._mlir</a><input aria-label="Toggle navigation of mlir._mlir_libs._mlir" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../_mlir_libs/_mlir/ir/index.html">mlir._mlir_libs._mlir.ir</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_mlir_libs/_mlir/passmanager/index.html">mlir._mlir_libs._mlir.passmanager</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_mlir_libs/_mlir/rewrite/index.html">mlir._mlir_libs._mlir.rewrite</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../_mlir_libs/_mlirExecutionEngine/index.html">mlir._mlir_libs._mlirExecutionEngine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_mlir_libs/_mlirPythonTestNanobind/index.html">mlir._mlir_libs._mlirPythonTestNanobind</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../_acc_ops_gen/index.html">mlir.dialects._acc_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_affine_enum_gen/index.html">mlir.dialects._affine_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_affine_ops_gen/index.html">mlir.dialects._affine_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_amdgpu_enum_gen/index.html">mlir.dialects._amdgpu_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_amdgpu_ops_gen/index.html">mlir.dialects._amdgpu_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_arith_enum_gen/index.html">mlir.dialects._arith_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_arith_ops_gen/index.html">mlir.dialects._arith_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_async_ops_gen/index.html">mlir.dialects._async_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_bufferization_enum_gen/index.html">mlir.dialects._bufferization_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_bufferization_ops_gen/index.html">mlir.dialects._bufferization_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_bufferization_transform_ops_gen/index.html">mlir.dialects._bufferization_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_builtin_ops_gen/index.html">mlir.dialects._builtin_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_cf_ops_gen/index.html">mlir.dialects._cf_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_complex_ops_gen/index.html">mlir.dialects._complex_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_emitc_ops_gen/index.html">mlir.dialects._emitc_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_func_ops_gen/index.html">mlir.dialects._func_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_gpu_enum_gen/index.html">mlir.dialects._gpu_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_gpu_ops_gen/index.html">mlir.dialects._gpu_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_gpu_transform_ops_gen/index.html">mlir.dialects._gpu_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_index_enum_gen/index.html">mlir.dialects._index_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_index_ops_gen/index.html">mlir.dialects._index_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_irdl_enum_gen/index.html">mlir.dialects._irdl_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_irdl_ops_gen/index.html">mlir.dialects._irdl_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_linalg_enum_gen/index.html">mlir.dialects._linalg_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_linalg_ops_gen/index.html">mlir.dialects._linalg_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_llvm_enum_gen/index.html">mlir.dialects._llvm_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_llvm_ops_gen/index.html">mlir.dialects._llvm_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_loop_transform_ops_gen/index.html">mlir.dialects._loop_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_math_ops_gen/index.html">mlir.dialects._math_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_memref_ops_gen/index.html">mlir.dialects._memref_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_memref_transform_ops_gen/index.html">mlir.dialects._memref_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_ml_program_ops_gen/index.html">mlir.dialects._ml_program_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_nvgpu_enum_gen/index.html">mlir.dialects._nvgpu_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_nvgpu_ops_gen/index.html">mlir.dialects._nvgpu_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_nvgpu_transform_ops_gen/index.html">mlir.dialects._nvgpu_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_nvvm_enum_gen/index.html">mlir.dialects._nvvm_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_nvvm_ops_gen/index.html">mlir.dialects._nvvm_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_ods_common/index.html">mlir.dialects._ods_common</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_omp_ops_gen/index.html">mlir.dialects._omp_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_pdl_ops_gen/index.html">mlir.dialects._pdl_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_python_test_ops_gen/index.html">mlir.dialects._python_test_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_rocdl_ops_gen/index.html">mlir.dialects._rocdl_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_scf_ops_gen/index.html">mlir.dialects._scf_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_shape_ops_gen/index.html">mlir.dialects._shape_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_shard_enum_gen/index.html">mlir.dialects._shard_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_shard_ops_gen/index.html">mlir.dialects._shard_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_smt_enum_gen/index.html">mlir.dialects._smt_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_smt_ops_gen/index.html">mlir.dialects._smt_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_sparse_tensor_enum_gen/index.html">mlir.dialects._sparse_tensor_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_sparse_tensor_ops_gen/index.html">mlir.dialects._sparse_tensor_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_sparse_tensor_transform_ops_gen/index.html">mlir.dialects._sparse_tensor_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_spirv_ops_gen/index.html">mlir.dialects._spirv_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_structured_transform_enum_gen/index.html">mlir.dialects._structured_transform_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_structured_transform_ops_gen/index.html">mlir.dialects._structured_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_tensor_ops_gen/index.html">mlir.dialects._tensor_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_tensor_transform_ops_gen/index.html">mlir.dialects._tensor_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_tosa_ops_gen/index.html">mlir.dialects._tosa_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_transform_debug_extension_ops_gen/index.html">mlir.dialects._transform_debug_extension_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_transform_enum_gen/index.html">mlir.dialects._transform_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_transform_ops_gen/index.html">mlir.dialects._transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_transform_pdl_extension_ops_gen/index.html">mlir.dialects._transform_pdl_extension_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_transform_smt_extension_ops_gen/index.html">mlir.dialects._transform_smt_extension_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_transform_tune_extension_ops_gen/index.html">mlir.dialects._transform_tune_extension_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_ub_ops_gen/index.html">mlir.dialects._ub_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_vector_enum_gen/index.html">mlir.dialects._vector_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_vector_ops_gen/index.html">mlir.dialects._vector_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_vector_transform_enum_gen/index.html">mlir.dialects._vector_transform_enum_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_vector_transform_ops_gen/index.html">mlir.dialects._vector_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_xegpu_transform_ops_gen/index.html">mlir.dialects._xegpu_transform_ops_gen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../affine/index.html">mlir.dialects.affine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../amdgpu/index.html">mlir.dialects.amdgpu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../arith/index.html">mlir.dialects.arith</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../async_dialect/index.html">mlir.dialects.async_dialect</a><input aria-label="Toggle navigation of mlir.dialects.async_dialect" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../async_dialect/passes/index.html">mlir.dialects.async_dialect.passes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../async_dialect/passes/index.html">mlir.dialects.async_dialect.passes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bufferization/index.html">mlir.dialects.bufferization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../builtin/index.html">mlir.dialects.builtin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cf/index.html">mlir.dialects.cf</a></li>
<li class="toctree-l2"><a class="reference internal" href="../complex/index.html">mlir.dialects.complex</a></li>
<li class="toctree-l2"><a class="reference internal" href="../emitc/index.html">mlir.dialects.emitc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../func/index.html">mlir.dialects.func</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../gpu/index.html">mlir.dialects.gpu</a><input aria-label="Toggle navigation of mlir.dialects.gpu" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../gpu/passes/index.html">mlir.dialects.gpu.passes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../gpu/passes/index.html">mlir.dialects.gpu.passes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index/index.html">mlir.dialects.index</a></li>
<li class="toctree-l2"><a class="reference internal" href="../irdl/index.html">mlir.dialects.irdl</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../linalg/index.html">mlir.dialects.linalg</a><input aria-label="Toggle navigation of mlir.dialects.linalg" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../linalg/opdsl/index.html">mlir.dialects.linalg.opdsl</a><input aria-label="Toggle navigation of mlir.dialects.linalg.opdsl" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/dump_oplib/index.html">mlir.dialects.linalg.opdsl.dump_oplib</a></li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../linalg/opdsl/lang/index.html">mlir.dialects.linalg.opdsl.lang</a><input aria-label="Toggle navigation of mlir.dialects.linalg.opdsl.lang" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../linalg/opdsl/lang/affine/index.html">mlir.dialects.linalg.opdsl.lang.affine</a></li>
<li class="toctree-l5"><a class="reference internal" href="../linalg/opdsl/lang/comprehension/index.html">mlir.dialects.linalg.opdsl.lang.comprehension</a></li>
<li class="toctree-l5"><a class="reference internal" href="../linalg/opdsl/lang/config/index.html">mlir.dialects.linalg.opdsl.lang.config</a></li>
<li class="toctree-l5"><a class="reference internal" href="../linalg/opdsl/lang/dsl/index.html">mlir.dialects.linalg.opdsl.lang.dsl</a></li>
<li class="toctree-l5"><a class="reference internal" href="../linalg/opdsl/lang/emitter/index.html">mlir.dialects.linalg.opdsl.lang.emitter</a></li>
<li class="toctree-l5"><a class="reference internal" href="../linalg/opdsl/lang/scalar_expr/index.html">mlir.dialects.linalg.opdsl.lang.scalar_expr</a></li>
<li class="toctree-l5"><a class="reference internal" href="../linalg/opdsl/lang/types/index.html">mlir.dialects.linalg.opdsl.lang.types</a></li>
<li class="toctree-l5"><a class="reference internal" href="../linalg/opdsl/lang/yaml_helper/index.html">mlir.dialects.linalg.opdsl.lang.yaml_helper</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../linalg/opdsl/ops/index.html">mlir.dialects.linalg.opdsl.ops</a><input aria-label="Toggle navigation of mlir.dialects.linalg.opdsl.ops" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../linalg/opdsl/ops/core_named_ops/index.html">mlir.dialects.linalg.opdsl.ops.core_named_ops</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../linalg/passes/index.html">mlir.dialects.linalg.passes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/dump_oplib/index.html">mlir.dialects.linalg.opdsl.dump_oplib</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../linalg/opdsl/index.html">mlir.dialects.linalg.opdsl</a><input aria-label="Toggle navigation of mlir.dialects.linalg.opdsl" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/dump_oplib/index.html">mlir.dialects.linalg.opdsl.dump_oplib</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../linalg/opdsl/lang/index.html">mlir.dialects.linalg.opdsl.lang</a><input aria-label="Toggle navigation of mlir.dialects.linalg.opdsl.lang" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/lang/affine/index.html">mlir.dialects.linalg.opdsl.lang.affine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/lang/comprehension/index.html">mlir.dialects.linalg.opdsl.lang.comprehension</a></li>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/lang/config/index.html">mlir.dialects.linalg.opdsl.lang.config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/lang/dsl/index.html">mlir.dialects.linalg.opdsl.lang.dsl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/lang/emitter/index.html">mlir.dialects.linalg.opdsl.lang.emitter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/lang/scalar_expr/index.html">mlir.dialects.linalg.opdsl.lang.scalar_expr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/lang/types/index.html">mlir.dialects.linalg.opdsl.lang.types</a></li>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/lang/yaml_helper/index.html">mlir.dialects.linalg.opdsl.lang.yaml_helper</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../linalg/opdsl/ops/index.html">mlir.dialects.linalg.opdsl.ops</a><input aria-label="Toggle navigation of mlir.dialects.linalg.opdsl.ops" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../linalg/opdsl/ops/core_named_ops/index.html">mlir.dialects.linalg.opdsl.ops.core_named_ops</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/lang/affine/index.html">mlir.dialects.linalg.opdsl.lang.affine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/lang/comprehension/index.html">mlir.dialects.linalg.opdsl.lang.comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/lang/config/index.html">mlir.dialects.linalg.opdsl.lang.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/lang/dsl/index.html">mlir.dialects.linalg.opdsl.lang.dsl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/lang/emitter/index.html">mlir.dialects.linalg.opdsl.lang.emitter</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../linalg/opdsl/lang/index.html">mlir.dialects.linalg.opdsl.lang</a><input aria-label="Toggle navigation of mlir.dialects.linalg.opdsl.lang" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/lang/affine/index.html">mlir.dialects.linalg.opdsl.lang.affine</a></li>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/lang/comprehension/index.html">mlir.dialects.linalg.opdsl.lang.comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/lang/config/index.html">mlir.dialects.linalg.opdsl.lang.config</a></li>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/lang/dsl/index.html">mlir.dialects.linalg.opdsl.lang.dsl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/lang/emitter/index.html">mlir.dialects.linalg.opdsl.lang.emitter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/lang/scalar_expr/index.html">mlir.dialects.linalg.opdsl.lang.scalar_expr</a></li>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/lang/types/index.html">mlir.dialects.linalg.opdsl.lang.types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/lang/yaml_helper/index.html">mlir.dialects.linalg.opdsl.lang.yaml_helper</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/lang/scalar_expr/index.html">mlir.dialects.linalg.opdsl.lang.scalar_expr</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/lang/types/index.html">mlir.dialects.linalg.opdsl.lang.types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/lang/yaml_helper/index.html">mlir.dialects.linalg.opdsl.lang.yaml_helper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/opdsl/ops/core_named_ops/index.html">mlir.dialects.linalg.opdsl.ops.core_named_ops</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../linalg/opdsl/ops/index.html">mlir.dialects.linalg.opdsl.ops</a><input aria-label="Toggle navigation of mlir.dialects.linalg.opdsl.ops" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../linalg/opdsl/ops/core_named_ops/index.html">mlir.dialects.linalg.opdsl.ops.core_named_ops</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../linalg/passes/index.html">mlir.dialects.linalg.passes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../llvm/index.html">mlir.dialects.llvm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../math/index.html">mlir.dialects.math</a></li>
<li class="toctree-l2"><a class="reference internal" href="../memref/index.html">mlir.dialects.memref</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ml_program/index.html">mlir.dialects.ml_program</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nvgpu/index.html">mlir.dialects.nvgpu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nvvm/index.html">mlir.dialects.nvvm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../openacc/index.html">mlir.dialects.openacc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../openmp/index.html">mlir.dialects.openmp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pdl/index.html">mlir.dialects.pdl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_test/index.html">mlir.dialects.python_test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quant/index.html">mlir.dialects.quant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../rocdl/index.html">mlir.dialects.rocdl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../scf/index.html">mlir.dialects.scf</a></li>
<li class="toctree-l2"><a class="reference internal" href="../shape/index.html">mlir.dialects.shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../shard/index.html">mlir.dialects.shard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../smt/index.html">mlir.dialects.smt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sparse_tensor/index.html">mlir.dialects.sparse_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../spirv/index.html">mlir.dialects.spirv</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">mlir.dialects.tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tosa/index.html">mlir.dialects.tosa</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/bufferization/index.html">mlir.dialects.transform.bufferization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/debug/index.html">mlir.dialects.transform.debug</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/extras/index.html">mlir.dialects.transform.extras</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/gpu/index.html">mlir.dialects.transform.gpu</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../transform/index.html">mlir.dialects.transform</a><input aria-label="Toggle navigation of mlir.dialects.transform" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../transform/bufferization/index.html">mlir.dialects.transform.bufferization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/debug/index.html">mlir.dialects.transform.debug</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/extras/index.html">mlir.dialects.transform.extras</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/gpu/index.html">mlir.dialects.transform.gpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/interpreter/index.html">mlir.dialects.transform.interpreter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/loop/index.html">mlir.dialects.transform.loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/memref/index.html">mlir.dialects.transform.memref</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/nvgpu/index.html">mlir.dialects.transform.nvgpu</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/pdl/index.html">mlir.dialects.transform.pdl</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/smt/index.html">mlir.dialects.transform.smt</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/sparse_tensor/index.html">mlir.dialects.transform.sparse_tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/structured/index.html">mlir.dialects.transform.structured</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/tensor/index.html">mlir.dialects.transform.tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/tune/index.html">mlir.dialects.transform.tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/vector/index.html">mlir.dialects.transform.vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../transform/xegpu/index.html">mlir.dialects.transform.xegpu</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../transform/interpreter/index.html">mlir.dialects.transform.interpreter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/loop/index.html">mlir.dialects.transform.loop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/memref/index.html">mlir.dialects.transform.memref</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/nvgpu/index.html">mlir.dialects.transform.nvgpu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/pdl/index.html">mlir.dialects.transform.pdl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/smt/index.html">mlir.dialects.transform.smt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/sparse_tensor/index.html">mlir.dialects.transform.sparse_tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/structured/index.html">mlir.dialects.transform.structured</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/tensor/index.html">mlir.dialects.transform.tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/tune/index.html">mlir.dialects.transform.tune</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/vector/index.html">mlir.dialects.transform.vector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../transform/xegpu/index.html">mlir.dialects.transform.xegpu</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ub/index.html">mlir.dialects.ub</a></li>
<li class="toctree-l2"><a class="reference internal" href="../vector/index.html">mlir.dialects.vector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../execution_engine/index.html">mlir.execution_engine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../extras/meta/index.html">mlir.extras.meta</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../extras/types/index.html">mlir.extras.types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ir/index.html">mlir.ir</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../passmanager/index.html">mlir.passmanager</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rewrite/index.html">mlir.rewrite</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../runtime/index.html">mlir.runtime</a><input aria-label="Toggle navigation of mlir.runtime" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><span class="icon"><svg><use href="#svg-arrow-right"></use></svg></span></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../runtime/np_to_memref/index.html">mlir.runtime.np_to_memref</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../runtime/np_to_memref/index.html">mlir.runtime.np_to_memref</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../../../../_sources/autoapi/mlir/dialects/tensor/index.rst.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle" aria-label="Toggle Light / Dark / Auto color theme">
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <span class="icon"><svg><use href="#svg-toc"></use></svg></span>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="module-mlir.dialects.tensor">
<span id="mlir-dialects-tensor"></span><h1>mlir.dialects.tensor<a class="headerlink" href="#module-mlir.dialects.tensor" title="Link to this heading">¶</a></h1>
<section id="attributes">
<h2>Attributes<a class="headerlink" href="#attributes" title="Link to this heading">¶</a></h2>
<div class="table-wrapper autosummary longtable docutils container">
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#id3" title="mlir.dialects.tensor.generate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate</span></code></a></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="classes">
<h2>Classes<a class="headerlink" href="#classes" title="Link to this heading">¶</a></h2>
<div class="table-wrapper autosummary longtable docutils container">
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.BitcastOp" title="mlir.dialects.tensor.BitcastOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BitcastOp</span></code></a></p></td>
<td><p>Bitcast a tensor from one type to another type of equivalent element width.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.CastOp" title="mlir.dialects.tensor.CastOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CastOp</span></code></a></p></td>
<td><p>Convert a tensor from one type to an equivalent type without changing any</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.CollapseShapeOp" title="mlir.dialects.tensor.CollapseShapeOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CollapseShapeOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">tensor.collapse_shape</span></code> op produces a new tensor of lower (or equal)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.ConcatOp" title="mlir.dialects.tensor.ConcatOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConcatOp</span></code></a></p></td>
<td><p>The &quot;concat&quot; operation constructs a tensor out of a variadic list of input</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.DimOp" title="mlir.dialects.tensor.DimOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DimOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">tensor.dim</span></code> operation takes a tensor and a dimension operand of type</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id0" title="mlir.dialects.tensor.EmptyOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EmptyOp</span></code></a></p></td>
<td><p>Extends the tensor.empty op.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.ExpandShapeOp" title="mlir.dialects.tensor.ExpandShapeOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExpandShapeOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">tensor.expand_shape</span></code> op produces a tensor of higher (or equal)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.ExtractOp" title="mlir.dialects.tensor.ExtractOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExtractOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">tensor.extract</span></code> op reads a ranked tensor and returns one element as</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp" title="mlir.dialects.tensor.ExtractSliceOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExtractSliceOp</span></code></a></p></td>
<td><p>The &quot;extract_slice&quot; operation extract a tensor from another tensor as</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.FromElementsOp" title="mlir.dialects.tensor.FromElementsOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FromElementsOp</span></code></a></p></td>
<td><p>Create a N-D tensor from a range of same-type arguments. The number of</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.GatherOp" title="mlir.dialects.tensor.GatherOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GatherOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">gather</span></code> operation extracts a subset of the elements from a <code class="docutils literal notranslate"><span class="pre">source</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.GenerateOp" title="mlir.dialects.tensor.GenerateOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GenerateOp</span></code></a></p></td>
<td><p>This operation creates a dynamically sized tensor with elements of any type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.InsertOp" title="mlir.dialects.tensor.InsertOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">InsertOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">tensor.insert</span></code> op inserts a scalar into a ranked tensor <code class="docutils literal notranslate"><span class="pre">dest</span></code> as</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp" title="mlir.dialects.tensor.InsertSliceOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">InsertSliceOp</span></code></a></p></td>
<td><p>The &quot;insert_slice&quot; operation insert a tensor <code class="docutils literal notranslate"><span class="pre">source</span></code> into another</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.PadOp" title="mlir.dialects.tensor.PadOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PadOp</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">tensor.pad</span></code> is an operation that pads the <code class="docutils literal notranslate"><span class="pre">source</span></code> tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp" title="mlir.dialects.tensor.ParallelInsertSliceOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ParallelInsertSliceOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">parallel_insert_slice</span></code> yields a subset tensor value to its parent</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.RankOp" title="mlir.dialects.tensor.RankOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RankOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">tensor.rank</span></code> operation takes a tensor operand and returns its rank.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.ReshapeOp" title="mlir.dialects.tensor.ReshapeOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ReshapeOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">reshape</span></code> operation converts a tensor from one type to an equivalent</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp" title="mlir.dialects.tensor.ScatterOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ScatterOp</span></code></a></p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">scatter</span></code> operation inserts a <code class="docutils literal notranslate"><span class="pre">source</span></code> tensor into a <code class="docutils literal notranslate"><span class="pre">dest</span></code> tensor at</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.SplatOp" title="mlir.dialects.tensor.SplatOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplatOp</span></code></a></p></td>
<td><p>Broadcast the operand to all elements of the result tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.YieldOp" title="mlir.dialects.tensor.YieldOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">YieldOp</span></code></a></p></td>
<td><p>This operation is used to yield a single value from a within a region. It</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id0" title="mlir.dialects.tensor.EmptyOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EmptyOp</span></code></a></p></td>
<td><p>Extends the tensor.empty op.</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Link to this heading">¶</a></h2>
<div class="table-wrapper autosummary longtable docutils container">
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.bitcast" title="mlir.dialects.tensor.bitcast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitcast</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.cast" title="mlir.dialects.tensor.cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cast</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.collapse_shape" title="mlir.dialects.tensor.collapse_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">collapse_shape</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.concat" title="mlir.dialects.tensor.concat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">concat</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.dim" title="mlir.dialects.tensor.dim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dim</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id2" title="mlir.dialects.tensor.empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">empty</span></code></a>(→ mlir.dialects._ods_common._cext.ir.Value)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.expand_shape" title="mlir.dialects.tensor.expand_shape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">expand_shape</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.extract" title="mlir.dialects.tensor.extract"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extract</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.extract_slice" title="mlir.dialects.tensor.extract_slice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extract_slice</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.from_elements" title="mlir.dialects.tensor.from_elements"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_elements</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.gather" title="mlir.dialects.tensor.gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gather</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#id3" title="mlir.dialects.tensor.generate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.insert" title="mlir.dialects.tensor.insert"><code class="xref py py-obj docutils literal notranslate"><span class="pre">insert</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.insert_slice" title="mlir.dialects.tensor.insert_slice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">insert_slice</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.pad" title="mlir.dialects.tensor.pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pad</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.parallel_insert_slice" title="mlir.dialects.tensor.parallel_insert_slice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parallel_insert_slice</span></code></a>(→ ParallelInsertSliceOp)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.rank" title="mlir.dialects.tensor.rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rank</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.reshape" title="mlir.dialects.tensor.reshape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reshape</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.scatter" title="mlir.dialects.tensor.scatter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">scatter</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.splat" title="mlir.dialects.tensor.splat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">splat</span></code></a>(→ _ods_ir)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#mlir.dialects.tensor.yield_" title="mlir.dialects.tensor.yield_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">yield_</span></code></a>(→ YieldOp)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#mlir.dialects.tensor.region_op" title="mlir.dialects.tensor.region_op"><code class="xref py py-obj docutils literal notranslate"><span class="pre">region_op</span></code></a>(op_constructor[, terminator])</p></td>
<td><p>Decorator to define an MLIR Op specified as a python function.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#id2" title="mlir.dialects.tensor.empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">empty</span></code></a>(→ mlir.dialects._ods_common._cext.ir.Value)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Link to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.BitcastOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">BitcastOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.BitcastOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>Bitcast a tensor from one type to another type of equivalent element width.
If both are ranked, then the rank should be the same and static dimensions
should match.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Bitcast from unsigned to signed or signless integer.</span>
<span class="nv">%2</span> <span class="o">=</span> <span class="nb">tensor.bitcast</span><span class="err"> </span><span class="nv">%1</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="kt">ui32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.BitcastOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.bitcast'</span></em><a class="headerlink" href="#mlir.dialects.tensor.BitcastOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.BitcastOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.BitcastOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.BitcastOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.BitcastOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.BitcastOp.dest">
<span class="sig-name descname"><span class="pre">dest</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.BitcastOp.dest" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.bitcast">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">bitcast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.bitcast" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CastOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">CastOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.CastOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>Convert a tensor from one type to an equivalent type without changing any
data elements. The source and destination types must both be tensor types
with the same element type. If both are ranked, then the rank should be the
same and static dimensions should match. The operation is invalid if
converting to a mismatching constant dimension.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Convert from unknown rank to rank 2 with unknown dimension sizes.</span>
<span class="nv">%2</span> <span class="o">=</span> <span class="nb">tensor.cast</span><span class="err"> </span><span class="nv">%1</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="o">*</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>

<span class="c1">// Convert to a type with more known dimensions.</span>
<span class="nv">%3</span> <span class="o">=</span> <span class="nb">tensor.cast</span><span class="err"> </span><span class="nv">%2</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>

<span class="c1">// Discard static dimension and rank information.</span>
<span class="nv">%4</span> <span class="o">=</span> <span class="nb">tensor.cast</span><span class="err"> </span><span class="nv">%3</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
<span class="nv">%5</span> <span class="o">=</span> <span class="nb">tensor.cast</span><span class="err"> </span><span class="nv">%4</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="o">*</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CastOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.cast'</span></em><a class="headerlink" href="#mlir.dialects.tensor.CastOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CastOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.CastOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CastOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.CastOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CastOp.dest">
<span class="sig-name descname"><span class="pre">dest</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.CastOp.dest" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.cast">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">cast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.cast" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CollapseShapeOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">CollapseShapeOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reassociation</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.CollapseShapeOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">tensor.collapse_shape</span></code> op produces a new tensor of lower (or equal)
rank whose dimension sizes are a reassociation of the original <code class="docutils literal notranslate"><span class="pre">src</span></code> dimensions.</p>
<p>A reassociation is defined as a continuous grouping of dimensions and is
represented by an array of DenseI64ArrayAttr attribute. The reassociation
maps are applied to the operand shape to obtain the result shape.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Dimension collapse (i, j) -&gt; i&#39; and k -&gt; k&#39;</span>
<span class="nv">%b</span> <span class="o">=</span> <span class="nb">tensor.collapse_shape</span><span class="err"> </span><span class="nv">%a</span><span class="err"> </span><span class="p">[[</span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">],</span><span class="err"> </span><span class="p">[</span><span class="mf">2</span><span class="p">]]</span>
<span class="err">    </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CollapseShapeOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.collapse_shape'</span></em><a class="headerlink" href="#mlir.dialects.tensor.CollapseShapeOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CollapseShapeOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.CollapseShapeOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CollapseShapeOp.src">
<span class="sig-name descname"><span class="pre">src</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.CollapseShapeOp.src" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CollapseShapeOp.reassociation">
<span class="sig-name descname"><span class="pre">reassociation</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.CollapseShapeOp.reassociation" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.CollapseShapeOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.CollapseShapeOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.collapse_shape">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">collapse_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reassociation</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.collapse_shape" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ConcatOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">ConcatOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.ConcatOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The “concat” operation constructs a tensor out of a variadic list of input
tensors, concatenated along a static dimension number. All inputs and the
result type must share the same rank.</p>
<p><code class="docutils literal notranslate"><span class="pre">dim</span></code> specifies the dimension along which to concatenate. The size of the
concatenated dimension in the result must be equal to the sum of the sizes
of the inputs along that dimension. All other dimensions in both the inputs
and result must be the same size.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%0</span> <span class="o">=</span> <span class="nb">tensor.concat</span><span class="err"> </span><span class="nx">dim</span><span class="p">(</span><span class="mf">0</span><span class="p">)</span><span class="err"> </span><span class="nv">%0</span><span class="p">,</span><span class="err"> </span><span class="nv">%1</span><span class="p">,</span><span class="err"> </span><span class="nv">%2</span><span class="err"> </span><span class="p">:</span>
<span class="err">    </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="mi">6</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="mi">6</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="mi">6</span><span class="p">x</span><span class="kt">f32</span><span class="p">)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">7</span><span class="p">x</span><span class="mi">6</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>

<span class="c1">// Dynamic + dynamic -&gt; static</span>
<span class="nv">%0</span> <span class="o">=</span> <span class="nb">tensor.concat</span><span class="err"> </span><span class="nx">dim</span><span class="p">(</span><span class="mf">1</span><span class="p">)</span><span class="err"> </span><span class="nv">%0</span><span class="p">,</span><span class="err"> </span><span class="nv">%1</span><span class="p">,</span><span class="err"> </span><span class="nv">%2</span><span class="err"> </span><span class="p">:</span>
<span class="err">    </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="mi">2</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="mi">10</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ConcatOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.concat'</span></em><a class="headerlink" href="#mlir.dialects.tensor.ConcatOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ConcatOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.ConcatOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ConcatOp.inputs">
<span class="sig-name descname"><span class="pre">inputs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ConcatOp.inputs" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ConcatOp.dim">
<span class="sig-name descname"><span class="pre">dim</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ConcatOp.dim" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ConcatOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ConcatOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.concat">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">concat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.concat" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.DimOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">DimOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.DimOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">tensor.dim</span></code> operation takes a tensor and a dimension operand of type
<code class="docutils literal notranslate"><span class="pre">index</span></code>. It returns the size of the requested dimension of the given
tensor. If the dimension index is out of bounds, the behavior is undefined.</p>
<p>The specified tensor type is that of the first operand.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Always returns 4, can be constant folded:</span>
<span class="nv">%c0</span> <span class="o">=</span> <span class="nb">arith.constant</span><span class="err"> </span><span class="mf">0</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">index</span>
<span class="nv">%x</span> <span class="o">=</span> <span class="nb">tensor.dim</span><span class="err"> </span><span class="nv">%A</span><span class="p">,</span><span class="err"> </span><span class="nv">%c0</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>

<span class="c1">// Return the dynamic dimension of %A.</span>
<span class="nv">%c1</span> <span class="o">=</span> <span class="nb">arith.constant</span><span class="err"> </span><span class="mf">1</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">index</span>
<span class="nv">%y</span> <span class="o">=</span> <span class="nb">tensor.dim</span><span class="err"> </span><span class="nv">%A</span><span class="p">,</span><span class="err"> </span><span class="nv">%c1</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>

<span class="c1">// Equivalent generic form:</span>
<span class="nv">%x</span><span class="err"> </span><span class="p">=</span><span class="err"> </span><span class="s2">&quot;tensor.dim&quot;</span><span class="p">(</span><span class="nv">%A</span><span class="p">,</span><span class="err"> </span><span class="nv">%c0</span><span class="p">)</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">index</span><span class="p">)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">index</span>
<span class="nv">%y</span><span class="err"> </span><span class="p">=</span><span class="err"> </span><span class="s2">&quot;tensor.dim&quot;</span><span class="p">(</span><span class="nv">%A</span><span class="p">,</span><span class="err"> </span><span class="nv">%c1</span><span class="p">)</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">index</span><span class="p">)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">index</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.DimOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.dim'</span></em><a class="headerlink" href="#mlir.dialects.tensor.DimOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.DimOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.DimOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.DimOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.DimOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.DimOp.index">
<span class="sig-name descname"><span class="pre">index</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.DimOp.index" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.DimOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.DimOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.dim">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">dim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.dim" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.EmptyOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">EmptyOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamicSizes</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.EmptyOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">tensor.empty</span></code> is an operation that defines a tensor of a particular shape.
The shape could be dynamic or static. The contents of the tensor are
unspecified and the only purpose of the op result is to materialize the
specified shape in IR and make it available to other transformations.</p>
<p><code class="docutils literal notranslate"><span class="pre">tensor.empty</span></code> is useful in transformations that expect destination style
ops. I.e., ops that implement <code class="docutils literal notranslate"><span class="pre">DestinationStyleOpInterface</span></code>. Ops that are
not in destination style can be made compatible with such transformations
with a <code class="docutils literal notranslate"><span class="pre">tensor.empty</span></code> destination.</p>
<p>Note: This op can be lowered to a <code class="docutils literal notranslate"><span class="pre">bufferization.alloc_tensor</span></code>, at which
point it turns into an explicit buffer allocation.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.EmptyOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.empty'</span></em><a class="headerlink" href="#mlir.dialects.tensor.EmptyOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.EmptyOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.EmptyOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.EmptyOp.dynamicSizes">
<span class="sig-name descname"><span class="pre">dynamicSizes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.EmptyOp.dynamicSizes" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.EmptyOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.EmptyOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.empty">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic_sizes</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.empty" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExpandShapeOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">ExpandShapeOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reassociation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_output_shape</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.ExpandShapeOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">tensor.expand_shape</span></code> op produces a tensor of higher (or equal)
rank than the operand <code class="docutils literal notranslate"><span class="pre">src</span></code> whose dimension sizes are a reassociation of
<code class="docutils literal notranslate"><span class="pre">src</span></code>.</p>
<p>A reassociation is defined as a continuous grouping of dimensions and is
represented with an array of DenseI64ArrayAttr attribute.  The reassociation
maps applied to the result tensor with the higher rank must result in the
operand tensor with the smaller rank.</p>
<p>The representation for the output shape supports a partially-static
specification via attributes specified through the <code class="docutils literal notranslate"><span class="pre">static_output_shape</span></code>
argument.  A special sentinel value <code class="docutils literal notranslate"><span class="pre">ShapedType::kDynamic</span></code> encodes that the
corresponding entry has a dynamic value.  There must be exactly as many SSA
inputs in <code class="docutils literal notranslate"><span class="pre">output_shape</span></code> as there are <code class="docutils literal notranslate"><span class="pre">ShapedType::kDynamic</span></code> entries in
<code class="docutils literal notranslate"><span class="pre">static_output_shape</span></code>.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Dimension expansion i -&gt; (i&#39;, j&#39;) and (k) -&gt; (k&#39;)</span>
<span class="nv">%b</span> <span class="o">=</span> <span class="nb">tensor.expand_shape</span><span class="err"> </span><span class="nv">%a</span><span class="err"> </span><span class="p">[[</span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">],</span><span class="err"> </span><span class="p">[</span><span class="mf">2</span><span class="p">]]</span><span class="err"> </span><span class="nx">output_shape</span><span class="err"> </span><span class="p">[</span><span class="nv">%sz0</span><span class="p">,</span><span class="err"> </span><span class="nv">%sz1</span><span class="p">,</span><span class="err"> </span><span class="mf">32</span><span class="p">]</span>
<span class="err">    </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="mi">32</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="mi">32</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExpandShapeOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.expand_shape'</span></em><a class="headerlink" href="#mlir.dialects.tensor.ExpandShapeOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExpandShapeOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.ExpandShapeOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExpandShapeOp.src">
<span class="sig-name descname"><span class="pre">src</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExpandShapeOp.src" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExpandShapeOp.output_shape">
<span class="sig-name descname"><span class="pre">output_shape</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExpandShapeOp.output_shape" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExpandShapeOp.reassociation">
<span class="sig-name descname"><span class="pre">reassociation</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExpandShapeOp.reassociation" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExpandShapeOp.static_output_shape">
<span class="sig-name descname"><span class="pre">static_output_shape</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExpandShapeOp.static_output_shape" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExpandShapeOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExpandShapeOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.expand_shape">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">expand_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reassociation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_output_shape</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.expand_shape" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">ExtractOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.ExtractOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">tensor.extract</span></code> op reads a ranked tensor and returns one element as
specified by the given indices. The result of the op is a value with the
same type as the elements of the tensor. The arity of indices must match
the rank of the accessed value. All indices should all be of <code class="docutils literal notranslate"><span class="pre">index</span></code> type.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%4</span> <span class="o">=</span> <span class="nb">tensor.extract</span><span class="err"> </span><span class="nv">%t</span><span class="p">[</span><span class="nv">%1</span><span class="p">,</span><span class="err"> </span><span class="nv">%2</span><span class="p">]</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;</span>
<span class="nv">%5</span> <span class="o">=</span> <span class="nb">tensor.extract</span><span class="err"> </span><span class="nv">%rt</span><span class="p">[</span><span class="nv">%1</span><span class="p">,</span><span class="err"> </span><span class="nv">%2</span><span class="p">]</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.extract'</span></em><a class="headerlink" href="#mlir.dialects.tensor.ExtractOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.ExtractOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractOp.tensor">
<span class="sig-name descname"><span class="pre">tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractOp.tensor" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractOp.indices">
<span class="sig-name descname"><span class="pre">indices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractOp.indices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.extract">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">extract</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.extract" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">ExtractSliceOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_strides</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The “extract_slice” operation extract a tensor from another tensor as
specified by the operation’s offsets, sizes and strides arguments.</p>
<p>The extract_slice operation supports the following arguments:</p>
<ul class="simple">
<li><p>source: the “base” tensor from which to extract a slice.</p></li>
<li><p>offsets: tensor-rank number of offsets into the “base” tensor from which</p></li>
</ul>
<p>to extract the slice.
* sizes: tensor-rank number of sizes which specify the sizes of the result
tensor type.
* strides: tensor-rank number of strides specifying subsampling in each
dimension.</p>
<p>The representation based on offsets, sizes and strides support a
partially-static specification via attributes specified through the
<code class="docutils literal notranslate"><span class="pre">static_offsets</span></code>, <code class="docutils literal notranslate"><span class="pre">static_sizes</span></code> and <code class="docutils literal notranslate"><span class="pre">static_strides</span></code> arguments. A special
sentinel value ShapedType::kDynamic encodes that the corresponding entry has
a dynamic value.</p>
<p>After buffer allocation, the “extract_slice” op is expected to lower into a
memref.subview op.</p>
<p>An extract_slice operation may additionally reduce the rank of the resulting
tensor by removing dimensions that are statically known to be of size 1.
This rank-reduction behavior is not required by the op semantics: this
flexibility allows to progressively drop unit dimensions while lowering
between different flavors of ops on that operate on tensors.</p>
<section id="verification-vs-inference-in-the-rank-reduced-case">
<h3>Verification vs Inference in the rank-reduced case<a class="headerlink" href="#verification-vs-inference-in-the-rank-reduced-case" title="Link to this heading">¶</a></h3>
<p>Note that there may be multiple ways to infer a resulting rank-reduced type.
e.g. 1x6x1 could potentially rank-reduce to either 1x6 or 6x1 2-D shapes.</p>
<p>To disambiguate, the inference helpers <code class="docutils literal notranslate"><span class="pre">inferCanonicalRankReducedResultType</span></code>
only drop the first unit dimensions, in order:
e.g. 1x6x1 rank-reduced to 2-D will infer the 6x1 2-D shape, but not 1x6.</p>
<p>Verification however has access to result type and does not need to infer.
The verifier calls <code class="docutils literal notranslate"><span class="pre">isRankReducedType(getSource(),</span> <span class="pre">getResult())</span></code> to
determine whether the result type is rank-reduced from the source type.
This computes a so-called rank-reduction mask, consisting of dropped unit
dims, to map the rank-reduced type to the source type by dropping ones:
e.g. 1x6 is a rank-reduced version of 1x6x1 by mask {2}
6x1 is a rank-reduced version of 1x6x1 by mask {0}
1x2x1x4 is a rank-reduced version of 1x1x2x1x1x4x1 by mask {1, 4, 6}
(remaining common 1 dimensions are matched eagerly)</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Rank-reducing extract_slice.</span>
<span class="nv">%1</span> <span class="o">=</span> <span class="nb">tensor.extract_slice</span><span class="err"> </span><span class="nv">%0</span><span class="p">[</span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">0</span><span class="p">][</span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="mf">16</span><span class="p">,</span><span class="err"> </span><span class="mf">4</span><span class="p">][</span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">]</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">8</span><span class="p">x</span><span class="mi">16</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">16</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
<span class="nv">%3</span> <span class="o">=</span> <span class="nb">tensor.extract_slice</span><span class="err"> </span><span class="nv">%2</span><span class="p">[</span><span class="nv">%o0</span><span class="p">,</span><span class="err"> </span><span class="mf">4</span><span class="p">,</span><span class="err"> </span><span class="nv">%o2</span><span class="p">][</span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="nv">%sz1</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">][</span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="nv">%st1</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">]</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">8</span><span class="p">x</span><span class="mi">16</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.extract_slice'</span></em><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp._ODS_OPERAND_SEGMENTS">
<span class="sig-name descname"><span class="pre">_ODS_OPERAND_SEGMENTS</span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp._ODS_OPERAND_SEGMENTS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp.offsets">
<span class="sig-name descname"><span class="pre">offsets</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp.offsets" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp.sizes">
<span class="sig-name descname"><span class="pre">sizes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp.sizes" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp.strides">
<span class="sig-name descname"><span class="pre">strides</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp.strides" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp.static_offsets">
<span class="sig-name descname"><span class="pre">static_offsets</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp.static_offsets" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp.static_sizes">
<span class="sig-name descname"><span class="pre">static_sizes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp.static_sizes" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp.static_strides">
<span class="sig-name descname"><span class="pre">static_strides</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp.static_strides" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ExtractSliceOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ExtractSliceOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</section>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.extract_slice">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">extract_slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_strides</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.extract_slice" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.FromElementsOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">FromElementsOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">elements</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.FromElementsOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>Create a N-D tensor from a range of same-type arguments. The number of
provided <code class="docutils literal notranslate"><span class="pre">elements</span></code> should equal to the number of the elements in the
result type. The <code class="docutils literal notranslate"><span class="pre">elements</span></code> correspond to a flattened tensor.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nb">tensor.from_elements</span><span class="err"> </span><span class="nv">%a</span><span class="p">,</span><span class="err"> </span><span class="nv">%b</span><span class="p">,</span><span class="err"> </span><span class="nv">%c</span><span class="p">,</span><span class="err"> </span><span class="nv">%d</span><span class="p">,</span><span class="err"> </span><span class="nv">%e</span><span class="p">,</span><span class="err"> </span><span class="nv">%f</span><span class="err"> </span><span class="p">:</span><span class="err">  </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">2</span><span class="p">x</span><span class="mi">3</span><span class="p">x</span><span class="kt">index</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>will result in a tensor</p>
<p>[[%a, %b, %c]
[%d, %e, %f]]</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.FromElementsOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.from_elements'</span></em><a class="headerlink" href="#mlir.dialects.tensor.FromElementsOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.FromElementsOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.FromElementsOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.FromElementsOp.elements">
<span class="sig-name descname"><span class="pre">elements</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.FromElementsOp.elements" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.FromElementsOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.FromElementsOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.from_elements">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">from_elements</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">elements</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.from_elements" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GatherOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">GatherOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gather_dims</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.GatherOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">gather</span></code> operation extracts a subset of the elements from a <code class="docutils literal notranslate"><span class="pre">source</span></code>
tensor at the given indices.</p>
<p>In its most general form, the tensor of indices specifies all the coordinates
of every element to extract (i.e. COO format, without the payload).
The indices are expected to be confined to coordinate values that fit the
range of the <code class="docutils literal notranslate"><span class="pre">source</span></code> tensor, otherwise the behavior is undefined.</p>
<p>The leading dimensions of the index tensor give the result tensor its leading
dimensions. The trailing dimensions of the result tensor are obtained from
the source tensor by omitting the dimensions specified in <code class="docutils literal notranslate"><span class="pre">gather_dims</span></code>
(rank-reducing semantics) or setting them to <code class="docutils literal notranslate"><span class="pre">1</span></code> (rank-preserving semantics)
(see examples).
The trailing dimension of the index tensor contains the coordinates and is
expected to have its size equal to the number of dimensions being gathered.
This convention allows an idiomatic specification and lowering of “gathering
multiple N-D slices from the source tensor”.</p>
<p>Note: in the examples below, we separate out the indexing part of the tensor
type by a whitespace for readability purposes.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// For each 1x2 triple of coordinates in %indices, extract the</span>
<span class="c1">// element (i.e. 0-D subset) at the coordinates triple in %source.</span>
<span class="c1">//</span>
<span class="nv">%out</span> <span class="o">=</span> <span class="nb">tensor.gather</span><span class="err"> </span><span class="nv">%source</span><span class="p">[</span><span class="nv">%indices</span><span class="p">]</span><span class="err"> </span><span class="nx">gather_dims</span><span class="p">([</span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="mf">2</span><span class="p">])</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="mi">2</span><span class="p">x</span><span class="err"> </span><span class="mi">3</span><span class="p">x</span><span class="kt">index</span><span class="p">&gt;)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="mi">2</span><span class="p">x</span><span class="err"> </span><span class="mi">1</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>

<span class="c1">// Note: result type may be further rank-reduced to tensor&lt;1x2x f32&gt;.</span>
</pre></div>
</div>
<p>A slice variant is provided to allow specifying whole slices of the source
tensor.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// For each 5x6 singleton of coordinates in %indices, extract the 2-D</span>
<span class="c1">// slice %source[*, %indices[...]:%indices[...] + 1, *] with the indices</span>
<span class="c1">// corresponding to the `gather_dims` attribute specified by %indices.</span>
<span class="c1">//</span>
<span class="nv">%out</span> <span class="o">=</span> <span class="nb">tensor.gather</span><span class="err"> </span><span class="nv">%source</span><span class="p">[</span><span class="nv">%indices</span><span class="p">]</span><span class="err"> </span><span class="nx">gather_dims</span><span class="p">([</span><span class="mf">1</span><span class="p">])</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="mi">5</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">6</span><span class="p">x</span><span class="mi">7</span><span class="p">x</span><span class="err"> </span><span class="mi">1</span><span class="p">x</span><span class="kt">index</span><span class="p">&gt;)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">6</span><span class="p">x</span><span class="mi">7</span><span class="p">x</span><span class="err"> </span><span class="mi">3</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="mi">5</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>

<span class="c1">// Note: result type may be further rank-reduced to tensor&lt;6x7x 3x5xf32&gt;.</span>
</pre></div>
</div>
<p>The dimensions specified in the gather_dims attribute are ones for which the
result tensor has size <code class="docutils literal notranslate"><span class="pre">1</span></code>.
I.e. if the source type is <code class="docutils literal notranslate"><span class="pre">axbxcxd</span></code> and the coordinates are [1, 3], then
the shape suffix is <code class="docutils literal notranslate"><span class="pre">ax1xcx1</span></code>.
Gather also allows rank-reducing semantics where the shape <code class="docutils literal notranslate"><span class="pre">ax1xcx1</span></code> can be
further simplified to <code class="docutils literal notranslate"><span class="pre">axc</span></code>.</p>
<p>The elemental type of the indices tensor can be any integer type.
In the absence of target-specific or problem specific information the default
type one should use is <code class="docutils literal notranslate"><span class="pre">index</span></code>.</p>
<p>This operation does not support unranked tensors.</p>
<p>An optional <code class="docutils literal notranslate"><span class="pre">unique</span></code> unit attribute may be specified to indicate that the
coordinates in <code class="docutils literal notranslate"><span class="pre">indices</span></code> are statically guaranteed to be unique at runtime.
Incorrectly setting the <code class="docutils literal notranslate"><span class="pre">unique</span></code> attribute when the coordinates are not truly
unique is undefined behavior.</p>
<p>Only full slices are meant to be supported by this op, if one desires
partial slices (e.g. strided windows) one should compose this op with other
tensor ops (e.g. tensor.extract_slice). This is to avoid a slippery slope of
complexity that would make the op unusable in practice.</p>
<p>At the tensor-level, the index tensor is specified in an AoS form (i.e.
coordinate tuple is the most minor). It is the responsibility of further
lowerings and bufferization to implement various concrete layouts.</p>
<p>Note: As currently specified, the operation must lower to an abstraction that
performs copies to the output tensor. This is because the buffer type system
is currently not rich enough to allow multiple non-contiguous views in the
same type. This is visible more clearly in a notional buffer version of the
op:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// memref&lt;?x4x1xf32&gt; is a contiguous buffer of ?x4x1 elements.</span>
<span class="c1">// gather from random source slices must copy to the contiguous output.</span>
<span class="nv">%out</span> <span class="o">=</span> <span class="nb">memref.gather</span><span class="err"> </span><span class="nv">%source</span><span class="p">[</span><span class="nv">%indices</span><span class="p">]</span><span class="err"> </span><span class="nx">gather_dims</span><span class="p">([</span><span class="mf">1</span><span class="p">])</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="p">(</span><span class="kt">memref</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="err"> </span><span class="mi">1</span><span class="p">x</span><span class="kt">index</span><span class="p">&gt;)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="err"> </span><span class="mi">4</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>

<span class="c1">// Nested buffer support would allow gather to directly index into the</span>
<span class="c1">// source buffer (i.e. represent a jagged view into the source).</span>
<span class="nv">%out</span> <span class="o">=</span> <span class="nb">memref.gather</span><span class="err"> </span><span class="nv">%source</span><span class="p">[</span><span class="nv">%indices</span><span class="p">]</span><span class="err"> </span><span class="nx">gather_dims</span><span class="p">([</span><span class="mf">1</span><span class="p">])</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="p">(</span><span class="kt">memref</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="err"> </span><span class="mi">1</span><span class="p">x</span><span class="kt">index</span><span class="p">&gt;)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="err"> </span><span class="p">x</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GatherOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.gather'</span></em><a class="headerlink" href="#mlir.dialects.tensor.GatherOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GatherOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.GatherOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GatherOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.GatherOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GatherOp.indices">
<span class="sig-name descname"><span class="pre">indices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.GatherOp.indices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GatherOp.gather_dims">
<span class="sig-name descname"><span class="pre">gather_dims</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.GatherOp.gather_dims" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GatherOp.unique">
<span class="sig-name descname"><span class="pre">unique</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.GatherOp.unique" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GatherOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.GatherOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.gather">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gather_dims</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.gather" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GenerateOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">GenerateOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamicExtents</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.GenerateOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>This operation creates a dynamically sized tensor with elements of any type.
It expects one index operand per dynamic extent of the result tensor.</p>
<p>The body region defines the tensor’s elements. It takes index operands as
its region arguments that span the index space. The element at the given
position is yielded with the <code class="docutils literal notranslate"><span class="pre">yield</span></code> operation (see <code class="docutils literal notranslate"><span class="pre">YieldOp</span></code>). There is
no defined ordering to the invocations of the body. It is conceptually
a “parallel map” operation.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%tnsr</span> <span class="o">=</span> <span class="nb">tensor.generate</span><span class="err"> </span><span class="nv">%m</span><span class="p">,</span><span class="err"> </span><span class="nv">%n</span><span class="err"> </span><span class="p">{</span>
<span class="nl">^bb0</span><span class="p">(</span><span class="nv">%i</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">index</span><span class="p">,</span><span class="err"> </span><span class="nv">%j</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">index</span><span class="p">,</span><span class="err"> </span><span class="nv">%k</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">index</span><span class="p">):</span>
<span class="err">  </span><span class="p">...</span>
  <span class="nb">yield</span><span class="err"> </span><span class="nv">%elem</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="p">}</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="mi">3</span><span class="p">x</span><span class="n n-Integer">?</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GenerateOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.generate'</span></em><a class="headerlink" href="#mlir.dialects.tensor.GenerateOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GenerateOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(1,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.GenerateOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GenerateOp.dynamicExtents">
<span class="sig-name descname"><span class="pre">dynamicExtents</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.GenerateOp.dynamicExtents" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GenerateOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.GenerateOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.GenerateOp.body">
<span class="sig-name descname"><span class="pre">body</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.GenerateOp.body" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.generate">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic_extents</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.generate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">InsertOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scalar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.InsertOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">tensor.insert</span></code> op inserts a scalar into a ranked tensor <code class="docutils literal notranslate"><span class="pre">dest</span></code> as
specified by the operation’s indices.</p>
<p>It returns a copy of <code class="docutils literal notranslate"><span class="pre">dest</span></code> with the indexed position updated to the value
of <code class="docutils literal notranslate"><span class="pre">scalar</span></code>.</p>
<p>The arity of <code class="docutils literal notranslate"><span class="pre">indices</span> <span class="pre">``must</span> <span class="pre">match</span> <span class="pre">the</span> <span class="pre">rank</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">tensor</span> <span class="pre">``dest</span></code>. All
indices should be of <code class="docutils literal notranslate"><span class="pre">index</span></code> type.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%4</span> <span class="o">=</span> <span class="nb">tensor.insert</span><span class="err"> </span><span class="nv">%t</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="nv">%dest</span><span class="p">[</span><span class="nv">%1</span><span class="p">,</span><span class="err"> </span><span class="nv">%2</span><span class="p">]</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;</span>
<span class="nv">%5</span> <span class="o">=</span> <span class="nb">tensor.insert</span><span class="err"> </span><span class="nv">%rt</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="nv">%dest</span><span class="p">[</span><span class="nv">%1</span><span class="p">,</span><span class="err"> </span><span class="nv">%2</span><span class="p">]</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.insert'</span></em><a class="headerlink" href="#mlir.dialects.tensor.InsertOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.InsertOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertOp.scalar">
<span class="sig-name descname"><span class="pre">scalar</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertOp.scalar" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertOp.dest">
<span class="sig-name descname"><span class="pre">dest</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertOp.dest" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertOp.indices">
<span class="sig-name descname"><span class="pre">indices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertOp.indices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.insert">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">insert</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scalar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.insert" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">InsertSliceOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_strides</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The “insert_slice” operation insert a tensor <code class="docutils literal notranslate"><span class="pre">source</span></code> into another
tensor <code class="docutils literal notranslate"><span class="pre">dest</span></code> as specified by the operation’s offsets, sizes and strides
arguments.</p>
<p>It returns a copy of <code class="docutils literal notranslate"><span class="pre">dest</span></code> with the proper slice updated with the value
of <code class="docutils literal notranslate"><span class="pre">source</span></code>.</p>
<p>The insert_slice operation supports the following arguments:</p>
<ul class="simple">
<li><p>source: the tensor that is inserted.</p></li>
<li><p>dest: the tensor into which the source tensor is inserted.</p></li>
<li><p>offsets: tensor-rank number of offsets into the <code class="docutils literal notranslate"><span class="pre">dest</span></code> tensor into which</p></li>
</ul>
<p>the slice is inserted.
* sizes: tensor-rank number of sizes which specify the sizes of the source
tensor type.
* strides: tensor-rank number of strides that specify subsampling in each
dimension.</p>
<p>The representation based on offsets, sizes and strides support a
partially-static specification via attributes specified through the
<code class="docutils literal notranslate"><span class="pre">static_offsets</span></code>, <code class="docutils literal notranslate"><span class="pre">static_sizes</span></code> and <code class="docutils literal notranslate"><span class="pre">static_strides</span></code> arguments. A special
sentinel value ShapedType::kDynamic encodes that the corresponding entry has
a dynamic value.</p>
<p>After buffer allocation, the “insert_slice” op is expected to lower into a
memref.subview op.</p>
<p>An insert_slice operation may additionally specify insertion into a tensor
of higher rank than the source tensor, along dimensions that are statically
known to be of size 1.
This rank-altering behavior is not required by the op semantics: this
flexibility allows to progressively drop unit dimensions while lowering
between different flavors of ops on that operate on tensors.
The rank-altering behavior of tensor.insert_slice matches the rank-reducing
behavior of tensor.extract_slice.</p>
<section id="verification-in-the-rank-reduced-case">
<h3>Verification in the rank-reduced case<a class="headerlink" href="#verification-in-the-rank-reduced-case" title="Link to this heading">¶</a></h3>
<p>The same verification discussion and mechanisms apply as for ExtractSliceOp.
Unlike ExtractSliceOp however, there is no need for a specific inference.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Rank-altering insert_slice.</span>
<span class="nv">%1</span> <span class="o">=</span> <span class="nb">tensor.insert_slice</span><span class="err"> </span><span class="nv">%t</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="nv">%0</span><span class="p">[</span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">0</span><span class="p">][</span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="mf">16</span><span class="p">,</span><span class="err"> </span><span class="mf">4</span><span class="p">][</span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">]</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">16</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">8</span><span class="p">x</span><span class="mi">16</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
<span class="nv">%3</span> <span class="o">=</span> <span class="nb">tensor.insert_slice</span><span class="err"> </span><span class="nv">%tt</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="nv">%2</span><span class="p">[</span><span class="nv">%o0</span><span class="p">,</span><span class="err"> </span><span class="mf">4</span><span class="p">,</span><span class="err"> </span><span class="nv">%o2</span><span class="p">][</span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="nv">%sz1</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">][</span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="nv">%st1</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">]</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">8</span><span class="p">x</span><span class="mi">16</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.insert_slice'</span></em><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp._ODS_OPERAND_SEGMENTS">
<span class="sig-name descname"><span class="pre">_ODS_OPERAND_SEGMENTS</span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp._ODS_OPERAND_SEGMENTS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.dest">
<span class="sig-name descname"><span class="pre">dest</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.dest" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.offsets">
<span class="sig-name descname"><span class="pre">offsets</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.offsets" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.sizes">
<span class="sig-name descname"><span class="pre">sizes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.sizes" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.strides">
<span class="sig-name descname"><span class="pre">strides</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.strides" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.static_offsets">
<span class="sig-name descname"><span class="pre">static_offsets</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.static_offsets" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.static_sizes">
<span class="sig-name descname"><span class="pre">static_sizes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.static_sizes" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.static_strides">
<span class="sig-name descname"><span class="pre">static_strides</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.static_strides" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.InsertSliceOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.InsertSliceOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</section>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.insert_slice">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">insert_slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_strides</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.insert_slice" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">PadOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_low</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_high</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nofold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.PadOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">tensor.pad</span></code> is an operation that pads the <code class="docutils literal notranslate"><span class="pre">source</span></code> tensor
with given <code class="docutils literal notranslate"><span class="pre">low</span></code> and <code class="docutils literal notranslate"><span class="pre">high</span></code> padding config.</p>
<p>The PadOp operation supports the following arguments:</p>
<ul class="simple">
<li><p>source: the “base” tensor on which to pad.</p></li>
<li><p>low: A list contains the padding along the start of each</p></li>
</ul>
<p>dimension, i.e., how many padded values are prepended
to the beginning of the tensor in each dimension.
* high: A list contains the padding along the end of each
dimension, i.e., how many padded values are appended
to the end of the tensor in each dimension.
* nofold: indicates that the operation should not be folded when source and
result types are equal.</p>
<p>The result tensor dimensions are <code class="docutils literal notranslate"><span class="pre">low[i]</span></code> + <code class="docutils literal notranslate"><span class="pre">dim[i]</span></code> + <code class="docutils literal notranslate"><span class="pre">high[i]</span></code> for each
dimension <code class="docutils literal notranslate"><span class="pre">i</span></code>. The number of elements of <code class="docutils literal notranslate"><span class="pre">low</span></code> and <code class="docutils literal notranslate"><span class="pre">high</span></code> must match the
rank of the input tensor. They can be either a constant or a dynamic value.</p>
<p>The region of the <code class="docutils literal notranslate"><span class="pre">tensor.pad</span></code> operation returns the value to use
for the padding. The arguments of the region represent the index
of the source being accessed. There should be as many arguments as
the rank of the <code class="docutils literal notranslate"><span class="pre">source</span></code> tensor. The value <code class="docutils literal notranslate"><span class="pre">yield</span></code>-ed by the
region is used as the value of the view at the given position.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">nofold</span></code> is set, the padding operation will not be folded away even
if the source type and the padded type have the same static shape. This can
be used, e.g., for packing or promotion to faster memory.</p>
<p>Example 1: add 3 zeros to the beginning and 5 zeros to the end of a 1D
tensor.</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%arg0</span><span class="err"> </span><span class="p">=</span><span class="err"> </span><span class="p">...</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">10</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;</span>
<span class="nv">%c0_i32</span> <span class="o">=</span> <span class="nb">arith.constant</span><span class="err"> </span><span class="mf">0</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">i32</span>
<span class="nv">%padded</span> <span class="o">=</span> <span class="nb">tensor.pad</span><span class="err"> </span><span class="nv">%arg0</span><span class="err"> </span><span class="nx">low</span><span class="p">[</span><span class="mf">3</span><span class="p">]</span><span class="err"> </span><span class="nx">high</span><span class="p">[</span><span class="mf">5</span><span class="p">]</span><span class="err"> </span><span class="p">{</span>
<span class="nl">^bb0</span><span class="p">(</span><span class="nv">%arg1:</span><span class="err"> </span><span class="kt">index</span><span class="p">):</span>
  <span class="nb">tensor.yield</span><span class="err"> </span><span class="nv">%c0_i32</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">i32</span>
<span class="p">}</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">10</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">18</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>Example 2: add 1 value to the beginning of dimension 0, 2 values to the end
of dimension 0, 2 values to the start of dimension 1, and 3 values to the
end of dimension 1.</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%pad_value</span><span class="err"> </span><span class="p">=</span><span class="err"> </span><span class="p">...</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="nv">%0</span> <span class="o">=</span> <span class="nb">tensor.pad</span><span class="err"> </span><span class="nv">%0</span><span class="err"> </span><span class="nx">low</span><span class="p">[</span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="mf">2</span><span class="p">]</span><span class="err"> </span><span class="nx">high</span><span class="p">[</span><span class="mf">2</span><span class="p">,</span><span class="err"> </span><span class="mf">3</span><span class="p">]</span><span class="err"> </span><span class="p">{</span>
<span class="nl">^bb0</span><span class="p">(</span><span class="nv">%arg0</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">index</span><span class="p">,</span><span class="err"> </span><span class="nv">%arg1</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">index</span><span class="p">):</span>
  <span class="nb">tensor.yield</span><span class="err"> </span><span class="nv">%pad_value</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="p">}</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>Example 3:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%pad_value</span><span class="err"> </span><span class="p">=</span><span class="err"> </span><span class="p">...</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="nv">%0</span> <span class="o">=</span> <span class="nb">tensor.pad</span><span class="err"> </span><span class="nv">%arg0</span><span class="err"> </span><span class="nx">low</span><span class="p">[</span><span class="mf">2</span><span class="p">,</span><span class="err"> </span><span class="nv">%arg1</span><span class="p">,</span><span class="err"> </span><span class="mf">3</span><span class="p">,</span><span class="err"> </span><span class="mf">3</span><span class="p">]</span><span class="err"> </span><span class="nx">high</span><span class="p">[</span><span class="mf">3</span><span class="p">,</span><span class="err"> </span><span class="mf">3</span><span class="p">,</span><span class="err"> </span><span class="nv">%arg1</span><span class="p">,</span><span class="err"> </span><span class="mf">2</span><span class="p">]</span><span class="err"> </span><span class="p">{</span>
<span class="nl">^bb0</span><span class="p">(</span><span class="nv">%arg2:</span><span class="err"> </span><span class="kt">index</span><span class="p">,</span><span class="err"> </span><span class="nv">%arg3:</span><span class="err"> </span><span class="kt">index</span><span class="p">,</span><span class="err"> </span><span class="nv">%arg4:</span><span class="err"> </span><span class="kt">index</span><span class="p">,</span><span class="err"> </span><span class="nv">%arg5:</span><span class="err"> </span><span class="kt">index</span><span class="p">):</span>
    <span class="nb">tensor.yield</span><span class="err"> </span><span class="nv">%pad_value</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="p">}</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="mi">2</span><span class="p">x</span><span class="mi">2</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">6</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>Example 4:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%pad_value</span><span class="err"> </span><span class="p">=</span><span class="err"> </span><span class="p">...</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="nv">%0</span> <span class="o">=</span> <span class="nb">tensor.pad</span><span class="err"> </span><span class="nv">%arg0</span><span class="err"> </span><span class="nx">low</span><span class="p">[</span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">0</span><span class="p">]</span><span class="err"> </span><span class="nx">high</span><span class="p">[</span><span class="nv">%ub0</span><span class="p">,</span><span class="err"> </span><span class="nv">%ub1</span><span class="p">]</span><span class="err"> </span><span class="p">{</span>
<span class="nl">^bb0</span><span class="p">(</span><span class="nv">%arg1:</span><span class="err"> </span><span class="kt">index</span><span class="p">,</span><span class="err"> </span><span class="nv">%arg2:</span><span class="err"> </span><span class="kt">index</span><span class="p">):</span>
  <span class="nb">tensor.yield</span><span class="err"> </span><span class="nv">%pad_value</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="p">}</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">2</span><span class="p">x</span><span class="mi">3</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>Example 5: Force a padded value to be always exist with <code class="docutils literal notranslate"><span class="pre">nofold</span></code>, even
though the padding config specifies that no new elements will be added to
the tensor.</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%pad_value</span><span class="err"> </span><span class="p">=</span><span class="err"> </span><span class="p">...</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="nv">%0</span> <span class="o">=</span> <span class="nb">tensor.pad</span><span class="err"> </span><span class="nv">%arg0</span><span class="err"> </span><span class="nx">nofold</span><span class="err"> </span><span class="nx">low</span><span class="p">[</span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">0</span><span class="p">]</span><span class="err"> </span><span class="nx">high</span><span class="p">[</span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">0</span><span class="p">]</span><span class="err"> </span><span class="p">{</span>
<span class="nl">^bb0</span><span class="p">(</span><span class="nv">%arg1:</span><span class="err"> </span><span class="kt">index</span><span class="p">,</span><span class="err"> </span><span class="nv">%arg2:</span><span class="err"> </span><span class="kt">index</span><span class="p">):</span>
  <span class="nb">tensor.yield</span><span class="err"> </span><span class="nv">%pad_value</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="p">}</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">2</span><span class="p">x</span><span class="mi">3</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span><span class="err"> </span><span class="nx">to</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">2</span><span class="p">x</span><span class="mi">3</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.pad'</span></em><a class="headerlink" href="#mlir.dialects.tensor.PadOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp._ODS_OPERAND_SEGMENTS">
<span class="sig-name descname"><span class="pre">_ODS_OPERAND_SEGMENTS</span></span><a class="headerlink" href="#mlir.dialects.tensor.PadOp._ODS_OPERAND_SEGMENTS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(1,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.PadOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.PadOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp.low">
<span class="sig-name descname"><span class="pre">low</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.PadOp.low" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp.high">
<span class="sig-name descname"><span class="pre">high</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.PadOp.high" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp.static_low">
<span class="sig-name descname"><span class="pre">static_low</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.PadOp.static_low" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp.static_high">
<span class="sig-name descname"><span class="pre">static_high</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.PadOp.static_high" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp.nofold">
<span class="sig-name descname"><span class="pre">nofold</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.PadOp.nofold" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.PadOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.PadOp.region">
<span class="sig-name descname"><span class="pre">region</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.PadOp.region" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.pad">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">low</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">high</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_low</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_high</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nofold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.pad" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">ParallelInsertSliceOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_strides</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">parallel_insert_slice</span></code> yields a subset tensor value to its parent
InParallelOpInterface. These subset tensor values are aggregated to
in some unspecified order into a full tensor value returned by the parent
parallel iterating op.
The <code class="docutils literal notranslate"><span class="pre">parallel_insert_slice</span></code> is one such op allowed in the
InParallelOpInterface op.</p>
<p>Conflicting writes result in undefined semantics, in that the indices written
to by multiple parallel updates might contain data from any of the updates,
or even a malformed bit pattern.</p>
<p>If an index is updated exactly once, the value contained at that index
in the resulting tensor will be equal to the value at a corresponding index
of a slice that was used for the updated. If an index is not updated at all,
its value will be equal to the one in the original tensor.</p>
<p>This op does not create a new value, which allows maintaining a clean
separation between the subset and full tensor.</p>
<p>Note that we cannot mark this operation as pure (Pures), even
though it has no side effects, because it will get DCEd during
canonicalization.</p>
<p>The parallel_insert_slice operation supports the following arguments:</p>
<ul class="simple">
<li><p>source: the tensor that is inserted.</p></li>
<li><p>dest: the tensor into which the source tensor is inserted.</p></li>
<li><p>offsets: tensor-rank number of offsets into the <code class="docutils literal notranslate"><span class="pre">dest</span></code> tensor into which</p></li>
</ul>
<p>the slice is inserted.
* sizes: tensor-rank number of sizes which specify the sizes of the source
tensor type.
* strides: tensor-rank number of strides that specify subsampling in each
dimension.</p>
<p>The representation based on offsets, sizes and strides support a
partially-static specification via attributes specified through the
<code class="docutils literal notranslate"><span class="pre">static_offsets</span></code>, <code class="docutils literal notranslate"><span class="pre">static_sizes</span></code> and <code class="docutils literal notranslate"><span class="pre">static_strides</span></code> arguments. A special
sentinel value ShapedType::kDynamic encodes that the corresponding entry has
a dynamic value.</p>
<p>After buffer allocation, the “parallel_insert_slice” op is expected to lower
into a memref.subview op.</p>
<p>A parallel_insert_slice operation may additionally specify insertion into a
tensor of higher rank than the source tensor, along dimensions that are
statically known to be of size 1.
This rank-altering behavior is not required by the op semantics: this
flexibility allows to progressively drop unit dimensions while lowering
between different flavors of ops on that operate on tensors.
The rank-altering behavior of tensor.parallel_insert_slice matches the
rank-reducing behavior of tensor.insert_slice and tensor.extract_slice.</p>
<section id="id1">
<h3>Verification in the rank-reduced case<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<p>The same verification discussion and mechanisms apply as for ExtractSliceOp.
Unlike ExtractSliceOp however, there is no need for a specific inference.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.parallel_insert_slice'</span></em><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp._ODS_OPERAND_SEGMENTS">
<span class="sig-name descname"><span class="pre">_ODS_OPERAND_SEGMENTS</span></span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp._ODS_OPERAND_SEGMENTS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp.dest">
<span class="sig-name descname"><span class="pre">dest</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp.dest" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp.offsets">
<span class="sig-name descname"><span class="pre">offsets</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp.offsets" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp.sizes">
<span class="sig-name descname"><span class="pre">sizes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp.sizes" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp.strides">
<span class="sig-name descname"><span class="pre">strides</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp.strides" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp.static_offsets">
<span class="sig-name descname"><span class="pre">static_offsets</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp.static_offsets" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp.static_sizes">
<span class="sig-name descname"><span class="pre">static_sizes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp.static_sizes" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ParallelInsertSliceOp.static_strides">
<span class="sig-name descname"><span class="pre">static_strides</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ParallelInsertSliceOp.static_strides" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.parallel_insert_slice">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">parallel_insert_slice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_offsets</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_strides</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp" title="mlir.dialects.tensor.ParallelInsertSliceOp"><span class="pre">ParallelInsertSliceOp</span></a></span></span><a class="headerlink" href="#mlir.dialects.tensor.parallel_insert_slice" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.RankOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">RankOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.RankOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">tensor.rank</span></code> operation takes a tensor operand and returns its rank.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%0</span> <span class="o">=</span> <span class="nb">tensor.rank</span><span class="err"> </span><span class="nv">%arg0</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="o">*</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
<span class="nv">%1</span> <span class="o">=</span> <span class="nb">tensor.rank</span><span class="err"> </span><span class="nv">%arg1</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.RankOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.rank'</span></em><a class="headerlink" href="#mlir.dialects.tensor.RankOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.RankOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.RankOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.RankOp.tensor">
<span class="sig-name descname"><span class="pre">tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.RankOp.tensor" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.rank">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">rank</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.rank" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ReshapeOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">ReshapeOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.ReshapeOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">reshape</span></code> operation converts a tensor from one type to an equivalent
type with a provided shape. The source and destination types are compatible
if both have the same element type, same number of elements. The following
combinations are possible:</p>
<p>a. Source type is ranked or unranked. Shape argument has static size.
Result type is ranked.</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Reshape statically-shaped tensor.</span>
<span class="nv">%dst</span> <span class="o">=</span> <span class="nb">tensor.reshape</span><span class="err"> </span><span class="nv">%src</span><span class="p">(</span><span class="nv">%shape</span><span class="p">)</span>
<span class="err">         </span><span class="p">:</span><span class="err"> </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
<span class="nv">%dst0</span> <span class="o">=</span> <span class="nb">tensor.reshape</span><span class="err"> </span><span class="nv">%src</span><span class="p">(</span><span class="nv">%shape0</span><span class="p">)</span>
<span class="err">         </span><span class="p">:</span><span class="err"> </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">2</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">2</span><span class="p">x</span><span class="mi">2</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
<span class="c1">// Flatten unranked tensor.</span>
<span class="nv">%dst</span> <span class="o">=</span> <span class="nb">tensor.reshape</span><span class="err"> </span><span class="nv">%src</span><span class="p">(</span><span class="nv">%shape</span><span class="p">)</span>
<span class="err">         </span><span class="p">:</span><span class="err"> </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="o">*</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>b. Source type is ranked or unranked. Shape argument has dynamic size.
Result type is unranked.</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Reshape dynamically-shaped 1D tensor.</span>
<span class="nv">%dst</span> <span class="o">=</span> <span class="nb">tensor.reshape</span><span class="err"> </span><span class="nv">%src</span><span class="p">(</span><span class="nv">%shape</span><span class="p">)</span>
<span class="err">         </span><span class="p">:</span><span class="err"> </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="o">*</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
<span class="c1">// Reshape unranked tensor.</span>
<span class="nv">%dst</span> <span class="o">=</span> <span class="nb">tensor.reshape</span><span class="err"> </span><span class="nv">%src</span><span class="p">(</span><span class="nv">%shape</span><span class="p">)</span>
<span class="err">         </span><span class="p">:</span><span class="err"> </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="o">*</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">i32</span><span class="p">&gt;)</span><span class="err"> </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="o">*</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ReshapeOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.reshape'</span></em><a class="headerlink" href="#mlir.dialects.tensor.ReshapeOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ReshapeOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.ReshapeOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ReshapeOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ReshapeOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ReshapeOp.shape">
<span class="sig-name descname"><span class="pre">shape</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ReshapeOp.shape" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ReshapeOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ReshapeOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.reshape">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">reshape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.reshape" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ScatterOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">ScatterOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scatter_dims</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.ScatterOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">scatter</span></code> operation inserts a <code class="docutils literal notranslate"><span class="pre">source</span></code> tensor into a <code class="docutils literal notranslate"><span class="pre">dest</span></code> tensor at
the given indices.</p>
<p>In its most general form, the tensor of indices specifies all the coordinates
of every element to insert (i.e. COO format, without the payload).
The indices are expected to be confined to coordinate values that fit the
range of the <code class="docutils literal notranslate"><span class="pre">dest</span></code> tensor, otherwise the behavior is undefined.</p>
<p>The leading dimensions of the index tensor must match that of the dest
tensor. The trailing dimensions of the dest tensor must match those of the
source tensor by omitting the dimensions specified in scatter_dims
(rank-reducing semantics) or setting them to <code class="docutils literal notranslate"><span class="pre">1</span></code> (rank-preserving semantics)
(see examples).
This convention allows an idiomatic specification and lowering of
“scattering multiple N-D slices into the dest tensor”.
The result type must match the type of the dest tensor.</p>
<p>Note: in the examples below, we separate out the indexing part of the tensor
type by a whitespace for readability purposes.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// For each 1x2 triple of coordinates in %indices, insert the</span>
<span class="c1">// element (i.e. 0-D subset) at the coordinates triple in %dest.</span>
<span class="c1">//</span>
<span class="nv">%out</span> <span class="o">=</span> <span class="nb">tensor.scatter</span><span class="err"> </span><span class="nv">%source</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="nv">%dest</span><span class="p">[</span><span class="nv">%indices</span><span class="p">]</span>
    <span class="nb">scatter_dims</span><span class="p">([</span><span class="mf">0</span><span class="p">,</span><span class="err"> </span><span class="mf">1</span><span class="p">,</span><span class="err"> </span><span class="mf">2</span><span class="p">])</span><span class="err"> </span><span class="nx">unique</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="mi">2</span><span class="p">x</span><span class="err"> </span><span class="mi">1</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">1</span><span class="p">x</span><span class="mi">2</span><span class="p">x</span><span class="err"> </span><span class="mi">3</span><span class="p">x</span><span class="kt">index</span><span class="p">&gt;)</span>
<span class="err">    </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>

<span class="c1">// Note: source type may be further rank-reduced to tensor&lt;1x2x f32&gt;.</span>
</pre></div>
</div>
<p>A slice variant is provided to allow specifying insertion of whole tensor
slices into the <code class="docutils literal notranslate"><span class="pre">dest</span></code> tensor.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// For each 3 singleton of coordinates in %indices, insert the 2-D</span>
<span class="c1">// slice into %dest[*, %indices[...]:%indices[...] + 1, *] with the</span>
<span class="c1">// indices corresponding to the scatter_dims attribute specified by</span>
<span class="c1">// %indices.</span>
<span class="c1">//</span>
<span class="nv">%out</span> <span class="o">=</span> <span class="nb">tensor.scatter</span><span class="err"> </span><span class="nv">%source</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="nv">%dest</span><span class="p">[</span><span class="nv">%indices</span><span class="p">]</span><span class="err"> </span><span class="nx">scatter_dims</span><span class="p">([</span><span class="mf">1</span><span class="p">])</span><span class="err"> </span><span class="nx">unique</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="p">(</span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="err"> </span><span class="mi">4</span><span class="p">x</span><span class="mi">1</span><span class="p">x</span><span class="mi">6</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">5</span><span class="p">x</span><span class="mi">6</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="err"> </span><span class="mi">1</span><span class="p">x</span><span class="kt">index</span><span class="p">&gt;)</span>
<span class="err">    </span><span class="o">-&gt;</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="mi">5</span><span class="p">x</span><span class="mi">6</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>The dimensions specified in the scatter_dims attribute are ones for which the
source tensor has size <code class="docutils literal notranslate"><span class="pre">1</span></code>.
I.e. if the dest type is <code class="docutils literal notranslate"><span class="pre">axbxcxd</span></code> and the coordinates are [1, 3], then
the source type suffix is <code class="docutils literal notranslate"><span class="pre">ax1xcx1</span></code>.
Scatter also allows rank-reducing semantics where the shape <code class="docutils literal notranslate"><span class="pre">ax1xcx1</span></code> can be
further simplified to <code class="docutils literal notranslate"><span class="pre">axc</span></code>.</p>
<p>The elemental type of the indices tensor can be any integer type.
In the absence of target-specific or problem specific information the default
type one should use is <code class="docutils literal notranslate"><span class="pre">index</span></code>.</p>
<p>This operation does not support unranked tensors.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">unique</span></code> unit attribute must be be specified to indicate that the
coordinates are statically guaranteed to be unique at runtime. If coordinates
are not truly unique at runtime, the behavior is undefined.</p>
<p>Only full slices are meant to be supported by this op, if one desires
partial slices (e.g. strided windows) one should compose this op with other
tensor ops (e.g. tensor.insert_slice). This is to avoid a slippery slope of
complexity that would make the op unusable in practice.</p>
<p>At the tensor-level, the index tensor is specified in an AoS form (i.e.
coordinate tuple is the most minor). It is the responsibility of further
lowerings and bufferization to implement various concrete layouts.</p>
<p>Note: As currently specified, the operation must lower to an abstraction that
performs copies to the output tensor. This is because the buffer type system
is currently not rich enough to allow multiple non-contiguous views in the
same type. This is visible more clearly in a notional buffer version of the
op:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// memref&lt;?x 4xf32&gt; is a contiguous buffer of ?x4 elements, scatter into</span>
<span class="c1">// random dest slices must copy to the contiguous dest.</span>
<span class="c1">//</span>
<span class="nb">some_side_effecting_op_writing_into</span><span class="err"> </span><span class="nv">%source</span><span class="p">,</span><span class="err"> </span><span class="p">...:</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="err"> </span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
<span class="nb">memref.scatter</span><span class="err"> </span><span class="nv">%source</span><span class="err"> </span><span class="nx">into</span><span class="err"> </span><span class="nv">%dest</span><span class="p">[</span><span class="nv">%indices</span><span class="p">]</span><span class="err"> </span><span class="nx">scatter_dims</span><span class="p">([</span><span class="mf">1</span><span class="p">])</span><span class="err"> </span><span class="nx">unique</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="p">(</span><span class="kt">memref</span><span class="p">&lt;</span><span class="mi">3</span><span class="p">x</span><span class="err"> </span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="err"> </span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;,</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="err"> </span><span class="mi">1</span><span class="p">x</span><span class="kt">index</span><span class="p">&gt;)</span>

<span class="c1">// Nested buffer support in the producing op would allow writing directly</span>
<span class="c1">// into the dest buffer.</span>
<span class="nv">%v</span> <span class="o">=</span> <span class="nb">some_nested_buffer_view_op</span><span class="err"> </span><span class="nv">%dest</span><span class="p">[</span><span class="nv">%indices</span><span class="p">]</span><span class="err"> </span><span class="nx">scatter_dims</span><span class="p">([</span><span class="mf">1</span><span class="p">])</span><span class="err"> </span><span class="nx">unique</span><span class="err"> </span><span class="p">:</span>
<span class="err">  </span><span class="kt">memref</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="err"> </span><span class="p">x</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;&gt;</span>
<span class="nb">some_side_effecting_op_writing_into</span><span class="err"> </span><span class="nv">%v</span><span class="p">,</span><span class="err"> </span><span class="p">...:</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="err"> </span><span class="p">x</span><span class="err"> </span><span class="kt">memref</span><span class="p">&lt;</span><span class="mi">4</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ScatterOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.scatter'</span></em><a class="headerlink" href="#mlir.dialects.tensor.ScatterOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ScatterOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.ScatterOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ScatterOp.source">
<span class="sig-name descname"><span class="pre">source</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ScatterOp.source" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ScatterOp.dest">
<span class="sig-name descname"><span class="pre">dest</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ScatterOp.dest" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ScatterOp.indices">
<span class="sig-name descname"><span class="pre">indices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ScatterOp.indices" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ScatterOp.scatter_dims">
<span class="sig-name descname"><span class="pre">scatter_dims</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ScatterOp.scatter_dims" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ScatterOp.unique">
<span class="sig-name descname"><span class="pre">unique</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ScatterOp.unique" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.ScatterOp.result">
<span class="sig-name descname"><span class="pre">result</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.ScatterOp.result" title="Link to this definition">¶</a></dt>
<dd><p>Shortcut to get an op result if it has only one (throws an error otherwise).</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.scatter">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">scatter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">result</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dest</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scatter_dims</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unique</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.scatter" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.SplatOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">SplatOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggregate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamicSizes</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.SplatOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>Broadcast the operand to all elements of the result tensor.</p>
<p>An additional argument of type <code class="docutils literal notranslate"><span class="pre">index</span></code> must be provided for each dynamic
dimension present in the result type.</p>
<p>Example for a statically shaped tensor:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="nv">%s</span> <span class="o">=</span> <span class="nb">arith.constant</span><span class="err"> </span><span class="mf">1.0</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">f32</span>
<span class="nv">%t</span> <span class="o">=</span> <span class="nb">tensor.splat</span><span class="err"> </span><span class="nv">%s</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="mi">8</span><span class="p">x</span><span class="mi">16</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<p>Example for a tensor containing dynamic dimensions:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span><span class="c1">// Broadcasts %s to a 3D dynamically shaped tensor, with %m and %n binding</span>
<span class="c1">// to dimensions 0 and 2 of the resulting tensor, respectively.</span>
<span class="nv">%m</span> <span class="o">=</span> <span class="nb">arith.constant</span><span class="err"> </span><span class="mf">10</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">index</span>
<span class="nv">%n</span> <span class="o">=</span> <span class="nb">arith.constant</span><span class="err"> </span><span class="mf">30</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">index</span>
<span class="nv">%t</span> <span class="o">=</span> <span class="nb">tensor.splat</span><span class="err"> </span><span class="nv">%s</span><span class="p">[</span><span class="nv">%m</span><span class="p">,</span><span class="err"> </span><span class="nv">%n</span><span class="p">]</span><span class="err"> </span><span class="p">:</span><span class="err"> </span><span class="kt">tensor</span><span class="p">&lt;</span><span class="n n-Integer">?</span><span class="p">x</span><span class="mi">20</span><span class="p">x</span><span class="n n-Integer">?</span><span class="p">x</span><span class="kt">f32</span><span class="p">&gt;</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.SplatOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.splat'</span></em><a class="headerlink" href="#mlir.dialects.tensor.SplatOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.SplatOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.SplatOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.SplatOp.input">
<span class="sig-name descname"><span class="pre">input</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.SplatOp.input" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.SplatOp.dynamicSizes">
<span class="sig-name descname"><span class="pre">dynamicSizes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.SplatOp.dynamicSizes" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.SplatOp.aggregate">
<span class="sig-name descname"><span class="pre">aggregate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span><span class="p"><span class="pre">[</span></span><span class="pre">_ods_ir</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#mlir.dialects.tensor.SplatOp.aggregate" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.splat">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">splat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">aggregate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic_sizes</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.splat" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mlir.dialects.tensor.YieldOp">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">YieldOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.YieldOp" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">_ods_ir</span></code></p>
<p>This operation is used to yield a single value from a within a region. It
is used to create dynamically sized tensors
(see <code class="docutils literal notranslate"><span class="pre">tensor.generate</span></code> and <code class="docutils literal notranslate"><span class="pre">tensor.pad</span></code> ops).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.YieldOp.OPERATION_NAME">
<span class="sig-name descname"><span class="pre">OPERATION_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'tensor.yield'</span></em><a class="headerlink" href="#mlir.dialects.tensor.YieldOp.OPERATION_NAME" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mlir.dialects.tensor.YieldOp._ODS_REGIONS">
<span class="sig-name descname"><span class="pre">_ODS_REGIONS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">(0,</span> <span class="pre">True)</span></em><a class="headerlink" href="#mlir.dialects.tensor.YieldOp._ODS_REGIONS" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mlir.dialects.tensor.YieldOp.value">
<span class="sig-name descname"><span class="pre">value</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">_ods_ir</span></span></span><a class="headerlink" href="#mlir.dialects.tensor.YieldOp.value" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.yield_">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">yield_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#mlir.dialects.tensor.YieldOp" title="mlir.dialects.tensor.YieldOp"><span class="pre">YieldOp</span></a></span></span><a class="headerlink" href="#mlir.dialects.tensor.yield_" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mlir.dialects.tensor.region_op">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">region_op</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">op_constructor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">terminator</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#mlir.dialects.tensor.region_op" title="Link to this definition">¶</a></dt>
<dd><p>Decorator to define an MLIR Op specified as a python function.</p>
<p>Requires that an <code class="docutils literal notranslate"><span class="pre">mlir.ir.InsertionPoint</span></code> and <code class="docutils literal notranslate"><span class="pre">mlir.ir.Location</span></code> are
active for the current thread (i.e. established in a <code class="docutils literal notranslate"><span class="pre">with</span></code> block).</p>
<p>Supports “naked” usage i.e., no parens if no args need to be passed to the Op constructor.</p>
<p>When applied as a decorator to a Python function, an entry block will
be constructed for the Op with types as specified <strong>as type hints on the args of the function</strong>.
The block arguments will be passed positionally to the Python function.</p>
<p>If a terminator is specified then the return from the decorated function will be passed
to the terminator as the last statement in the entry block. Note, the API for the terminator
is a (possibly empty) list; terminator accepting single values should be wrapped in a
<code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">args:</span> <span class="pre">term(args[0])</span></code></p>
<p>The identifier (name) of the function will become:</p>
<ol class="arabic simple">
<li><p>A single value result if the Op returns a single value;</p></li>
<li><p>An OpResultList (as a list) if the Op returns multiple values;</p></li>
<li><p>The Operation if the Op returns no results.</p></li>
</ol>
<p>See examples in tensor.py and transform.extras.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="id0">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">EmptyOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sizes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../../_mlir_libs/_mlir/ir/index.html#mlir._mlir_libs._mlir.ir.Value" title="mlir._mlir_libs._mlir.ir.Value"><span class="pre">Value</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">element_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../_mlir_libs/_mlir/ir/index.html#mlir._mlir_libs._mlir.ir.Type" title="mlir._mlir_libs._mlir.ir.Type"><span class="pre">Type</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../_mlir_libs/_mlir/ir/index.html#mlir._mlir_libs._mlir.ir.Attribute" title="mlir._mlir_libs._mlir.ir.Attribute"><span class="pre">Attribute</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id0" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#id0" title="mlir.dialects.tensor.EmptyOp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EmptyOp</span></code></a></p>
<p>Extends the tensor.empty op.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="id2">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sizes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="../../_mlir_libs/_mlir/ir/index.html#mlir._mlir_libs._mlir.ir.Value" title="mlir._mlir_libs._mlir.ir.Value"><span class="pre">Value</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">element_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../_mlir_libs/_mlir/ir/index.html#mlir._mlir_libs._mlir.ir.Type" title="mlir._mlir_libs._mlir.ir.Type"><span class="pre">Type</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="../../_mlir_libs/_mlir/ir/index.html#mlir._mlir_libs._mlir.ir.Attribute" title="mlir._mlir_libs._mlir.ir.Attribute"><span class="pre">Attribute</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">mlir.dialects._ods_common._cext.ir.Value</span></span></span><a class="headerlink" href="#id2" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py data">
<dt class="sig sig-object py" id="id3">
<span class="sig-prename descclassname"><span class="pre">mlir.dialects.tensor.</span></span><span class="sig-name descname"><span class="pre">generate</span></span><a class="headerlink" href="#id3" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../tosa/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">mlir.dialects.tosa</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../spirv/index.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">mlir.dialects.spirv</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, MLIR authors
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">mlir.dialects.tensor</a><ul>
<li><a class="reference internal" href="#attributes">Attributes</a></li>
<li><a class="reference internal" href="#classes">Classes</a></li>
<li><a class="reference internal" href="#functions">Functions</a></li>
<li><a class="reference internal" href="#module-contents">Module Contents</a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.BitcastOp"><code class="docutils literal notranslate"><span class="pre">BitcastOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.BitcastOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">BitcastOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.BitcastOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">BitcastOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.BitcastOp.source"><code class="docutils literal notranslate"><span class="pre">BitcastOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.BitcastOp.dest"><code class="docutils literal notranslate"><span class="pre">BitcastOp.dest()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.bitcast"><code class="docutils literal notranslate"><span class="pre">bitcast()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.CastOp"><code class="docutils literal notranslate"><span class="pre">CastOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.CastOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">CastOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.CastOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">CastOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.CastOp.source"><code class="docutils literal notranslate"><span class="pre">CastOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.CastOp.dest"><code class="docutils literal notranslate"><span class="pre">CastOp.dest()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.cast"><code class="docutils literal notranslate"><span class="pre">cast()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.CollapseShapeOp"><code class="docutils literal notranslate"><span class="pre">CollapseShapeOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.CollapseShapeOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">CollapseShapeOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.CollapseShapeOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">CollapseShapeOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.CollapseShapeOp.src"><code class="docutils literal notranslate"><span class="pre">CollapseShapeOp.src()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.CollapseShapeOp.reassociation"><code class="docutils literal notranslate"><span class="pre">CollapseShapeOp.reassociation()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.CollapseShapeOp.result"><code class="docutils literal notranslate"><span class="pre">CollapseShapeOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.collapse_shape"><code class="docutils literal notranslate"><span class="pre">collapse_shape()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ConcatOp"><code class="docutils literal notranslate"><span class="pre">ConcatOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.ConcatOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">ConcatOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ConcatOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">ConcatOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ConcatOp.inputs"><code class="docutils literal notranslate"><span class="pre">ConcatOp.inputs()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ConcatOp.dim"><code class="docutils literal notranslate"><span class="pre">ConcatOp.dim()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ConcatOp.result"><code class="docutils literal notranslate"><span class="pre">ConcatOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.concat"><code class="docutils literal notranslate"><span class="pre">concat()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.DimOp"><code class="docutils literal notranslate"><span class="pre">DimOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.DimOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">DimOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.DimOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">DimOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.DimOp.source"><code class="docutils literal notranslate"><span class="pre">DimOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.DimOp.index"><code class="docutils literal notranslate"><span class="pre">DimOp.index()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.DimOp.result"><code class="docutils literal notranslate"><span class="pre">DimOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.dim"><code class="docutils literal notranslate"><span class="pre">dim()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.EmptyOp"><code class="docutils literal notranslate"><span class="pre">EmptyOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.EmptyOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">EmptyOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.EmptyOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">EmptyOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.EmptyOp.dynamicSizes"><code class="docutils literal notranslate"><span class="pre">EmptyOp.dynamicSizes()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.EmptyOp.result"><code class="docutils literal notranslate"><span class="pre">EmptyOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.empty"><code class="docutils literal notranslate"><span class="pre">empty()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExpandShapeOp"><code class="docutils literal notranslate"><span class="pre">ExpandShapeOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExpandShapeOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">ExpandShapeOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExpandShapeOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">ExpandShapeOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExpandShapeOp.src"><code class="docutils literal notranslate"><span class="pre">ExpandShapeOp.src()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExpandShapeOp.output_shape"><code class="docutils literal notranslate"><span class="pre">ExpandShapeOp.output_shape()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExpandShapeOp.reassociation"><code class="docutils literal notranslate"><span class="pre">ExpandShapeOp.reassociation()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExpandShapeOp.static_output_shape"><code class="docutils literal notranslate"><span class="pre">ExpandShapeOp.static_output_shape()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExpandShapeOp.result"><code class="docutils literal notranslate"><span class="pre">ExpandShapeOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.expand_shape"><code class="docutils literal notranslate"><span class="pre">expand_shape()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractOp"><code class="docutils literal notranslate"><span class="pre">ExtractOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">ExtractOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">ExtractOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractOp.tensor"><code class="docutils literal notranslate"><span class="pre">ExtractOp.tensor()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractOp.indices"><code class="docutils literal notranslate"><span class="pre">ExtractOp.indices()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractOp.result"><code class="docutils literal notranslate"><span class="pre">ExtractOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.extract"><code class="docutils literal notranslate"><span class="pre">extract()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp._ODS_OPERAND_SEGMENTS"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp._ODS_OPERAND_SEGMENTS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp.source"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp.offsets"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp.offsets()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp.sizes"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp.sizes()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp.strides"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp.strides()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp.static_offsets"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp.static_offsets()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp.static_sizes"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp.static_sizes()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp.static_strides"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp.static_strides()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ExtractSliceOp.result"><code class="docutils literal notranslate"><span class="pre">ExtractSliceOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.extract_slice"><code class="docutils literal notranslate"><span class="pre">extract_slice()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.FromElementsOp"><code class="docutils literal notranslate"><span class="pre">FromElementsOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.FromElementsOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">FromElementsOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.FromElementsOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">FromElementsOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.FromElementsOp.elements"><code class="docutils literal notranslate"><span class="pre">FromElementsOp.elements()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.FromElementsOp.result"><code class="docutils literal notranslate"><span class="pre">FromElementsOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.from_elements"><code class="docutils literal notranslate"><span class="pre">from_elements()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GatherOp"><code class="docutils literal notranslate"><span class="pre">GatherOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.GatherOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">GatherOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GatherOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">GatherOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GatherOp.source"><code class="docutils literal notranslate"><span class="pre">GatherOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GatherOp.indices"><code class="docutils literal notranslate"><span class="pre">GatherOp.indices()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GatherOp.gather_dims"><code class="docutils literal notranslate"><span class="pre">GatherOp.gather_dims()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GatherOp.unique"><code class="docutils literal notranslate"><span class="pre">GatherOp.unique()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GatherOp.result"><code class="docutils literal notranslate"><span class="pre">GatherOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.gather"><code class="docutils literal notranslate"><span class="pre">gather()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GenerateOp"><code class="docutils literal notranslate"><span class="pre">GenerateOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.GenerateOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">GenerateOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GenerateOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">GenerateOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GenerateOp.dynamicExtents"><code class="docutils literal notranslate"><span class="pre">GenerateOp.dynamicExtents()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GenerateOp.result"><code class="docutils literal notranslate"><span class="pre">GenerateOp.result()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.GenerateOp.body"><code class="docutils literal notranslate"><span class="pre">GenerateOp.body()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.generate"><code class="docutils literal notranslate"><span class="pre">generate()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertOp"><code class="docutils literal notranslate"><span class="pre">InsertOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">InsertOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">InsertOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertOp.scalar"><code class="docutils literal notranslate"><span class="pre">InsertOp.scalar()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertOp.dest"><code class="docutils literal notranslate"><span class="pre">InsertOp.dest()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertOp.indices"><code class="docutils literal notranslate"><span class="pre">InsertOp.indices()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertOp.result"><code class="docutils literal notranslate"><span class="pre">InsertOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.insert"><code class="docutils literal notranslate"><span class="pre">insert()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp._ODS_OPERAND_SEGMENTS"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp._ODS_OPERAND_SEGMENTS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.source"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.dest"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.dest()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.offsets"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.offsets()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.sizes"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.sizes()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.strides"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.strides()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.static_offsets"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.static_offsets()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.static_sizes"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.static_sizes()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.static_strides"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.static_strides()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.InsertSliceOp.result"><code class="docutils literal notranslate"><span class="pre">InsertSliceOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.insert_slice"><code class="docutils literal notranslate"><span class="pre">insert_slice()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp"><code class="docutils literal notranslate"><span class="pre">PadOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">PadOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp._ODS_OPERAND_SEGMENTS"><code class="docutils literal notranslate"><span class="pre">PadOp._ODS_OPERAND_SEGMENTS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">PadOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp.source"><code class="docutils literal notranslate"><span class="pre">PadOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp.low"><code class="docutils literal notranslate"><span class="pre">PadOp.low()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp.high"><code class="docutils literal notranslate"><span class="pre">PadOp.high()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp.static_low"><code class="docutils literal notranslate"><span class="pre">PadOp.static_low()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp.static_high"><code class="docutils literal notranslate"><span class="pre">PadOp.static_high()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp.nofold"><code class="docutils literal notranslate"><span class="pre">PadOp.nofold()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp.result"><code class="docutils literal notranslate"><span class="pre">PadOp.result()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.PadOp.region"><code class="docutils literal notranslate"><span class="pre">PadOp.region()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.pad"><code class="docutils literal notranslate"><span class="pre">pad()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp._ODS_OPERAND_SEGMENTS"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp._ODS_OPERAND_SEGMENTS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp.source"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp.dest"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp.dest()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp.offsets"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp.offsets()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp.sizes"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp.sizes()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp.strides"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp.strides()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp.static_offsets"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp.static_offsets()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp.static_sizes"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp.static_sizes()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ParallelInsertSliceOp.static_strides"><code class="docutils literal notranslate"><span class="pre">ParallelInsertSliceOp.static_strides()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.parallel_insert_slice"><code class="docutils literal notranslate"><span class="pre">parallel_insert_slice()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.RankOp"><code class="docutils literal notranslate"><span class="pre">RankOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.RankOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">RankOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.RankOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">RankOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.RankOp.tensor"><code class="docutils literal notranslate"><span class="pre">RankOp.tensor()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.rank"><code class="docutils literal notranslate"><span class="pre">rank()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ReshapeOp"><code class="docutils literal notranslate"><span class="pre">ReshapeOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.ReshapeOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">ReshapeOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ReshapeOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">ReshapeOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ReshapeOp.source"><code class="docutils literal notranslate"><span class="pre">ReshapeOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ReshapeOp.shape"><code class="docutils literal notranslate"><span class="pre">ReshapeOp.shape()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ReshapeOp.result"><code class="docutils literal notranslate"><span class="pre">ReshapeOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.reshape"><code class="docutils literal notranslate"><span class="pre">reshape()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp"><code class="docutils literal notranslate"><span class="pre">ScatterOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">ScatterOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">ScatterOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp.source"><code class="docutils literal notranslate"><span class="pre">ScatterOp.source()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp.dest"><code class="docutils literal notranslate"><span class="pre">ScatterOp.dest()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp.indices"><code class="docutils literal notranslate"><span class="pre">ScatterOp.indices()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp.scatter_dims"><code class="docutils literal notranslate"><span class="pre">ScatterOp.scatter_dims()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp.unique"><code class="docutils literal notranslate"><span class="pre">ScatterOp.unique()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.ScatterOp.result"><code class="docutils literal notranslate"><span class="pre">ScatterOp.result()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.scatter"><code class="docutils literal notranslate"><span class="pre">scatter()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.SplatOp"><code class="docutils literal notranslate"><span class="pre">SplatOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.SplatOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">SplatOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.SplatOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">SplatOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.SplatOp.input"><code class="docutils literal notranslate"><span class="pre">SplatOp.input()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.SplatOp.dynamicSizes"><code class="docutils literal notranslate"><span class="pre">SplatOp.dynamicSizes()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.SplatOp.aggregate"><code class="docutils literal notranslate"><span class="pre">SplatOp.aggregate()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.splat"><code class="docutils literal notranslate"><span class="pre">splat()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.YieldOp"><code class="docutils literal notranslate"><span class="pre">YieldOp</span></code></a><ul>
<li><a class="reference internal" href="#mlir.dialects.tensor.YieldOp.OPERATION_NAME"><code class="docutils literal notranslate"><span class="pre">YieldOp.OPERATION_NAME</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.YieldOp._ODS_REGIONS"><code class="docutils literal notranslate"><span class="pre">YieldOp._ODS_REGIONS</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.YieldOp.value"><code class="docutils literal notranslate"><span class="pre">YieldOp.value()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#mlir.dialects.tensor.yield_"><code class="docutils literal notranslate"><span class="pre">yield_()</span></code></a></li>
<li><a class="reference internal" href="#mlir.dialects.tensor.region_op"><code class="docutils literal notranslate"><span class="pre">region_op()</span></code></a></li>
<li><a class="reference internal" href="#id0"><code class="docutils literal notranslate"><span class="pre">EmptyOp</span></code></a></li>
<li><a class="reference internal" href="#id2"><code class="docutils literal notranslate"><span class="pre">empty()</span></code></a></li>
<li><a class="reference internal" href="#id3"><code class="docutils literal notranslate"><span class="pre">generate</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/scripts/furo.js?v=46bd48cc"></script>
    </body>
</html>