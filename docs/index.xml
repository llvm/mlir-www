<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Code Documentation on MLIR</title><link>https://mlir.llvm.org/docs/</link><description>Recent content in Code Documentation on MLIR</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 29 Nov 2019 15:26:15 +0000</lastBuildDate><atom:link href="https://mlir.llvm.org/docs/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://mlir.llvm.org/docs/OpenMPPasses/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/OpenMPPasses/</guid><description>-omp-offload-privatization-prepare Prepare OpenMP maps for privatization for deferred target tasks
When generating LLVMIR for privatized variables in an OpenMP offloading directive (eg. omp::TargetOp) that creates a deferred target task (when the nowait clause is used), we need to copy the privatized variable out of the stack of the generating task and into the heap so that the deferred target task can still access it. However, if such a privatized variable is also mapped, typically the case for allocatables, then the corresponding omp::MapInfoOp needs to be fixed up to map the new heap-allocated variable and not the original variable.</description></item><item><title/><link>https://mlir.llvm.org/docs/TargetLLVMIRTransforms/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/TargetLLVMIRTransforms/</guid><description>-llvm-target-to-data-layout Derive data layout attributes from LLVM target attributes
Derive a DataLayoutSpecInterface-implementing data layout attribute from the LLVM-backend target specified by the TargetAttrInterface-implementing attribute attached to the target op at the name llvm.target.
Options -initialize-llvm-targets : Whether to pre-load all available target machines, that LLVM is configured to support, into the TargetRegistry. -llvm-target-to-target-features Update attached #llvm.target&amp;rsquo;s features per the described target
Obtain the TargetMachine specified by the attached #llvm.target&amp;rsquo;s attributes and obtain from it the full list of features of the selected target.</description></item><item><title>Action: Tracing and Debugging MLIR-based Compilers</title><link>https://mlir.llvm.org/docs/ActionTracing/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ActionTracing/</guid><description>Overview Wrapping a Transformation in an Action Intercepting Actions MLIR-provided Handlers Debug Counters ExecutionContext See also the slides and the recording from the MLIR Open Meeting where this feature was demoed.
Overview Action are means to encapsulate any transformation of any granularity in a way that can be intercepted by the framework for debugging or tracing purposes, including skipping a transformation programmatically (think about &amp;ldquo;compiler fuel&amp;rdquo; or &amp;ldquo;debug counters&amp;rdquo; in LLVM).</description></item><item><title>Bufferization</title><link>https://mlir.llvm.org/docs/Bufferization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Bufferization/</guid><description>Overview Deprecated Passes What is One-Shot Bufferize? Goals of Bufferization Destination-Passing Style Tensor / Buffer Boundary Using One-Shot Bufferize Memory Layouts Extending One-Shot Bufferize Debugging Buffer Copies Overview Bufferization in MLIR is the process of converting ops with tensor semantics to ops with memref semantics. There are multiple MLIR passes that are related to bufferization. These passes typically run as one of the last steps in a pass pipeline, right before lowering to memref ops to LLVM.</description></item><item><title>Data Layout Modeling</title><link>https://mlir.llvm.org/docs/DataLayout/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DataLayout/</guid><description>Data layout information allows the compiler to answer questions related to how a value of a particular type is stored in memory. For example, the size of a value or its address alignment requirements. It enables, among others, the generation of various linear memory addressing schemes for containers of abstract types and deeper reasoning about vectors.
The data layout subsystem is designed to scale to MLIR&amp;rsquo;s open type and operation system.</description></item><item><title>Diagnostic Infrastructure</title><link>https://mlir.llvm.org/docs/Diagnostics/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Diagnostics/</guid><description>Source Locations Diagnostic Engine Constructing a Diagnostic Diagnostic Appending arguments Attaching notes Managing Metadata InFlight Diagnostic Diagnostic Configuration Options Print Operation On Diagnostic Print StackTrace On Diagnostic Common Diagnostic Handlers Scoped Diagnostic Handler SourceMgr Diagnostic Handler SourceMgr Diagnostic Verifier Handler Parallel Diagnostic Handler This document presents an introduction to using and interfacing with MLIR&amp;rsquo;s diagnostics infrastructure.
See MLIR specification for more information about MLIR, the structure of the IR, operations, etc.</description></item><item><title>Dialect Conversion</title><link>https://mlir.llvm.org/docs/DialectConversion/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DialectConversion/</guid><description>This document describes a framework in MLIR in which to perform operation conversions between, and within dialects. This framework allows for transforming illegal operations to those supported by a provided conversion target, via a set of pattern-based operation rewriting patterns.
The dialect conversion framework consists of the following components:
A Conversion Target A set of Rewrite Patterns A Type Converter (Optional) Modes of Conversion Conversion Target Recursive Legality Rewrite Pattern Specification Conversion Patterns Type Conversion Type Converter Region Signature Conversion Debugging Modes of Conversion When applying a conversion to a set of operations, there are several different conversion modes that may be selected from:</description></item><item><title>Interfaces</title><link>https://mlir.llvm.org/docs/Interfaces/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Interfaces/</guid><description>MLIR is a generic and extensible framework, representing different dialects with their own attributes, operations, types, and so on. MLIR Dialects can express operations with a wide variety of semantics and different levels of abstraction. The downside to this is that MLIR transformations and analyses need to be able to account for the semantics of every operation, or be overly conservative. Without care, this can result in code with special-cases for each supported operation type.</description></item><item><title>LLVM IR Target</title><link>https://mlir.llvm.org/docs/TargetLLVMIR/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/TargetLLVMIR/</guid><description>This document describes the mechanisms of producing LLVM IR from MLIR. The overall flow is two-stage:
conversion of the IR to a set of dialects translatable to LLVM IR, for example LLVM Dialect or one of the hardware-specific dialects derived from LLVM IR intrinsics such as AMX, X86Vector or ArmNeon; translation of MLIR dialects to LLVM IR. This flow allows the non-trivial transformation to be performed within MLIR using MLIR APIs and makes the translation between MLIR and LLVM IR simple and potentially bidirectional.</description></item><item><title>MLIR Bytecode Format</title><link>https://mlir.llvm.org/docs/BytecodeFormat/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/BytecodeFormat/</guid><description>This document describes the MLIR bytecode format and its encoding. This format is versioned and stable: we don&amp;rsquo;t plan to ever break compatibility, that is a dialect should be able to deserialize any older bytecode. Similarly, we support back-deployment so that an older version of the format can be targetted.
That said, it is important to realize that the promises of the bytecode format are made assuming immutable dialects: the format allows backward and forward compatibility, but only when nothing in a dialect changes (operations, types, attributes definitions).</description></item><item><title>MLIR C API</title><link>https://mlir.llvm.org/docs/CAPI/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/CAPI/</guid><description>Current status: Under development, API unstable, built by default.
Design Scope Object Model Naming Convention and Ownership Model Nullity Type Hierarchies Auxiliary Types Printing Common Patterns Indexed Components Iterable Components Extending the API Extensions for Dialect Attributes and Types Extensions for Interfaces Design Many languages can interoperate with C but have a harder time with C++ due to name mangling and memory model differences. Although the C API for MLIR can be used directly from C, it is primarily intended to be wrapped in higher-level language- or library-specific constructs.</description></item><item><title>MLIR Language Reference</title><link>https://mlir.llvm.org/docs/LangRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/LangRef/</guid><description>MLIR (Multi-Level IR) is a compiler intermediate representation with similarities to traditional three-address SSA representations (like LLVM IR or SIL), but which introduces notions from polyhedral loop optimization as first-class concepts. This hybrid design is optimized to represent, analyze, and transform high level dataflow graphs as well as target-specific code generated for high performance data parallel systems. Beyond its representational capabilities, its single continuous design provides a framework to lower from dataflow graphs to high-performance target-specific code.</description></item><item><title>MLIR Release Notes</title><link>https://mlir.llvm.org/docs/ReleaseNotes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ReleaseNotes/</guid><description>This document tries to provide some context about MLIR important changes in the context of LLVM releases. It is updated on a best effort basis.
At the moment the MLIR community does not qualify the LLVM release branch specifically, it is a snapshot of the MLIR development at the time of the release.
LLVM 20 LLVM 18 Properties: beyond attributes LLVM 17 Bytecode Properties: beyond attributes Action: Tracing and Debugging MLIR-based Compilers Transform Dialect Others LLVM 20 All the MLIR runners other than mlir-cpu-runner have been removed, as their functionality has been merged into it, and it has been renamed to mlir-runner.</description></item><item><title>Operation Canonicalization</title><link>https://mlir.llvm.org/docs/Canonicalization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Canonicalization/</guid><description>Canonicalization is an important part of compiler IR design: it makes it easier to implement reliable compiler transformations and to reason about what is better or worse in the code, and it forces interesting discussions about the goals of a particular level of IR. Dan Gohman wrote an article exploring these issues; it is worth reading if you&amp;rsquo;re not familiar with these concepts.
Most compilers have canonicalization passes, and sometimes they have many different ones (e.</description></item><item><title>Ownership-based Buffer Deallocation</title><link>https://mlir.llvm.org/docs/OwnershipBasedBufferDeallocation/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/OwnershipBasedBufferDeallocation/</guid><description>Function boundary ABI Inserting bufferization.dealloc operations Supported interfaces Limitations Example Buffer Deallocation Simplification Pass Lower Deallocations Pass Generic Lowering Specialized Lowerings One-Shot Bufferize does not deallocate any buffers that it allocates. After running One-Shot Bufferize, the resulting IR may have a number of memref.alloc ops, but no memref.dealloc ops. Buffer dellocation is delegated to the -ownership-based-buffer-deallocation pass.
On a high level, buffers are &amp;ldquo;owned&amp;rdquo; by a basic block. Ownership materializes as an i1 SSA value and can be thought of as &amp;ldquo;responsibility to deallocate&amp;rdquo;.</description></item><item><title>Pass Infrastructure</title><link>https://mlir.llvm.org/docs/PassManagement/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PassManagement/</guid><description>Operation Pass Op-Agnostic Operation Passes Filtered Operation Pass Operation Pass: Static Schedule Filtering Dependent Dialects Initialization Analysis Management Querying Analyses Preserving Analyses Pass Failure Pass Manager OpPassManager Dynamic Pass Pipelines Instance Specific Pass Options Pass Statistics Pass Registration Pass Pipeline Registration Textual Pass Pipeline Specification Declarative Pass Specification Tablegen Specification Pass Instrumentation Standard Instrumentations Crash and Failure Reproduction Local Reproducer Generation Passes represent the basic infrastructure for transformation and optimization.</description></item><item><title>Passes</title><link>https://mlir.llvm.org/docs/Passes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Passes/</guid><description>This document describes the available MLIR passes and their contracts.
General Transformation Passes -bubble-down-memory-space-casts -canonicalize -composite-fixed-point-pass -control-flow-sink -cse -generate-runtime-verification -inline -loop-invariant-code-motion -loop-invariant-subset-hoisting -mem2reg -print-ir -print-op-stats -remove-dead-values -sccp -snapshot-op-locations -sroa -strip-debuginfo -symbol-dce -symbol-privatize -topological-sort -view-op-graph Bufferization Passes -buffer-deallocation-simplification -buffer-hoisting -buffer-loop-hoisting -buffer-results-to-out-params -bufferization-lower-deallocations -drop-equivalent-buffer-results -eliminate-empty-tensors -empty-tensor-to-alloc-tensor -one-shot-bufferize -optimize-allocation-liveness -ownership-based-buffer-deallocation -promote-buffers-to-stack Conversion Passes -arm-neon-2d-to-intr -convert-affine-for-to-gpu -convert-amdgpu-to-rocdl -convert-arith-to-amdgpu -convert-arith-to-apfloat -convert-arith-to-arm-sme -convert-arith-to-emitc -convert-arith-to-llvm -convert-arith-to-spirv -convert-arm-sme-to-llvm -convert-arm-sme-to-scf -convert-async-to-llvm -convert-bufferization-to-memref -convert-cf-to-llvm -convert-cf-to-spirv -convert-complex-to-libm -convert-complex-to-llvm -convert-complex-to-rocdl-library-calls -convert-complex-to-spirv -convert-complex-to-standard -convert-func-to-emitc -convert-func-to-llvm -convert-func-to-spirv -convert-gpu-to-llvm-spv -convert-gpu-to-nvvm -convert-gpu-to-rocdl -convert-gpu-to-spirv -convert-index-to-llvm -convert-index-to-spirv -convert-linalg-to-std -convert-math-to-emitc -convert-math-to-funcs -convert-math-to-libm -convert-math-to-llvm -convert-math-to-rocdl -convert-math-to-spirv -convert-math-to-xevm -convert-memref-to-emitc -convert-memref-to-spirv -convert-nvgpu-to-nvvm -convert-nvvm-to-llvm -convert-openacc-to-scf -convert-openmp-to-llvm -convert-parallel-loops-to-gpu -convert-pdl-to-pdl-interp -convert-scf-to-cf -convert-scf-to-emitc -convert-scf-to-openmp -convert-scf-to-spirv -convert-shape-constraints -convert-shape-to-std -convert-shard-to-mpi -convert-spirv-to-llvm -convert-tensor-to-linalg -convert-tensor-to-spirv -convert-to-emitc -convert-to-llvm -convert-ub-to-llvm -convert-ub-to-spirv -convert-vector-to-amx -convert-vector-to-arm-sme -convert-vector-to-gpu -convert-vector-to-llvm -convert-vector-to-scf -convert-vector-to-spirv -convert-vector-to-xegpu -convert-xegpu-to-xevm -convert-xevm-to-llvm -finalize-memref-to-llvm -gpu-to-llvm -lift-cf-to-scf -lower-affine -lower-host-to-llvm -map-memref-spirv-storage-class -reconcile-unrealized-casts -set-llvm-module-datalayout -tosa-to-arith -tosa-to-linalg -tosa-to-linalg-named -tosa-to-mlprogram -tosa-to-scf -tosa-to-tensor &amp;lsquo;acc&amp;rsquo; Dialect Passes -acc-implicit-data -acc-implicit-declare -acc-implicit-routine -acc-legalize-serial -acc-loop-tiling -openacc-legalize-data-values &amp;lsquo;affine&amp;rsquo; Dialect Passes -affine-data-copy-generate -affine-expand-index-ops -affine-expand-index-ops-as-affine -affine-loop-coalescing -affine-loop-fusion -affine-loop-invariant-code-motion -affine-loop-normalize -affine-loop-tile -affine-loop-unroll -affine-loop-unroll-jam -affine-parallelize -affine-pipeline-data-transfer -affine-raise-from-memref -affine-scalrep -affine-simplify-min-max -affine-simplify-structures -affine-super-vectorize &amp;lsquo;amdgpu&amp;rsquo; Dialect Passes -amdgpu-emulate-atomics -amdgpu-fold-memrefs-ops -amdgpu-maskedload-to-load -amdgpu-resolve-strided-metadata &amp;lsquo;arith&amp;rsquo; Dialect Passes -arith-emulate-unsupported-floats -arith-emulate-wide-int -arith-expand -arith-int-range-narrowing -arith-unsigned-when-equivalent -int-range-optimizations &amp;lsquo;arm_sme&amp;rsquo; Dialect Passes -arm-sme-outer-product-fusion -arm-sme-vector-legalization -enable-arm-streaming -test-arm-sme-tile-allocation &amp;lsquo;arm_sve&amp;rsquo; Dialect Passes -arm-sve-legalize-vector-storage &amp;lsquo;async&amp;rsquo; Dialect Passes -async-func-to-async-runtime -async-parallel-for -async-runtime-policy-based-ref-counting -async-runtime-ref-counting -async-runtime-ref-counting-opt -async-to-async-runtime &amp;rsquo;emitc&amp;rsquo; Dialect Passes -form-expressions -wrap-emitc-func-in-class &amp;lsquo;func&amp;rsquo; Dialect Passes -duplicate-function-elimination &amp;lsquo;gpu&amp;rsquo; Dialect Passes -gpu-async-region -gpu-decompose-memrefs -gpu-eliminate-barriers -gpu-kernel-outlining -gpu-launch-sink-index-computations -gpu-map-parallel-loops -gpu-module-to-binary -nvvm-attach-target -rocdl-attach-target -spirv-attach-target -xevm-attach-target &amp;rsquo;linalg&amp;rsquo; Dialect Passes -convert-elementwise-to-linalg -convert-linalg-to-affine-loops -convert-linalg-to-loops -convert-linalg-to-parallel-loops -linalg-block-pack-matmul -linalg-detensorize -linalg-fold-into-elementwise -linalg-fold-unit-extent-dims -linalg-fuse-elementwise-ops -linalg-generalize-named-ops -linalg-inline-scalar-operands -linalg-morph-ops -linalg-specialize-generic-ops -simplify-depthwise-conv &amp;rsquo;llvm&amp;rsquo; Dialect Passes -ensure-debug-info-scope-on-llvm-func -llvm-add-comdats -llvm-legalize-for-export -llvm-optimize-for-nvvm-target -llvm-request-c-wrappers -llvm-use-default-visibility &amp;lsquo;math&amp;rsquo; Dialect Passes -math-expand-ops -math-extend-to-supported-types -math-sincos-fusion -math-uplift-to-fma &amp;lsquo;memref&amp;rsquo; Dialect Passes -expand-realloc -expand-strided-metadata -flatten-memref -fold-memref-alias-ops -memref-emulate-wide-int -memref-expand -normalize-memrefs -reify-result-shapes -resolve-ranked-shaped-type-result-dims -resolve-shaped-type-result-dims &amp;lsquo;shard&amp;rsquo; Dialect Passes -shard-partition -sharding-propagation &amp;lsquo;ml_program&amp;rsquo; Dialect Passes -mlprogram-pipeline-globals &amp;rsquo;nvgpu&amp;rsquo; Dialect Passes -nvgpu-optimize-shared-memory &amp;lsquo;quant&amp;rsquo; Dialect Passes -lower-quant-ops -normalize-quant-types -strip-func-quant-types Reducer Passes -opt-reduction-pass -reduction-tree &amp;lsquo;scf&amp;rsquo; Dialect Passes -scf-for-loop-canonicalization -scf-for-loop-peeling -scf-for-loop-range-folding -scf-for-loop-specialization -scf-for-to-while -scf-forall-to-for -scf-forall-to-parallel -scf-parallel-for-to-nested-fors -scf-parallel-loop-fusion -scf-parallel-loop-specialization -scf-parallel-loop-tiling -test-scf-parallel-loop-collapsing &amp;lsquo;shape&amp;rsquo; Dialect Passes -outline-shape-computation -remove-shape-constraints -shape-to-shape-lowering &amp;lsquo;sparse_tensor&amp;rsquo; Dialect Passes -lower-sparse-foreach-to-scf -lower-sparse-iteration-to-scf -lower-sparse-ops-to-foreach -pre-sparsification-rewrite -sparse-assembler -sparse-buffer-rewrite -sparse-gpu-codegen -sparse-reinterpret-map -sparse-space-collapse -sparse-storage-specifier-to-llvm -sparse-tensor-codegen -sparse-tensor-conversion -sparse-vectorization -sparsification -sparsification-and-bufferization -stage-sparse-ops &amp;lsquo;spv&amp;rsquo; Dialect Passes -decorate-spirv-composite-type-layout -spirv-canonicalize-gl -spirv-lower-abi-attrs -spirv-promote-to-replicated-constants -spirv-rewrite-inserts -spirv-unify-aliased-resource -spirv-update-vce -spirv-webgpu-prepare &amp;rsquo;tensor&amp;rsquo; Dialect Passes -fold-tensor-subset-ops &amp;rsquo;transform&amp;rsquo; Dialect Passes -transform-dialect-check-uses -transform-infer-effects -transform-interpreter -transform-preload-library &amp;lsquo;vector&amp;rsquo; Dialect Passes -lower-vector-mask -lower-vector-multi-reduction -lower-vector-to-from-elements-to-shuffle-tree TOSA Dialect Passes -tosa-arith-const-to-tosa-const -tosa-attach-target -tosa-convert-integer-type-to-signless -tosa-infer-shapes -tosa-layerwise-constant-fold -tosa-make-broadcastable -tosa-narrow-i64-to-i32 -tosa-optional-decompositions -tosa-reduce-transposes -tosa-validate XeGPU Dialect Passes -xegpu-blocking -xegpu-fold-alias-ops -xegpu-optimize-block-loads -xegpu-propagate-layout -xegpu-subgroup-distribute -xegpu-vector-linearize -xegpu-wg-to-sg-distribute General Transformation Passes -bubble-down-memory-space-casts Bubbles down memory-space cast operations.</description></item><item><title>Pattern Rewriting : Generic DAG-to-DAG Rewriting</title><link>https://mlir.llvm.org/docs/PatternRewriter/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PatternRewriter/</guid><description>Introduction Defining Patterns Benefit Root Operation Name (Optional) matchAndRewrite implementation Application Recursion Debug Names and Labels Initialization Construction Pattern Rewriter Pattern Application Common Pattern Drivers Dialect Conversion Driver Walk Pattern Rewrite Driver Greedy Pattern Rewrite Driver Debugging Pattern Filtering Common Pass Utilities This document details the design and API of the pattern rewriting infrastructure present in MLIR, a general DAG-to-DAG transformation framework. This framework is widely used throughout MLIR for canonicalization, conversion, and general transformation.</description></item><item><title>Pattern Search</title><link>https://mlir.llvm.org/docs/PatternSearch/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PatternSearch/</guid><description>Search for an operation name below (e.g., linalg.matvec) to find a list of all Pattern classes that insert, erase, or modify that operation.
The search index used here is generated by running all lit tests in MLIR with the additional flag --pattern-logging-listener, which produces a record of each rewrite operation and the names of the operations it affected.
Caveats:
Some records may be missing due to incomplete test coverage. Patterns are only indexed if they define a debugName, and while most patterns have one, they are not required to.</description></item><item><title>PDLL - PDL Language</title><link>https://mlir.llvm.org/docs/PDLL/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PDLL/</guid><description>This document details the PDL Language (PDLL), a custom frontend language for writing pattern rewrites targeting MLIR.
Note: This document assumes a familiarity with MLIR concepts; more specifically the concepts detailed within the MLIR Pattern Rewriting and Operation Definition Specification (ODS) documentation.
Introduction Rationale Why build a new language instead of improving TableGen DRR? Why not build a DSL in &amp;ldquo;X&amp;rdquo;? Language Specification Includes Patterns Variables Operation Expression Attribute Expression Type Expression Tuples Constraints Rewriters Introduction Pattern matching is an extremely important component within MLIR, as it encompasses many different facets of the compiler.</description></item><item><title>Quantization</title><link>https://mlir.llvm.org/docs/Quantization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Quantization/</guid><description>This document outlines the design of the MLIR quantization system. While the term &amp;ldquo;quantization&amp;rdquo; is highly overloaded, in this case, it refers to a fairly narrow scope of techniques in use to enable conversion of floating-point computations to corresponding and plausible variants expressed in integer math for inference, as has historically been supported by low-bit depth inference engines such as TFLite, various accelerator hardware, and many DSPs.
Much of this is inspired by the approach taken in this paper with many extensions and adaptations folded in.</description></item><item><title>Remark Infrastructure</title><link>https://mlir.llvm.org/docs/Remarks/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Remarks/</guid><description>Remarks are structured, human- and machine-readable notes emitted by the compiler to communicate:
What transformations were applied What optimizations were missed Why certain decisions were made The RemarkEngine collects remarks during compilation and routes them to a pluggable streamer. By default, MLIR integrates with LLVM&amp;rsquo;s llvm::remarks infrastructure, enabling you to:
Stream remarks as passes run Serialize to YAML or LLVM Bitstream Overview Opt-in â€“ Disabled by default; zero overhead unless enabled.</description></item><item><title>Shape Inference</title><link>https://mlir.llvm.org/docs/ShapeInference/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ShapeInference/</guid><description>Shape inference as discussed here is considered a specific instance of type inference for ShapedType. Type constraints are along (at least) three axis: 1) elemental type, 2) rank (including static or dynamic), 3) dimensions. While some operations have no compile time fixed shape (e.g., output shape is dictated by data) we could still have some knowledge of constraints/bounds in the system for that operation (e.g., the output of a tf.where is at most the size of the input data).</description></item><item><title>SPIR-V Dialect to LLVM Dialect conversion manual</title><link>https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/</guid><description>This manual describes the conversion from SPIR-V Dialect to LLVM Dialect. It assumes familiarity with both, and describes the design choices behind the modelling of SPIR-V concepts in LLVM Dialect. The conversion is an ongoing work, and is expected to grow as more features are implemented.
Conversion can be performed by invoking an appropriate conversion pass:
mlir-opt -convert-spirv-to-llvm &amp;lt;filename.mlir&amp;gt; This pass performs type and operation conversions for SPIR-V operations as described in this document.</description></item><item><title>Symbols and Symbol Tables</title><link>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</guid><description>Symbol Defining or declaring a Symbol Symbol Table Referencing a Symbol Manipulating a Symbol Symbol Visibility With Regions, the multi-level aspect of MLIR is structural in the IR. A lot of infrastructure within the compiler is built around this nesting structure; including the processing of operations within the pass manager. One advantage of the MLIR design is that it is able to process operations in parallel, utilizing multiple threads. This is possible due to a property of the IR known as IsolatedFromAbove.</description></item><item><title>Table-driven Declarative Rewrite Rule (DRR)</title><link>https://mlir.llvm.org/docs/DeclarativeRewrites/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DeclarativeRewrites/</guid><description>In addition to subclassing the mlir::RewritePattern C++ class, MLIR also supports defining rewrite rules in a declarative manner. Similar to Op Definition Specification (ODS), this is achieved via TableGen, which is a language to maintain records of domain-specific information. The rewrite rules are specified concisely in a TableGen record, which will be expanded into an equivalent mlir::RewritePattern subclass at compiler build time.
This manual explains in detail all of the available mechanisms for defining rewrite rules in such a declarative manner.</description></item></channel></rss>