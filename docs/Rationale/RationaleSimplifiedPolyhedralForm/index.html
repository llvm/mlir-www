<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>MLIR: The case for a simplified polyhedral form - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.119.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script>
<link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script>
<script src=https://mlir.llvm.org/js/bundle.js></script>
<script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li></ul></li><li><a href="https://github.com/llvm/llvm-project/issues?q=is%3Aissue%20state%3Aopen%20label%3Amlir">Bugs</a></li><li><a href=https://github.com/llvm/mlir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/MLIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>MLIR: The case for a simplified polyhedral form</h1><p>MLIR embraces polyhedral compiler techniques for their many advantages
representing and transforming dense numerical kernels, but it uses a form that
differs significantly from other polyhedral frameworks.</p><p><strong>Disclaimer / Warning</strong></p><p>This document is a very early design proposal (which has since been accepted)
that explored the tradeoffs of using this simplified form vs the traditional
polyhedral schedule list form. At some point, this document could be dusted off
and written as a proper academic paper, but until now, it is better to included
it in this crafty form than not to. Beware that this document uses archaic
syntax and should not be considered a canonical reference to modern MLIR.</p><h2 id=introduction>Introduction&nbsp;<a class=headline-hash href=#introduction>¶</a></h2><p>This document discusses general goals of the project, introduces context and the
two alternatives, then talks about the tradeoffs of these designs. Written by
Chris Lattner.</p><h2 id=general-goals-of-an-ir-and-goals-of-mlfuncs-specifically>General goals of an IR, and goals of mlfunc&rsquo;s specifically&nbsp;<a class=headline-hash href=#general-goals-of-an-ir-and-goals-of-mlfuncs-specifically>¶</a></h2><p>Our currently planned representation for MLIR consists of two kinds of
functions: an LLVM-like &ldquo;CFG Function&rdquo; and an &ldquo;ML Function&rdquo;: a function
represented in multidimensional loop form. The idea is that a CFG function is
capable of full generality for expressing arbitrary computation, but is awkward
for loop transformations. In contrast, mlfunc&rsquo;s are limited (e.g. to control
flow involving loop nests over affine spaces) but these limitations make it much
easier to transform and analyze, particularly for the set of computations in a
machine learning kernel.</p><p>The design of an intermediate representations is an optimization problem, which
makes intentional tradeoffs that aim to make certain kinds of compiler
transformations simple. After all, it is &ldquo;possible&rdquo; to do almost any
transformation on any IR: we could theoretically do loop transformations on
assembly language. OTOH, such transformations would take too long to write,
would be fragile due to irrelevant changes, would be difficult to maintain, and
difficult to make target independent. Performing transformations on the &ldquo;right
level&rdquo; of IR makes it much easier to do analysis and transformation of code, and
can make them faster by reducing the size of the IR, and eliminating
possibilities that would have otherwise have to be considered.</p><p>This is the reason we&rsquo;re interested in adding polyhedral techniques to an IR in
the first place: though our base &ldquo;CFG function&rdquo; representation is fully capable
of expressing any computation, it is &ldquo;too&rdquo; expressive. The limitations imposed
by polyhedral techniques (e.g. on affine loop bounds and array subscripts)
define a closed algebra that can represent an interesting range of
transformations and their compositions, and because of their simplicity, we can
perform (e.g.) dependence analysis more efficiently and more reliably.</p><p>This raises an important question that this document examines: given we are
introducing a redundant and limited way to express code and transformations,
exactly what form is best to perform the analyses and transformations we want?</p><p>We explore two different design points that are capable of expressing the same
class of affine loop computations, but which use different representational
forms. These forms trade off verbosity, ease of transformation, and ease of
analysis in interesting ways.</p><h2 id=context-traditional-polyhedral-form>Context: Traditional Polyhedral Form&nbsp;<a class=headline-hash href=#context-traditional-polyhedral-form>¶</a></h2><p>We started by discussing a representation that uses the traditional polyhedral
schedule set + domain representation, e.g. consider C-like code like:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl>  <span class=kt>void</span> <span class=nf>simple_example</span><span class=p>(...)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=o>++</span><span class=n>i</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>N</span><span class=p>;</span> <span class=o>++</span><span class=n>j</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>         <span class=kt>float</span> <span class=n>tmp</span> <span class=o>=</span> <span class=n>X</span><span class=p>[</span><span class=n>i</span><span class=p>,</span><span class=n>j</span><span class=p>]</span>    <span class=c1>// S1
</span></span></span><span class=line><span class=cl><span class=c1></span>         <span class=n>A</span><span class=p>[</span><span class=n>i</span><span class=p>,</span><span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span> <span class=o>+</span> <span class=mi>1</span>      <span class=c1>// S2
</span></span></span><span class=line><span class=cl><span class=c1></span>         <span class=n>B</span><span class=p>[</span><span class=n>i</span><span class=p>,</span><span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span> <span class=o>*</span> <span class=mi>42</span>     <span class=c1>// S3
</span></span></span><span class=line><span class=cl><span class=c1></span>       <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><p>The polyhedral representation doesn&rsquo;t care about the actual computation, so we
will abstract them into S1/S2/S3 in the discussion below. Originally, we planned
to represent this with a classical form like (syntax details are not important
and probably slightly incorrect below):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  mlfunc <span class=nf>@simple_example</span><span class=p>(...</span> <span class=nv>%N</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>%tmp</span> <span class=p>=</span> call <span class=nf>@S1</span><span class=p>(</span><span class=nv>%X</span><span class=p>,</span> <span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> <span class=nv>%i</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> <span class=nv>%j</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      schedule<span class=p>:</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>,</span> <span class=m>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    call <span class=nf>@S2</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> <span class=nv>%i</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> <span class=nv>%j</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      schedule<span class=p>:</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>,</span> <span class=m>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    call <span class=nf>@S3</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%B</span><span class=p>,</span> <span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> <span class=nv>%i</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> <span class=nv>%j</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      schedule<span class=p>:</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>,</span> <span class=m>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><p>In this design, an mlfunc is an unordered bag of instructions whose execution
order is fully controlled by their schedule.</p><p>However, we recently agreed that a more explicit schedule tree representation is
a better fit for our needs, because it exposes important structure that will
make analyses and optimizations more efficient, and also makes the scoping of
SSA values more explicit. This leads us to a representation along the lines of:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  mlfunc <span class=nf>@simple_example</span><span class=p>(...</span> <span class=nv>%N</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    d0<span class=err>/</span><span class=nl>d1 =</span> mlspace
</span></span><span class=line><span class=cl>    for S1<span class=p>(</span>d0<span class=p>),</span> S2<span class=p>(</span>d0<span class=p>),</span> S3<span class=p>(</span>d0<span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      for S1<span class=p>(</span>d1<span class=p>),</span> S2<span class=p>(</span>d1<span class=p>),</span> S3<span class=p>(</span>d1<span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nv>%tmp</span> <span class=p>=</span> call <span class=nf>@S1</span><span class=p>(</span><span class=nv>%X</span><span class=p>,</span> d0<span class=p>,</span> d1<span class=p>)</span>      <span class=err>;;</span> S1
</span></span><span class=line><span class=cl>          domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d0 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d1 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        call <span class=nf>@S2</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%A</span><span class=p>,</span> d0<span class=p>,</span> d1<span class=p>)</span>      <span class=err>;;</span> S2
</span></span><span class=line><span class=cl>          domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d0 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d1 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        call <span class=nf>@S3</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%B</span><span class=p>,</span> d0<span class=p>,</span> d1<span class=p>)</span>      <span class=err>;;</span> S3
</span></span><span class=line><span class=cl>          domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d0 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d1 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><p>This change makes the nesting structure of the loops an explicit part of the
representation, and makes lexical ordering within a loop significant
(eliminating the constant 0/1/2 of schedules).</p><p>It isn&rsquo;t obvious in the example above, but the representation allows for some
interesting features, including the ability for instructions within a loop nest
to have non-equal domains, like this - the second instruction ignores the outer
10 points inside the loop:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  mlfunc <span class=nf>@reduced_domain_example</span><span class=p>(...</span> <span class=nv>%N</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    d0<span class=err>/</span><span class=nl>d1 =</span> mlspace
</span></span><span class=line><span class=cl>    for S1<span class=p>(</span>d0<span class=p>),</span> S2<span class=p>(</span>d0<span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      for S1<span class=p>(</span>d1<span class=p>),</span> S2<span class=p>(</span>d1<span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nv>%tmp</span> <span class=p>=</span> call <span class=nf>@S1</span><span class=p>(</span><span class=nv>%X</span><span class=p>,</span> d0<span class=p>,</span> d1<span class=p>)</span>    <span class=err>;;</span> S1
</span></span><span class=line><span class=cl>          domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d0 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d1 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        call <span class=nf>@S2</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%A</span><span class=p>,</span> d0<span class=p>,</span> d1<span class=p>)</span>      <span class=err>;;</span> S2
</span></span><span class=line><span class=cl>          domain<span class=p>:</span> <span class=p>(</span><span class=m>10</span> <span class=p>&lt;=</span> d0 <span class=p>&lt;</span> <span class=nv>%N</span><span class=m>-10</span><span class=p>),</span> <span class=p>(</span><span class=m>10</span> <span class=p>&lt;=</span> d1 <span class=p>&lt;</span> <span class=nv>%N</span><span class=m>-10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><p>It also allows schedule remapping within the instruction, like this example that
introduces a diagonal skew through a simple change to the schedules of the two
instructions:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  mlfunc <span class=nf>@skewed_domain_example</span><span class=p>(...</span> <span class=nv>%N</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    d0<span class=err>/</span><span class=nl>d1 =</span> mlspace
</span></span><span class=line><span class=cl>    for S1<span class=p>(</span>d0<span class=p>),</span> S2<span class=p>(</span>d0<span class=err>+</span>d1<span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      for S1<span class=p>(</span>d0<span class=err>+</span>d1<span class=p>),</span> S2<span class=p>(</span>d1<span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nv>%tmp</span> <span class=p>=</span> call <span class=nf>@S1</span><span class=p>(</span><span class=nv>%X</span><span class=p>,</span> d0<span class=p>,</span> d1<span class=p>)</span>    <span class=err>;;</span> S1
</span></span><span class=line><span class=cl>          domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d0 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d1 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        call <span class=nf>@S2</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%A</span><span class=p>,</span> d0<span class=p>,</span> d1<span class=p>)</span>      <span class=err>;;</span> S2
</span></span><span class=line><span class=cl>          domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d0 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> d1 <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><p>This form has great power, and the polyhedral code generator (which lowers from
an mlfunc to a cfgfunc representation) handles this power so things that
introduce loop transformations don&rsquo;t have to explicitly manipulate the looping
structure.</p><h2 id=proposal-simplified-polyhedral-form>Proposal: Simplified Polyhedral Form&nbsp;<a class=headline-hash href=#proposal-simplified-polyhedral-form>¶</a></h2><p>This document proposes and explores the idea of going one step further, moving
all of the domain and schedule information into the &ldquo;schedule tree&rdquo;. In this
form, we would have a representation where all instructions inside of a given
for-loop are known to have the same domain, which is maintained by the loop. In
the simplified form, we also have an &ldquo;if&rdquo; instruction that takes an affine
condition.</p><p>Our simple example above would be represented as:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  mlfunc <span class=nf>@simple_example</span><span class=p>(...</span> <span class=nv>%N</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    affine<span class=p>.</span>for <span class=nv>%i</span> <span class=p>=</span> <span class=m>0</span> <span class=p>...</span> <span class=nv>%N</span> step <span class=m>1</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      affine<span class=p>.</span>for <span class=nv>%j</span> <span class=p>=</span> <span class=m>0</span> <span class=p>...</span> <span class=nv>%N</span> step <span class=m>1</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c>// identity noop in this case, but can exist in general.
</span></span></span><span class=line><span class=cl><span class=c></span>        <span class=nv>%0</span><span class=p>,</span><span class=nv>%1</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#57</span><span class=p>(</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nv>%tmp</span> <span class=p>=</span> call <span class=nf>@S1</span><span class=p>(</span><span class=nv>%X</span><span class=p>,</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        call <span class=nf>@S2</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        call <span class=nf>@S3</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%B</span><span class=p>,</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><p>The example with the reduced domain would be represented with an if instruction:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  mlfunc <span class=nf>@reduced_domain_example</span><span class=p>(...</span> <span class=nv>%N</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    affine<span class=p>.</span>for <span class=nv>%i</span> <span class=p>=</span> <span class=m>0</span> <span class=p>...</span> <span class=nv>%N</span> step <span class=m>1</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      affine<span class=p>.</span>for <span class=nv>%j</span> <span class=p>=</span> <span class=m>0</span> <span class=p>...</span> <span class=nv>%N</span> step <span class=m>1</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c>// identity noop in this case, but can exist in general.
</span></span></span><span class=line><span class=cl><span class=c></span>        <span class=nv>%0</span><span class=p>,</span><span class=nv>%1</span> <span class=p>=</span> affinecall <span class=nv>#57</span><span class=p>(</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nv>%tmp</span> <span class=p>=</span> call <span class=nf>@S1</span><span class=p>(</span><span class=nv>%X</span><span class=p>,</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        if <span class=p>(</span><span class=m>10</span> <span class=p>&lt;=</span> <span class=nv>%i</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=m>-10</span><span class=p>),</span> <span class=p>(</span><span class=m>10</span> <span class=p>&lt;=</span> <span class=nv>%j</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=m>-10</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>          <span class=nv>%2</span><span class=p>,</span><span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>apply<span class=p>(</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>)</span>    <span class=c>// identity noop in this case
</span></span></span><span class=line><span class=cl><span class=c></span>
</span></span><span class=line><span class=cl>          call <span class=nf>@S2</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%2</span><span class=p>,</span> <span class=nv>%3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><p>These IRs represent exactly the same information, and use a similar information
density. The &rsquo;traditional&rsquo; form introduces an extra level of abstraction
(schedules and domains) that make it easy to transform instructions at the
expense of making it difficult to reason about how those instructions will come
out after code generation. With the simplified form, transformations have to do
parts of code generation inline with their transformation: instead of simply
changing a schedule to <strong>(i+j, j)</strong> to get skewing, you&rsquo;d have to generate this
code explicitly (potentially implemented by making polyhedral codegen a library
that transformations call into):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>mlfunc <span class=nf>@skewed_domain_example</span><span class=p>(...</span> <span class=nv>%N</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  affine<span class=p>.</span>for <span class=nv>%t1</span> <span class=p>=</span> <span class=m>0</span> <span class=p>...</span> <span class=m>2</span><span class=p>*</span>N<span class=m>-2</span> step <span class=m>1</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    affine<span class=p>.</span>for <span class=nv>%t2</span> <span class=p>=</span> max<span class=p>(</span><span class=m>0</span><span class=p>,</span> t1<span class=err>-</span>N<span class=err>+</span><span class=m>1</span><span class=p>)</span> <span class=p>...</span> min<span class=p>(</span>N<span class=p>,</span> t1<span class=p>)</span> step <span class=m>1</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=p>(</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>)</span> <span class=p>=</span> <span class=p>(</span><span class=nv>%t1</span><span class=err>-</span><span class=nv>%t2</span><span class=p>,</span> <span class=nv>%t2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=p>...</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=evaluation>Evaluation&nbsp;<a class=headline-hash href=#evaluation>¶</a></h2><p>Both of these forms are capable of expressing the same class of computation:
multidimensional loop nests with affine loop bounds and affine memory
references. That said, they pose very different tradeoffs in other ways.</p><h3 id=commonality-can-express-same-computation>Commonality: can express same computation&nbsp;<a class=headline-hash href=#commonality-can-express-same-computation>¶</a></h3><p>Both of these can express the same sorts of computation, e.g. kernels written in
one form are representable in the other form in all cases.</p><h3 id=commonality-dependence-analysis>Commonality: dependence analysis&nbsp;<a class=headline-hash href=#commonality-dependence-analysis>¶</a></h3><p>These representations both use affine functions for data layout mapping and
access subscripts, and dependence analysis works the same way.</p><h3 id=commonality-difficulty-of-determining-optimal-transformation-series>Commonality: difficulty of determining optimal transformation series&nbsp;<a class=headline-hash href=#commonality-difficulty-of-determining-optimal-transformation-series>¶</a></h3><p>One major challenge in performance of optimization of this sort of code is
choosing the ordering and behavior of various loop transformations that get
applied. There are non-local effects of every decision, and neither
representation helps solve this inherently hard problem.</p><h3 id=commonality-compactness-of-ir>Commonality: compactness of IR&nbsp;<a class=headline-hash href=#commonality-compactness-of-ir>¶</a></h3><p>In the cases that are most relevant to us (hyper rectangular spaces) these forms
are directly equivalent: a traditional instruction with a limited domain (e.g.
the &ldquo;reduced_domain_example&rdquo; above) ends up having one level of ML &lsquo;if&rsquo; inside
its loops. The simplified form pays for this by eliminating schedules and
domains from the IR. Both forms allow code duplication to reduce dynamic
branches in the IR: the traditional approach allows instruction splitting, the
simplified form supports instruction duplication.</p><p>It is important to point out that the traditional form wins on compactness in
the extreme cases: e.g. the loop skewing case. These cases will be rare in
practice for our workloads, and are exactly the cases that downstream
transformations want to be explicit about what they are doing.</p><h3 id=simplicity-of-code-generation>Simplicity of code generation&nbsp;<a class=headline-hash href=#simplicity-of-code-generation>¶</a></h3><p>A key final stage of an mlfunc is its conversion to a CFG function, which is
required as part of lowering to the target machine. The simplified form has a
clear advantage here: the IR has a direct correspondence to the structure of the
generated code.</p><p>In contrast, the traditional form has significant complexity in the lowering
process to a CFG function, because the verbosity not imbued in the IR needs to
come out during code generation. Code generation from ISL shows that it is
possible to do this, but it is a non-trivial transformation.</p><h3 id=ease-of-transformation>Ease of transformation&nbsp;<a class=headline-hash href=#ease-of-transformation>¶</a></h3><p>An advantage for the traditional form is that it is easier to perform certain
transformations on it: skewing and tiling are just transformations on the
schedule of the instructions in question, it doesn&rsquo;t require changing the loop
structure.</p><p>In practice, the simplified form requires moving the complexity of code
generation into the transformations themselves - this is sometimes trivial,
sometimes involved. The author believes that this should be possible by making
the code generation algorithms themselves be library functions that
transformations call into, instead of an opaque block that happens at the end of
the mlfunc processing.</p><p>Also, the sorts of transformations performed today by XLA (including tiling,
padding, unrolling, and other rectangular transformations) should be easy enough
to implement on either representation. The only cases that are a challenge are
more advanced cases like skewing, e.g. for DMA data movement generation.</p><h3 id=ease-of-analysis-cost-models>Ease of analysis: Cost models&nbsp;<a class=headline-hash href=#ease-of-analysis-cost-models>¶</a></h3><p>The simplified form is much easier for analyses and transformations to build
cost models for (e.g. answering the question of &ldquo;how much code bloat will be
caused by unrolling a loop at this level?&rdquo;), because it is easier to predict
what target code will be generated. With the traditional form, these analyses
will have to anticipate what polyhedral codegen will do to a set of instructions
under consideration: something that is non-trivial in the interesting cases in
question (see &ldquo;Cost of code generation&rdquo;).</p><h3 id=cost-of-code-generation>Cost of code generation&nbsp;<a class=headline-hash href=#cost-of-code-generation>¶</a></h3><p>State of the art polyhedral code generation is
<a href=https://lirias.kuleuven.be/bitstream/123456789/497238/1/toplas-astgen.pdf>expensive and complicated</a>,
sometimes exponential time complexity. We expect that most machine learning
workloads will be hyper-rectangular, and thus it should be easy to specialize in
important cases. That said, the traditional polyhedral representation makes it
very easy to introduce complicated and expensive schedules, and provides no way
to understand and project a cost model for using them. All downstream clients of
the IR need to be prepared to handle the full generality of IR that may come to
them.</p><p>The simplified form defines this away: the concepts in the IR remain simple, and
the code much more directly reflects the cost model for lowering to CFG
functions and machine code. This is expected to be very important in the late
stages of a code generator for an accelerator.</p><h3 id=ssa-in-ml-functions>SSA in ML Functions&nbsp;<a class=headline-hash href=#ssa-in-ml-functions>¶</a></h3><p>We agree already that values defined in an mlfunc can include scalar values and
they are defined based on traditional dominance. In the simplified form, this is
very simple: arguments and induction variables defined in for-loops are live
inside their lexical body, and linear series of instructions have the same &ldquo;top
down&rdquo; dominance relation that a basic block does.</p><p>In the traditional form though, this is not the case: it seems that a lot of
knowledge about how codegen will emit the code is necessary to determine if SSA
form is correct or not. For example, this is invalid code:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  <span class=nv>%tmp</span> <span class=p>=</span> call <span class=nf>@S1</span><span class=p>(</span><span class=nv>%X</span><span class=p>,</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    domain<span class=p>:</span> <span class=p>(</span><span class=m>10</span> <span class=p>&lt;=</span> <span class=nv>%i</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> <span class=nv>%j</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    schedule<span class=p>:</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  call <span class=nf>@S2</span><span class=p>(</span><span class=nv>%tmp</span><span class=p>,</span> <span class=nv>%A</span><span class=p>,</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    domain<span class=p>:</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> <span class=nv>%i</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>),</span> <span class=p>(</span><span class=m>0</span> <span class=p>&lt;=</span> <span class=nv>%j</span> <span class=p>&lt;</span> <span class=nv>%N</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    schedule<span class=p>:</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)</span>
</span></span></code></pre></div><p>Because <code>%tmp</code> isn&rsquo;t defined on some iterations of the %i loop.</p><p>This matters because it makes the verifier more complicated, but more
significantly, it means that load promotion and other optimizations that will
produce SSA form will need to be aware of this and be able to model what codegen
does.</p><p>An emergent property of this that we discussed recently is that PHI nodes in
mlfunc&rsquo;s (if we support them) will also have to have domains.</p><h3 id=lack-of-redundancy-in-ir>Lack of redundancy in IR&nbsp;<a class=headline-hash href=#lack-of-redundancy-in-ir>¶</a></h3><p>The traditional form has multiple encodings for the same sorts of behavior: you
end up having bits on <code>affine.for</code> loops to specify whether codegen should use
&ldquo;atomic/separate&rdquo; policies, unroll loops, etc. Instructions can be split or can
generate multiple copies of their instruction because of overlapping domains,
etc.</p><p>This is a problem for analyses and cost models, because they each have to reason
about these additional forms in the IR.</p><h3 id=suitability-to-purpose-lowering-to-machine-code>Suitability to purpose: lowering to machine code&nbsp;<a class=headline-hash href=#suitability-to-purpose-lowering-to-machine-code>¶</a></h3><p>One of the main drivers for this work is lowering to low-level accelerator code,
including two-dimensional vectorization, insertion of DMAs, and other
utilization of the matrix accelerator units. In the author&rsquo;s opinion, the extra
compactness of the traditional form is a negative for this purpose: reasoning
about the generated machine code will require understanding the mapping from
mlfunc to lowered code, which means that it must understand what code generation
will do.</p><p>In the simplified form, the effect of &ldquo;code generation&rdquo; is always obvious from
the IR itself, which should make it easier to perform vectorization to target
instructions and other analyses we need to perform.</p><h2 id=third-alternative-two-different-levels-of-mlfunc>Third Alternative: two different levels of mlfunc&nbsp;<a class=headline-hash href=#third-alternative-two-different-levels-of-mlfunc>¶</a></h2><p>One hybrid alternative is to support both the traditional and simplified forms
of mlfunc in our IR.</p><p>The stages could look like this, for example:</p><ol><li>Early performance transformations could be done on the traditional form.</li><li>Partial code generation lowers to the simplified form</li><li>Target specific lowering phases for tiling, and vectorization and other 2D
transforms that don&rsquo;t benefit much from the traditional form could be run.</li><li>Final codegen to a cfg func can be done when all of the instructions are
replaced with ones valid on the target.</li></ol><p>While this is possible, it isn&rsquo;t clear what would justify the complexity of this
approach. Unless there is a super compelling reason for this, it would be nice
to not do this. <strong>Update:</strong> we discussed this as a design team and agreed that
this wouldn&rsquo;t be a good way to go.</p><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/ title="MLIR: Incremental Application to Graph Algorithms in ML Frameworks"><i class="fas fa-arrow-left" aria-hidden=true></i> Prev - MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a>
<a class="nav nav-next" href=https://mlir.llvm.org/docs/Rationale/SideEffectsAndSpeculation/ title="Side Effects & Speculation">Next - Side Effects & Speculation <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=https://mlir.llvm.org/governance/>Governance</a></li><li><a href=https://mlir.llvm.org/users/>Users of MLIR</a></li><li><a href=https://mlir.llvm.org/pubs/>MLIR Related Publications</a></li><li><a href=https://mlir.llvm.org/talks/>Talks</a></li><li><a href=https://mlir.llvm.org/deprecation/>Deprecations & Current Refactoring</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/getting_started/ReportingIssues/>Reporting Issues</a></li><li><a href=https://mlir.llvm.org/getting_started/Debugging/>Debugging Tips</a></li><li><a href=https://mlir.llvm.org/getting_started/Faq/>FAQ</a></li><li><a href=https://mlir.llvm.org/getting_started/Contributing/>How to Contribute</a></li><li><a href=https://mlir.llvm.org/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=https://mlir.llvm.org/getting_started/openprojects/>Open Projects</a></li><li><a href=https://mlir.llvm.org/getting_started/Glossary/>Glossary</a></li><li><a href=https://mlir.llvm.org/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-reduce/>MLIR Reduce</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-rewrite/>mlir-rewrite</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/ActionTracing/>Action: Tracing and Debugging MLIR-based Compilers</a></li><li><a href=https://mlir.llvm.org/docs/Bufferization/>Bufferization</a></li><li><a href=https://mlir.llvm.org/docs/DataLayout/>Data Layout Modeling</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/DefiningDialects/>Defining Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Constraints/>Constraints</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Assembly/>Customizing Assembly Behavior</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Operations/>Operation Definition Specification (ODS)</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/DialectConversion/>Dialect Conversion</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/>Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMDGPU/>'amdgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArithOps/>'arith' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSME/>'ArmSME' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/BufferizationOps/>'bufferization' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/>'cf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/DLTIDialect/>'dlti' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/EmitC/>'emitc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Func/>'func' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IndexOps/>'index' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IRDL/>'irdl' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/Linalg/>'linalg' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/>Linalg OpDSL</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MLProgramOps/>'ml_program' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MPI/>'mpi' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVGPU/>'nvgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/>'omp' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/ODS/>ODS Documentation</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PtrOps/>'ptr' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Shard/>'shard' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SMT/>'smt' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/UBOps/>'ub' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/VCIXDialect/>'vcix' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeGPU/>'xegpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeVMDialect/>'xevm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/>OpInterface definitions</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SPIR-V/>SPIR-V Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Transform/>Transform Dialect</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Interfaces/>Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/TargetLLVMIR/>LLVM IR Target</a></li><li><a href=https://mlir.llvm.org/docs/BytecodeFormat/>MLIR Bytecode Format</a></li><li><a href=https://mlir.llvm.org/docs/CAPI/>MLIR C API</a></li><li><a href=https://mlir.llvm.org/docs/LangRef/>MLIR Language Reference</a></li><li><a href=https://mlir.llvm.org/docs/ReleaseNotes/>MLIR Release Notes</a></li><li><a href=https://mlir.llvm.org/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=https://mlir.llvm.org/docs/OwnershipBasedBufferDeallocation/>Ownership-based Buffer Deallocation</a></li><li><a href=https://mlir.llvm.org/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/Passes/>Passes</a></li><li><a href=https://mlir.llvm.org/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=https://mlir.llvm.org/docs/PDLL/>PDLL - PDL Language</a></li><li><a href=https://mlir.llvm.org/docs/Quantization/>Quantization</a></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/Rationale/>Rationale<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li class=active><a href=https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/SideEffectsAndSpeculation/>Side Effects & Speculation</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/ShapeInference/>Shape Inference</a></li><li><a href=https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=https://mlir.llvm.org/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=https://mlir.llvm.org/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Traits/>Traits<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Traits/Broadcastable/>The `Broadcastable` Trait</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/transform/>Transform Dialect Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch0/>Chapter 0: A Primer on “Structured” Linalg Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch1/>Chapter 1: Combining Existing Transformations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch2/>Chapter 2: Adding a Simple New Transformation Operation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch3/>Chapter 3: More than Simple Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch4/>Chapter 4: Matching Payload with Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/ChH/>Chapter H: Reproducing Halide Schedule</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/MlirOpt/>Using `mlir-opt`</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>