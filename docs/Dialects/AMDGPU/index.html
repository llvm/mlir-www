<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>'amdgpu' Dialect - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.119.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Dialects/AMDGPU/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script>
<link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script>
<script src=https://mlir.llvm.org/js/bundle.js></script>
<script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li><li class=child><a href=/python-bindings/>Python Bindings API docs</a></li></ul></li><li><a href="https://github.com/llvm/llvm-project/issues?q=is%3Aissue%20state%3Aopen%20label%3Amlir">Bugs</a></li><li><a href=https://github.com/llvm/mlir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/MLIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>'amdgpu' Dialect</h1><p>The <code>AMDGPU</code> dialect provides wrappers around AMD-specific functionality
and LLVM intrinsics. These wrappers should be used in conjunction with
more generic dialects, such as <code>gpu</code> and <code>vector</code>, when generating LLVM IR
that will eventually be executed on AMD hardware.</p><p><nav id=TableOfContents><ul><li><a href=#operations>Operations</a><ul><li><a href=#amdgpudpp-amdgpudppop><code>amdgpu.dpp</code> (amdgpu::DPPOp)</a></li><li><a href=#amdgpuext_packed_fp8-amdgpuextpackedfp8op><code>amdgpu.ext_packed_fp8</code> (amdgpu::ExtPackedFp8Op)</a></li><li><a href=#amdgpufat_raw_buffer_cast-amdgpufatrawbuffercastop><code>amdgpu.fat_raw_buffer_cast</code> (amdgpu::FatRawBufferCastOp)</a></li><li><a href=#amdgpugather_to_lds-amdgpugathertoldsop><code>amdgpu.gather_to_lds</code> (amdgpu::GatherToLDSOp)</a></li><li><a href=#amdgpulds_barrier-amdgpuldsbarrierop><code>amdgpu.lds_barrier</code> (amdgpu::LDSBarrierOp)</a></li><li><a href=#amdgpumake_dma_base-amdgpumakedmabaseop><code>amdgpu.make_dma_base</code> (amdgpu::MakeDmaBaseOp)</a></li><li><a href=#amdgpumake_dma_descriptor-amdgpumakedmadescriptorop><code>amdgpu.make_dma_descriptor</code> (amdgpu::MakeDmaDescriptorOp)</a></li><li><a href=#amdgpumake_gather_dma_base-amdgpumakegatherdmabaseop><code>amdgpu.make_gather_dma_base</code> (amdgpu::MakeGatherDmaBaseOp)</a></li><li><a href=#amdgpumemory_counter_wait-amdgpumemorycounterwaitop><code>amdgpu.memory_counter_wait</code> (amdgpu::MemoryCounterWaitOp)</a></li><li><a href=#amdgpumfma-amdgpumfmaop><code>amdgpu.mfma</code> (amdgpu::MFMAOp)</a></li><li><a href=#amdgpupacked_scaled_trunc-amdgpupackedscaledtruncop><code>amdgpu.packed_scaled_trunc</code> (amdgpu::PackedScaledTruncOp)</a></li><li><a href=#amdgpupacked_stoch_round_fp8-amdgpupackedstochroundfp8op><code>amdgpu.packed_stoch_round_fp8</code> (amdgpu::PackedStochRoundFp8Op)</a></li><li><a href=#amdgpupacked_trunc_2xfp8-amdgpupackedtrunc2xfp8op><code>amdgpu.packed_trunc_2xfp8</code> (amdgpu::PackedTrunc2xFp8Op)</a></li><li><a href=#amdgpupermlane_swap-amdgpupermlaneswapop><code>amdgpu.permlane_swap</code> (amdgpu::PermlaneSwapOp)</a></li><li><a href=#amdgpuraw_buffer_atomic_cmpswap-amdgpurawbufferatomiccmpswapop><code>amdgpu.raw_buffer_atomic_cmpswap</code> (amdgpu::RawBufferAtomicCmpswapOp)</a></li><li><a href=#amdgpuraw_buffer_atomic_fadd-amdgpurawbufferatomicfaddop><code>amdgpu.raw_buffer_atomic_fadd</code> (amdgpu::RawBufferAtomicFaddOp)</a></li><li><a href=#amdgpuraw_buffer_atomic_fmax-amdgpurawbufferatomicfmaxop><code>amdgpu.raw_buffer_atomic_fmax</code> (amdgpu::RawBufferAtomicFmaxOp)</a></li><li><a href=#amdgpuraw_buffer_atomic_smax-amdgpurawbufferatomicsmaxop><code>amdgpu.raw_buffer_atomic_smax</code> (amdgpu::RawBufferAtomicSmaxOp)</a></li><li><a href=#amdgpuraw_buffer_atomic_umin-amdgpurawbufferatomicuminop><code>amdgpu.raw_buffer_atomic_umin</code> (amdgpu::RawBufferAtomicUminOp)</a></li><li><a href=#amdgpuraw_buffer_load-amdgpurawbufferloadop><code>amdgpu.raw_buffer_load</code> (amdgpu::RawBufferLoadOp)</a></li><li><a href=#amdgpuraw_buffer_store-amdgpurawbufferstoreop><code>amdgpu.raw_buffer_store</code> (amdgpu::RawBufferStoreOp)</a></li><li><a href=#amdgpuscaled_ext_packed-amdgpuscaledextpackedop><code>amdgpu.scaled_ext_packed</code> (amdgpu::ScaledExtPackedOp)</a></li><li><a href=#amdgpuscaled_ext_packed_matrix-amdgpuscaledextpackedmatrixop><code>amdgpu.scaled_ext_packed_matrix</code> (amdgpu::ScaledExtPackedMatrixOp)</a></li><li><a href=#amdgpuscaled_mfma-amdgpuscaledmfmaop><code>amdgpu.scaled_mfma</code> (amdgpu::ScaledMFMAOp)</a></li><li><a href=#amdgpusched_barrier-amdgpuschedbarrierop><code>amdgpu.sched_barrier</code> (amdgpu::SchedBarrierOp)</a></li><li><a href=#amdgpuswizzle_bitmode-amdgpuswizzlebitmodeop><code>amdgpu.swizzle_bitmode</code> (amdgpu::SwizzleBitModeOp)</a></li><li><a href=#amdgputranspose_load-amdgputransposeloadop><code>amdgpu.transpose_load</code> (amdgpu::TransposeLoadOp)</a></li><li><a href=#amdgpuwmma-amdgpuwmmaop><code>amdgpu.wmma</code> (amdgpu::WMMAOp)</a></li></ul></li><li><a href=#attributes-24>Attributes</a><ul><li><a href=#addressspaceattr>AddressSpaceAttr</a></li><li><a href=#dpppermattr>DPPPermAttr</a></li><li><a href=#mfmapermbattr>MFMAPermBAttr</a></li><li><a href=#sched_barrier_opt_enumattr>sched_barrier_opt_enumAttr</a></li></ul></li><li><a href=#types>Types</a><ul><li><a href=#tdmbasetype>TDMBaseType</a></li><li><a href=#tdmdescriptortype>TDMDescriptorType</a></li><li><a href=#tdmgatherbasetype>TDMGatherBaseType</a></li></ul></li><li><a href=#enums>Enums</a><ul><li><a href=#addressspace>AddressSpace</a></li><li><a href=#dppperm>DPPPerm</a></li><li><a href=#mfmapermb>MFMAPermB</a></li><li><a href=#sched_barrier_opt_enum>sched_barrier_opt_enum</a></li></ul></li></ul></nav><h2 id=operations>Operations&nbsp;<a class=headline-hash href=#operations>¶</a></h2><p><a href=https://github.com/llvm/llvm-project/blob/main/mlir/include/mlir/Dialect/AMDGPU/IR/AMDGPU.td>source</a></p><h3 id=amdgpudpp-amdgpudppop><code>amdgpu.dpp</code> (amdgpu::DPPOp)&nbsp;<a class=headline-hash href=#amdgpudpp-amdgpudppop>¶</a></h3><p><em>AMDGPU DPP operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.dpp` $old $src $kind (`(` $permArgument^ `)`)? attr-dict `:` type($result)
</code></pre><p>This operation represents DPP functionality in a GPU program.
DPP provides the following operations:</p><ul><li>Full crossbar in a group of four (<code>quad_perm</code>)</li><li>Wavefront shift left by one lane (<code>wave_shl</code>)</li><li>Wavefront shift right by one lane (<code>wave_shr</code>)</li><li>Wavefront rotate right by one lane (<code>wave_ror</code>)</li><li>Wavefront rotate left by one lane (<code>wave_rol</code>)</li><li>Row shift left by 1–15 lanes (<code>row_shl</code>)</li><li>Row shift right by 1–15 lanes (<code>row_shr</code>)</li><li>Row rotate right by 1–15 lanes (<code>row_ror</code>)</li><li>Reverse within a row (<code>row_mirror</code>)</li><li>Reverse within a half-row (<code>row_half_mirror</code>)</li><li>Broadcast the 15th lane of each row to the next row (<code>row_bcast</code>)</li><li>Broadcast lane 31 to rows 2 and 3 (<code>row_bcast</code>)</li></ul><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>SameTypeOperands</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes>Attributes:&nbsp;<a class=headline-hash href=#attributes>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::amdgpu::DPPPermAttr</td><td>The possible permutations for a DPP operation</td></tr><tr><td><code>permArgument</code></td><td>::mlir::Attribute</td><td>32-bit signless integer attribute or array attribute or unit attribute</td></tr><tr><td><code>row_mask</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>bank_mask</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>bound_ctrl</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands>Operands:&nbsp;<a class=headline-hash href=#operands>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>old</code></td><td>any type</td></tr><tr><td style=text-align:center><code>src</code></td><td>any type</td></tr></tbody></table><h4 id=results>Results:&nbsp;<a class=headline-hash href=#results>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>any type</td></tr></tbody></table><h3 id=amdgpuext_packed_fp8-amdgpuextpackedfp8op><code>amdgpu.ext_packed_fp8</code> (amdgpu::ExtPackedFp8Op)&nbsp;<a class=headline-hash href=#amdgpuext_packed_fp8-amdgpuextpackedfp8op>¶</a></h3><p><em>Extend a fp8 value to a float or a vector of packed fp8 values to two floats</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.ext_packed_fp8` attr-dict $source `[` $index `]` `:` type($source) `to` type($res)
</code></pre><p>Extend one or two 8-bit floats in <code>source[index]</code> to a 32-bit float or
two floats and return them.</p><p>This rather unusual signature arises from the fact that AMD GPUs cannot
easily work with sub 32-bit quantities, so the compiler intrinsics for
extending 8-bit floats (which are, currently, the only way to work with
this operation) take packed vectors of 4 such floats.</p><p>If the passed-in vector has fewer than four elements, or the input is scalar,
the remaining values in the &lt;4 x i8> will be filled with
undefined values as needed.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-1>Attributes:&nbsp;<a class=headline-hash href=#attributes-1>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>index</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is non-negative whose maximum value is 3</td></tr></table><h4 id=operands-1>Operands:&nbsp;<a class=headline-hash href=#operands-1>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>f8E5M2FNUZ type or f8E4M3FNUZ type or f8E5M2 type or f8E4M3FN type or vector of f8E5M2FNUZ type or f8E4M3FNUZ type or f8E5M2 type or f8E4M3FN type values of length 1/2/3/4</td></tr></tbody></table><h4 id=results-1>Results:&nbsp;<a class=headline-hash href=#results-1>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit float or fixed-length vector of 32-bit float values of length 2</td></tr></tbody></table><h3 id=amdgpufat_raw_buffer_cast-amdgpufatrawbuffercastop><code>amdgpu.fat_raw_buffer_cast</code> (amdgpu::FatRawBufferCastOp)&nbsp;<a class=headline-hash href=#amdgpufat_raw_buffer_cast-amdgpufatrawbuffercastop>¶</a></h3><p><em>Create a raw buffer fat pointer that matches <code>memref</code></em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.fat_raw_buffer_cast` $source oilist (`validBytes` `(` $validBytes `)`
              | `cacheSwizzleStride` `(` $cacheSwizzleStride `)`
              | `boundsCheck` `(` $boundsCheck `)`
              | `resetOffset` $resetOffset )
              attr-dict `:` type($source) `to` type($result)
</code></pre><p>Wraps the memory pointed to by <code>source</code> as a raw buffer fat pointer, or,
in LLVM terms, a <code>ptr addrspace(7)</code>, returning a memref that has the same
sizes and layout but the <code>#amdgpu.address_space&lt;fat_raw_buffer></code>
address space.</p><p>This memref can be used with standard memref operations like <code>memref.load</code>,
<code>memref.store</code>, and <code>memref.atomicrmw</code>, which will be lowered to the relevant
buffer intrinsics. (<code>vector.masked_load/store</code> will work once there&rsquo;s backend
support for lowering them, and then this document will be updated)</p><p>If <code>validBytes</code> is given, it is the number of bytes that will be valid as
an offset to <code>out</code>. If it is not provided, this will be inferred from
the size of the memref during lowering. This size is
max_{d = 0 upto rank(source)} (sizes[d] * strides[d]) * sizeof(element type).</p><p>The flags of the buffer descriptor will be set up to enable raw usage -
for example, stride = 0, add_tid = 0, and so on. The <code>boundsCheck</code>
property determines if bounds checking is enabled or not (on architectures
where this can be controlled - that is, on RDNA chips).</p><p>If <code>cacheSwizzleStride</code> is provided, L1 cache swizzling will be enabled
on architectures that support it. This swizzling, unlike the main swizzling
mode (whose usage makes a buffer non-raw) does not affect index calculation,
but does affect cache behavior. Mixing access between cache-swizzled raw
buffers and other forms of memory access, like ordinary pointer loads or
unswizzled buffer pointers can cause incorrect behavior and must be avoided.</p><p>This operation preserves the sizes, strides, and offset of the input
memref - they&rsquo;ll be added in by <code>memref.load</code> later. However, if
<code>resetOffset</code> is set, that offset will be added to the base pointer.
If the value of the memref&rsquo;s offset is not uniform (independent of the lane/thread ID),
this will lead to substantially decreased performance due to the need for
a waterfall loop on the base address of the buffer resource.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>ReifyRankedShapedTypeOpInterface</code>, <code>ViewLikeOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-2>Attributes:&nbsp;<a class=headline-hash href=#attributes-2>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>boundsCheck</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>resetOffset</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h4 id=operands-2>Operands:&nbsp;<a class=headline-hash href=#operands-2>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>validBytes</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>cacheSwizzleStride</code></td><td>14-bit signless integer</td></tr></tbody></table><h4 id=results-2>Results:&nbsp;<a class=headline-hash href=#results-2>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>memref of any type values</td></tr></tbody></table><h3 id=amdgpugather_to_lds-amdgpugathertoldsop><code>amdgpu.gather_to_lds</code> (amdgpu::GatherToLDSOp)&nbsp;<a class=headline-hash href=#amdgpugather_to_lds-amdgpugathertoldsop>¶</a></h3><p><em>MLIR wrapper for CDNA Gather to LDS instructions</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.gather_to_lds` $src `[` $srcIndices `]` `,` $dst `[` $dstIndices `]` attr-dict `:` $transferType `,` type($src) `,` type($dst)
</code></pre><p>The <code>amdgpu.gather_to_lds</code> op is a wrapper around the <code>global_load_lds</code> instructions.</p><p>Operands:</p><ul><li><code>$src</code>: global memory (including fat buffer) memref to read from.</li><li><code>$srcIndices</code>: indices into <code>$src</code> to read from for this thread.</li><li><code>$dst</code>: LDS memory memref to write to.</li><li><code>$dstIndices</code>: base indices into <code>$dst</code> to write to for the subgroup of this thread.
The elements gathered by the subgroup will be written contiguously in order of lane ID
starting at <code>$dst[$dstIndices]</code>. Byte-sized (ex. i8) or short-sized (ex. i16)
types will be zero-padded/extended to 32 bits before being written. 96-bit types
(ex. vector&lt;3xf32>) will be zero-padded to 128 bits before being written. Only the
offsets held by lane 0 are used.</li><li><code>$transferType</code>: type of the data to be transferred by each thread. This is used to determine
the size of the data to be transferred and the number of threads in the subgroup.
The transfer type must be a scalar type or a vector type with a single element type.</li></ul><p>The <code>$dst</code>, along with its indices, points to the memory location the subgroup of this thread
will write to.</p><p>Note: only supported on gfx9 and gfx10.</p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-3>Attributes:&nbsp;<a class=headline-hash href=#attributes-3>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>transferType</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-3>Operands:&nbsp;<a class=headline-hash href=#operands-3>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>srcIndices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>dst</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>dstIndices</code></td><td>variadic of index</td></tr></tbody></table><h3 id=amdgpulds_barrier-amdgpuldsbarrierop><code>amdgpu.lds_barrier</code> (amdgpu::LDSBarrierOp)&nbsp;<a class=headline-hash href=#amdgpulds_barrier-amdgpuldsbarrierop>¶</a></h3><p><em>Barrier that includes a wait for LDS memory operations.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.lds_barrier` attr-dict
</code></pre><p><code>amdgpu.lds_barrier</code> is both a barrier (all workitems in a workgroup must reach
the barrier before any of them may proceed past it) and a wait for all
operations that affect the Local Data Store (LDS) issued from that wrokgroup
to complete before the workgroup may continue. Since the LDS is per-workgroup
memory, this barrier may be used, for example, to ensure all workitems have
written data to LDS before any workitem attempts to read from it.</p><p>Note that <code>lds_barrier</code> does <strong>not</strong> force reads to or from global memory
to complete before execution continues. Therefore, it should be used when
operations on global memory can be issued far in advance of when their results
are used (for example, by writing them to LDS).</p><p>WARNING: On architectures that do not support the BackOffBarrier feature,
(those which will implement this barrier by emitting inline assembly),
use of this operation will impede the usabiliity of memory watches (including
breakpoints set on variables) when debugging.</p><h3 id=amdgpumake_dma_base-amdgpumakedmabaseop><code>amdgpu.make_dma_base</code> (amdgpu::MakeDmaBaseOp)&nbsp;<a class=headline-hash href=#amdgpumake_dma_base-amdgpumakedmabaseop>¶</a></h3><p><em>Pair of based addresses used when moving tiles between LDS and global memory.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.make_dma_base` $global `[` $global_indices `]` `,` $lds `[` $lds_indices `]` attr-dict `:` type($global) `,` type($lds) `-&gt;` type(results)
</code></pre><p>This operation creates a pair of addresses that will be used by tensor_load_to_lds
and tensor_store_from_lds.</p><p>This operation creates a value corresponding to the tensor descriptor (D#) group 0
found in TensorLoadToLDSOp and TensorStoreFromLDSOp in the rocdl dialect.</p><p>For example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  <span class=nv>%base</span> <span class=p>=</span> amdgpu<span class=p>.</span>make_dma_base <span class=nv>%global</span><span class=p>[</span><span class=nv>%idx0</span><span class=p>,</span> <span class=nv>%idx1</span><span class=p>],</span> <span class=nv>%lds</span><span class=p>[</span><span class=nv>%idx2</span><span class=p>,</span> <span class=nv>%idx3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x64x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x64x</span><span class=k>i32</span><span class=p>,</span> <span class=nv>#gpu.address_space</span><span class=p>&lt;</span>workgroup<span class=p>&gt;&gt;</span> <span class=p>-&gt;</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_base<span class=p>&lt;</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nv>%descriptor</span> <span class=p>=</span> amdgpu<span class=p>.</span>make_dma_descriptor <span class=nv>%base</span> globalSize <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>2</span><span class=p>]</span> globalStride <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>1</span><span class=p>]</span> sharedSize <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>2</span><span class=p>]</span> <span class=p>:</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_base<span class=p>&lt;</span><span class=k>i32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_descriptor
</span></span><span class=line><span class=cl>  amdgpu<span class=p>.</span><span class=kt>tensor</span>_load_to_lds <span class=nv>%descriptor</span> <span class=p>:</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_descriptor
</span></span></code></pre></div><p>to</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  <span class=c>// pseudo-code
</span></span></span><span class=line><span class=cl><span class=c></span>  <span class=nv>%global_base</span> <span class=p>=</span> llvm<span class=p>.</span>extractvalue <span class=nv>%global_memref</span><span class=p>[</span><span class=m>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=nv>%global_address</span> <span class=p>=</span> llvm<span class=p>.</span>get_element_ptr <span class=p>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nv>%lds_base</span> <span class=p>=</span> llvm<span class=p>.</span>extractvalue <span class=nv>%lds_memref</span><span class=p>[</span><span class=m>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=nv>%lds_address</span> <span class=p>=</span> llvm<span class=p>.</span>get_element_ptr <span class=p>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>// Definition of %base
</span></span></span><span class=line><span class=cl><span class=c></span>  <span class=nv>%undef</span> <span class=p>=</span> llvm<span class=p>.</span>mlir<span class=p>.</span>undef <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nv>%v0</span> <span class=p>=</span> llvm<span class=p>.</span>insertelement <span class=nv>%15</span><span class=p>,</span> <span class=nv>%undef</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nv>%v1</span> <span class=p>=</span> llvm<span class=p>.</span>insertelement <span class=nv>%lds_address</span><span class=p>,</span> <span class=nv>%v0</span><span class=p>[</span><span class=m>1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nv>%v2</span> <span class=p>=</span> llvm<span class=p>.</span>insertelement <span class=nv>%global_address_low</span><span class=p>,</span> <span class=nv>%v1</span><span class=p>[</span><span class=m>2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nv>%base</span> <span class=p>=</span> llvm<span class=p>.</span>insertelement <span class=nv>%global_address_high</span><span class=p>,</span> <span class=nv>%v2</span><span class=p>[</span><span class=m>3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  rocdl<span class=p>.</span><span class=kt>tensor</span><span class=p>.</span>load<span class=p>.</span>to<span class=p>.</span>lds <span class=nv>%base</span><span class=p>,</span> <span class=nv>%dgroup1</span><span class=p>,</span> <span class=nv>%dgroup2</span><span class=p>,</span> <span class=nv>%dgroup3</span> cachepolicy <span class=m>0</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>These tensor DMA operations were introduced in gfx1250.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-4>Operands:&nbsp;<a class=headline-hash href=#operands-4>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>global</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>global_indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>lds</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>lds_indices</code></td><td>variadic of index</td></tr></tbody></table><h4 id=results-3>Results:&nbsp;<a class=headline-hash href=#results-3>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>Pair of base addresses that move data between LDS and global storage.</td></tr></tbody></table><h3 id=amdgpumake_dma_descriptor-amdgpumakedmadescriptorop><code>amdgpu.make_dma_descriptor</code> (amdgpu::MakeDmaDescriptorOp)&nbsp;<a class=headline-hash href=#amdgpumake_dma_descriptor-amdgpumakedmadescriptorop>¶</a></h3><p><em>Make all descriptor groups needed by TensorLoadToLDS/TensorStoreFromLDS.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.make_dma_descriptor` $base
              `globalSize` custom&lt;DynamicIndexList&gt;($global_dynamic_sizes, $global_static_sizes)
              `globalStride` custom&lt;DynamicIndexList&gt;($global_dynamic_strides, $global_static_strides)
              `sharedSize` custom&lt;DynamicIndexList&gt;($shared_dynamic_sizes, $shared_static_sizes)
              ( `padShared` `(` $pad_amount^ `every` $pad_interval `)` )?
              ( `workgroupMask` $workgroup_mask^ ( `earlyTimeout` $early_timeout^)?)?
              ( `atomicBarrier` `(` $atomic_barrier_address^ `[` $atomic_barrier_indices `]`
              `:` type($atomic_barrier_address) `)`)?
              ( `iterate` $global_increment^ `,` $lds_increment `,` $iteration_count )?
              attr-dict `:` qualified(type($base)) `-&gt;` type(results)
</code></pre><p>Make all descriptor groups needed by tensor memory operations.</p><p>The $base operand corresponds to the base pair addresses, one must be an address in LDS
while the other must be a global memory location.</p><p>$global_{static/dynamic}<em>sizes determine the size of the tensor.
$global</em>{static/dynamic}<em>strides determine the strides of the tensor.
$shared</em>{static/dynamic}_sizes determines the size of the tile.</p><p>$workgroup_mask broadcast load to workgroups inside of a workgroup cluster
(0 = do not broadcast result to workgroup, 1 = broadcast result to workgroup). Ignored for stores.
An all zeros mask is interpreted as a non-broadcasted load.</p><p>$early_timeout return data to requesters as soon as cache supplies it.</p><p>Padding can be applied to the LDS address when copying from memory to LDS,
but not when copying from LDS to memory.
The values in the padded target addresses remain the same as before the operation was applied.
$pad_interval must be a power of two contained in [2, 256].
$pad_amount must be a value contained in [1, 128].</p><p>$atomic_barrier_address must be aligned to 8 bytes.</p><p>2D and 3D tensors may be iterated over by setting $global_increment, $lds_increment, and $iteration_count.
$global_increment determines how much to increment the starting global memory address per iteration in units of the $base&rsquo;s element type.
$lds_increment determines how much to increment the starting LDS address per iteration in units of the $base&rsquo;s element type.
$iterate_count determines how many times to iterate, it must be a value in the inclusive interval [1, 256].</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl> <span class=c>// Example of moving a two-dimensional tensor to LDS.
</span></span></span><span class=line><span class=cl><span class=c></span> <span class=nv>%base</span> <span class=p>=</span> amdgpu<span class=p>.</span>make_dma_base <span class=nv>%global</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>],</span> <span class=nv>%lds</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x64x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x64x</span><span class=k>i32</span><span class=p>,</span> <span class=nv>#gpu.address_space</span><span class=p>&lt;</span>workgroup<span class=p>&gt;&gt;</span> <span class=p>-&gt;</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_base<span class=p>&lt;</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl> <span class=nv>%descriptor</span> <span class=p>=</span> amdgpu<span class=p>.</span>make_dma_descriptor <span class=nv>%base</span> globalSize <span class=p>[</span><span class=m>64</span><span class=p>,</span> <span class=m>64</span><span class=p>]</span> globalStride <span class=p>[</span><span class=m>64</span><span class=p>,</span> <span class=m>1</span><span class=p>]</span> sharedSize <span class=p>[</span><span class=m>64</span><span class=p>,</span> <span class=m>64</span><span class=p>]</span> <span class=p>:</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_base<span class=p>&lt;</span><span class=k>i32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_descriptor
</span></span><span class=line><span class=cl> amdgpu<span class=p>.</span><span class=kt>tensor</span>_load_to_lds <span class=nv>%descriptor</span> <span class=p>:</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_descriptor
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> <span class=c>// Example of moving a two dimension tensor to LDS where padding is applied after every integer.
</span></span></span><span class=line><span class=cl><span class=c></span> <span class=nv>%base</span> <span class=p>=</span> amdgpu<span class=p>.</span>make_dma_base <span class=nv>%global</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>],</span> <span class=nv>%lds</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x32x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x64x</span><span class=k>i32</span><span class=p>,</span> <span class=nv>#gpu.address_space</span><span class=p>&lt;</span>workgroup<span class=p>&gt;&gt;</span> <span class=p>-&gt;</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_base<span class=p>&lt;</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl> <span class=nv>%descriptor</span> <span class=p>=</span> amdgpu<span class=p>.</span>make_dma_descriptor <span class=nv>%base</span> globalSize <span class=p>[</span><span class=m>32</span><span class=p>,</span> <span class=m>32</span><span class=p>]</span> globalStride <span class=p>[</span><span class=m>32</span><span class=p>,</span> <span class=m>1</span><span class=p>]</span> sharedSize <span class=p>[</span><span class=m>64</span><span class=p>,</span> <span class=m>64</span><span class=p>]</span> padShared<span class=p>(</span><span class=nv>%pad_amount</span> every <span class=nv>%pad_interval</span><span class=p>)</span> <span class=p>:</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_base<span class=p>&lt;</span><span class=k>i32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_descriptor
</span></span><span class=line><span class=cl> amdgpu<span class=p>.</span><span class=kt>tensor</span>_load_to_lds <span class=nv>%descriptor</span> <span class=p>:</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_descriptor
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-4>Attributes:&nbsp;<a class=headline-hash href=#attributes-4>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>global_static_sizes</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td><code>global_static_strides</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr><tr><td><code>shared_static_sizes</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></table><h4 id=operands-5>Operands:&nbsp;<a class=headline-hash href=#operands-5>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>Pair of base addresses that move data between LDS and global storage.</td></tr><tr><td style=text-align:center><code>global_dynamic_sizes</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>global_dynamic_strides</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>shared_dynamic_sizes</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>workgroup_mask</code></td><td>fixed-length vector of 1-bit signless integer values of length 16</td></tr><tr><td style=text-align:center><code>early_timeout</code></td><td>1-bit signless integer</td></tr><tr><td style=text-align:center><code>pad_amount</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>pad_interval</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>atomic_barrier_address</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>atomic_barrier_indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>global_increment</code></td><td>index</td></tr><tr><td style=text-align:center><code>lds_increment</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>iteration_count</code></td><td>index</td></tr></tbody></table><h4 id=results-4>Results:&nbsp;<a class=headline-hash href=#results-4>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>desc</code></td><td>Descriptors used in tensor store/load operations.</td></tr></tbody></table><h3 id=amdgpumake_gather_dma_base-amdgpumakegatherdmabaseop><code>amdgpu.make_gather_dma_base</code> (amdgpu::MakeGatherDmaBaseOp)&nbsp;<a class=headline-hash href=#amdgpumake_gather_dma_base-amdgpumakegatherdmabaseop>¶</a></h3><p><em>Pair of based addresses used when moving tiles between LDS and global memory.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.make_gather_dma_base` $global `[` $global_indices `]` `,` $lds `[` $lds_indices `]` attr-dict `:` type($global) `,` type($lds) `-&gt;` type(results)
</code></pre><p>This operation creates a pair of addresses that will be used by <code>tensor_load_to_lds</code>
and <code>tensor_store_from_lds</code>.</p><p>This operation creates a value corresponding to the tensor descriptor (D#) group 0
found in TensorLoadToLDSOp and TensorStoreFromLDSOp in the rocdl dialect.</p><p>Unlike <code>make_dma_base</code>, this operation returns <code>!amdgpu.tdm_gather_base&lt;$element_type, $index_type></code>
which is only compatible with <code>make_gather_dma_descriptor</code>. Using the descriptor returned
by <code>make_gather_dma_descriptor</code> will set the <code>tensor_load_to_lds</code> and <code>tensor_store_from_lds</code> to gather mode.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  <span class=nv>%base</span> <span class=p>=</span> amdgpu<span class=p>.</span>make_gather_dma_base <span class=nv>%global</span><span class=p>[</span><span class=nv>%idx0</span><span class=p>,</span> <span class=nv>%idx1</span><span class=p>],</span> <span class=nv>%lds</span><span class=p>[</span><span class=nv>%idx2</span><span class=p>,</span> <span class=nv>%idx3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x64x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x64x</span><span class=k>i32</span><span class=p>,</span> <span class=nv>#gpu.address_space</span><span class=p>&lt;</span>workgroup<span class=p>&gt;&gt;</span> <span class=p>-&gt;</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_gather_base<span class=p>&lt;</span><span class=k>i32</span><span class=p>,</span> <span class=k>i16</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=c>// %indices : i16
</span></span></span><span class=line><span class=cl><span class=c></span>  <span class=nv>%descriptor</span> <span class=p>=</span> amdgpu<span class=p>.</span>make_gather_dma_descriptor <span class=nv>%base</span><span class=p>[</span><span class=nv>%indices</span><span class=p>]</span> globalSize <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>2</span><span class=p>]</span> globalStride <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>1</span><span class=p>]</span> sharedSize <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>2</span><span class=p>]</span> <span class=p>:</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_gather_base<span class=p>&lt;</span><span class=k>i32</span><span class=p>,</span> <span class=k>i16</span><span class=p>&gt;,</span> <span class=k>i16</span> <span class=p>-&gt;</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_descriptor
</span></span><span class=line><span class=cl>  amdgpu<span class=p>.</span><span class=kt>tensor</span>_load_to_lds <span class=nv>%descriptor</span> <span class=p>:</span> <span class=p>!</span>amdgpu<span class=p>.</span>tdm_descriptor
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-6>Operands:&nbsp;<a class=headline-hash href=#operands-6>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>global</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>global_indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>lds</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>lds_indices</code></td><td>variadic of index</td></tr></tbody></table><h4 id=results-5>Results:&nbsp;<a class=headline-hash href=#results-5>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>Pair of base addresses that move data between LDS and global storage.</td></tr></tbody></table><h3 id=amdgpumemory_counter_wait-amdgpumemorycounterwaitop><code>amdgpu.memory_counter_wait</code> (amdgpu::MemoryCounterWaitOp)&nbsp;<a class=headline-hash href=#amdgpumemory_counter_wait-amdgpumemorycounterwaitop>¶</a></h3><p><em>Wait for specified hardware counters</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.memory_counter_wait` oilist( `load` `(` $load `)` | `store` `(` $store `)` | `ds` `(` $ds `)` | `exp` `(` $exp `)` | `tensor` `(` $tensor `)` ) attr-dict
</code></pre><p>Wait for the specified counters to be less-than or equal-to the provided
values before continuing.</p><p>Counters can lower to different instructions on different architectires,
including clamping to the some HW supported max value or combining multiple
counters into one.</p><h4 id=attributes-5>Attributes:&nbsp;<a class=headline-hash href=#attributes-5>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>load</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>store</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>ds</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>exp</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>tensor</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h3 id=amdgpumfma-amdgpumfmaop><code>amdgpu.mfma</code> (amdgpu::MFMAOp)&nbsp;<a class=headline-hash href=#amdgpumfma-amdgpumfmaop>¶</a></h3><p><em>MLIR wrapper for CDNA mfma instructions</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.mfma` custom&lt;MNKDimensionList&gt;($m, $n, $k) $sourceA `*` $sourceB `+` $destC
              attr-dict
              `blgp` `=` $blgp
              `:` type($sourceA) `,` type($sourceB) `,` type($destC)
</code></pre><p>The <code>amdgpu.mfma</code> op is an MLIR wrapper around intrinsics
for various <code>mfma</code> instructions in the CDNA architecture, which perform
multiple outer products in order to allow fast matrix multiplication.</p><p>The wrapper will select an appropriate <code>mfma</code> instruction, if one is available,
based on the provided <code>m</code>, <code>k</code>, <code>n</code>, and <code>nBlks</code> attributes, along with the
types of the source and destination arguments.</p><p>For information on the layouts of the input and output matrices (which are stored
in <code>sourceA</code>, <code>sourceB</code>, <code>destC</code>, and <code>destD</code>), see the CDNA ISA documentation.</p><p>The <code>cbsz</code>, <code>abid</code>, and <code>blgp</code> parameters control how the lanes of the wave
are permuted when matrix data is being loaded: <code>blgp</code> can be any number of
fixed permutations, <code>cbsz</code> specifies the log_2 of the number of chunks the lanes
holding sourceA are split into, and <code>abid</code> selects one of those chunks.</p><p>Note, this wrapper allows specifying <code>vector&lt;4Kxi8></code> arguments to MFMA
intrinsics that take an integer type of width <code>4K</code>. For example,
one can provide a vector&lt;4xi8> as an argument to an MFMA instruction that
logically takes 4 i8s but whose intrinsics are specified to take an i32.
In these cases, the bytes in the vector will be concatenated in little-endian
order (that is, v[0] will go to arg[7:0], v[1] to arg[15:8] and so on).</p><p>The negateA, negateB, and negateC flags are only supported for double-precision
operations on gfx94x.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  <span class=nv>%0</span> <span class=p>=</span> amdgpu<span class=p>.</span>mfma <span class=m>16x16x16</span> <span class=nv>%matA</span> <span class=p>*</span> <span class=nv>%matB</span> <span class=err>+</span> <span class=nv>%matC</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nv>%1</span> <span class=p>=</span> amdgpu<span class=p>.</span>mfma <span class=m>32x32x1</span> <span class=nv>%matD</span> <span class=p>*</span> <span class=nv>%matE</span> <span class=err>+</span> <span class=nv>%matF</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span> <span class=nl>abid =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span> <span class=nl>cbsz =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span> <span class=nl>blocks =</span> <span class=m>2</span> <span class=p>:</span> <span class=k>i32</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nl>blgp =</span> bcast_second_32 <span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=k>f32</span><span class=p>,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-6>Attributes:&nbsp;<a class=headline-hash href=#attributes-6>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>m</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {4, 16, 32}</td></tr><tr><td><code>n</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {4, 16, 32}</td></tr><tr><td><code>k</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {1, 2, 4, 8, 16, 32, 64, 128}</td></tr><tr><td><code>blocks</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {1, 2, 4, 16}</td></tr><tr><td><code>cbsz</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>abid</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>blgp</code></td><td>::mlir::amdgpu::MFMAPermBAttr</td><td>The possible permutations of the lanes storing B available in an MFMA</td></tr><tr><td><code>reducePrecision</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>negateA</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>negateB</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>negateC</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h4 id=operands-7>Operands:&nbsp;<a class=headline-hash href=#operands-7>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>sourceA</code></td><td>32-bit float or 64-bit float or 32-bit signless integer or 64-bit signless integer or vector of 32-bit float values of length 2 or vector of 16-bit float values of length 4/8 or vector of bfloat16 type values of length 2/4/8 or vector of 8-bit signless integer values of length 4/8/16 or vector of f8E5M2FNUZ type or f8E4M3FNUZ type values of length 8 or vector of f8E5M2 type or f8E4M3FN type values of length 8/32 or vector of f6E2M3FN type or f6E3M2FN type or f4E2M1FN type values of length 32</td></tr><tr><td style=text-align:center><code>sourceB</code></td><td>32-bit float or 64-bit float or 32-bit signless integer or 64-bit signless integer or vector of 32-bit float values of length 2 or vector of 16-bit float values of length 4/8 or vector of bfloat16 type values of length 2/4/8 or vector of 8-bit signless integer values of length 4/8/16 or vector of f8E5M2FNUZ type or f8E4M3FNUZ type values of length 8 or vector of f8E5M2 type or f8E4M3FN type values of length 8/32 or vector of f6E2M3FN type or f6E3M2FN type or f4E2M1FN type values of length 32</td></tr><tr><td style=text-align:center><code>destC</code></td><td>64-bit float or vector of 32-bit float values of length 4/16/32 or vector of 32-bit signless integer values of length 4/16/32 or vector of 64-bit float values of length 4</td></tr></tbody></table><h4 id=results-6>Results:&nbsp;<a class=headline-hash href=#results-6>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>destD</code></td><td>64-bit float or vector of 32-bit float values of length 4/16/32 or vector of 32-bit signless integer values of length 4/16/32 or vector of 64-bit float values of length 4</td></tr></tbody></table><h3 id=amdgpupacked_scaled_trunc-amdgpupackedscaledtruncop><code>amdgpu.packed_scaled_trunc</code> (amdgpu::PackedScaledTruncOp)&nbsp;<a class=headline-hash href=#amdgpupacked_scaled_trunc-amdgpupackedscaledtruncop>¶</a></h3><p><em>Round two floats into a packed vector of floats</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.packed_scaled_trunc` attr-dict $source `into` ($existing^):(`undef`)? `[` $index `]`
              `,` $scale
              `:` type($source) `to` type($res) (`into` type($existing)^)?
</code></pre><p>Scale and round the inputs <code>source</code> (which is undefined if not
specified) into the low or high word (bottom two or top two) elements
of the returned vector, keeping the other two elements of <code>existing</code>
unchanged if present (or undefined if it was not passed in).</p><p>The reason for this odd signature is that AMD GPUs cannot easily work with
sub-registers, and so the conversion intrinsics take 32-bit wide
packed vectors of float values.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-7>Attributes:&nbsp;<a class=headline-hash href=#attributes-7>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>index</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is non-negative whose maximum value is 7</td></tr></table><h4 id=operands-8>Operands:&nbsp;<a class=headline-hash href=#operands-8>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>vector of 32-bit float or 16-bit float or bfloat16 type values of length 1/2</td></tr><tr><td style=text-align:center><code>scale</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>existing</code></td><td>fixed-length vector of f8E5M2 type or f8E4M3FN type values of length 4 or fixed-length vector of f4E2M1FN type values of length 8</td></tr></tbody></table><h4 id=results-7>Results:&nbsp;<a class=headline-hash href=#results-7>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>fixed-length vector of f8E5M2 type or f8E4M3FN type values of length 4 or fixed-length vector of f4E2M1FN type values of length 8</td></tr></tbody></table><h3 id=amdgpupacked_stoch_round_fp8-amdgpupackedstochroundfp8op><code>amdgpu.packed_stoch_round_fp8</code> (amdgpu::PackedStochRoundFp8Op)&nbsp;<a class=headline-hash href=#amdgpupacked_stoch_round_fp8-amdgpupackedstochroundfp8op>¶</a></h3><p><em>Round float stochiastically into a packed vector of 8-bit floats</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.packed_stoch_round_fp8` attr-dict $source `+` $stochiasticParam
              `into` ($existing^):(`undef`)? `[` $storeIndex `]`
              `:` type($source) `to` type($res) (`into` type($existing)^)?
</code></pre><p>Round the input <code>source</code>, adding in <code>stochiasticParam</code>, and place it into
the <code>storeIndex</code>th element of <code>res</code>.</p><p>If <code>existing</code> is passed in, elements of <code>res</code> other than the one at <code>storeIndex</code>
are copied from <code>existing</code>.</p><p>The reason for this odd signature is that AMD GPUs cannot easily work with
sub-registers, and so the conversion intrinsics (which are currently the
only way to work with 8-bit float types) take packed vectors of 4 8-bit
values.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-8>Attributes:&nbsp;<a class=headline-hash href=#attributes-8>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>storeIndex</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is non-negative whose maximum value is 3</td></tr></table><h4 id=operands-9>Operands:&nbsp;<a class=headline-hash href=#operands-9>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>stochiasticParam</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>existing</code></td><td>fixed-length vector of f8E4M3FNUZ type or f8E5M2FNUZ type or f8E4M3FN type or f8E5M2 type values of length 4</td></tr></tbody></table><h4 id=results-8>Results:&nbsp;<a class=headline-hash href=#results-8>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>fixed-length vector of f8E4M3FNUZ type or f8E5M2FNUZ type or f8E4M3FN type or f8E5M2 type values of length 4</td></tr></tbody></table><h3 id=amdgpupacked_trunc_2xfp8-amdgpupackedtrunc2xfp8op><code>amdgpu.packed_trunc_2xfp8</code> (amdgpu::PackedTrunc2xFp8Op)&nbsp;<a class=headline-hash href=#amdgpupacked_trunc_2xfp8-amdgpupackedtrunc2xfp8op>¶</a></h3><p><em>Round two floats into a packed vector of 8-bit floats</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.packed_trunc_2xfp8` attr-dict $sourceA `,` ($sourceB^):(`undef`)?
              `into` ($existing^):(`undef`)? `[` `word` $wordIndex `]`
              `:` type($sourceA) `to` type($res) (`into` type($existing)^)?
</code></pre><p>Round the inputs <code>sourceA</code> and <code>sourceB</code> (which is undefined if not
specified) into the low or high word (bottom two or top two) elements
of the returned vector, keeping the other two elements of <code>existing</code>
unchanged if present (or undefined if it was not passed in).</p><p>The reason for this odd signature is that AMD GPUs cannot easily work with
sub-registers, and so the conversion intrinsics (which are currently the
only way to work with 8-bit float types) take packed vectors of 4 8-bit
values.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-9>Attributes:&nbsp;<a class=headline-hash href=#attributes-9>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>wordIndex</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is non-negative whose maximum value is 1</td></tr></table><h4 id=operands-10>Operands:&nbsp;<a class=headline-hash href=#operands-10>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>sourceA</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>sourceB</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>existing</code></td><td>fixed-length vector of f8E4M3FNUZ type or f8E5M2FNUZ type or f8E4M3FN type or f8E5M2 type values of length 4</td></tr></tbody></table><h4 id=results-9>Results:&nbsp;<a class=headline-hash href=#results-9>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>fixed-length vector of f8E4M3FNUZ type or f8E5M2FNUZ type or f8E4M3FN type or f8E5M2 type values of length 4</td></tr></tbody></table><h3 id=amdgpupermlane_swap-amdgpupermlaneswapop><code>amdgpu.permlane_swap</code> (amdgpu::PermlaneSwapOp)&nbsp;<a class=headline-hash href=#amdgpupermlane_swap-amdgpupermlaneswapop>¶</a></h3><p><em>AMDGPU permlane swap op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.permlane_swap` $src $row_length attr-dict `:` type($result)
</code></pre><p>High-level wrapper on <code>rocdl.permlane{16,32}.swap</code> variants for permutations
on rows of lanes in a subgroup.</p><p>Supports arbitrary int/float/vector types, which will be repacked to i32 and
one or more <code>rocdl.permlane_swap</code> ops during lowering.
Supported lane permutations:</p><ul><li>Swap the data between odd and even rows of 16 lanes</li><li>Swap the data between the first 32 lanes and the last 32 lanes</li></ul><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%0</span> <span class=p>=</span> amdgpu<span class=p>.</span>permlane_swap <span class=nv>%src</span> <span class=m>16</span> <span class=p>:</span> <span class=k>f16</span>
</span></span><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> amdgpu<span class=p>.</span>permlane_swap <span class=nv>%src</span> <span class=m>32</span> <span class=p>{</span> <span class=nl>fetch_inactive =</span> true<span class=p>,</span> <span class=nl>bound_ctrl =</span> true <span class=p>}</span> <span class=p>:</span> <span class=k>f16</span>
</span></span></code></pre></div><p>Operands:</p><ul><li><code>$src</code>: Vector register to permute across lanes of the subgroup.</li><li><code>$row_length</code>: The length of a row to permute in number of lanes (valid values are 16 and 32).</li><li><code>$fetch_inactive</code>: Optional. Used to dertermine behavior of a fetch from a disabled lane.
<code>fetch_inactive = false</code>: If the source lane is disabled, use <code>bound_ctrl</code> to determine the source value.
<code>fetch_inactive = true</code>: If the source lane is disabled, fetch the source value anyway (ignoring <code>bound_ctrl</code>).</li><li><code>$bound_ctrl</code>: Optional. Used to determine what a thread should do if its source operand is from
a disabled lane: use the value zero, or disable the write.
<code>bound_ctrl = false</code>: Do not write when source is from a disabled lane
<code>bound_ctrl = true</code>: Use zero as input if source is from a disabled lane</li></ul><p>Note: Lowering is only supported on gfx950 and up.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-10>Attributes:&nbsp;<a class=headline-hash href=#attributes-10>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>row_length</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>fetch_inactive</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>bound_ctrl</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-11>Operands:&nbsp;<a class=headline-hash href=#operands-11>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>Integer or Float or fixed-length vector of Integer or Float values of ranks 1</td></tr></tbody></table><h4 id=results-10>Results:&nbsp;<a class=headline-hash href=#results-10>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>Integer or Float or fixed-length vector of Integer or Float values of ranks 1</td></tr></tbody></table><h3 id=amdgpuraw_buffer_atomic_cmpswap-amdgpurawbufferatomiccmpswapop><code>amdgpu.raw_buffer_atomic_cmpswap</code> (amdgpu::RawBufferAtomicCmpswapOp)&nbsp;<a class=headline-hash href=#amdgpuraw_buffer_atomic_cmpswap-amdgpurawbufferatomiccmpswapop>¶</a></h3><p><em>Raw Buffer Atomic compare-and-swap</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.raw_buffer_atomic_cmpswap` attr-dict $src `,` $cmp `-&gt;` $memref `[` $indices `]`
              (`sgprOffset` $sgprOffset^)? `:`
              type($value) `-&gt;` type($memref) `,` type($indices)
</code></pre><p>The <code>amdgpu.raw_buffer_atomic_cmpswap</code> op is a wrapper around the
buffer-based atomic compare-and-swap min available on AMD GPUs.</p><p>The index into the buffer is computed as for <code>memref.store</code> with the addition
of <code>indexOffset</code> (which is used to aid in emitting vectorized code) and,
if present <code>sgprOffset</code> (which is added after bounds checks and includes
any non-zero offset on the memref type).</p><p>All indexing components are given in terms of the memref&rsquo;s element size, not
the byte lengths required by the intrinsic.</p><p>Out of bounds atomic operations are ignored in hardware.</p><p>See <code>amdgpu.raw_buffer_load</code> for a description of how the underlying
instruction is constructed.</p><p>Traits: <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>InferTypeOpInterface</code></p><h4 id=attributes-11>Attributes:&nbsp;<a class=headline-hash href=#attributes-11>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>boundsCheck</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>indexOffset</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h4 id=operands-12>Operands:&nbsp;<a class=headline-hash href=#operands-12>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>any type</td></tr><tr><td style=text-align:center><code>cmp</code></td><td>any type</td></tr><tr><td style=text-align:center><code>memref</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>sgprOffset</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-11>Results:&nbsp;<a class=headline-hash href=#results-11>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>value</code></td><td>any type</td></tr></tbody></table><h3 id=amdgpuraw_buffer_atomic_fadd-amdgpurawbufferatomicfaddop><code>amdgpu.raw_buffer_atomic_fadd</code> (amdgpu::RawBufferAtomicFaddOp)&nbsp;<a class=headline-hash href=#amdgpuraw_buffer_atomic_fadd-amdgpurawbufferatomicfaddop>¶</a></h3><p><em>Raw Buffer Floating-point Atomic Add (MI-* only)</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.raw_buffer_atomic_fadd` attr-dict $value `-&gt;` $memref `[` $indices `]`
              (`sgprOffset` $sgprOffset^)? `:`
              type($value) `-&gt;` type($memref) `,` type($indices)
</code></pre><p>The <code>amdgpu.raw_buffer_atomic_fadd</code> op is a wrapper around the
buffer-based atomic floating point addition available on the MI-* series
of AMD GPUs.</p><p>The index into the buffer is computed as for <code>memref.store</code> with the addition
of <code>indexOffset</code> (which is used to aid in emitting vectorized code) and,
if present <code>sgprOffset</code> (which is added after bounds checks and includes
any non-zero offset on the memref type).</p><p>All indexing components are given in terms of the memref&rsquo;s element size, not
the byte lengths required by the intrinsic.</p><p>Out of bounds atomic operations are ignored in hardware.</p><p>See <code>amdgpu.raw_buffer_load</code> for a description of how the underlying
instruction is constructed.</p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-12>Attributes:&nbsp;<a class=headline-hash href=#attributes-12>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>boundsCheck</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>indexOffset</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h4 id=operands-13>Operands:&nbsp;<a class=headline-hash href=#operands-13>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>value</code></td><td>32-bit float or vector of 16-bit float or bfloat16 type values of length 2</td></tr><tr><td style=text-align:center><code>memref</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>sgprOffset</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=amdgpuraw_buffer_atomic_fmax-amdgpurawbufferatomicfmaxop><code>amdgpu.raw_buffer_atomic_fmax</code> (amdgpu::RawBufferAtomicFmaxOp)&nbsp;<a class=headline-hash href=#amdgpuraw_buffer_atomic_fmax-amdgpurawbufferatomicfmaxop>¶</a></h3><p><em>Raw Buffer Floating-point Atomic Max (non-GFX9)</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.raw_buffer_atomic_fmax` attr-dict $value `-&gt;` $memref `[` $indices `]`
              (`sgprOffset` $sgprOffset^)? `:`
              type($value) `-&gt;` type($memref) `,` type($indices)
</code></pre><p>The <code>amdgpu.raw_buffer_atomic_fmax</code> op is a wrapper around the
buffer-based atomic floating point max available on AMD GPUs (except GFX9).</p><p>The index into the buffer is computed as for <code>memref.store</code> with the addition
of <code>indexOffset</code> (which is used to aid in emitting vectorized code) and,
if present <code>sgprOffset</code> (which is added after bounds checks and includes
any non-zero offset on the memref type).</p><p>All indexing components are given in terms of the memref&rsquo;s element size, not
the byte lengths required by the intrinsic.</p><p>Out of bounds atomic operations are ignored in hardware.</p><p>See <code>amdgpu.raw_buffer_load</code> for a description of how the underlying
instruction is constructed.</p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-13>Attributes:&nbsp;<a class=headline-hash href=#attributes-13>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>boundsCheck</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>indexOffset</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h4 id=operands-14>Operands:&nbsp;<a class=headline-hash href=#operands-14>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>value</code></td><td>32-bit float or 64-bit float</td></tr><tr><td style=text-align:center><code>memref</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>sgprOffset</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=amdgpuraw_buffer_atomic_smax-amdgpurawbufferatomicsmaxop><code>amdgpu.raw_buffer_atomic_smax</code> (amdgpu::RawBufferAtomicSmaxOp)&nbsp;<a class=headline-hash href=#amdgpuraw_buffer_atomic_smax-amdgpurawbufferatomicsmaxop>¶</a></h3><p><em>Raw Buffer Signed Integer Atomic Max</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.raw_buffer_atomic_smax` attr-dict $value `-&gt;` $memref `[` $indices `]`
              (`sgprOffset` $sgprOffset^)? `:`
              type($value) `-&gt;` type($memref) `,` type($indices)
</code></pre><p>The <code>amdgpu.raw_buffer_atomic_smax</code> op is a wrapper around the
buffer-based atomic signed integer max available on AMD GPUs.</p><p>The index into the buffer is computed as for <code>memref.store</code> with the addition
of <code>indexOffset</code> (which is used to aid in emitting vectorized code) and,
if present <code>sgprOffset</code> (which is added after bounds checks and includes
any non-zero offset on the memref type).</p><p>All indexing components are given in terms of the memref&rsquo;s element size, not
the byte lengths required by the intrinsic.</p><p>Out of bounds atomic operations are ignored in hardware.</p><p>See <code>amdgpu.raw_buffer_load</code> for a description of how the underlying
instruction is constructed.</p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-14>Attributes:&nbsp;<a class=headline-hash href=#attributes-14>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>boundsCheck</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>indexOffset</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h4 id=operands-15>Operands:&nbsp;<a class=headline-hash href=#operands-15>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>value</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>memref</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>sgprOffset</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=amdgpuraw_buffer_atomic_umin-amdgpurawbufferatomicuminop><code>amdgpu.raw_buffer_atomic_umin</code> (amdgpu::RawBufferAtomicUminOp)&nbsp;<a class=headline-hash href=#amdgpuraw_buffer_atomic_umin-amdgpurawbufferatomicuminop>¶</a></h3><p><em>Raw Buffer Unsigned Integer Atomic Min</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.raw_buffer_atomic_umin` attr-dict $value `-&gt;` $memref `[` $indices `]`
              (`sgprOffset` $sgprOffset^)? `:`
              type($value) `-&gt;` type($memref) `,` type($indices)
</code></pre><p>The <code>amdgpu.raw_buffer_atomic_umin</code> op is a wrapper around the
buffer-based atomic signed integer min available on AMD GPUs.</p><p>The index into the buffer is computed as for <code>memref.store</code> with the addition
of <code>indexOffset</code> (which is used to aid in emitting vectorized code) and,
if present <code>sgprOffset</code> (which is added after bounds checks and includes
any non-zero offset on the memref type).</p><p>All indexing components are given in terms of the memref&rsquo;s element size, not
the byte lengths required by the intrinsic.</p><p>Out of bounds atomic operations are ignored in hardware.</p><p>See <code>amdgpu.raw_buffer_load</code> for a description of how the underlying
instruction is constructed.</p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-15>Attributes:&nbsp;<a class=headline-hash href=#attributes-15>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>boundsCheck</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>indexOffset</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h4 id=operands-16>Operands:&nbsp;<a class=headline-hash href=#operands-16>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>value</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>memref</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>sgprOffset</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=amdgpuraw_buffer_load-amdgpurawbufferloadop><code>amdgpu.raw_buffer_load</code> (amdgpu::RawBufferLoadOp)&nbsp;<a class=headline-hash href=#amdgpuraw_buffer_load-amdgpurawbufferloadop>¶</a></h3><p><em>Raw Buffer load, exposing GCN features</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.raw_buffer_load` attr-dict $memref `[` $indices `]`
              (`sgprOffset` $sgprOffset^)? `:`
              type($memref) (`,` type($indices)^)? `-&gt;` type($value)
</code></pre><p>The <code>amdgpu.raw_buffer_load</code> op is a wrapper around the buffer load intrinsics
available on AMD GPUs, including extensions in newer GPUs.</p><p>The index into the buffer is computed as for <code>memref.load</code> with the additon
of <code>indexOffset</code> and <code>sgprOffset</code> (which <strong>may or may not</strong> be considered
in bounds checks and includes any offset present on the memref type if it&rsquo;s
non-zero).</p><p>All indices and offsets are in units of the memref&rsquo;s data type and are
converted to bytes during lowering.</p><p>When a load is out of bounds, the instruction returns zero.
Partially-out of bounds have chipset-dependent behavior: whether reading
2 elements starting at index 7 of a <code>memref&lt;8xf32></code> returns the last element
in the first vector component depends on the architecture.</p><p>The memref struct is converted into a buffer resource (a V#) and the arguments
are translated to intrinsic arguments as follows:</p><ul><li>The base address of the buffer is the base address of the memref</li><li>The stride is 0 to enable raw mode</li><li>The number of records is the size of the memref, in bytes
In the case of dynamically-shaped memrefs, this is computed at runtime
as max_d (size(d) * stride(d)) * sizeof(elementType(memref))</li><li>The offset enable bit is 1, the index enable bit is 0.</li><li>The thread ID addition bit is off</li><li>If <code>boundsCheck</code> is false and the target chipset is RDNA, OOB_SELECT is set
to 2 to disable bounds checks, otherwise it is 3</li><li>The cache coherency bits are off</li></ul><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-16>Attributes:&nbsp;<a class=headline-hash href=#attributes-16>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>boundsCheck</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>indexOffset</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h4 id=operands-17>Operands:&nbsp;<a class=headline-hash href=#operands-17>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>memref</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>sgprOffset</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-12>Results:&nbsp;<a class=headline-hash href=#results-12>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>value</code></td><td>any type</td></tr></tbody></table><h3 id=amdgpuraw_buffer_store-amdgpurawbufferstoreop><code>amdgpu.raw_buffer_store</code> (amdgpu::RawBufferStoreOp)&nbsp;<a class=headline-hash href=#amdgpuraw_buffer_store-amdgpurawbufferstoreop>¶</a></h3><p><em>Raw Buffer Store, exposing GCN features</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.raw_buffer_store` attr-dict $value `-&gt;` $memref `[` $indices `]`
              (`sgprOffset` $sgprOffset^)? `:`
              type($value) `-&gt;` type($memref) (`,` type($indices)^)?
</code></pre><p>The <code>amdgpu.raw_buffer_store</code> op is a wrapper around the buffer store
intrinsics available on AMD GPUs, including extensions in newer GPUs.</p><p>The store index is computed as in <code>memref.store</code> with the addition of
<code>indexOffset</code> (which is included for uniformity with atomics and may be useful
when writing vectorized code) and <code>sgprOffset</code> (which is added after bounds
checks and implicitly includes the offset of the memref type if non-zero).
All index components are in terms of the elements of the memref, not bytes,
and are scaled up appropriately.</p><p>Out of bounds stores are ignored in hardware.
Wthether a vector write that includes some in-bounds and soeme out-of-bounds
components is partically completed is chipset-dependent.</p><p>See <code>amdgpu.raw_buffer_load</code> for a description of how the underlying
instruction is constructed.</p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-17>Attributes:&nbsp;<a class=headline-hash href=#attributes-17>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>boundsCheck</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>indexOffset</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h4 id=operands-18>Operands:&nbsp;<a class=headline-hash href=#operands-18>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>value</code></td><td>any type</td></tr><tr><td style=text-align:center><code>memref</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>sgprOffset</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=amdgpuscaled_ext_packed-amdgpuscaledextpackedop><code>amdgpu.scaled_ext_packed</code> (amdgpu::ScaledExtPackedOp)&nbsp;<a class=headline-hash href=#amdgpuscaled_ext_packed-amdgpuscaledextpackedop>¶</a></h3><p><em>Extend a vector of packed floating point values</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.scaled_ext_packed` attr-dict $source `[` $index `]` `,` $scale `:` type($source) `to` type($res)
</code></pre><p>Extend and scale two packed floats in <code>source[index]</code> to two floats and
return them.</p><p>This rather unusual signature arises from the fact that AMD GPUs cannot
easily work with sub 32-bit quantities, so the compiler intrinsics for
extending 8-bit floats (which are, currently, the only way to work with
this operation) take packed vectors of 2 such floats.</p><p>If the passed-in vector has fewer than two elements, or the input is scalar,
the remaining values in the &lt;2 x i8> will be filled with
undefined values as needed.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-18>Attributes:&nbsp;<a class=headline-hash href=#attributes-18>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>index</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is non-negative whose maximum value is 7</td></tr></table><h4 id=operands-19>Operands:&nbsp;<a class=headline-hash href=#operands-19>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>vector of f8E5M2 type or f8E4M3FN type values of length 1/2/3/4 or vector of f4E2M1FN type values of length 1/2/3/4/5/6/7/8</td></tr><tr><td style=text-align:center><code>scale</code></td><td>32-bit float</td></tr></tbody></table><h4 id=results-13>Results:&nbsp;<a class=headline-hash href=#results-13>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>fixed-length vector of 32-bit float values of length 2 or fixed-length vector of 16-bit float values of length 2 or fixed-length vector of bfloat16 type values of length 2</td></tr></tbody></table><h3 id=amdgpuscaled_ext_packed_matrix-amdgpuscaledextpackedmatrixop><code>amdgpu.scaled_ext_packed_matrix</code> (amdgpu::ScaledExtPackedMatrixOp)&nbsp;<a class=headline-hash href=#amdgpuscaled_ext_packed_matrix-amdgpuscaledextpackedmatrixop>¶</a></h3><p><em>Extend a wave-wide matrix of packed floating point values</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.scaled_ext_packed_matrix` attr-dict $source
              `scale` `(` $scale `)`
              `blockSize` `(` $blockSize `)`
              `firstScaleLane` `(` $firstScaleLane`)`
              `firstScaleByte` `(` $firstScaleByte `)`
              `:` type($source) `,` type($scale) `-&gt;` type($res)
</code></pre><p>Extend matrix of microfloats (8 or 16 elements per lane) using a set of scales
that may be stored on other lanes.</p><p>The scales applied to the input microfloats are stored in bytes which
come from the <code>scales</code> input provided in a <em>half</em> of the wave identified
by <code>firstScaleLane</code>. The bytes used is selected by <code>firstScaleByte</code> and depends
on the type of <code>source</code>. The 16 vectors in consecutive lanes starting from
<code>firstScaleLane</code> (which we&rsquo;ll call the scale vectors) will be used by both
halves of the wave (with lane L reading from L % 16&rsquo;th scale vector).</p><p>When <code>source</code> is either F4E2M1FN, F6E2M3FN, or F6E3M2FN each half of the
wave will use a different byte. The first one being <code>firstScaleByte</code> and
the second one being <code>firstScaleByte</code> + 1. When the block size is 32,
<code>firstScaleByte</code> can be either 0 or 2, selecting halves of the scale vectors.
Lanes 0-15 will read from <code>firstScaleByte</code> and lanes 16-31 will read
from <code>firstScaleByte</code> + 1.</p><p>For example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// Input: 8-element vector of F8E4M3FN, converting to F32
</span></span></span><span class=line><span class=cl><span class=c>// Lanes 0-15 read from byte 0, lanes 16-31 read from byte 1
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%result</span> <span class=p>=</span> amdgpu<span class=p>.</span>scaled_ext_packed_matrix <span class=nv>%source</span> scale<span class=p>(</span><span class=nv>%scales</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  blockSize<span class=p>(</span><span class=m>32</span><span class=p>)</span> firstScaleLane<span class=p>(</span><span class=m>0</span><span class=p>)</span> firstScaleByte<span class=p>(</span><span class=m>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span>f8E4M3FN<span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span>f8E8M0FNU<span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Input: 16-element vector of F6E2M3FN, converting to F16
</span></span></span><span class=line><span class=cl><span class=c>// Lanes 0-15 read from byte 2, lanes 16-31 read from byte 3
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%result</span> <span class=p>=</span> amdgpu<span class=p>.</span>scaled_ext_packed_matrix <span class=nv>%source</span> scale<span class=p>(</span><span class=nv>%scales</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  blockSize<span class=p>(</span><span class=m>32</span><span class=p>)</span> firstScaleLane<span class=p>(</span><span class=m>16</span><span class=p>)</span> firstScaleByte<span class=p>(</span><span class=m>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span>f6E2M3FN<span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span>f8E8M0FNU<span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f16</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>When <code>source</code> is either F4E2M1FN, F6E2M3FN, or F6E3M2FN and
the block size is 16, <code>firstScaleByte</code> can be 0 or 1.
Lanes 0-15 read from the <code>firstScaleByte</code>th element of the scale vectors,
while lanes 16-31 read from <code>firstScaleByte</code> + 2.
For example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// Input: 8-element vector of F8E5M2, converting to BF16
</span></span></span><span class=line><span class=cl><span class=c>// Lanes 0-15 read from byte 0, lanes 16-31 read from byte 2 (0+2)
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%result</span> <span class=p>=</span> amdgpu<span class=p>.</span>scaled_ext_packed_matrix <span class=nv>%source</span> scale<span class=p>(</span><span class=nv>%scales</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  blockSize<span class=p>(</span><span class=m>16</span><span class=p>)</span> firstScaleLane<span class=p>(</span><span class=m>0</span><span class=p>)</span> firstScaleByte<span class=p>(</span><span class=m>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span>f8E5M2<span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span>f8E8M0FNU<span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>bf16</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Input: 16-element vector of F6E3M2FN, converting to F32
</span></span></span><span class=line><span class=cl><span class=c>// Lanes 0-15 read from byte 1, lanes 16-31 read from byte 3 (1+2)
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%result</span> <span class=p>=</span> amdgpu<span class=p>.</span>scaled_ext_packed_matrix <span class=nv>%source</span> scale<span class=p>(</span><span class=nv>%scales</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  blockSize<span class=p>(</span><span class=m>16</span><span class=p>)</span> firstScaleLane<span class=p>(</span><span class=m>16</span><span class=p>)</span> firstScaleByte<span class=p>(</span><span class=m>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span>f6E3M2FN<span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span>f8E8M0FNU<span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Note: the layout for the scales generally mirrors how the WMMA
instructions use for matrix scales. These selection operands allows
one to choose portions of the matrix to convert.</p><p>When <code>source</code> is either F8E4M3FN or F8E5M2 and <code>blockSize</code> is 32,
then the same byte will be used by both halves of the wave.
In this case, <code>firstScaleByte</code> can be any value from 0 to 3.</p><p>When <code>source</code> is either F8E4M3FN or F8E5M2 and <code>blockSize</code> is 16,
following combinations are allowed:</p><ul><li><code>firstScaleLane(0), firstScaleByte(0)</code></li><li><code>firstScaleLane(16), firstScaleByte(2)</code>
all other combinations are reserved.</li></ul><p>Available on gfx1250+.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-19>Attributes:&nbsp;<a class=headline-hash href=#attributes-19>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>blockSize</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {16, 32}</td></tr><tr><td><code>firstScaleLane</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {0, 16}</td></tr><tr><td><code>firstScaleByte</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose minimum value is 0 whose maximum value is 3</td></tr></table><h4 id=operands-20>Operands:&nbsp;<a class=headline-hash href=#operands-20>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>vector&lt;8xF4E2M1FN> of f4E2M1FN type values or vector&lt;8xF8E4M3FN> of f8E4M3FN type values or vector&lt;8xF8E5M2> of f8E5M2 type values or vector&lt;16xF6E2M3FN> of f6E2M3FN type values or vector&lt;16xF6E3M2FN> of f6E3M2FN type values</td></tr><tr><td style=text-align:center><code>scale</code></td><td>vector&lt;4xF8E8M0FNU> of f8E8M0FNU type values</td></tr></tbody></table><h4 id=results-14>Results:&nbsp;<a class=headline-hash href=#results-14>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>vector&lt;8xF32> of 32-bit float values or vector&lt;8xF16> of 16-bit float values or vector&lt;8xBF16> of bfloat16 type values or vector&lt;16xF32> of 32-bit float values or vector&lt;16xF16> of 16-bit float values or vector&lt;16xBF16> of bfloat16 type values</td></tr></tbody></table><h3 id=amdgpuscaled_mfma-amdgpuscaledmfmaop><code>amdgpu.scaled_mfma</code> (amdgpu::ScaledMFMAOp)&nbsp;<a class=headline-hash href=#amdgpuscaled_mfma-amdgpuscaledmfmaop>¶</a></h3><p><em>MLIR wrapper for CDNA scaled mfma instructions</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.scaled_mfma` custom&lt;MNKDimensionList&gt;($m, $n, $k) ` `
              `(` $scalesA `[` $scalesIdxA `]` `*` $sourceA `)` `*`
              `(` $scalesB `[` $scalesIdxB `]` `*` $sourceB `)` `+` $destC
              attr-dict
              `:` type($scalesA) `,` type($sourceA) `,` type($scalesB) `,` type($sourceB) `,` type($destC)
</code></pre><p>The <code>amdgpu.scaled_mfma</code> op is an MLIR wrapper around intrinsics
for various scaled versions of <code>mfma</code> instructions in the CDNA architecture, which
perform multiple outer products in order to allow fast matrix multiplication.</p><p>The wrapper will select an appropriate <code>mfma</code> instruction, if one is available,
based on the provided <code>m</code>, <code>k</code>, <code>n</code>, and <code>nBlks</code> attributes, along with the
types of the source and destination arguments.</p><p>Note, this wrapper allows specifying <code>vector&lt;4Kxi8></code> arguments to MFMA
intrinsics that take an integer type of width <code>4K</code>. For example,
one can provide a <code>vector&lt;4xi8></code> as an argument to an MFMA instruction that
logically takes 4 i8s but whose intrinsics are specified to take an i32.
In these cases, the bytes in the vector will be concatenated in little-endian
order (that is, v[0] will go to arg[7:0], v[1] to arg[15:8] and so on).</p><p>This wrapper takes inspiration from <code>amdgpu.mfma</code>, but has some key differences:</p><ul><li><code>amdgpu.scaled_mfma</code> operates on fp4 (f4E2M1FN), fp6 (f6E2M3FN and f6E3M2FN) and
fp8 (f8E4M3FN and f8E5M2) types using either M=N=16, K=128 or M=N=32, K=64 as
their tile size.</li><li><code>amdgpu.scaled_mfma</code> does not support broadcasting. So, <code>cbsz</code>, <code>abid</code>, and <code>blgp</code>
are omitted from this wrapper.</li><li>The <code>negateA</code>, <code>negateB</code>, and <code>negateC</code> flags in <code>amdgpu.mfma</code> are only supported
for double-precision operations on gfx94x and so are not included here.</li></ul><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  <span class=nv>%0</span> <span class=p>=</span> amdgpu<span class=p>.</span>scaled_mfma <span class=m>32x32x64</span> <span class=p>(</span><span class=nv>%arg0</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>*</span> <span class=nv>%arg1</span><span class=p>)</span> <span class=p>*</span> <span class=p>(</span><span class=nv>%arg0</span><span class=p>[</span><span class=m>1</span><span class=p>]</span> <span class=p>*</span> <span class=nv>%arg1</span><span class=p>)</span> <span class=err>+</span> <span class=nv>%arg2</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span>f8E8M0FNU<span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x</span>f6E2M3FN<span class=p>&gt;,</span> f8E8M0FNU<span class=p>,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x</span>f6E2M3FN<span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-20>Attributes:&nbsp;<a class=headline-hash href=#attributes-20>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>m</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {16, 32}</td></tr><tr><td><code>n</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {16, 32}</td></tr><tr><td><code>k</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {64, 128}</td></tr><tr><td><code>scalesIdxA</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is non-negative whose maximum value is 3</td></tr><tr><td><code>scalesIdxB</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is non-negative whose maximum value is 3</td></tr></table><h4 id=operands-21>Operands:&nbsp;<a class=headline-hash href=#operands-21>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>sourceA</code></td><td>vector of f8E5M2 type or f8E4M3FN type values of length 32 or vector of f6E2M3FN type or f6E3M2FN type or f4E2M1FN type values of length 32</td></tr><tr><td style=text-align:center><code>sourceB</code></td><td>vector of f8E5M2 type or f8E4M3FN type values of length 32 or vector of f6E2M3FN type or f6E3M2FN type or f4E2M1FN type values of length 32</td></tr><tr><td style=text-align:center><code>destC</code></td><td>vector of 32-bit float values of length 4/16</td></tr><tr><td style=text-align:center><code>scalesA</code></td><td>f8E8M0FNU type or fixed-length vector of f8E8M0FNU type values of length 4</td></tr><tr><td style=text-align:center><code>scalesB</code></td><td>f8E8M0FNU type or fixed-length vector of f8E8M0FNU type values of length 4</td></tr></tbody></table><h4 id=results-15>Results:&nbsp;<a class=headline-hash href=#results-15>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>destD</code></td><td>vector of 32-bit float values of length 4/16</td></tr></tbody></table><h3 id=amdgpusched_barrier-amdgpuschedbarrierop><code>amdgpu.sched_barrier</code> (amdgpu::SchedBarrierOp)&nbsp;<a class=headline-hash href=#amdgpusched_barrier-amdgpuschedbarrierop>¶</a></h3><p><em>Barrier that limits the backend scheduler of instruction movement</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.sched_barrier` `allow` `=` $opts attr-dict
</code></pre><p><code>amdgpu.sched_barrier</code> serves as a barrier that could be
configured to restrict movements of instructions through it as
defined by sched_barrier_opts.</p><h4 id=attributes-21>Attributes:&nbsp;<a class=headline-hash href=#attributes-21>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>opts</code></td><td>::mlir::amdgpu::sched_barrier_opt_enumAttr</td><td>The possible options for scheduling barriers</td></tr></table><h3 id=amdgpuswizzle_bitmode-amdgpuswizzlebitmodeop><code>amdgpu.swizzle_bitmode</code> (amdgpu::SwizzleBitModeOp)&nbsp;<a class=headline-hash href=#amdgpuswizzle_bitmode-amdgpuswizzlebitmodeop>¶</a></h3><p><em>AMDGPU ds_swizzle op, bitmode variant</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.swizzle_bitmode` $src $and_mask $or_mask $xor_mask attr-dict `:` type($result)
</code></pre><p>High-level wrapper on bitmode <code>rocdl.ds_swizzle</code> op, masks are represented
as separate fields so user won&rsquo;t need to do manual bitpacking.</p><p>Supports arbitrary int/float/vector types, which will be repacked to i32 and
one or more <code>rocdl.ds_swizzle</code> ops during lowering.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-22>Attributes:&nbsp;<a class=headline-hash href=#attributes-22>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>and_mask</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>or_mask</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>xor_mask</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h4 id=operands-22>Operands:&nbsp;<a class=headline-hash href=#operands-22>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>Integer or Float or fixed-length vector of Integer or Float values of ranks 1</td></tr></tbody></table><h4 id=results-16>Results:&nbsp;<a class=headline-hash href=#results-16>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>Integer or Float or fixed-length vector of Integer or Float values of ranks 1</td></tr></tbody></table><h3 id=amdgputranspose_load-amdgputransposeloadop><code>amdgpu.transpose_load</code> (amdgpu::TransposeLoadOp)&nbsp;<a class=headline-hash href=#amdgputranspose_load-amdgputransposeloadop>¶</a></h3><p><em>MLIR wrapper for CDNA Transpose Load instructions</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.transpose_load` $src `[` $srcIndices `]` attr-dict `:` type($src) `-&gt;` type($result)
</code></pre><p>The <code>amdgpu.transpose_load</code> op is a wrapper around the <code>ds_read_tr</code> instructions.
The transpose load op represents a subgroup load from LDS memory,
where the subgroup of threads collectively reads a matrix from the source
memref, with each thread reading a vector of the matrix, and gets a transposed matrix
in as the result. That is, each thread reads a vector of the col-major matrix at different
indices, and the thread&rsquo;s read result is a vector of the corresponding row of the transposed
matrix.</p><p>This op is a direct wrapper around the ROCDL <code>ds_read_tr</code> family intrinsics. Please refer
to the CDNA4 ISA documentation for more details about its exact semantics.</p><p>Format example:</p><pre tabindex=0><code>%0 = amdgpu.transpose_load %src[%srcIndices] : memref&lt;128x256xf16&gt; -&gt; vector&lt;4xf16&gt;
</code></pre><p>Operands:</p><ul><li><code>$src</code>: LDS memref to read from.</li><li><code>$srcIndices</code>: indices into <code>$src</code> to read from for this thread.</li><li><code>$result</code>: target register this transpose load instruction will write to.</li></ul><p>Note: Lowering is only supported on gfx950 and up.</p><p>Traits: <code>SameVariadicOperandSize</code></p><h4 id=operands-23>Operands:&nbsp;<a class=headline-hash href=#operands-23>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>srcIndices</code></td><td>variadic of index</td></tr></tbody></table><h4 id=results-17>Results:&nbsp;<a class=headline-hash href=#results-17>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=amdgpuwmma-amdgpuwmmaop><code>amdgpu.wmma</code> (amdgpu::WMMAOp)&nbsp;<a class=headline-hash href=#amdgpuwmma-amdgpuwmmaop>¶</a></h3><p><em>MLIR wrapper for wmma instructions</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `amdgpu.wmma` custom&lt;MNKDimensionList&gt;($m, $n, $k) $sourceA `*` $sourceB `+` $destC
              attr-dict
              `:` type($sourceA) `,` type($sourceB) `,` type($destC)
</code></pre><p>The <code>amdgpu.wmma</code> op is an MLIR wrapper around intrinsics for various <code>wmma</code>
instructions in the AMDGPU architecture, which perform matrix multiplication.</p><p>On gfx11/RDNA3, wmma intrinsics have M=N=K=16 dimensions.</p><p>On gfx12/RDNA4, wmma intrinsics have M=N=16 dimensions and support K=16 for
all element types, and K=32 for i4 sources.</p><p>On gfx1250, wmma intrinsics have M=N=16 and K dimensions of 4, 32, 64, or 128,
depending on the element types.</p><p>On gfx11/RDNA3, emitting f16->f16 (or bf16->bf16) wmma the output is a 16xf16
(or 16xbf16) vector containing only 8 valid values:</p><ul><li>If <code>subwordOffset</code> is 0, then the output is stored at indices 0, 2, 4, &mldr;, 14.</li><li>If <code>subwordOffset</code> is 1, then the output is stored at indices 1, 3, 5, &mldr;, 15.
On gfx12/RDNA4 and gfx1250, the result is instead returned as vector where all
the values are valid and the <code>subwordOffset</code> must be <code>0</code>, as it cannot be used.</li></ul><p><code>unsignedA</code> and <code>unsignedB</code> flag that the <code>int8</code> LLVM inputs are unsigned.</p><p>The <code>clamp</code> flag is used to saturate the output of type T to <code>numeric_limits&lt;T>::max()</code>
in case of overflow.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  <span class=nv>%0</span> <span class=p>=</span> amdgpu<span class=p>.</span>wmma <span class=m>16x16x16</span> <span class=nv>%matA</span> <span class=p>*</span> <span class=nv>%matB</span> <span class=err>+</span> <span class=nv>%matC</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f16</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nv>%1</span> <span class=p>=</span> amdgpu<span class=p>.</span>wmma <span class=m>16x16x64</span> <span class=nv>%matD</span> <span class=p>*</span> <span class=nv>%matE</span> <span class=err>+</span> <span class=nv>%matF</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>i8</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nv>%2</span> <span class=p>=</span> amdgpu<span class=p>.</span>wmma <span class=m>16x16x128</span> <span class=nv>%matG</span> <span class=p>*</span> <span class=nv>%matH</span> <span class=err>+</span> <span class=nv>%matI</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>64x</span>f4E2M1FN<span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>64x</span>f4E2M1FN<span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nv>%3</span> <span class=p>=</span> amdgpu<span class=p>.</span>wmma <span class=m>16x16x4</span> <span class=nv>%matJ</span> <span class=p>*</span> <span class=nv>%matK</span> <span class=err>+</span> <span class=nv>%matL</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-23>Attributes:&nbsp;<a class=headline-hash href=#attributes-23>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>m</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {16}</td></tr><tr><td><code>n</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {16}</td></tr><tr><td><code>k</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {4, 16, 32, 64, 128}</td></tr><tr><td><code>subwordOffset</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose value is one of {0, 1}</td></tr><tr><td><code>unsignedA</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>unsignedB</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>clamp</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h4 id=operands-24>Operands:&nbsp;<a class=headline-hash href=#operands-24>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>sourceA</code></td><td>vector of 32-bit float values of length 2 or vector of 16-bit float or bfloat16 type values of length 4/8/16 or vector of 8-bit signless integer or 8-bit signed integer or 8-bit unsigned integer values of length 4/8/16/32 or vector of f8E4M3FN type or f8E5M2 type values of length 4/8/32/64 or vector of 4-bit signless integer or 4-bit signed integer or 4-bit unsigned integer values of length 4/8/16</td></tr><tr><td style=text-align:center><code>sourceB</code></td><td>vector of 32-bit float values of length 2 or vector of 16-bit float or bfloat16 type values of length 4/8/16 or vector of 8-bit signless integer or 8-bit signed integer or 8-bit unsigned integer values of length 4/8/16/32 or vector of f8E4M3FN type or f8E5M2 type values of length 4/8/32/64 or vector of 4-bit signless integer or 4-bit signed integer or 4-bit unsigned integer values of length 4/8/16</td></tr><tr><td style=text-align:center><code>destC</code></td><td>vector of 32-bit float or 32-bit signless integer values of length 4/8 or vector of 16-bit float or bfloat16 type values of length 4/8/16</td></tr></tbody></table><h4 id=results-18>Results:&nbsp;<a class=headline-hash href=#results-18>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>destD</code></td><td>vector of 32-bit float or 32-bit signless integer values of length 4/8 or vector of 16-bit float or bfloat16 type values of length 4/8/16</td></tr></tbody></table><h2 id=attributes-24>Attributes&nbsp;<a class=headline-hash href=#attributes-24>¶</a></h2><h3 id=addressspaceattr>AddressSpaceAttr&nbsp;<a class=headline-hash href=#addressspaceattr>¶</a></h3><p><em>AMDGPU-specific address spaces</em></p><p>Syntax:</p><pre tabindex=0><code>#amdgpu.address_space&lt;
  ::mlir::amdgpu::AddressSpace   # value
&gt;
</code></pre><p>AMDGPU-specific memory spaces that may not have exact analogues on other
GPU targets or backends.</p><ul><li><code>fat_raw_buffer</code> is the memory space used when a memref is stored as
as a &ldquo;buffer fat pointer&rdquo; - that is, a buffer resource (that is set up to
use raw byte-level indexing) along with its offset. The AMDGPU backend
implements <code>ptr addrspace(7)</code> to represent these fat pointers so that
buffer resources (which allow advanced features like bounds checking or
cache swizzling) can be used like ordinary LLVM pointers or memrefs.
See also the <code>fat_raw_buffer_cast</code> operation</li><li><code>buffer_rsrc</code> is the memory space for <code>ptr addrspace(8)</code>, representing a
buffer resource. It should not be used for memrefs, since it does not support
indexing</li><li><code>fat_structured_buffer</code> represents <code>ptr addrspace(9)</code>, a buffer resource
that carries both an index and offset field, which are used for complex
structured indexing that is primarily seen in graphics applications. This
is also incompatible with the simple indexing model supported by memref.</li></ul><h4 id=parameters>Parameters:&nbsp;<a class=headline-hash href=#parameters>¶</a></h4><table><thead><tr><th style=text-align:center>Parameter</th><th style=text-align:center>C++ type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>value</td><td style=text-align:center><code>::mlir::amdgpu::AddressSpace</code></td><td>an enum of type AddressSpace</td></tr></tbody></table><h3 id=dpppermattr>DPPPermAttr&nbsp;<a class=headline-hash href=#dpppermattr>¶</a></h3><p><em>The possible permutations for a DPP operation</em></p><p>Syntax:</p><pre tabindex=0><code>#amdgpu.dpp_perm&lt;
  ::mlir::amdgpu::DPPPerm   # value
&gt;
</code></pre><h4 id=parameters-1>Parameters:&nbsp;<a class=headline-hash href=#parameters-1>¶</a></h4><table><thead><tr><th style=text-align:center>Parameter</th><th style=text-align:center>C++ type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>value</td><td style=text-align:center><code>::mlir::amdgpu::DPPPerm</code></td><td>an enum of type DPPPerm</td></tr></tbody></table><h3 id=mfmapermbattr>MFMAPermBAttr&nbsp;<a class=headline-hash href=#mfmapermbattr>¶</a></h3><p><em>The possible permutations of the lanes storing B available in an MFMA</em></p><p>Syntax:</p><pre tabindex=0><code>#amdgpu.mfma_perm_b&lt;
  ::mlir::amdgpu::MFMAPermB   # value
&gt;
</code></pre><h4 id=parameters-2>Parameters:&nbsp;<a class=headline-hash href=#parameters-2>¶</a></h4><table><thead><tr><th style=text-align:center>Parameter</th><th style=text-align:center>C++ type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>value</td><td style=text-align:center><code>::mlir::amdgpu::MFMAPermB</code></td><td>an enum of type MFMAPermB</td></tr></tbody></table><h3 id=sched_barrier_opt_enumattr>sched_barrier_opt_enumAttr&nbsp;<a class=headline-hash href=#sched_barrier_opt_enumattr>¶</a></h3><p><em>The possible options for scheduling barriers</em></p><p>Syntax:</p><pre tabindex=0><code>#amdgpu.sched_barrier_opt&lt;
  ::mlir::amdgpu::sched_barrier_opt_enum   # value
&gt;
</code></pre><h4 id=parameters-3>Parameters:&nbsp;<a class=headline-hash href=#parameters-3>¶</a></h4><table><thead><tr><th style=text-align:center>Parameter</th><th style=text-align:center>C++ type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>value</td><td style=text-align:center><code>::mlir::amdgpu::sched_barrier_opt_enum</code></td><td>an enum of type sched_barrier_opt_enum</td></tr></tbody></table><h2 id=types>Types&nbsp;<a class=headline-hash href=#types>¶</a></h2><h3 id=tdmbasetype>TDMBaseType&nbsp;<a class=headline-hash href=#tdmbasetype>¶</a></h3><p><em>Pair of base addresses that move data between LDS and global storage.</em></p><p>Syntax:</p><pre tabindex=0><code>!amdgpu.tdm_base&lt;
  Type   # elementType
&gt;
</code></pre><p>This type is opaque and it is used to represent a struct of two addresses.
One address is in LDS while the other is in global memory.</p><p>The value defined by this operation is only intended to be used by
amdgpu.tdm_make_descriptor.</p><h4 id=parameters-4>Parameters:&nbsp;<a class=headline-hash href=#parameters-4>¶</a></h4><table><thead><tr><th style=text-align:center>Parameter</th><th style=text-align:center>C++ type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>elementType</td><td style=text-align:center><code>Type</code></td><td></td></tr></tbody></table><h3 id=tdmdescriptortype>TDMDescriptorType&nbsp;<a class=headline-hash href=#tdmdescriptortype>¶</a></h3><p><em>Descriptors used in tensor store/load operations.</em></p><p>Syntax: <code>!amdgpu.tdm_descriptor</code></p><p>This type is opaque and corresponds to the two or four descriptor groups
used in tensor_load_to_lds or tensor_store_from_lds.</p><h3 id=tdmgatherbasetype>TDMGatherBaseType&nbsp;<a class=headline-hash href=#tdmgatherbasetype>¶</a></h3><p><em>Pair of base addresses that move data between LDS and global storage.</em></p><p>Syntax:</p><pre tabindex=0><code>!amdgpu.tdm_gather_base&lt;
  Type,   # elementType
  Type   # indexType
&gt;
</code></pre><p>This type is opaque and it is used to represent a struct of two addresses.
One address is in LDS while the other is in global memory.</p><p>This operation is similar to amdgpu.tdm_make_base but intended to be
used in gather mode.</p><p>The value defined by this operation is only intended to be used by
amdgpu.tdm_make_gather_descriptor.</p><h4 id=parameters-5>Parameters:&nbsp;<a class=headline-hash href=#parameters-5>¶</a></h4><table><thead><tr><th style=text-align:center>Parameter</th><th style=text-align:center>C++ type</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>elementType</td><td style=text-align:center><code>Type</code></td><td></td></tr><tr><td style=text-align:center>indexType</td><td style=text-align:center><code>Type</code></td><td></td></tr></tbody></table><h2 id=enums>Enums&nbsp;<a class=headline-hash href=#enums>¶</a></h2><h3 id=addressspace>AddressSpace&nbsp;<a class=headline-hash href=#addressspace>¶</a></h3><p><em>AMDGPU-specific address spaces</em></p><h4 id=cases>Cases:&nbsp;<a class=headline-hash href=#cases>¶</a></h4><table><thead><tr><th style=text-align:center>Symbol</th><th style=text-align:center>Value</th><th>String</th></tr></thead><tbody><tr><td style=text-align:center>FatRawBuffer</td><td style=text-align:center><code>0</code></td><td>fat_raw_buffer</td></tr><tr><td style=text-align:center>BufferRsrc</td><td style=text-align:center><code>1</code></td><td>buffer_rsrc</td></tr><tr><td style=text-align:center>FatStructuredBuffer</td><td style=text-align:center><code>2</code></td><td>fat_structured_buffer</td></tr></tbody></table><h3 id=dppperm>DPPPerm&nbsp;<a class=headline-hash href=#dppperm>¶</a></h3><p><em>The possible permutations for a DPP operation</em></p><h4 id=cases-1>Cases:&nbsp;<a class=headline-hash href=#cases-1>¶</a></h4><table><thead><tr><th style=text-align:center>Symbol</th><th style=text-align:center>Value</th><th>String</th></tr></thead><tbody><tr><td style=text-align:center>quad_perm</td><td style=text-align:center><code>0</code></td><td>quad_perm</td></tr><tr><td style=text-align:center>row_shl</td><td style=text-align:center><code>1</code></td><td>row_shl</td></tr><tr><td style=text-align:center>row_shr</td><td style=text-align:center><code>2</code></td><td>row_shr</td></tr><tr><td style=text-align:center>row_ror</td><td style=text-align:center><code>3</code></td><td>row_ror</td></tr><tr><td style=text-align:center>wave_shl</td><td style=text-align:center><code>4</code></td><td>wave_shl</td></tr><tr><td style=text-align:center>wave_shr</td><td style=text-align:center><code>5</code></td><td>wave_shr</td></tr><tr><td style=text-align:center>wave_ror</td><td style=text-align:center><code>6</code></td><td>wave_ror</td></tr><tr><td style=text-align:center>wave_rol</td><td style=text-align:center><code>7</code></td><td>wave_rol</td></tr><tr><td style=text-align:center>row_mirror</td><td style=text-align:center><code>8</code></td><td>row_mirror</td></tr><tr><td style=text-align:center>row_half_mirror</td><td style=text-align:center><code>9</code></td><td>row_half_mirror</td></tr><tr><td style=text-align:center>row_bcast_15</td><td style=text-align:center><code>10</code></td><td>row_bcast_15</td></tr><tr><td style=text-align:center>row_bcast_31</td><td style=text-align:center><code>11</code></td><td>row_bcast_31</td></tr></tbody></table><h3 id=mfmapermb>MFMAPermB&nbsp;<a class=headline-hash href=#mfmapermb>¶</a></h3><p><em>The possible permutations of the lanes storing B available in an MFMA</em></p><h4 id=cases-2>Cases:&nbsp;<a class=headline-hash href=#cases-2>¶</a></h4><table><thead><tr><th style=text-align:center>Symbol</th><th style=text-align:center>Value</th><th>String</th></tr></thead><tbody><tr><td style=text-align:center>none</td><td style=text-align:center><code>0</code></td><td>none</td></tr><tr><td style=text-align:center>bcast_first_32</td><td style=text-align:center><code>1</code></td><td>bcast_first_32</td></tr><tr><td style=text-align:center>bcast_second_32</td><td style=text-align:center><code>2</code></td><td>bcast_second_32</td></tr><tr><td style=text-align:center>rotate_16_right</td><td style=text-align:center><code>3</code></td><td>rotate_16_right</td></tr><tr><td style=text-align:center>bcast_first_16</td><td style=text-align:center><code>4</code></td><td>bcast_first_16</td></tr><tr><td style=text-align:center>bcast_second_16</td><td style=text-align:center><code>5</code></td><td>bcast_second_16</td></tr><tr><td style=text-align:center>bcast_third_16</td><td style=text-align:center><code>6</code></td><td>bcast_third_16</td></tr><tr><td style=text-align:center>bcast_fourth_16</td><td style=text-align:center><code>7</code></td><td>bcast_fourth_16</td></tr></tbody></table><h3 id=sched_barrier_opt_enum>sched_barrier_opt_enum&nbsp;<a class=headline-hash href=#sched_barrier_opt_enum>¶</a></h3><p><em>The possible options for scheduling barriers</em></p><h4 id=cases-3>Cases:&nbsp;<a class=headline-hash href=#cases-3>¶</a></h4><table><thead><tr><th style=text-align:center>Symbol</th><th style=text-align:center>Value</th><th>String</th></tr></thead><tbody><tr><td style=text-align:center>none</td><td style=text-align:center><code>0</code></td><td>none</td></tr><tr><td style=text-align:center>non_mem_non_sideffect</td><td style=text-align:center><code>1</code></td><td>non_mem_non_sideffect</td></tr><tr><td style=text-align:center>valu</td><td style=text-align:center><code>2</code></td><td>valu</td></tr><tr><td style=text-align:center>salu</td><td style=text-align:center><code>4</code></td><td>salu</td></tr><tr><td style=text-align:center>mfma_wmma</td><td style=text-align:center><code>8</code></td><td>mfma_wmma</td></tr><tr><td style=text-align:center>all_vmem</td><td style=text-align:center><code>16</code></td><td>all_vmem</td></tr><tr><td style=text-align:center>vmem_read</td><td style=text-align:center><code>32</code></td><td>vmem_read</td></tr><tr><td style=text-align:center>vmem_write</td><td style=text-align:center><code>64</code></td><td>vmem_write</td></tr><tr><td style=text-align:center>all_ds</td><td style=text-align:center><code>128</code></td><td>all_ds</td></tr><tr><td style=text-align:center>ds_read</td><td style=text-align:center><code>256</code></td><td>ds_read</td></tr><tr><td style=text-align:center>ds_write</td><td style=text-align:center><code>512</code></td><td>ds_write</td></tr><tr><td style=text-align:center>transcendental</td><td style=text-align:center><code>1024</code></td><td>transcendental</td></tr></tbody></table><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=https://mlir.llvm.org/docs/Dialects/Affine/ title="'affine' Dialect"><i class="fas fa-arrow-left" aria-hidden=true></i> Prev - 'affine' Dialect</a>
<a class="nav nav-next" href=https://mlir.llvm.org/docs/Dialects/AMX/ title="'amx' Dialect">Next - 'amx' Dialect <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=https://mlir.llvm.org/governance/>Governance</a></li><li><a href=https://mlir.llvm.org/users/>Users of MLIR</a></li><li><a href=https://mlir.llvm.org/pubs/>MLIR Related Publications</a></li><li><a href=https://mlir.llvm.org/talks/>Talks</a></li><li><a href=https://mlir.llvm.org/deprecation/>Deprecations & Current Refactoring</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/getting_started/ReportingIssues/>Reporting Issues</a></li><li><a href=https://mlir.llvm.org/getting_started/Debugging/>Debugging Tips</a></li><li><a href=https://mlir.llvm.org/getting_started/Faq/>FAQ</a></li><li><a href=https://mlir.llvm.org/getting_started/Contributing/>How to Contribute</a></li><li><a href=https://mlir.llvm.org/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=https://mlir.llvm.org/getting_started/openprojects/>Open Projects</a></li><li><a href=https://mlir.llvm.org/getting_started/Glossary/>Glossary</a></li><li><a href=https://mlir.llvm.org/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-reduce/>MLIR Reduce</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-rewrite/>mlir-rewrite</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/OpenMPPasses/></a></li><li><a href=https://mlir.llvm.org/docs/TargetLLVMIRTransforms/></a></li><li><a href=https://mlir.llvm.org/docs/ActionTracing/>Action: Tracing and Debugging MLIR-based Compilers</a></li><li><a href=https://mlir.llvm.org/docs/Bufferization/>Bufferization</a></li><li><a href=https://mlir.llvm.org/docs/DataLayout/>Data Layout Modeling</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/DefiningDialects/>Defining Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Constraints/>Constraints</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Assembly/>Customizing Assembly Behavior</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Operations/>Operation Definition Specification (ODS)</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/DialectConversion/>Dialect Conversion</a></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/Dialects/>Dialects<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/XeGPUTransformOps/></a></li><li><a href=https://mlir.llvm.org/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Affine/>'affine' Dialect</a></li><li class=active><a href=https://mlir.llvm.org/docs/Dialects/AMDGPU/>'amdgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArithOps/>'arith' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSME/>'ArmSME' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/BufferizationOps/>'bufferization' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/>'cf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/DLTIDialect/>'dlti' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/EmitC/>'emitc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Func/>'func' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IndexOps/>'index' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IRDL/>'irdl' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/Linalg/>'linalg' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/>Linalg OpDSL</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MLProgramOps/>'ml_program' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MPI/>'mpi' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVGPU/>'nvgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/>'omp' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/ODS/>ODS Documentation</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PtrOps/>'ptr' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Shard/>'shard' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SMT/>'smt' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/UBOps/>'ub' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/VCIXDialect/>'vcix' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/WasmSSAOps/>'wasmssa' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeGPU/>'xegpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeVMDialect/>'xevm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/>OpInterface definitions</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SPIR-V/>SPIR-V Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Transform/>Transform Dialect</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Interfaces/>Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/TargetLLVMIR/>LLVM IR Target</a></li><li><a href=https://mlir.llvm.org/docs/BytecodeFormat/>MLIR Bytecode Format</a></li><li><a href=https://mlir.llvm.org/docs/CAPI/>MLIR C API</a></li><li><a href=https://mlir.llvm.org/docs/LangRef/>MLIR Language Reference</a></li><li><a href=https://mlir.llvm.org/docs/ReleaseNotes/>MLIR Release Notes</a></li><li><a href=https://mlir.llvm.org/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=https://mlir.llvm.org/docs/OwnershipBasedBufferDeallocation/>Ownership-based Buffer Deallocation</a></li><li><a href=https://mlir.llvm.org/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/Passes/>Passes</a></li><li><a href=https://mlir.llvm.org/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=https://mlir.llvm.org/docs/PatternSearch/>Pattern Search</a></li><li><a href=https://mlir.llvm.org/docs/PDLL/>PDLL - PDL Language</a></li><li><a href=https://mlir.llvm.org/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/SideEffectsAndSpeculation/>Side Effects & Speculation</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Remarks/>Remark Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/ShapeInference/>Shape Inference</a></li><li><a href=https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=https://mlir.llvm.org/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=https://mlir.llvm.org/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Traits/>Traits<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Traits/Broadcastable/>The `Broadcastable` Trait</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/transform/>Transform Dialect Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch0/>Chapter 0: A Primer on “Structured” Linalg Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch1/>Chapter 1: Combining Existing Transformations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch2/>Chapter 2: Adding a Simple New Transformation Operation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch3/>Chapter 3: More than Simple Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch4/>Chapter 4: Matching Payload with Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/ChH/>Chapter H: Reproducing Halide Schedule</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/MlirOpt/>Using `mlir-opt`</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>