<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>'nvvm' Dialect - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.119.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Dialects/NVVMDialect/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script>
<link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script>
<script src=https://mlir.llvm.org/js/bundle.js></script>
<script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li><li class=child><a href=/python-bindings/>Python Bindings API docs</a></li></ul></li><li><a href="https://github.com/llvm/llvm-project/issues?q=is%3Aissue%20state%3Aopen%20label%3Amlir">Bugs</a></li><li><a href=https://github.com/llvm/mlir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/MLIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>'nvvm' Dialect</h1><p>The NVVM dialect is MLIR&rsquo;s LLVM-IR-based, NVIDIA-specific backend dialect. It
models NVVM intrinsics and public ISA functionality and introduces NVIDIA
extensions to the MLIR/LLVM type system and address spaces (e.g., global,
shared, and cluster memory), enabling faithful lowering of GPU kernels to the
NVPTX toolchain. While a NVVM op usually maps to a single LLVM IR intrinsic,
the NVVM dialect uses type polymorphism and other attributes so that a single
NVVM op can map to different LLVM intrinsics.</p><p><nav id=TableOfContents><ul><li><a href=#scope-and-capabilities>Scope and Capabilities</a></li><li><a href=#placement-in-the-lowering-pipeline>Placement in the Lowering Pipeline</a></li><li><a href=#target-configuration-and-serialization>Target Configuration and Serialization</a></li><li><a href=#inline-ptx>Inline PTX</a></li><li><a href=#memory-spaces>Memory Spaces</a><ul><li><a href=#memory-space-details>Memory Space Details</a></li></ul></li><li><a href=#mbarrier-objects>MBarrier objects</a></li><li><a href=#non-goals>Non-Goals</a></li><li><a href=#operations>Operations</a><ul><li><a href=#nvvmbarrier0-nvvmbarrier0op><code>nvvm.barrier0</code> (NVVM::Barrier0Op)</a></li><li><a href=#nvvmbarrierarrive-nvvmbarrierarriveop><code>nvvm.barrier.arrive</code> (NVVM::BarrierArriveOp)</a></li><li><a href=#nvvmbarrier-nvvmbarrierop><code>nvvm.barrier</code> (NVVM::BarrierOp)</a></li><li><a href=#nvvmreadptxsregntidx-nvvmblockdimxop><code>nvvm.read.ptx.sreg.ntid.x</code> (NVVM::BlockDimXOp)</a></li><li><a href=#nvvmreadptxsregntidy-nvvmblockdimyop><code>nvvm.read.ptx.sreg.ntid.y</code> (NVVM::BlockDimYOp)</a></li><li><a href=#nvvmreadptxsregntidz-nvvmblockdimzop><code>nvvm.read.ptx.sreg.ntid.z</code> (NVVM::BlockDimZOp)</a></li><li><a href=#nvvmreadptxsregctaidx-nvvmblockidxop><code>nvvm.read.ptx.sreg.ctaid.x</code> (NVVM::BlockIdXOp)</a></li><li><a href=#nvvmreadptxsregctaidy-nvvmblockidyop><code>nvvm.read.ptx.sreg.ctaid.y</code> (NVVM::BlockIdYOp)</a></li><li><a href=#nvvmreadptxsregctaidz-nvvmblockidzop><code>nvvm.read.ptx.sreg.ctaid.z</code> (NVVM::BlockIdZOp)</a></li><li><a href=#nvvmreadptxsregclusterctaidx-nvvmblockinclusteridxop><code>nvvm.read.ptx.sreg.cluster.ctaid.x</code> (NVVM::BlockInClusterIdXOp)</a></li><li><a href=#nvvmreadptxsregclusterctaidy-nvvmblockinclusteridyop><code>nvvm.read.ptx.sreg.cluster.ctaid.y</code> (NVVM::BlockInClusterIdYOp)</a></li><li><a href=#nvvmreadptxsregclusterctaidz-nvvmblockinclusteridzop><code>nvvm.read.ptx.sreg.cluster.ctaid.z</code> (NVVM::BlockInClusterIdZOp)</a></li><li><a href=#nvvmbreakpoint-nvvmbreakpoint><code>nvvm.breakpoint</code> (NVVM::Breakpoint)</a></li><li><a href=#nvvmstbulk-nvvmbulkstoreop><code>nvvm.st.bulk</code> (NVVM::BulkStoreOp)</a></li><li><a href=#nvvmreadptxsregclock64-nvvmclock64op><code>nvvm.read.ptx.sreg.clock64</code> (NVVM::Clock64Op)</a></li><li><a href=#nvvmreadptxsregclock-nvvmclockop><code>nvvm.read.ptx.sreg.clock</code> (NVVM::ClockOp)</a></li><li><a href=#nvvmclusterarrive-nvvmclusterarriveop><code>nvvm.cluster.arrive</code> (NVVM::ClusterArriveOp)</a></li><li><a href=#nvvmclusterarriverelaxed-nvvmclusterarriverelaxedop><code>nvvm.cluster.arrive.relaxed</code> (NVVM::ClusterArriveRelaxedOp)</a></li><li><a href=#nvvmreadptxsregclusternctarank-nvvmclusterdim><code>nvvm.read.ptx.sreg.cluster.nctarank</code> (NVVM::ClusterDim)</a></li><li><a href=#nvvmreadptxsregclusternctaidx-nvvmclusterdimblocksxop><code>nvvm.read.ptx.sreg.cluster.nctaid.x</code> (NVVM::ClusterDimBlocksXOp)</a></li><li><a href=#nvvmreadptxsregclusternctaidy-nvvmclusterdimblocksyop><code>nvvm.read.ptx.sreg.cluster.nctaid.y</code> (NVVM::ClusterDimBlocksYOp)</a></li><li><a href=#nvvmreadptxsregclusternctaidz-nvvmclusterdimblockszop><code>nvvm.read.ptx.sreg.cluster.nctaid.z</code> (NVVM::ClusterDimBlocksZOp)</a></li><li><a href=#nvvmreadptxsregnclusteridx-nvvmclusterdimxop><code>nvvm.read.ptx.sreg.nclusterid.x</code> (NVVM::ClusterDimXOp)</a></li><li><a href=#nvvmreadptxsregnclusteridy-nvvmclusterdimyop><code>nvvm.read.ptx.sreg.nclusterid.y</code> (NVVM::ClusterDimYOp)</a></li><li><a href=#nvvmreadptxsregnclusteridz-nvvmclusterdimzop><code>nvvm.read.ptx.sreg.nclusterid.z</code> (NVVM::ClusterDimZOp)</a></li><li><a href=#nvvmreadptxsregclusterctarank-nvvmclusterid><code>nvvm.read.ptx.sreg.cluster.ctarank</code> (NVVM::ClusterId)</a></li><li><a href=#nvvmreadptxsregclusteridx-nvvmclusteridxop><code>nvvm.read.ptx.sreg.clusterid.x</code> (NVVM::ClusterIdXOp)</a></li><li><a href=#nvvmreadptxsregclusteridy-nvvmclusteridyop><code>nvvm.read.ptx.sreg.clusterid.y</code> (NVVM::ClusterIdYOp)</a></li><li><a href=#nvvmreadptxsregclusteridz-nvvmclusteridzop><code>nvvm.read.ptx.sreg.clusterid.z</code> (NVVM::ClusterIdZOp)</a></li><li><a href=#nvvmclusterlaunchcontrolquerycancel-nvvmclusterlaunchcontrolquerycancelop><code>nvvm.clusterlaunchcontrol.query.cancel</code> (NVVM::ClusterLaunchControlQueryCancelOp)</a></li><li><a href=#nvvmclusterlaunchcontroltrycancel-nvvmclusterlaunchcontroltrycancelop><code>nvvm.clusterlaunchcontrol.try.cancel</code> (NVVM::ClusterLaunchControlTryCancelOp)</a></li><li><a href=#nvvmclusterwait-nvvmclusterwaitop><code>nvvm.cluster.wait</code> (NVVM::ClusterWaitOp)</a></li><li><a href=#nvvmconvertbf16x2tof8x2-nvvmconvertbf16x2tof8x2op><code>nvvm.convert.bf16x2.to.f8x2</code> (NVVM::ConvertBF16x2ToF8x2Op)</a></li><li><a href=#nvvmconvertf16x2tof8x2-nvvmconvertf16x2tof8x2op><code>nvvm.convert.f16x2.to.f8x2</code> (NVVM::ConvertF16x2ToF8x2Op)</a></li><li><a href=#nvvmconvertf32x2tobf16x2-nvvmconvertf32x2tobf16x2op><code>nvvm.convert.f32x2.to.bf16x2</code> (NVVM::ConvertF32x2ToBF16x2Op)</a></li><li><a href=#nvvmconvertf32x2tof16x2-nvvmconvertf32x2tof16x2op><code>nvvm.convert.f32x2.to.f16x2</code> (NVVM::ConvertF32x2ToF16x2Op)</a></li><li><a href=#nvvmconvertf32x2tof4x2-nvvmconvertf32x2tof4x2op><code>nvvm.convert.f32x2.to.f4x2</code> (NVVM::ConvertF32x2ToF4x2Op)</a></li><li><a href=#nvvmconvertf32x2tof6x2-nvvmconvertf32x2tof6x2op><code>nvvm.convert.f32x2.to.f6x2</code> (NVVM::ConvertF32x2ToF6x2Op)</a></li><li><a href=#nvvmconvertf32x2tof8x2-nvvmconvertf32x2tof8x2op><code>nvvm.convert.f32x2.to.f8x2</code> (NVVM::ConvertF32x2ToF8x2Op)</a></li><li><a href=#nvvmconvertf32x4tof4x4-nvvmconvertf32x4tof4x4op><code>nvvm.convert.f32x4.to.f4x4</code> (NVVM::ConvertF32x4ToF4x4Op)</a></li><li><a href=#nvvmconvertf32x4tof6x4-nvvmconvertf32x4tof6x4op><code>nvvm.convert.f32x4.to.f6x4</code> (NVVM::ConvertF32x4ToF6x4Op)</a></li><li><a href=#nvvmconvertf32x4tof8x4-nvvmconvertf32x4tof8x4op><code>nvvm.convert.f32x4.to.f8x4</code> (NVVM::ConvertF32x4ToF8x4Op)</a></li><li><a href=#nvvmconvertf4x2tof16x2-nvvmconvertf4x2tof16x2op><code>nvvm.convert.f4x2.to.f16x2</code> (NVVM::ConvertF4x2ToF16x2Op)</a></li><li><a href=#nvvmconvertf6x2tof16x2-nvvmconvertf6x2tof16x2op><code>nvvm.convert.f6x2.to.f16x2</code> (NVVM::ConvertF6x2ToF16x2Op)</a></li><li><a href=#nvvmconvertf8x2tobf16x2-nvvmconvertf8x2tobf16x2op><code>nvvm.convert.f8x2.to.bf16x2</code> (NVVM::ConvertF8x2ToBF16x2Op)</a></li><li><a href=#nvvmconvertf8x2tof16x2-nvvmconvertf8x2tof16x2op><code>nvvm.convert.f8x2.to.f16x2</code> (NVVM::ConvertF8x2ToF16x2Op)</a></li><li><a href=#nvvmconvertfloattotf32-nvvmconvertfloattotf32op><code>nvvm.convert.float.to.tf32</code> (NVVM::ConvertFloatToTF32Op)</a></li><li><a href=#nvvmcpasyncbulkcommitgroup-nvvmcpasyncbulkcommitgroupop><code>nvvm.cp.async.bulk.commit.group</code> (NVVM::CpAsyncBulkCommitGroupOp)</a></li><li><a href=#nvvmcpasyncbulksharedclusterglobal-nvvmcpasyncbulkglobaltosharedclusterop><code>nvvm.cp.async.bulk.shared.cluster.global</code> (NVVM::CpAsyncBulkGlobalToSharedClusterOp)</a></li><li><a href=#nvvmcpasyncbulkprefetch-nvvmcpasyncbulkprefetchop><code>nvvm.cp.async.bulk.prefetch</code> (NVVM::CpAsyncBulkPrefetchOp)</a></li><li><a href=#nvvmcpasyncbulkglobalsharedcta-nvvmcpasyncbulksharedctatoglobalop><code>nvvm.cp.async.bulk.global.shared.cta</code> (NVVM::CpAsyncBulkSharedCTAToGlobalOp)</a></li><li><a href=#nvvmcpasyncbulksharedclustersharedcta-nvvmcpasyncbulksharedctatosharedclusterop><code>nvvm.cp.async.bulk.shared.cluster.shared.cta</code> (NVVM::CpAsyncBulkSharedCTAToSharedClusterOp)</a></li><li><a href=#nvvmcpasyncbulktensorsharedclusterglobal-nvvmcpasyncbulktensorglobaltosharedclusterop><code>nvvm.cp.async.bulk.tensor.shared.cluster.global</code> (NVVM::CpAsyncBulkTensorGlobalToSharedClusterOp)</a></li><li><a href=#nvvmcpasyncbulktensorprefetch-nvvmcpasyncbulktensorprefetchop><code>nvvm.cp.async.bulk.tensor.prefetch</code> (NVVM::CpAsyncBulkTensorPrefetchOp)</a></li><li><a href=#nvvmcpasyncbulktensorreduce-nvvmcpasyncbulktensorreduceop><code>nvvm.cp.async.bulk.tensor.reduce</code> (NVVM::CpAsyncBulkTensorReduceOp)</a></li><li><a href=#nvvmcpasyncbulktensorglobalsharedcta-nvvmcpasyncbulktensorsharedctatoglobalop><code>nvvm.cp.async.bulk.tensor.global.shared.cta</code> (NVVM::CpAsyncBulkTensorSharedCTAToGlobalOp)</a></li><li><a href=#nvvmcpasyncbulkwait_group-nvvmcpasyncbulkwaitgroupop><code>nvvm.cp.async.bulk.wait_group</code> (NVVM::CpAsyncBulkWaitGroupOp)</a></li><li><a href=#nvvmcpasynccommitgroup-nvvmcpasynccommitgroupop><code>nvvm.cp.async.commit.group</code> (NVVM::CpAsyncCommitGroupOp)</a></li><li><a href=#nvvmcpasyncmbarrierarrive-nvvmcpasyncmbarrierarriveop><code>nvvm.cp.async.mbarrier.arrive</code> (NVVM::CpAsyncMBarrierArriveOp)</a></li><li><a href=#nvvmcpasyncsharedglobal-nvvmcpasyncop><code>nvvm.cp.async.shared.global</code> (NVVM::CpAsyncOp)</a></li><li><a href=#nvvmcpasyncwaitgroup-nvvmcpasyncwaitgroupop><code>nvvm.cp.async.wait.group</code> (NVVM::CpAsyncWaitGroupOp)</a></li><li><a href=#nvvmdotaccumulate2way-nvvmdotaccumulate2wayop><code>nvvm.dot.accumulate.2way</code> (NVVM::DotAccumulate2WayOp)</a></li><li><a href=#nvvmdotaccumulate4way-nvvmdotaccumulate4wayop><code>nvvm.dot.accumulate.4way</code> (NVVM::DotAccumulate4WayOp)</a></li><li><a href=#nvvmelectsync-nvvmelectsyncop><code>nvvm.elect.sync</code> (NVVM::ElectSyncOp)</a></li><li><a href=#nvvmreadptxsregenvreg0-nvvmenvreg0op><code>nvvm.read.ptx.sreg.envreg0</code> (NVVM::EnvReg0Op)</a></li><li><a href=#nvvmreadptxsregenvreg10-nvvmenvreg10op><code>nvvm.read.ptx.sreg.envreg10</code> (NVVM::EnvReg10Op)</a></li><li><a href=#nvvmreadptxsregenvreg11-nvvmenvreg11op><code>nvvm.read.ptx.sreg.envreg11</code> (NVVM::EnvReg11Op)</a></li><li><a href=#nvvmreadptxsregenvreg12-nvvmenvreg12op><code>nvvm.read.ptx.sreg.envreg12</code> (NVVM::EnvReg12Op)</a></li><li><a href=#nvvmreadptxsregenvreg13-nvvmenvreg13op><code>nvvm.read.ptx.sreg.envreg13</code> (NVVM::EnvReg13Op)</a></li><li><a href=#nvvmreadptxsregenvreg14-nvvmenvreg14op><code>nvvm.read.ptx.sreg.envreg14</code> (NVVM::EnvReg14Op)</a></li><li><a href=#nvvmreadptxsregenvreg15-nvvmenvreg15op><code>nvvm.read.ptx.sreg.envreg15</code> (NVVM::EnvReg15Op)</a></li><li><a href=#nvvmreadptxsregenvreg16-nvvmenvreg16op><code>nvvm.read.ptx.sreg.envreg16</code> (NVVM::EnvReg16Op)</a></li><li><a href=#nvvmreadptxsregenvreg17-nvvmenvreg17op><code>nvvm.read.ptx.sreg.envreg17</code> (NVVM::EnvReg17Op)</a></li><li><a href=#nvvmreadptxsregenvreg18-nvvmenvreg18op><code>nvvm.read.ptx.sreg.envreg18</code> (NVVM::EnvReg18Op)</a></li><li><a href=#nvvmreadptxsregenvreg19-nvvmenvreg19op><code>nvvm.read.ptx.sreg.envreg19</code> (NVVM::EnvReg19Op)</a></li><li><a href=#nvvmreadptxsregenvreg1-nvvmenvreg1op><code>nvvm.read.ptx.sreg.envreg1</code> (NVVM::EnvReg1Op)</a></li><li><a href=#nvvmreadptxsregenvreg20-nvvmenvreg20op><code>nvvm.read.ptx.sreg.envreg20</code> (NVVM::EnvReg20Op)</a></li><li><a href=#nvvmreadptxsregenvreg21-nvvmenvreg21op><code>nvvm.read.ptx.sreg.envreg21</code> (NVVM::EnvReg21Op)</a></li><li><a href=#nvvmreadptxsregenvreg22-nvvmenvreg22op><code>nvvm.read.ptx.sreg.envreg22</code> (NVVM::EnvReg22Op)</a></li><li><a href=#nvvmreadptxsregenvreg23-nvvmenvreg23op><code>nvvm.read.ptx.sreg.envreg23</code> (NVVM::EnvReg23Op)</a></li><li><a href=#nvvmreadptxsregenvreg24-nvvmenvreg24op><code>nvvm.read.ptx.sreg.envreg24</code> (NVVM::EnvReg24Op)</a></li><li><a href=#nvvmreadptxsregenvreg25-nvvmenvreg25op><code>nvvm.read.ptx.sreg.envreg25</code> (NVVM::EnvReg25Op)</a></li><li><a href=#nvvmreadptxsregenvreg26-nvvmenvreg26op><code>nvvm.read.ptx.sreg.envreg26</code> (NVVM::EnvReg26Op)</a></li><li><a href=#nvvmreadptxsregenvreg27-nvvmenvreg27op><code>nvvm.read.ptx.sreg.envreg27</code> (NVVM::EnvReg27Op)</a></li><li><a href=#nvvmreadptxsregenvreg28-nvvmenvreg28op><code>nvvm.read.ptx.sreg.envreg28</code> (NVVM::EnvReg28Op)</a></li><li><a href=#nvvmreadptxsregenvreg29-nvvmenvreg29op><code>nvvm.read.ptx.sreg.envreg29</code> (NVVM::EnvReg29Op)</a></li><li><a href=#nvvmreadptxsregenvreg2-nvvmenvreg2op><code>nvvm.read.ptx.sreg.envreg2</code> (NVVM::EnvReg2Op)</a></li><li><a href=#nvvmreadptxsregenvreg30-nvvmenvreg30op><code>nvvm.read.ptx.sreg.envreg30</code> (NVVM::EnvReg30Op)</a></li><li><a href=#nvvmreadptxsregenvreg31-nvvmenvreg31op><code>nvvm.read.ptx.sreg.envreg31</code> (NVVM::EnvReg31Op)</a></li><li><a href=#nvvmreadptxsregenvreg3-nvvmenvreg3op><code>nvvm.read.ptx.sreg.envreg3</code> (NVVM::EnvReg3Op)</a></li><li><a href=#nvvmreadptxsregenvreg4-nvvmenvreg4op><code>nvvm.read.ptx.sreg.envreg4</code> (NVVM::EnvReg4Op)</a></li><li><a href=#nvvmreadptxsregenvreg5-nvvmenvreg5op><code>nvvm.read.ptx.sreg.envreg5</code> (NVVM::EnvReg5Op)</a></li><li><a href=#nvvmreadptxsregenvreg6-nvvmenvreg6op><code>nvvm.read.ptx.sreg.envreg6</code> (NVVM::EnvReg6Op)</a></li><li><a href=#nvvmreadptxsregenvreg7-nvvmenvreg7op><code>nvvm.read.ptx.sreg.envreg7</code> (NVVM::EnvReg7Op)</a></li><li><a href=#nvvmreadptxsregenvreg8-nvvmenvreg8op><code>nvvm.read.ptx.sreg.envreg8</code> (NVVM::EnvReg8Op)</a></li><li><a href=#nvvmreadptxsregenvreg9-nvvmenvreg9op><code>nvvm.read.ptx.sreg.envreg9</code> (NVVM::EnvReg9Op)</a></li><li><a href=#nvvmexit-nvvmexit><code>nvvm.exit</code> (NVVM::Exit)</a></li><li><a href=#nvvmfencembarrierinit-nvvmfencembarrierinitop><code>nvvm.fence.mbarrier.init</code> (NVVM::FenceMbarrierInitOp)</a></li><li><a href=#nvvmfenceproxyacquire-nvvmfenceproxyacquireop><code>nvvm.fence.proxy.acquire</code> (NVVM::FenceProxyAcquireOp)</a></li><li><a href=#nvvmfenceproxy-nvvmfenceproxyop><code>nvvm.fence.proxy</code> (NVVM::FenceProxyOp)</a></li><li><a href=#nvvmfenceproxyrelease-nvvmfenceproxyreleaseop><code>nvvm.fence.proxy.release</code> (NVVM::FenceProxyReleaseOp)</a></li><li><a href=#nvvmfenceproxysync_restrict-nvvmfenceproxysyncrestrictop><code>nvvm.fence.proxy.sync_restrict</code> (NVVM::FenceProxySyncRestrictOp)</a></li><li><a href=#nvvmfencesccluster-nvvmfencescclusterop><code>nvvm.fence.sc.cluster</code> (NVVM::FenceScClusterOp)</a></li><li><a href=#nvvmfencesync_restrict-nvvmfencesyncrestrictop><code>nvvm.fence.sync_restrict</code> (NVVM::FenceSyncRestrictOp)</a></li><li><a href=#nvvmreadptxsregglobaltimerlo-nvvmglobaltimerloop><code>nvvm.read.ptx.sreg.globaltimer.lo</code> (NVVM::GlobalTimerLoOp)</a></li><li><a href=#nvvmreadptxsregglobaltimer-nvvmglobaltimerop><code>nvvm.read.ptx.sreg.globaltimer</code> (NVVM::GlobalTimerOp)</a></li><li><a href=#nvvmreadptxsregnctaidx-nvvmgriddimxop><code>nvvm.read.ptx.sreg.nctaid.x</code> (NVVM::GridDimXOp)</a></li><li><a href=#nvvmreadptxsregnctaidy-nvvmgriddimyop><code>nvvm.read.ptx.sreg.nctaid.y</code> (NVVM::GridDimYOp)</a></li><li><a href=#nvvmreadptxsregnctaidz-nvvmgriddimzop><code>nvvm.read.ptx.sreg.nctaid.z</code> (NVVM::GridDimZOp)</a></li><li><a href=#nvvmreadptxsreggridid-nvvmgrididop><code>nvvm.read.ptx.sreg.gridid</code> (NVVM::GridIdOp)</a></li><li><a href=#nvvmgriddepcontrol-nvvmgriddepcontrolop><code>nvvm.griddepcontrol</code> (NVVM::GriddepcontrolOp)</a></li><li><a href=#nvvminline_ptx-nvvminlineptxop><code>nvvm.inline_ptx</code> (NVVM::InlinePtxOp)</a></li><li><a href=#nvvmreadptxsreglaneid-nvvmlaneidop><code>nvvm.read.ptx.sreg.laneid</code> (NVVM::LaneIdOp)</a></li><li><a href=#nvvmreadptxsreglanemaskeq-nvvmlanemaskeqop><code>nvvm.read.ptx.sreg.lanemask.eq</code> (NVVM::LaneMaskEqOp)</a></li><li><a href=#nvvmreadptxsreglanemaskge-nvvmlanemaskgeop><code>nvvm.read.ptx.sreg.lanemask.ge</code> (NVVM::LaneMaskGeOp)</a></li><li><a href=#nvvmreadptxsreglanemaskgt-nvvmlanemaskgtop><code>nvvm.read.ptx.sreg.lanemask.gt</code> (NVVM::LaneMaskGtOp)</a></li><li><a href=#nvvmreadptxsreglanemaskle-nvvmlanemaskleop><code>nvvm.read.ptx.sreg.lanemask.le</code> (NVVM::LaneMaskLeOp)</a></li><li><a href=#nvvmreadptxsreglanemasklt-nvvmlanemaskltop><code>nvvm.read.ptx.sreg.lanemask.lt</code> (NVVM::LaneMaskLtOp)</a></li><li><a href=#nvvmldmatrix-nvvmldmatrixop><code>nvvm.ldmatrix</code> (NVVM::LdMatrixOp)</a></li><li><a href=#nvvmmbarrierarrive_dropexpect_tx-nvvmmbarrierarrivedropexpecttxop><code>nvvm.mbarrier.arrive_drop.expect_tx</code> (NVVM::MBarrierArriveDropExpectTxOp)</a></li><li><a href=#nvvmmbarrierarrive_dropnocomplete-nvvmmbarrierarrivedropnocompleteop><code>nvvm.mbarrier.arrive_drop.nocomplete</code> (NVVM::MBarrierArriveDropNocompleteOp)</a></li><li><a href=#nvvmmbarrierarrive_drop-nvvmmbarrierarrivedropop><code>nvvm.mbarrier.arrive_drop</code> (NVVM::MBarrierArriveDropOp)</a></li><li><a href=#nvvmmbarrierarriveexpect_tx-nvvmmbarrierarriveexpecttxop><code>nvvm.mbarrier.arrive.expect_tx</code> (NVVM::MBarrierArriveExpectTxOp)</a></li><li><a href=#nvvmmbarrierarrivenocomplete-nvvmmbarrierarrivenocompleteop><code>nvvm.mbarrier.arrive.nocomplete</code> (NVVM::MBarrierArriveNocompleteOp)</a></li><li><a href=#nvvmmbarrierarrive-nvvmmbarrierarriveop><code>nvvm.mbarrier.arrive</code> (NVVM::MBarrierArriveOp)</a></li><li><a href=#nvvmmbarriercomplete_tx-nvvmmbarriercompletetxop><code>nvvm.mbarrier.complete_tx</code> (NVVM::MBarrierCompleteTxOp)</a></li><li><a href=#nvvmmbarrierexpect_tx-nvvmmbarrierexpecttxop><code>nvvm.mbarrier.expect_tx</code> (NVVM::MBarrierExpectTxOp)</a></li><li><a href=#nvvmmbarrierinit-nvvmmbarrierinitop><code>nvvm.mbarrier.init</code> (NVVM::MBarrierInitOp)</a></li><li><a href=#nvvmmbarrierinval-nvvmmbarrierinvalop><code>nvvm.mbarrier.inval</code> (NVVM::MBarrierInvalOp)</a></li><li><a href=#nvvmmbarriertestwait-nvvmmbarriertestwaitop><code>nvvm.mbarrier.test.wait</code> (NVVM::MBarrierTestWaitOp)</a></li><li><a href=#nvvmmbarriertry_wait-nvvmmbarriertrywaitop><code>nvvm.mbarrier.try_wait</code> (NVVM::MBarrierTryWaitOp)</a></li><li><a href=#nvvmmbarriertry_waitparity-nvvmmbarriertrywaitparityop><code>nvvm.mbarrier.try_wait.parity</code> (NVVM::MBarrierTryWaitParityOp)</a></li><li><a href=#nvvmmapa-nvvmmapaop><code>nvvm.mapa</code> (NVVM::MapaOp)</a></li><li><a href=#nvvmmatchsync-nvvmmatchsyncop><code>nvvm.match.sync</code> (NVVM::MatchSyncOp)</a></li><li><a href=#nvvmmemorybarrier-nvvmmembarop><code>nvvm.memory.barrier</code> (NVVM::MembarOp)</a></li><li><a href=#nvvmmmablock_scale-nvvmmmablockscaleop><code>nvvm.mma.block_scale</code> (NVVM::MmaBlockScaleOp)</a></li><li><a href=#nvvmmmasync-nvvmmmaop><code>nvvm.mma.sync</code> (NVVM::MmaOp)</a></li><li><a href=#nvvmmmaspblock_scale-nvvmmmaspblockscaleop><code>nvvm.mma.sp.block_scale</code> (NVVM::MmaSpBlockScaleOp)</a></li><li><a href=#nvvmmmaspsync-nvvmmmaspop><code>nvvm.mma.sp.sync</code> (NVVM::MmaSpOp)</a></li><li><a href=#nvvmnanosleep-nvvmnanosleepop><code>nvvm.nanosleep</code> (NVVM::NanosleepOp)</a></li><li><a href=#nvvmpmevent-nvvmpmeventop><code>nvvm.pmevent</code> (NVVM::PMEventOp)</a></li><li><a href=#nvvmprmt-nvvmpermuteop><code>nvvm.prmt</code> (NVVM::PermuteOp)</a></li><li><a href=#nvvmprefetch-nvvmprefetchop><code>nvvm.prefetch</code> (NVVM::PrefetchOp)</a></li><li><a href=#nvvmrcpapproxftzf-nvvmrcpapproxftzf32op><code>nvvm.rcp.approx.ftz.f</code> (NVVM::RcpApproxFtzF32Op)</a></li><li><a href=#nvvmreduxsync-nvvmreduxop><code>nvvm.redux.sync</code> (NVVM::ReduxOp)</a></li><li><a href=#nvvmsetmaxregister-nvvmsetmaxregisterop><code>nvvm.setmaxregister</code> (NVVM::SetMaxRegisterOp)</a></li><li><a href=#nvvmshflsync-nvvmshflop><code>nvvm.shfl.sync</code> (NVVM::ShflOp)</a></li><li><a href=#nvvmreadptxsregnsmid-nvvmsmdimop><code>nvvm.read.ptx.sreg.nsmid</code> (NVVM::SmDimOp)</a></li><li><a href=#nvvmreadptxsregsmid-nvvmsmidop><code>nvvm.read.ptx.sreg.smid</code> (NVVM::SmIdOp)</a></li><li><a href=#nvvmstmatrix-nvvmstmatrixop><code>nvvm.stmatrix</code> (NVVM::StMatrixOp)</a></li><li><a href=#nvvmbarwarpsync-nvvmsyncwarpop><code>nvvm.bar.warp.sync</code> (NVVM::SyncWarpOp)</a></li><li><a href=#nvvmtcgen05alloc-nvvmtcgen05allocop><code>nvvm.tcgen05.alloc</code> (NVVM::Tcgen05AllocOp)</a></li><li><a href=#nvvmtcgen05commit-nvvmtcgen05commitop><code>nvvm.tcgen05.commit</code> (NVVM::Tcgen05CommitOp)</a></li><li><a href=#nvvmtcgen05cp-nvvmtcgen05cpop><code>nvvm.tcgen05.cp</code> (NVVM::Tcgen05CpOp)</a></li><li><a href=#nvvmtcgen05dealloc-nvvmtcgen05deallocop><code>nvvm.tcgen05.dealloc</code> (NVVM::Tcgen05DeallocOp)</a></li><li><a href=#nvvmtcgen05fence-nvvmtcgen05fenceop><code>nvvm.tcgen05.fence</code> (NVVM::Tcgen05FenceOp)</a></li><li><a href=#nvvmtcgen05ld-nvvmtcgen05ldop><code>nvvm.tcgen05.ld</code> (NVVM::Tcgen05LdOp)</a></li><li><a href=#nvvmtcgen05mmablock_scale-nvvmtcgen05mmablockscaleop><code>nvvm.tcgen05.mma.block_scale</code> (NVVM::Tcgen05MMABlockScaleOp)</a></li><li><a href=#nvvmtcgen05mma-nvvmtcgen05mmaop><code>nvvm.tcgen05.mma</code> (NVVM::Tcgen05MMAOp)</a></li><li><a href=#nvvmtcgen05mmaspblock_scale-nvvmtcgen05mmasparseblockscaleop><code>nvvm.tcgen05.mma.sp.block_scale</code> (NVVM::Tcgen05MMASparseBlockScaleOp)</a></li><li><a href=#nvvmtcgen05mmasp-nvvmtcgen05mmasparseop><code>nvvm.tcgen05.mma.sp</code> (NVVM::Tcgen05MMASparseOp)</a></li><li><a href=#nvvmtcgen05mmaws-nvvmtcgen05mmawsop><code>nvvm.tcgen05.mma.ws</code> (NVVM::Tcgen05MMAWsOp)</a></li><li><a href=#nvvmtcgen05mmawssp-nvvmtcgen05mmawssparseop><code>nvvm.tcgen05.mma.ws.sp</code> (NVVM::Tcgen05MMAWsSparseOp)</a></li><li><a href=#nvvmtcgen05mma_smem_desc-nvvmtcgen05mmasmemdescop><code>nvvm.tcgen05.mma_smem_desc</code> (NVVM::Tcgen05MmaSmemDescOp)</a></li><li><a href=#nvvmtcgen05relinquish_alloc_permit-nvvmtcgen05relinquishallocpermitop><code>nvvm.tcgen05.relinquish_alloc_permit</code> (NVVM::Tcgen05RelinquishAllocPermitOp)</a></li><li><a href=#nvvmtcgen05shift-nvvmtcgen05shiftop><code>nvvm.tcgen05.shift</code> (NVVM::Tcgen05ShiftOp)</a></li><li><a href=#nvvmtcgen05st-nvvmtcgen05stop><code>nvvm.tcgen05.st</code> (NVVM::Tcgen05StOp)</a></li><li><a href=#nvvmtcgen05wait-nvvmtcgen05waitop><code>nvvm.tcgen05.wait</code> (NVVM::Tcgen05WaitOp)</a></li><li><a href=#nvvmreadptxsregtidx-nvvmthreadidxop><code>nvvm.read.ptx.sreg.tid.x</code> (NVVM::ThreadIdXOp)</a></li><li><a href=#nvvmreadptxsregtidy-nvvmthreadidyop><code>nvvm.read.ptx.sreg.tid.y</code> (NVVM::ThreadIdYOp)</a></li><li><a href=#nvvmreadptxsregtidz-nvvmthreadidzop><code>nvvm.read.ptx.sreg.tid.z</code> (NVVM::ThreadIdZOp)</a></li><li><a href=#nvvmvotesync-nvvmvotesyncop><code>nvvm.vote.sync</code> (NVVM::VoteSyncOp)</a></li><li><a href=#nvvmwmmaload-nvvmwmmaloadop><code>nvvm.wmma.load</code> (NVVM::WMMALoadOp)</a></li><li><a href=#nvvmwmmamma-nvvmwmmammaop><code>nvvm.wmma.mma</code> (NVVM::WMMAMmaOp)</a></li><li><a href=#nvvmwmmastore-nvvmwmmastoreop><code>nvvm.wmma.store</code> (NVVM::WMMAStoreOp)</a></li><li><a href=#nvvmreadptxsregnwarpid-nvvmwarpdimop><code>nvvm.read.ptx.sreg.nwarpid</code> (NVVM::WarpDimOp)</a></li><li><a href=#nvvmreadptxsregwarpid-nvvmwarpidop><code>nvvm.read.ptx.sreg.warpid</code> (NVVM::WarpIdOp)</a></li><li><a href=#nvvmreadptxsregwarpsize-nvvmwarpsizeop><code>nvvm.read.ptx.sreg.warpsize</code> (NVVM::WarpSizeOp)</a></li><li><a href=#nvvmwgmmafencealigned-nvvmwgmmafencealignedop><code>nvvm.wgmma.fence.aligned</code> (NVVM::WgmmaFenceAlignedOp)</a></li><li><a href=#nvvmwgmmacommitgroupsyncaligned-nvvmwgmmagroupsyncalignedop><code>nvvm.wgmma.commit.group.sync.aligned</code> (NVVM::WgmmaGroupSyncAlignedOp)</a></li><li><a href=#nvvmwgmmamma_async-nvvmwgmmammaasyncop><code>nvvm.wgmma.mma_async</code> (NVVM::WgmmaMmaAsyncOp)</a></li><li><a href=#nvvmwgmmawaitgroupsyncaligned-nvvmwgmmawaitgroupsyncop><code>nvvm.wgmma.wait.group.sync.aligned</code> (NVVM::WgmmaWaitGroupSyncOp)</a></li></ul></li></ul></nav><h2 id=scope-and-capabilities>Scope and Capabilities&nbsp;<a class=headline-hash href=#scope-and-capabilities>¶</a></h2><p>The dialect covers core GPU features such as thread/block builtins, barriers
and atomics, warp-level collectives (e.g., shuffle/vote), matrix/tensor core
operations (e.g., <code>mma.sync</code>, <code>wgmma</code>), tensor memory accelerator (TMA)
operations, asynchronous copies (<code>cp.async</code>, bulk/tensor variants) with memory
barriers, cache and prefetch controls, and NVVM-specific attributes and enums
(e.g., FP rounding modes, memory scopes, and MMA types/layouts).</p><h2 id=placement-in-the-lowering-pipeline>Placement in the Lowering Pipeline&nbsp;<a class=headline-hash href=#placement-in-the-lowering-pipeline>¶</a></h2><p>NVVM sits below target-agnostic dialects like <code>gpu</code> and NVIDIA&rsquo;s <code>nvgpu</code>.
Typical pipelines convert <code>gpu</code>/<code>nvgpu</code> ops into NVVM using
<code>-convert-gpu-to-nvvm</code> and <code>-convert-nvgpu-to-nvvm</code>, then translate into LLVM
for final code generation via NVPTX backend.</p><h2 id=target-configuration-and-serialization>Target Configuration and Serialization&nbsp;<a class=headline-hash href=#target-configuration-and-serialization>¶</a></h2><p>NVVM provides a <code>#nvvm.target</code> attribute to describe the GPU target (SM,
features, and flags). In conjunction with <code>gpu</code> serialization (e.g.,
<code>gpu-module-to-binary</code>), this enables producing architecture-specific GPU
binaries (such as CUBIN) from nested GPU modules.</p><h2 id=inline-ptx>Inline PTX&nbsp;<a class=headline-hash href=#inline-ptx>¶</a></h2><p>When an intrinsic is unavailable or a performance-critical sequence must be
expressed directly, NVVM provides an <code>nvvm.inline_ptx</code> op to embed PTX inline
as a last-resort escape hatch, with explicit operands and results.</p><h2 id=memory-spaces>Memory Spaces&nbsp;<a class=headline-hash href=#memory-spaces>¶</a></h2><p>The NVVM dialect introduces the following memory spaces, each with distinct
scopes and lifetimes:</p><table><thead><tr><th>Memory Space</th><th>Address Space</th><th>Scope</th></tr></thead><tbody><tr><td><code>generic</code></td><td>0</td><td>All threads</td></tr><tr><td><code>global</code></td><td>1</td><td>All threads (device)</td></tr><tr><td><code>shared</code></td><td>3</td><td>Thread block (CTA)</td></tr><tr><td><code>constant</code></td><td>4</td><td>All threads</td></tr><tr><td><code>local</code></td><td>5</td><td>Single thread</td></tr><tr><td><code>tensor</code></td><td>6</td><td>Thread block (CTA)</td></tr><tr><td><code>shared_cluster</code></td><td>7</td><td>Thread block cluster</td></tr></tbody></table><h3 id=memory-space-details>Memory Space Details&nbsp;<a class=headline-hash href=#memory-space-details>¶</a></h3><ul><li><strong>generic</strong>: Can point to any memory space; requires runtime resolution of
actual address space. Use when pointer origin is unknown at compile time.
Performance varies based on the underlying memory space. A pointer to this
memory space is represented by <code>LLVM_PointerGeneric</code> in the NVVM Ops.</li><li><strong>global</strong>: Accessible by all threads across all blocks; persists across
kernel launches. Highest latency but largest capacity (device memory). Best
for large data and inter-kernel communication. A pointer to this memory space
is represented by <code>LLVM_PointerGlobal</code> in the NVVM Ops.</li><li><strong>shared</strong>: Shared within a thread block (CTA); very fast on-chip memory for
cooperation between threads in the same block. Limited capacity. Ideal for
block-level collaboration, caching, and reducing global memory traffic.
This memory is usually referred as <code>shared_cta</code> in the NVVMOps and as
<code>shared::cta</code> in the PTX ISA. A pointer to this memory space is represented
by the <code>LLVM_PointerShared</code> type in the NVVM Ops.</li><li><strong>constant</strong>: Read-only memory cached per SM. Size typically limited to 64KB.
Best for read-only data and uniform values accessed by all threads. A pointer
to this memory space is represented by <code>LLVM_PointerConst</code> type in NVVM Ops.</li><li><strong>local</strong>: Private to each thread. Use for per-thread private data and
automatic variables that don&rsquo;t fit in registers. A pointer to this memory is
represented by <code>LLVM_PointerLocal</code> type in NVVM Ops.</li><li><strong>tensor</strong>: Special memory space for tensor core operations. Used by
<code>tcgen05</code> instructions on SM 100+ for tensor input/output operations.
A pointer to this memory space is represented by the <code>LLVM_PointerTensor</code>
type in the NVVM Ops.</li><li><strong>shared_cluster</strong>: Distributed shared memory across thread blocks within a
cluster (SM 90+). Enables collaboration beyond single-block scope with fast
access across cluster threads. This memory is usually referred as
<code>shared_cluster</code> in the NVVMOps and as <code>shared::cluster</code> in the PTX ISA.
A pointer to this memory space is represented by the <code>LLVM_PointerSharedCluster</code>
type in the NVVM Ops.</li></ul><h2 id=mbarrier-objects>MBarrier objects&nbsp;<a class=headline-hash href=#mbarrier-objects>¶</a></h2><p>An <code>mbarrier</code> is a barrier created in shared memory that supports
synchronizing any subset of threads within a CTA. An <em>mbarrier object</em>
is an opaque object in shared memory with <code>.b64</code> type and an alignment of
8-bytes. Unlike <code>nvvm.barrier</code> Op which can access only a limited number
of barriers per CTA, the <em>mbarrier objects</em> are user-defined and are only
limited by the total shared memory size available. The list of operations
supported on an <em>mbarrier object</em> is exposed through the <code>nvvm.mbarrier.*</code>
family of NVVM Ops.</p><h2 id=non-goals>Non-Goals&nbsp;<a class=headline-hash href=#non-goals>¶</a></h2><p>NVVM is not a place for convenience or &ldquo;wrapper&rdquo; ops. It is not intended to
introduce high-level ops that expand into multiple unrelated NVVM intrinsics or
that lower to no intrinsic at all. Such abstractions belong in higher-level
dialects (e.g., <code>nvgpu</code>, <code>gpu</code>, or project-specific dialects). The design
intent is a thin, predictable, low-level surface with near-mechanical lowering
to NVVM/LLVM IR.</p><h2 id=operations>Operations&nbsp;<a class=headline-hash href=#operations>¶</a></h2><p>All operations in the NVIDIA&rsquo;s instruction set have a custom form in MLIR. The mnemonic
of an operation is that used in LLVM IR prefixed with &ldquo;<code>nvvm.</code>&rdquo;.</p><p><a href=https://github.com/llvm/llvm-project/blob/main/mlir/include/mlir/Dialect/LLVMIR/NVVMOps.td>source</a></p><h3 id=nvvmbarrier0-nvvmbarrier0op><code>nvvm.barrier0</code> (NVVM::Barrier0Op)&nbsp;<a class=headline-hash href=#nvvmbarrier0-nvvmbarrier0op>¶</a></h3><p><em>CTA Barrier Synchronization Op (Barrier ID 0)</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.barrier0` attr-dict
</code></pre><p>The <code>nvvm.barrier0</code> operation is a convenience operation that performs barrier
synchronization and communication within a CTA (Cooperative Thread Array) using
barrier ID 0. It is functionally equivalent to <code>nvvm.barrier</code> or <code>nvvm.barrier id=0</code>.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-bar>For more information, see PTX ISA</a></p><h3 id=nvvmbarrierarrive-nvvmbarrierarriveop><code>nvvm.barrier.arrive</code> (NVVM::BarrierArriveOp)&nbsp;<a class=headline-hash href=#nvvmbarrierarrive-nvvmbarrierarriveop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.barrier.arrive` (`id` `=` $barrierId^)? `number_of_threads` `=` $numberOfThreads attr-dict
</code></pre><p>Thread that executes this op announces their arrival at the barrier with
given id and continue their execution.</p><p>The default barrier id is 0 that is similar to <code>nvvm.barrier</code> Op. When
<code>barrierId</code> is not present, the default barrier id is used.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-bar>For more information, see PTX ISA</a></p><p>Interfaces: <code>BasicPtxBuilderInterface</code></p><h4 id=operands>Operands:&nbsp;<a class=headline-hash href=#operands>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>barrierId</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>numberOfThreads</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmbarrier-nvvmbarrierop><code>nvvm.barrier</code> (NVVM::BarrierOp)&nbsp;<a class=headline-hash href=#nvvmbarrier-nvvmbarrierop>¶</a></h3><p><em>CTA Barrier Synchronization Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.barrier` (`id` `=` $barrierId^)? (`number_of_threads` `=` $numberOfThreads^)? (qualified($reductionOp)^ $reductionPredicate)? (`-&gt;` type($res)^)? attr-dict
</code></pre><p>The <code>nvvm.barrier</code> operation performs barrier synchronization and communication
within a CTA (Cooperative Thread Array). It causes executing threads to wait for
all non-exited threads participating in the barrier to arrive.</p><p>The operation takes two optional operands:</p><ul><li><code>barrierId</code>: Specifies a logical barrier resource with value 0 through 15.
Each CTA instance has sixteen barriers numbered 0..15. Defaults to 0 if not specified.</li><li><code>numberOfThreads</code>: Specifies the number of threads participating in the barrier.
When specified, the value must be a multiple of the warp size. If not specified,
all threads in the CTA participate in the barrier.</li><li><code>reductionOp</code>: specifies the reduction operation (<code>popc</code>, <code>and</code>, <code>or</code>).</li><li><code>reductionPredicate</code>: specifies the predicate to be used with the
<code>reductionOp</code>.</li></ul><p>The barrier operation guarantees that when the barrier completes, prior memory
accesses requested by participating threads are performed relative to all threads
participating in the barrier. It also ensures that no new memory access is
requested by participating threads before the barrier completes.</p><p>When a barrier completes, the waiting threads are restarted without delay, and
the barrier is reinitialized so that it can be immediately reused.</p><p>This operation generates an aligned barrier, indicating that all threads in the CTA
will execute the same barrier instruction. Behavior is undefined if all threads in the
CTA do not reach this instruction.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-bar>For more information, see PTX ISA</a></p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes>Attributes:&nbsp;<a class=headline-hash href=#attributes>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>reductionOp</code></td><td>::mlir::NVVM::BarrierReductionAttr</td><td>NVVM barrier reduction operation</td></tr></table><h4 id=operands-1>Operands:&nbsp;<a class=headline-hash href=#operands-1>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>barrierId</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>numberOfThreads</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>reductionPredicate</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results>Results:&nbsp;<a class=headline-hash href=#results>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmreadptxsregntidx-nvvmblockdimxop><code>nvvm.read.ptx.sreg.ntid.x</code> (NVVM::BlockDimXOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregntidx-nvvmblockdimxop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.ntid.x` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-1>Attributes:&nbsp;<a class=headline-hash href=#attributes-1>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-1>Results:&nbsp;<a class=headline-hash href=#results-1>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregntidy-nvvmblockdimyop><code>nvvm.read.ptx.sreg.ntid.y</code> (NVVM::BlockDimYOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregntidy-nvvmblockdimyop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.ntid.y` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-2>Attributes:&nbsp;<a class=headline-hash href=#attributes-2>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-2>Results:&nbsp;<a class=headline-hash href=#results-2>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregntidz-nvvmblockdimzop><code>nvvm.read.ptx.sreg.ntid.z</code> (NVVM::BlockDimZOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregntidz-nvvmblockdimzop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.ntid.z` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-3>Attributes:&nbsp;<a class=headline-hash href=#attributes-3>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-3>Results:&nbsp;<a class=headline-hash href=#results-3>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregctaidx-nvvmblockidxop><code>nvvm.read.ptx.sreg.ctaid.x</code> (NVVM::BlockIdXOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregctaidx-nvvmblockidxop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.ctaid.x` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-4>Attributes:&nbsp;<a class=headline-hash href=#attributes-4>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-4>Results:&nbsp;<a class=headline-hash href=#results-4>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregctaidy-nvvmblockidyop><code>nvvm.read.ptx.sreg.ctaid.y</code> (NVVM::BlockIdYOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregctaidy-nvvmblockidyop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.ctaid.y` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-5>Attributes:&nbsp;<a class=headline-hash href=#attributes-5>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-5>Results:&nbsp;<a class=headline-hash href=#results-5>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregctaidz-nvvmblockidzop><code>nvvm.read.ptx.sreg.ctaid.z</code> (NVVM::BlockIdZOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregctaidz-nvvmblockidzop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.ctaid.z` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-6>Attributes:&nbsp;<a class=headline-hash href=#attributes-6>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-6>Results:&nbsp;<a class=headline-hash href=#results-6>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusterctaidx-nvvmblockinclusteridxop><code>nvvm.read.ptx.sreg.cluster.ctaid.x</code> (NVVM::BlockInClusterIdXOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusterctaidx-nvvmblockinclusteridxop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.cluster.ctaid.x` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSM&lt;90></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-7>Attributes:&nbsp;<a class=headline-hash href=#attributes-7>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-7>Results:&nbsp;<a class=headline-hash href=#results-7>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusterctaidy-nvvmblockinclusteridyop><code>nvvm.read.ptx.sreg.cluster.ctaid.y</code> (NVVM::BlockInClusterIdYOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusterctaidy-nvvmblockinclusteridyop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.cluster.ctaid.y` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSM&lt;90></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-8>Attributes:&nbsp;<a class=headline-hash href=#attributes-8>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-8>Results:&nbsp;<a class=headline-hash href=#results-8>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusterctaidz-nvvmblockinclusteridzop><code>nvvm.read.ptx.sreg.cluster.ctaid.z</code> (NVVM::BlockInClusterIdZOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusterctaidz-nvvmblockinclusteridzop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.cluster.ctaid.z` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSM&lt;90></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-9>Attributes:&nbsp;<a class=headline-hash href=#attributes-9>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-9>Results:&nbsp;<a class=headline-hash href=#results-9>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmbreakpoint-nvvmbreakpoint><code>nvvm.breakpoint</code> (NVVM::Breakpoint)&nbsp;<a class=headline-hash href=#nvvmbreakpoint-nvvmbreakpoint>¶</a></h3><p><em>Breakpoint Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.breakpoint` attr-dict
</code></pre><p>Breakpoint suspends execution of the program for debugging.
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#miscellaneous-instructions-brkpt>For more information, see PTX ISA</a></p><h3 id=nvvmstbulk-nvvmbulkstoreop><code>nvvm.st.bulk</code> (NVVM::BulkStoreOp)&nbsp;<a class=headline-hash href=#nvvmstbulk-nvvmbulkstoreop>¶</a></h3><p><em>Bulk Store Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.st.bulk` $addr `,` `size` `=` $size (`,` `init` `=` $initVal^)? attr-dict `:` type($addr)
</code></pre><p>Initializes a region of shared memory at the address given by <code>addr</code>.
The <code>size</code> operand specifies the number of bytes to initialize and must be
a multiple of 8.
The <code>initVal</code> operand specifies the value to initialize the memory to. The
only supported value is 0.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#data-movement-and-conversion-instructions-st-bulk>For more information, see PTX ISA</a></p><h4 id=attributes-10>Attributes:&nbsp;<a class=headline-hash href=#attributes-10>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>initVal</code></td><td>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></table><h4 id=operands-2>Operands:&nbsp;<a class=headline-hash href=#operands-2>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>size</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmreadptxsregclock64-nvvmclock64op><code>nvvm.read.ptx.sreg.clock64</code> (NVVM::Clock64Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclock64-nvvmclock64op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.clock64` attr-dict `:` type($res)
</code></pre><h4 id=results-10>Results:&nbsp;<a class=headline-hash href=#results-10>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclock-nvvmclockop><code>nvvm.read.ptx.sreg.clock</code> (NVVM::ClockOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclock-nvvmclockop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.clock` attr-dict `:` type($res)
</code></pre><h4 id=results-11>Results:&nbsp;<a class=headline-hash href=#results-11>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmclusterarrive-nvvmclusterarriveop><code>nvvm.cluster.arrive</code> (NVVM::ClusterArriveOp)&nbsp;<a class=headline-hash href=#nvvmclusterarrive-nvvmclusterarriveop>¶</a></h3><p><em>Cluster Barrier Arrive Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cluster.arrive` attr-dict
</code></pre><p>The <code>cluster.arrive</code> can be used by the threads within the cluster for synchronization and
communication. The <code>cluster.arrive</code> instruction marks the warps&rsquo; arrival at the barrier
without causing the executing thread to wait for other participating threads.</p><p>The <code>aligned</code> attribute, when provided, generates the .aligned version of the PTX instruction.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-barrier-cluster>For more information, see PTX ISA</a></p><h4 id=attributes-11>Attributes:&nbsp;<a class=headline-hash href=#attributes-11>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>aligned</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h3 id=nvvmclusterarriverelaxed-nvvmclusterarriverelaxedop><code>nvvm.cluster.arrive.relaxed</code> (NVVM::ClusterArriveRelaxedOp)&nbsp;<a class=headline-hash href=#nvvmclusterarriverelaxed-nvvmclusterarriverelaxedop>¶</a></h3><p><em>Cluster Barrier Relaxed Arrive Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cluster.arrive.relaxed` attr-dict
</code></pre><p>The <code>cluster.arrive</code> can be used by the threads within the cluster for synchronization and
communication. The <code>cluster.arrive</code> instruction marks the warps&rsquo; arrival at the barrier
without causing the executing thread to wait for other participating threads.</p><p>The <code>aligned</code> attribute, when provided, generates the .aligned version of the PTX instruction.
The .relaxed qualifier on <code>cluster.arrive</code> specifies that there are no memory
ordering and visibility guarantees provided for the memory accesses performed prior to
<code>cluster.arrive</code>.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-barrier-cluster>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSM&lt;90></code></p><h4 id=attributes-12>Attributes:&nbsp;<a class=headline-hash href=#attributes-12>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>aligned</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h3 id=nvvmreadptxsregclusternctarank-nvvmclusterdim><code>nvvm.read.ptx.sreg.cluster.nctarank</code> (NVVM::ClusterDim)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusternctarank-nvvmclusterdim>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.cluster.nctarank` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-13>Attributes:&nbsp;<a class=headline-hash href=#attributes-13>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-12>Results:&nbsp;<a class=headline-hash href=#results-12>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusternctaidx-nvvmclusterdimblocksxop><code>nvvm.read.ptx.sreg.cluster.nctaid.x</code> (NVVM::ClusterDimBlocksXOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusternctaidx-nvvmclusterdimblocksxop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.cluster.nctaid.x` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSM&lt;90></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-14>Attributes:&nbsp;<a class=headline-hash href=#attributes-14>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-13>Results:&nbsp;<a class=headline-hash href=#results-13>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusternctaidy-nvvmclusterdimblocksyop><code>nvvm.read.ptx.sreg.cluster.nctaid.y</code> (NVVM::ClusterDimBlocksYOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusternctaidy-nvvmclusterdimblocksyop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.cluster.nctaid.y` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSM&lt;90></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-15>Attributes:&nbsp;<a class=headline-hash href=#attributes-15>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-14>Results:&nbsp;<a class=headline-hash href=#results-14>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusternctaidz-nvvmclusterdimblockszop><code>nvvm.read.ptx.sreg.cluster.nctaid.z</code> (NVVM::ClusterDimBlocksZOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusternctaidz-nvvmclusterdimblockszop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.cluster.nctaid.z` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-16>Attributes:&nbsp;<a class=headline-hash href=#attributes-16>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-15>Results:&nbsp;<a class=headline-hash href=#results-15>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregnclusteridx-nvvmclusterdimxop><code>nvvm.read.ptx.sreg.nclusterid.x</code> (NVVM::ClusterDimXOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregnclusteridx-nvvmclusterdimxop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.nclusterid.x` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-17>Attributes:&nbsp;<a class=headline-hash href=#attributes-17>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-16>Results:&nbsp;<a class=headline-hash href=#results-16>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregnclusteridy-nvvmclusterdimyop><code>nvvm.read.ptx.sreg.nclusterid.y</code> (NVVM::ClusterDimYOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregnclusteridy-nvvmclusterdimyop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.nclusterid.y` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-18>Attributes:&nbsp;<a class=headline-hash href=#attributes-18>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-17>Results:&nbsp;<a class=headline-hash href=#results-17>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregnclusteridz-nvvmclusterdimzop><code>nvvm.read.ptx.sreg.nclusterid.z</code> (NVVM::ClusterDimZOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregnclusteridz-nvvmclusterdimzop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.nclusterid.z` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-19>Attributes:&nbsp;<a class=headline-hash href=#attributes-19>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-18>Results:&nbsp;<a class=headline-hash href=#results-18>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusterctarank-nvvmclusterid><code>nvvm.read.ptx.sreg.cluster.ctarank</code> (NVVM::ClusterId)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusterctarank-nvvmclusterid>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.cluster.ctarank` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSM&lt;90></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-20>Attributes:&nbsp;<a class=headline-hash href=#attributes-20>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-19>Results:&nbsp;<a class=headline-hash href=#results-19>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusteridx-nvvmclusteridxop><code>nvvm.read.ptx.sreg.clusterid.x</code> (NVVM::ClusterIdXOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusteridx-nvvmclusteridxop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.clusterid.x` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSM&lt;90></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-21>Attributes:&nbsp;<a class=headline-hash href=#attributes-21>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-20>Results:&nbsp;<a class=headline-hash href=#results-20>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusteridy-nvvmclusteridyop><code>nvvm.read.ptx.sreg.clusterid.y</code> (NVVM::ClusterIdYOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusteridy-nvvmclusteridyop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.clusterid.y` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-22>Attributes:&nbsp;<a class=headline-hash href=#attributes-22>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-21>Results:&nbsp;<a class=headline-hash href=#results-21>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregclusteridz-nvvmclusteridzop><code>nvvm.read.ptx.sreg.clusterid.z</code> (NVVM::ClusterIdZOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregclusteridz-nvvmclusteridzop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.clusterid.z` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-23>Attributes:&nbsp;<a class=headline-hash href=#attributes-23>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-22>Results:&nbsp;<a class=headline-hash href=#results-22>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmclusterlaunchcontrolquerycancel-nvvmclusterlaunchcontrolquerycancelop><code>nvvm.clusterlaunchcontrol.query.cancel</code> (NVVM::ClusterLaunchControlQueryCancelOp)&nbsp;<a class=headline-hash href=#nvvmclusterlaunchcontrolquerycancel-nvvmclusterlaunchcontrolquerycancelop>¶</a></h3><p><em>Query the response of a clusterlaunchcontrol.try.cancel operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.clusterlaunchcontrol.query.cancel` `query` `=` $query_type `,` $try_cancel_response attr-dict `:` type($res)
</code></pre><p><code>clusterlaunchcontrol.query.cancel</code> queries the response of a
<code>clusterlaunchcontrol.try.cancel</code> operation specified by operand
<code>try_cancel_response</code>.</p><p>Operand <code>query_type</code> specifies the type of query to perform and can be one
of the following:</p><ul><li><code>is_canceled</code> : Returns true if the try cancel request succeeded,
and false otherwise.</li><li><code>get_first_cta_id_{x/y/z}</code> : Returns the x, y, or z coordinate of the
first CTA in the canceled cluster. Behaviour is defined only if the try
cancel request succeeded.</li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-query-cancel>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSM&lt;100></code></p><h4 id=attributes-24>Attributes:&nbsp;<a class=headline-hash href=#attributes-24>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>query_type</code></td><td>::mlir::NVVM::ClusterLaunchControlQueryTypeAttr</td><td><details><summary>NVVM ClusterLaunchControlQueryType</summary><p>Enum cases:</p><ul><li>is_canceled (<code>IS_CANCELED</code>)</li><li>get_first_cta_id_x (<code>GET_FIRST_CTA_ID_X</code>)</li><li>get_first_cta_id_y (<code>GET_FIRST_CTA_ID_Y</code>)</li><li>get_first_cta_id_z (<code>GET_FIRST_CTA_ID_Z</code>)</li></ul></details></td></tr></table><h4 id=operands-3>Operands:&nbsp;<a class=headline-hash href=#operands-3>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>try_cancel_response</code></td><td>128-bit signless integer</td></tr></tbody></table><h4 id=results-23>Results:&nbsp;<a class=headline-hash href=#results-23>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>1-bit signless integer or 32-bit signless integer</td></tr></tbody></table><h3 id=nvvmclusterlaunchcontroltrycancel-nvvmclusterlaunchcontroltrycancelop><code>nvvm.clusterlaunchcontrol.try.cancel</code> (NVVM::ClusterLaunchControlTryCancelOp)&nbsp;<a class=headline-hash href=#nvvmclusterlaunchcontroltrycancel-nvvmclusterlaunchcontroltrycancelop>¶</a></h3><p><em>Request atomically canceling the launch of a cluster that has not started running yet</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.clusterlaunchcontrol.try.cancel` (`multicast` $multicast^ `,`)? $smemAddress `,` $mbarrier attr-dict
</code></pre><p><code>clusterlaunchcontrol.try.cancel</code> requests atomically canceling the launch
of a cluster that has not started running yet. It asynchronously writes an
opaque response to shared memory indicating whether the operation succeeded
or failed.</p><p>Operand <code>smemAddress</code> specifies the naturally aligned address of the
16-byte wide shared memory location where the request&rsquo;s response is written.</p><p>Operand <code>mbarrier</code> specifies the mbarrier object used to track the
completion of the asynchronous operation.</p><p>If <code>multicast</code> is specified, the response is asynchronously written to the
corresponding local shared memory location (specifed by <code>addr</code>) of each CTA
in the requesting cluster.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-try-cancel>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSM&lt;100></code></p><h4 id=attributes-25>Attributes:&nbsp;<a class=headline-hash href=#attributes-25>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>multicast</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h4 id=operands-4>Operands:&nbsp;<a class=headline-hash href=#operands-4>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>smemAddress</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>mbarrier</code></td><td>LLVM pointer in address space 3</td></tr></tbody></table><h3 id=nvvmclusterwait-nvvmclusterwaitop><code>nvvm.cluster.wait</code> (NVVM::ClusterWaitOp)&nbsp;<a class=headline-hash href=#nvvmclusterwait-nvvmclusterwaitop>¶</a></h3><p><em>Cluster Barrier Wait Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cluster.wait` attr-dict
</code></pre><p>The <code>cluster.wait</code> causes the executing thread to wait for all non-exited threads
of the cluster to perform <code>cluster.arrive</code>. The <code>aligned</code> attribute, when provided,
generates the .aligned version of the PTX instruction.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-barrier-cluster>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSM&lt;90></code></p><h4 id=attributes-26>Attributes:&nbsp;<a class=headline-hash href=#attributes-26>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>aligned</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h3 id=nvvmconvertbf16x2tof8x2-nvvmconvertbf16x2tof8x2op><code>nvvm.convert.bf16x2.to.f8x2</code> (NVVM::ConvertBF16x2ToF8x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertbf16x2tof8x2-nvvmconvertbf16x2tof8x2op>¶</a></h3><p><em>Convert a pair of bf16 inputs to f8x2</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.bf16x2.to.f8x2` $a attr-dict `:` type($a) `-&gt;` type($dst) `(` $dstTy `)`
</code></pre><p>This Op converts the given bf16 inputs in a bf16x2 vector to the specified
f8 type.
The result <code>dst</code> is represented as an i16 type or as a vector
of two i8 types.
If <code>dst</code> is returned as an i16 type, the converted values from <code>a</code>
are packed such that the value converted from the first element of <code>a</code>
is stored in the upper 8 bits of <code>dst</code> and the value converted from the
second element of <code>a</code> is stored in the lower 8 bits of <code>dst</code>.
If <code>dst</code> is returned as a vector type, each converted value is stored as an
i8 element in the vector.
The <code>rnd</code> and <code>sat</code> attributes specify the rounding and saturation modes
respectively.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-27>Attributes:&nbsp;<a class=headline-hash href=#attributes-27>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>rnd</code></td><td>::mlir::NVVM::FPRoundingModeAttr</td><td>NVVM FPRoundingMode kind</td></tr><tr><td><code>sat</code></td><td>::mlir::NVVM::SaturationModeAttr</td><td>NVVM SaturationMode kind</td></tr><tr><td><code>dstTy</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-5>Operands:&nbsp;<a class=headline-hash href=#operands-5>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>vector of bfloat16 type values of length 2</td></tr></tbody></table><h4 id=results-24>Results:&nbsp;<a class=headline-hash href=#results-24>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>16-bit signless integer or vector of 8-bit signless integer values of length 2</td></tr></tbody></table><h3 id=nvvmconvertf16x2tof8x2-nvvmconvertf16x2tof8x2op><code>nvvm.convert.f16x2.to.f8x2</code> (NVVM::ConvertF16x2ToF8x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf16x2tof8x2-nvvmconvertf16x2tof8x2op>¶</a></h3><p><em>Convert an f16x2 input to f8x2</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f16x2.to.f8x2` $a attr-dict `:` type($a) `-&gt;` type($dst) `(` $dstTy `)`
</code></pre><p>This Op converts the given f16 inputs in an f16x2 vector to the specified
f8 type.
The result <code>dst</code> is represented as an i16 type or as a vector
of two i8 types.
If <code>dst</code> is returned as an i16 type, the converted values from <code>a</code>
are packed such that the value converted from the first element of <code>a</code>
is stored in the upper 8 bits of <code>dst</code> and the value converted from the
second element of <code>a</code> is stored in the lower 8 bits of <code>dst</code>.
If <code>dst</code> is returned as a vector type, each converted value is stored as an
i8 element in the vector.
The <code>relu</code> attribute, when set, lowers to the &lsquo;.relu&rsquo; variant of
the cvt instruction.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-28>Attributes:&nbsp;<a class=headline-hash href=#attributes-28>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>dstTy</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-6>Operands:&nbsp;<a class=headline-hash href=#operands-6>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>vector of 16-bit float values of length 2</td></tr></tbody></table><h4 id=results-25>Results:&nbsp;<a class=headline-hash href=#results-25>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>16-bit signless integer or vector of 8-bit signless integer values of length 2</td></tr></tbody></table><h3 id=nvvmconvertf32x2tobf16x2-nvvmconvertf32x2tobf16x2op><code>nvvm.convert.f32x2.to.bf16x2</code> (NVVM::ConvertF32x2ToBF16x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf32x2tobf16x2-nvvmconvertf32x2tobf16x2op>¶</a></h3><p><em>Convert two F32 values to packed bf16x2.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f32x2.to.bf16x2` $src_hi `,` $src_lo (`,` $random_bits^)? attr-dict `:` type($dst)
</code></pre><p>Converts two F32 values to packed bf16x2 format with
the specified rounding mode. The <code>src_hi</code> and <code>src_lo</code> parameters
correspond to operands <code>a</code> and <code>b</code> in the PTX ISA, respectively.</p><p>The <code>random_bits</code> parameter is required for stochastic rounding and
provides the
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#cvt-rs-rbits-layout-bf16>random bits</a> to be used for the conversion.</p><p>The <code>relu</code> attribute clamps negative results to 0.</p><p>The <code>sat</code> attribute determines saturation behavior.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-29>Attributes:&nbsp;<a class=headline-hash href=#attributes-29>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>rnd</code></td><td>::mlir::NVVM::FPRoundingModeAttr</td><td>NVVM FPRoundingMode kind</td></tr><tr><td><code>sat</code></td><td>::mlir::NVVM::SaturationModeAttr</td><td>NVVM SaturationMode kind</td></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-7>Operands:&nbsp;<a class=headline-hash href=#operands-7>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src_hi</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>src_lo</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>random_bits</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-26>Results:&nbsp;<a class=headline-hash href=#results-26>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of bfloat16 type values of length 2</td></tr></tbody></table><h3 id=nvvmconvertf32x2tof16x2-nvvmconvertf32x2tof16x2op><code>nvvm.convert.f32x2.to.f16x2</code> (NVVM::ConvertF32x2ToF16x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf32x2tof16x2-nvvmconvertf32x2tof16x2op>¶</a></h3><p><em>Convert two F32 values to packed f16x2.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f32x2.to.f16x2` $src_hi `,` $src_lo (`,` $random_bits^)? attr-dict `:` type($dst)
</code></pre><p>Converts two F32 values to packed f16x2 format with
the specified rounding mode. The <code>src_hi</code> and <code>src_lo</code> parameters
correspond to operands <code>a</code> and <code>b</code> in the PTX ISA, respectively.</p><p>The <code>random_bits</code> parameter is required for stochastic rounding and
provides the
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#cvt-rs-rbits-layout-f16>random bits</a> to be used for the conversion.</p><p>The <code>relu</code> attribute clamps negative results to 0.</p><p>The <code>sat</code> attribute determines saturation behavior.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-30>Attributes:&nbsp;<a class=headline-hash href=#attributes-30>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>rnd</code></td><td>::mlir::NVVM::FPRoundingModeAttr</td><td>NVVM FPRoundingMode kind</td></tr><tr><td><code>sat</code></td><td>::mlir::NVVM::SaturationModeAttr</td><td>NVVM SaturationMode kind</td></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-8>Operands:&nbsp;<a class=headline-hash href=#operands-8>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src_hi</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>src_lo</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>random_bits</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-27>Results:&nbsp;<a class=headline-hash href=#results-27>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 16-bit float values of length 2</td></tr></tbody></table><h3 id=nvvmconvertf32x2tof4x2-nvvmconvertf32x2tof4x2op><code>nvvm.convert.f32x2.to.f4x2</code> (NVVM::ConvertF32x2ToF4x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf32x2tof4x2-nvvmconvertf32x2tof4x2op>¶</a></h3><p><em>Convert a pair of float inputs to f4x2</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f32x2.to.f4x2` $a `,` $b attr-dict `:` type($dst) `(` $dstTy `)`
</code></pre><p>This Op converts each of the given float inputs to the specified fp4 type.
The result <code>dst</code> is returned as an i8 type where the converted values are
packed such that the value converted from <code>a</code> is stored in the upper 4 bits
of <code>dst</code> and the value converted from <code>b</code> is stored in the lower 4 bits of
<code>dst</code>.
The <code>relu</code> attribute, when set, lowers to the &lsquo;.relu&rsquo; variant of
the cvt instruction.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-31>Attributes:&nbsp;<a class=headline-hash href=#attributes-31>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>dstTy</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-9>Operands:&nbsp;<a class=headline-hash href=#operands-9>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>b</code></td><td>32-bit float</td></tr></tbody></table><h4 id=results-28>Results:&nbsp;<a class=headline-hash href=#results-28>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>8-bit signless integer</td></tr></tbody></table><h3 id=nvvmconvertf32x2tof6x2-nvvmconvertf32x2tof6x2op><code>nvvm.convert.f32x2.to.f6x2</code> (NVVM::ConvertF32x2ToF6x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf32x2tof6x2-nvvmconvertf32x2tof6x2op>¶</a></h3><p><em>Convert a pair of float inputs to f6x2</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f32x2.to.f6x2` $a `,` $b attr-dict `:` type($dst) `(` $dstTy `)`
</code></pre><p>This Op converts each of the given float inputs to the specified fp6 type.
The result <code>dst</code> is represented either as an i16 type or as a vector
of two i8 types.
If <code>dst</code> is returned as an i16 type, the converted values are packed such
that the value converted from <code>a</code> is stored in the upper 8 bits of <code>dst</code>
with 2 MSB bits padded with zeros and the value converted from <code>b</code> is
stored in the lower 8 bits of <code>dst</code> with 2 MSB bits padded with zeros.
If <code>dst</code> is returned as a vector type, each converted value is stored as an
i8 element in the vector.
The <code>relu</code> attribute, when set, lowers to the &lsquo;.relu&rsquo; variant of
the cvt instruction.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-32>Attributes:&nbsp;<a class=headline-hash href=#attributes-32>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>dstTy</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-10>Operands:&nbsp;<a class=headline-hash href=#operands-10>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>b</code></td><td>32-bit float</td></tr></tbody></table><h4 id=results-29>Results:&nbsp;<a class=headline-hash href=#results-29>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>16-bit signless integer or vector of 8-bit signless integer values of length 2</td></tr></tbody></table><h3 id=nvvmconvertf32x2tof8x2-nvvmconvertf32x2tof8x2op><code>nvvm.convert.f32x2.to.f8x2</code> (NVVM::ConvertF32x2ToF8x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf32x2tof8x2-nvvmconvertf32x2tof8x2op>¶</a></h3><p><em>Convert a pair of float inputs to f8x2</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f32x2.to.f8x2` $a `,` $b attr-dict `:` type($dst) `(` $dstTy `)`
</code></pre><p>This Op converts each of the given float inputs to the specified fp8 type.
The result <code>dst</code> is represented as an i16 type or as a vector
of two i8 types.
If <code>dst</code> is returned as an i16 type, the converted values are packed such
that the value converted from <code>a</code> is stored in the upper 8 bits of <code>dst</code>
and the value converted from <code>b</code> is stored in the lower 8 bits of <code>dst</code>.
If <code>dst</code> is returned as a vector type, each converted value is stored as an
i8 element in the vector.
The <code>rnd</code> and <code>sat</code> attributes specify the rounding and saturation modes respectively.
The <code>relu</code> attribute, when set, lowers to the &lsquo;.relu&rsquo; variant of
the cvt instruction.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-33>Attributes:&nbsp;<a class=headline-hash href=#attributes-33>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>rnd</code></td><td>::mlir::NVVM::FPRoundingModeAttr</td><td>NVVM FPRoundingMode kind</td></tr><tr><td><code>sat</code></td><td>::mlir::NVVM::SaturationModeAttr</td><td>NVVM SaturationMode kind</td></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>dstTy</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-11>Operands:&nbsp;<a class=headline-hash href=#operands-11>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>32-bit float</td></tr><tr><td style=text-align:center><code>b</code></td><td>32-bit float</td></tr></tbody></table><h4 id=results-30>Results:&nbsp;<a class=headline-hash href=#results-30>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>16-bit signless integer or vector of 8-bit signless integer values of length 2</td></tr></tbody></table><h3 id=nvvmconvertf32x4tof4x4-nvvmconvertf32x4tof4x4op><code>nvvm.convert.f32x4.to.f4x4</code> (NVVM::ConvertF32x4ToF4x4Op)&nbsp;<a class=headline-hash href=#nvvmconvertf32x4tof4x4-nvvmconvertf32x4tof4x4op>¶</a></h3><p><em>Convert vector&lt;4xf32> to packed f4x4 with stochastic rounding (.rs) and satfinite</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f32x4.to.f4x4` $src `,` $rbits attr-dict `:` type($src) `-&gt;` type($dst) `(` $dstTy `)`
</code></pre><p>Converts a vector&lt;4xf32> to packed f4x4 format using
stochastic rounding (.rs) mode with SATFINITE saturation. Randomness is
provided by the <code>rbits</code> parameter. The <code>dstTy</code> attribute specifies the
target floating-point format. The <code>relu</code> attribute clamps negative results to 0.</p><p>Note: These operations always use RS rounding mode and SATFINITE saturation mode.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSMa&lt;100,103></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-34>Attributes:&nbsp;<a class=headline-hash href=#attributes-34>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>dstTy</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-12>Operands:&nbsp;<a class=headline-hash href=#operands-12>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>vector of 32-bit float values of length 4</td></tr><tr><td style=text-align:center><code>rbits</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-31>Results:&nbsp;<a class=headline-hash href=#results-31>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>16-bit signless integer</td></tr></tbody></table><h3 id=nvvmconvertf32x4tof6x4-nvvmconvertf32x4tof6x4op><code>nvvm.convert.f32x4.to.f6x4</code> (NVVM::ConvertF32x4ToF6x4Op)&nbsp;<a class=headline-hash href=#nvvmconvertf32x4tof6x4-nvvmconvertf32x4tof6x4op>¶</a></h3><p><em>Convert vector&lt;4xf32> to packed f6x4 with stochastic rounding (.rs) and satfinite</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f32x4.to.f6x4` $src `,` $rbits attr-dict `:` type($src) `-&gt;` type($dst) `(` $dstTy `)`
</code></pre><p>Converts a vector&lt;4xf32> to packed f6x4 format using
stochastic rounding (.rs) mode with SATFINITE saturation. Randomness is
provided by the <code>rbits</code> parameter. The <code>dstTy</code> attribute specifies the
target floating-point format. The <code>relu</code> attribute clamps negative results to 0.</p><p>Note: These operations always use RS rounding mode and SATFINITE saturation mode.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSMa&lt;100,103></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-35>Attributes:&nbsp;<a class=headline-hash href=#attributes-35>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>dstTy</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-13>Operands:&nbsp;<a class=headline-hash href=#operands-13>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>vector of 32-bit float values of length 4</td></tr><tr><td style=text-align:center><code>rbits</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-32>Results:&nbsp;<a class=headline-hash href=#results-32>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 8-bit signless integer values of length 4</td></tr></tbody></table><h3 id=nvvmconvertf32x4tof8x4-nvvmconvertf32x4tof8x4op><code>nvvm.convert.f32x4.to.f8x4</code> (NVVM::ConvertF32x4ToF8x4Op)&nbsp;<a class=headline-hash href=#nvvmconvertf32x4tof8x4-nvvmconvertf32x4tof8x4op>¶</a></h3><p><em>Convert vector&lt;4xf32> to packed f8x4 with stochastic rounding (.rs) and satfinite</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f32x4.to.f8x4` $src `,` $rbits attr-dict `:` type($src) `-&gt;` type($dst) `(` $dstTy `)`
</code></pre><p>Converts a vector&lt;4xf32> to packed f8x4 format using
stochastic rounding (.rs) mode with SATFINITE saturation. Randomness is
provided by the <code>rbits</code> parameter. The <code>dstTy</code> attribute specifies the
target floating-point format. The <code>relu</code> attribute clamps negative results to 0.</p><p>Note: These operations always use RS rounding mode and SATFINITE saturation mode.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>NVVMRequiresSMa&lt;100,103></code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-36>Attributes:&nbsp;<a class=headline-hash href=#attributes-36>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>dstTy</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-14>Operands:&nbsp;<a class=headline-hash href=#operands-14>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>vector of 32-bit float values of length 4</td></tr><tr><td style=text-align:center><code>rbits</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-33>Results:&nbsp;<a class=headline-hash href=#results-33>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 8-bit signless integer values of length 4</td></tr></tbody></table><h3 id=nvvmconvertf4x2tof16x2-nvvmconvertf4x2tof16x2op><code>nvvm.convert.f4x2.to.f16x2</code> (NVVM::ConvertF4x2ToF16x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf4x2tof16x2-nvvmconvertf4x2tof16x2op>¶</a></h3><p><em>Convert a pair of f4 inputs to f16x2</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f4x2.to.f16x2` $src attr-dict `:` type($src) `(` $srcType `)` `-&gt;` type($dst)
</code></pre><p>This Op converts the given f4 inputs in a packed i8 to f16.</p><p>The result <code>dst</code> is represented as a vector of f16 elements.
The <code>relu</code> attribute, when set, lowers to the &lsquo;.relu&rsquo; variant of
the cvt instruction."</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-37>Attributes:&nbsp;<a class=headline-hash href=#attributes-37>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>srcType</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-15>Operands:&nbsp;<a class=headline-hash href=#operands-15>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>8-bit signless integer</td></tr></tbody></table><h4 id=results-34>Results:&nbsp;<a class=headline-hash href=#results-34>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 16-bit float values of length 2</td></tr></tbody></table><h3 id=nvvmconvertf6x2tof16x2-nvvmconvertf6x2tof16x2op><code>nvvm.convert.f6x2.to.f16x2</code> (NVVM::ConvertF6x2ToF16x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf6x2tof16x2-nvvmconvertf6x2tof16x2op>¶</a></h3><p><em>Convert a pair of f6 inputs to f16x2</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f6x2.to.f16x2` $src attr-dict `:` type($src) `(` $srcType `)` `-&gt;` type($dst)
</code></pre><p>This Op converts the given f6 inputs in a i8x2 vector to f16.</p><p>The result <code>dst</code> is represented as a vector of f16 elements.
The <code>relu</code> attribute, when set, lowers to the &lsquo;.relu&rsquo; variant of
the cvt instruction."</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-38>Attributes:&nbsp;<a class=headline-hash href=#attributes-38>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>srcType</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-16>Operands:&nbsp;<a class=headline-hash href=#operands-16>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>vector of 8-bit signless integer values of length 2</td></tr></tbody></table><h4 id=results-35>Results:&nbsp;<a class=headline-hash href=#results-35>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 16-bit float values of length 2</td></tr></tbody></table><h3 id=nvvmconvertf8x2tobf16x2-nvvmconvertf8x2tobf16x2op><code>nvvm.convert.f8x2.to.bf16x2</code> (NVVM::ConvertF8x2ToBF16x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf8x2tobf16x2-nvvmconvertf8x2tobf16x2op>¶</a></h3><p><em>Convert a pair of f8 inputs to bf16x2</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f8x2.to.bf16x2` $src attr-dict `:` type($src) `(` $srcType `)` `-&gt;` type($dst)
</code></pre><p>This Op converts the given f8 inputs in a i8x2 vector to bf16.</p><p>The result <code>dst</code> is represented as a vector of bf16 elements.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-39>Attributes:&nbsp;<a class=headline-hash href=#attributes-39>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>srcType</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-17>Operands:&nbsp;<a class=headline-hash href=#operands-17>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>vector of 8-bit signless integer values of length 2</td></tr></tbody></table><h4 id=results-36>Results:&nbsp;<a class=headline-hash href=#results-36>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of bfloat16 type values of length 2</td></tr></tbody></table><h3 id=nvvmconvertf8x2tof16x2-nvvmconvertf8x2tof16x2op><code>nvvm.convert.f8x2.to.f16x2</code> (NVVM::ConvertF8x2ToF16x2Op)&nbsp;<a class=headline-hash href=#nvvmconvertf8x2tof16x2-nvvmconvertf8x2tof16x2op>¶</a></h3><p><em>Convert a pair of f8 inputs to f16x2</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.f8x2.to.f16x2` $src attr-dict `:` type($src) `(` $srcType `)` `-&gt;` type($dst)
</code></pre><p>This Op converts the given f8 inputs in a i8x2 vector to f16.</p><p>The result <code>dst</code> is represented as a vector of f16 elements.
The <code>relu</code> attribute, when set, lowers to the &lsquo;.relu&rsquo; variant of
the cvt instruction."</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-40>Attributes:&nbsp;<a class=headline-hash href=#attributes-40>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>srcType</code></td><td>::mlir::TypeAttr</td><td>any type attribute</td></tr></table><h4 id=operands-18>Operands:&nbsp;<a class=headline-hash href=#operands-18>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>vector of 8-bit signless integer values of length 2</td></tr></tbody></table><h4 id=results-37>Results:&nbsp;<a class=headline-hash href=#results-37>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 16-bit float values of length 2</td></tr></tbody></table><h3 id=nvvmconvertfloattotf32-nvvmconvertfloattotf32op><code>nvvm.convert.float.to.tf32</code> (NVVM::ConvertFloatToTF32Op)&nbsp;<a class=headline-hash href=#nvvmconvertfloattotf32-nvvmconvertfloattotf32op>¶</a></h3><p><em>Convert the given float input to TF32</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.convert.float.to.tf32` $src attr-dict
</code></pre><p>This Op converts the given f32 input to tf32.
The result <code>res</code> is represented as an i32 type.
The <code>relu</code> attribute, when set, lowers to the &lsquo;.relu&rsquo; variant of
the cvt instruction. The <code>rnd</code> and <code>sat</code> attributes specify the
the rounding and saturation modes respectively.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt>For more information, see PTX ISA</a></p><h4 id=attributes-41>Attributes:&nbsp;<a class=headline-hash href=#attributes-41>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>rnd</code></td><td>::mlir::NVVM::FPRoundingModeAttr</td><td>NVVM FPRoundingMode kind</td></tr><tr><td><code>sat</code></td><td>::mlir::NVVM::SaturationModeAttr</td><td>NVVM SaturationMode kind</td></tr><tr><td><code>relu</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-19>Operands:&nbsp;<a class=headline-hash href=#operands-19>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>32-bit float</td></tr></tbody></table><h4 id=results-38>Results:&nbsp;<a class=headline-hash href=#results-38>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncbulkcommitgroup-nvvmcpasyncbulkcommitgroupop><code>nvvm.cp.async.bulk.commit.group</code> (NVVM::CpAsyncBulkCommitGroupOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulkcommitgroup-nvvmcpasyncbulkcommitgroupop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.commit.group` attr-dict
</code></pre><p>This Op commits all prior initiated but uncommitted cp.async.bulk
instructions into a cp.async.bulk-group.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk-commit-group>For more information, see PTX ISA</a></p><h3 id=nvvmcpasyncbulksharedclusterglobal-nvvmcpasyncbulkglobaltosharedclusterop><code>nvvm.cp.async.bulk.shared.cluster.global</code> (NVVM::CpAsyncBulkGlobalToSharedClusterOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulksharedclusterglobal-nvvmcpasyncbulkglobaltosharedclusterop>¶</a></h3><p><em>Async bulk copy from global to Shared {cta or cluster} memory</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.shared.cluster.global` $dstMem `,` $srcMem `,` $mbar `,` $size
              (`multicast_mask` `=` $multicastMask^ )?
              (`l2_cache_hint` `=` $l2CacheHint^ )?
              attr-dict  `:` type($dstMem) `,` type($srcMem)
</code></pre><p>Initiates an asynchronous copy operation from global memory to shared
memory or shared_cluster memory.</p><p>The <code>multicastMask</code> operand is optional and can be used only when the
destination is shared::cluster memory. When it is present, this Op copies
data from global memory to shared memory of multiple CTAs in the cluster.
Operand <code>multicastMask</code> specifies the destination CTAs in the cluster such
that each bit position in the 16-bit <code>multicastMask</code> operand corresponds to
the <code>nvvm.read.ptx.sreg.ctaid</code> of the destination CTA.</p><p>The <code>l2CacheHint</code> operand is optional, and it is used to specify cache
eviction policy that may be used during the memory access.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk>For more information, see PTX ISA</a></p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=operands-20>Operands:&nbsp;<a class=headline-hash href=#operands-20>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dstMem</code></td><td>LLVM pointer in address space 3 or LLVM pointer in address space 7</td></tr><tr><td style=text-align:center><code>srcMem</code></td><td>LLVM pointer in address space 1</td></tr><tr><td style=text-align:center><code>mbar</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>size</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>multicastMask</code></td><td>16-bit signless integer</td></tr><tr><td style=text-align:center><code>l2CacheHint</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncbulkprefetch-nvvmcpasyncbulkprefetchop><code>nvvm.cp.async.bulk.prefetch</code> (NVVM::CpAsyncBulkPrefetchOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulkprefetch-nvvmcpasyncbulkprefetchop>¶</a></h3><p><em>Async bulk prefetch from global memory to L2 cache</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.prefetch` $srcMem `,` $size (`l2_cache_hint` `=` $l2CacheHint^ )?
              attr-dict  `:` type($srcMem)
</code></pre><p>Initiates an asynchronous prefetch of data from the location
specified by <code>srcMem</code> to the L2 cache.</p><p>The <code>l2CacheHint</code> operand is optional, and it is used to specify cache
eviction policy that may be used during the memory access.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  nvvm<span class=p>.</span>cp<span class=p>.</span>async<span class=p>.</span>bulk<span class=p>.</span>prefetch <span class=nv>%src</span><span class=p>,</span> <span class=nv>%size</span> <span class=p>:</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>1</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>// with l2_cache_hint
</span></span></span><span class=line><span class=cl><span class=c></span>  nvvm<span class=p>.</span>cp<span class=p>.</span>async<span class=p>.</span>bulk<span class=p>.</span>prefetch <span class=nv>%src</span><span class=p>,</span> <span class=nv>%size</span> <span class=nl>l2_cache_hint =</span> <span class=nv>%ch</span> <span class=p>:</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>1</span><span class=p>&gt;</span>
</span></span></code></pre></div><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk-prefetch>For more information, see PTX ISA</a></p><h4 id=operands-21>Operands:&nbsp;<a class=headline-hash href=#operands-21>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>srcMem</code></td><td>LLVM pointer in address space 1</td></tr><tr><td style=text-align:center><code>size</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>l2CacheHint</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncbulkglobalsharedcta-nvvmcpasyncbulksharedctatoglobalop><code>nvvm.cp.async.bulk.global.shared.cta</code> (NVVM::CpAsyncBulkSharedCTAToGlobalOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulkglobalsharedcta-nvvmcpasyncbulksharedctatoglobalop>¶</a></h3><p><em>Async bulk copy from Shared CTA memory to Global memory</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.global.shared.cta` $dstMem `,` $srcMem `,` $size
              (`l2_cache_hint` `=` $l2CacheHint^ )?
              (`byte_mask` `=` $byteMask^ )?
              attr-dict `:` type($dstMem) `,` type($srcMem)
</code></pre><p>Initiates an asynchronous copy operation from Shared CTA memory to
global memory. The 32-bit operand <code>size</code> specifies the amount of
memory to be copied, in terms of number of bytes. <code>size</code> must be a
multiple of 16. The <code>l2CacheHint</code> operand is optional, and it is used
to specify cache eviction policy that may be used during the memory
access. The <code>byteMask</code> operand is optional. The i-th bit in the 16-bit
wide <code>byteMask</code> specifies whether the i-th byte of each 16-byte wide
chunk of source data is copied to the destination. If the bit is set,
the byte is copied.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  nvvm<span class=p>.</span>cp<span class=p>.</span>async<span class=p>.</span>bulk<span class=p>.</span>global<span class=p>.</span>shared<span class=p>.</span>cta <span class=nv>%dst</span><span class=p>,</span> <span class=nv>%src</span><span class=p>,</span> <span class=nv>%size</span>
</span></span><span class=line><span class=cl>      <span class=p>:</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>1</span><span class=p>&gt;,</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>3</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>// with l2_cache_hint
</span></span></span><span class=line><span class=cl><span class=c></span>  nvvm<span class=p>.</span>cp<span class=p>.</span>async<span class=p>.</span>bulk<span class=p>.</span>global<span class=p>.</span>shared<span class=p>.</span>cta <span class=nv>%dst</span><span class=p>,</span> <span class=nv>%src</span><span class=p>,</span> <span class=nv>%size</span> <span class=nl>l2_cache_hint =</span> <span class=nv>%ch</span>
</span></span><span class=line><span class=cl>      <span class=p>:</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>1</span><span class=p>&gt;,</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>3</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>// with byte_mask
</span></span></span><span class=line><span class=cl><span class=c></span>  nvvm<span class=p>.</span>cp<span class=p>.</span>async<span class=p>.</span>bulk<span class=p>.</span>global<span class=p>.</span>shared<span class=p>.</span>cta <span class=nv>%dst</span><span class=p>,</span> <span class=nv>%src</span><span class=p>,</span> <span class=nv>%size</span> <span class=nl>byte_mask =</span> <span class=nv>%mask</span>
</span></span><span class=line><span class=cl>      <span class=p>:</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>1</span><span class=p>&gt;,</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>3</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>// with both l2_cache_hint and byte_mask
</span></span></span><span class=line><span class=cl><span class=c></span>  nvvm<span class=p>.</span>cp<span class=p>.</span>async<span class=p>.</span>bulk<span class=p>.</span>global<span class=p>.</span>shared<span class=p>.</span>cta <span class=nv>%dst</span><span class=p>,</span> <span class=nv>%src</span><span class=p>,</span> <span class=nv>%size</span> <span class=nl>l2_cache_hint =</span> <span class=nv>%ch</span> <span class=nl>byte_mask =</span> <span class=nv>%mask</span>
</span></span><span class=line><span class=cl>      <span class=p>:</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>1</span><span class=p>&gt;,</span> <span class=p>!</span>llvm<span class=p>.</span>ptr<span class=p>&lt;</span><span class=m>3</span><span class=p>&gt;</span>
</span></span></code></pre></div><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk>For more information, see PTX ISA</a></p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=operands-22>Operands:&nbsp;<a class=headline-hash href=#operands-22>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dstMem</code></td><td>LLVM pointer in address space 1</td></tr><tr><td style=text-align:center><code>srcMem</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>size</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>l2CacheHint</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>byteMask</code></td><td>16-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncbulksharedclustersharedcta-nvvmcpasyncbulksharedctatosharedclusterop><code>nvvm.cp.async.bulk.shared.cluster.shared.cta</code> (NVVM::CpAsyncBulkSharedCTAToSharedClusterOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulksharedclustersharedcta-nvvmcpasyncbulksharedctatosharedclusterop>¶</a></h3><p><em>Async bulk copy from Shared CTA memory to Shared cluster memory</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.shared.cluster.shared.cta` $dstMem `,` $srcMem `,` $mbar `,` $size
              attr-dict  `:` type($dstMem) `,` type($srcMem)
</code></pre><p>Initiates an asynchronous copy operation from Shared CTA memory to Shared
cluster memory.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk>For more information, see PTX ISA</a></p><h4 id=operands-23>Operands:&nbsp;<a class=headline-hash href=#operands-23>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dstMem</code></td><td>LLVM pointer in address space 7</td></tr><tr><td style=text-align:center><code>srcMem</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>mbar</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>size</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncbulktensorsharedclusterglobal-nvvmcpasyncbulktensorglobaltosharedclusterop><code>nvvm.cp.async.bulk.tensor.shared.cluster.global</code> (NVVM::CpAsyncBulkTensorGlobalToSharedClusterOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulktensorsharedclusterglobal-nvvmcpasyncbulktensorglobaltosharedclusterop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.tensor.shared.cluster.global` $dstMem `,`
              $tmaDescriptor `,`
              $mbar `,`
              `box` `[`$coordinates `]`
              (`im2col` `[` $im2colOffsets^ `]` )?
              (`multicast_mask` `=` $multicastMask^ )?
              (`l2_cache_hint` `=` $l2CacheHint^ )?
              (`predicate` `=` $predicate^)?
              attr-dict  `:` type($dstMem) `,` type($tmaDescriptor)
</code></pre><p>Initiates an asynchronous copy operation on the tensor data from global
memory to shared::cluster (or) shared::cta memory. This Op supports all
the load modes specified in <code>TMALoadMode</code>.</p><p>The <code>multicastMask</code> operand is optional. When it is present, the Op copies
data from global memory to shared memory of multiple CTAs in the cluster.
Operand <code>multicastMask</code> specifies the destination CTAs in the cluster such
that each bit position in the 16-bit <code>multicastMask</code> operand corresponds to
the <code>nvvm.read.ptx.sreg.ctaid</code> of the destination CTA.</p><p>The <code>l2CacheHint</code> operand is optional, and it is used to specify cache
eviction policy that may be used during the memory access.</p><p>When the <code>isCTAOnly</code> attribute is set to true, the destination is
shared::cta only. Hence, <code>multicastMask</code> and <code>CTAGroup</code> are not applicable
when <code>isCTAOnly</code> is true.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk-tensor>For more information, see PTX ISA</a></p><p>Traits: <code>AttrSizedOperandSegments</code>, <code>NVVMRequiresSM&lt;90></code></p><p>Interfaces: <code>BasicPtxBuilderInterface</code></p><h4 id=attributes-42>Attributes:&nbsp;<a class=headline-hash href=#attributes-42>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>mode</code></td><td>::mlir::NVVM::TMALoadModeAttr</td><td><details><summary>List of Load-Modes supported for TMA Tensor Ops</summary><pre><code>TMA Tensor Ops support the following modes, when copying data from
global memory to shared memory (i.e. load):
<p>Tile Mode: It&rsquo;s the default mode. The source multi-dimensional tensor
layout is preserved at the destination.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-tiled-mode>For more information, see PTX ISA</a></p>
<p>Im2col Mode: This mode is used when <code>im2colOffsets</code> operands are present.
The elements in the Bounding Box of the source tensor are rearranged into
columns at the destination. In this mode, the tensor has to be at least
3-dimensional. The number of <code>im2colOffsets</code> is <code>dims - 2</code> where <code>dims</code>
is the dimension of the tensor.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-im2col-mode>For more information, see PTX ISA</a></p>
<p>Im2col_W Mode: This mode is similar to Im2Col mode with the restriction that
elements are accessed across the W dimension only. The number of <code>im2colOffsets</code>
are always two, referred as <code>wHalo</code> and <code>wOffset</code>.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-im2col-w-w128-modes>For more information, see PTX ISA</a></p>
<p>Im2col_W_128 Mode: This mode is similar to Im2Col_W mode with the number of
elements accessed across the W dimension is always 128 only.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-im2col-w-w128-modes>For more information, see PTX ISA</a></p>
<p>Tile_Gather4 Mode: This mode is similar to Tile mode but works only on 2D tensor.
In gather4 mode, four rows in the source 2D tensor are combined to form a single
2D tensor at the destination. This mode requires five co-ordinates. The first one
represents the column-index followed by four row indices.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-tiled-scatter4-gather4-modes>For more information, see PTX ISA</a>
</code></pre></p></details></td></tr><tr><td><code>isCTAOnly</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>group</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr></table><h4 id=operands-24>Operands:&nbsp;<a class=headline-hash href=#operands-24>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dstMem</code></td><td>LLVM pointer in address space 3 or LLVM pointer in address space 7</td></tr><tr><td style=text-align:center><code>tmaDescriptor</code></td><td>LLVM pointer in address space 0</td></tr><tr><td style=text-align:center><code>coordinates</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>mbar</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>im2colOffsets</code></td><td>variadic of 16-bit signless integer</td></tr><tr><td style=text-align:center><code>multicastMask</code></td><td>16-bit signless integer</td></tr><tr><td style=text-align:center><code>l2CacheHint</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>predicate</code></td><td>1-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncbulktensorprefetch-nvvmcpasyncbulktensorprefetchop><code>nvvm.cp.async.bulk.tensor.prefetch</code> (NVVM::CpAsyncBulkTensorPrefetchOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulktensorprefetch-nvvmcpasyncbulktensorprefetchop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.tensor.prefetch` $tmaDescriptor `,`
              `box` `[`$coordinates `]`
              (`im2col` `[` $im2colOffsets^ `]` )?
              (`l2_cache_hint` `=` $l2CacheHint^ )?
              attr-dict  `:` type($tmaDescriptor)
</code></pre><p>Initiates an asynchronous prefetch operation on the tensor data from global
memory to L2 cache. This Op supports all the load modes specified in
<code>TMALoadMode</code>.</p><p>The <code>l2CacheHint</code> operand is optional, and it is used to specify cache
eviction policy that may be used during the memory access.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk-prefetch-tensor>For more information, see PTX ISA</a></p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-43>Attributes:&nbsp;<a class=headline-hash href=#attributes-43>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>mode</code></td><td>::mlir::NVVM::TMALoadModeAttr</td><td><details><summary>List of Load-Modes supported for TMA Tensor Ops</summary><pre><code>TMA Tensor Ops support the following modes, when copying data from
global memory to shared memory (i.e. load):
<p>Tile Mode: It&rsquo;s the default mode. The source multi-dimensional tensor
layout is preserved at the destination.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-tiled-mode>For more information, see PTX ISA</a></p>
<p>Im2col Mode: This mode is used when <code>im2colOffsets</code> operands are present.
The elements in the Bounding Box of the source tensor are rearranged into
columns at the destination. In this mode, the tensor has to be at least
3-dimensional. The number of <code>im2colOffsets</code> is <code>dims - 2</code> where <code>dims</code>
is the dimension of the tensor.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-im2col-mode>For more information, see PTX ISA</a></p>
<p>Im2col_W Mode: This mode is similar to Im2Col mode with the restriction that
elements are accessed across the W dimension only. The number of <code>im2colOffsets</code>
are always two, referred as <code>wHalo</code> and <code>wOffset</code>.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-im2col-w-w128-modes>For more information, see PTX ISA</a></p>
<p>Im2col_W_128 Mode: This mode is similar to Im2Col_W mode with the number of
elements accessed across the W dimension is always 128 only.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-im2col-w-w128-modes>For more information, see PTX ISA</a></p>
<p>Tile_Gather4 Mode: This mode is similar to Tile mode but works only on 2D tensor.
In gather4 mode, four rows in the source 2D tensor are combined to form a single
2D tensor at the destination. This mode requires five co-ordinates. The first one
represents the column-index followed by four row indices.

<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensor-tiled-scatter4-gather4-modes>For more information, see PTX ISA</a>
</code></pre></p></details></td></tr></table><h4 id=operands-25>Operands:&nbsp;<a class=headline-hash href=#operands-25>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tmaDescriptor</code></td><td>LLVM pointer in address space 0</td></tr><tr><td style=text-align:center><code>coordinates</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>im2colOffsets</code></td><td>variadic of 16-bit signless integer</td></tr><tr><td style=text-align:center><code>l2CacheHint</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncbulktensorreduce-nvvmcpasyncbulktensorreduceop><code>nvvm.cp.async.bulk.tensor.reduce</code> (NVVM::CpAsyncBulkTensorReduceOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulktensorreduce-nvvmcpasyncbulktensorreduceop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.tensor.reduce` $tmaDescriptor `,`
              $srcMem `,`
              `box` `[`$coordinates `]`
              (`l2_cache_hint` `=` $l2CacheHint^ )?
              attr-dict  `:` type($tmaDescriptor) `,` type($srcMem)
</code></pre><p>Initiates an asynchronous reduction operation of tensor data in
global memory with tensor data in shared memory.</p><p>The <code>mode</code> attribute indicates whether the copy mode is tile or im2col.
The <code>redOp</code> attribute specifies the reduction operations applied.
The supported reduction operations are:
{add, min, max, inc, dec, and, or, xor}</p><p>The <code>l2CacheHint</code> operand is optional, and it is used to specify cache
eviction policy that may be used during the memory access.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-reduce-async-bulk-tensor>For more information, see PTX ISA</a></p><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-44>Attributes:&nbsp;<a class=headline-hash href=#attributes-44>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>redKind</code></td><td>::mlir::NVVM::TMAReduxKindAttr</td><td>NVVM TMA redux kind</td></tr><tr><td><code>mode</code></td><td>::mlir::NVVM::TMAStoreModeAttr</td><td>NVVM TMA Store Mode</td></tr></table><h4 id=operands-26>Operands:&nbsp;<a class=headline-hash href=#operands-26>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tmaDescriptor</code></td><td>LLVM pointer type</td></tr><tr><td style=text-align:center><code>srcMem</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>coordinates</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>l2CacheHint</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncbulktensorglobalsharedcta-nvvmcpasyncbulktensorsharedctatoglobalop><code>nvvm.cp.async.bulk.tensor.global.shared.cta</code> (NVVM::CpAsyncBulkTensorSharedCTAToGlobalOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulktensorglobalsharedcta-nvvmcpasyncbulktensorsharedctatoglobalop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.tensor.global.shared.cta` $tmaDescriptor `,`
              $srcMem `,`
              `box` `[`$coordinates `]`
              (`l2_cache_hint` `=` $l2CacheHint^ )?
              (`,` `predicate` `=` $predicate^)?
              attr-dict `:` type($tmaDescriptor) `,` type($srcMem)
</code></pre><p>Initiates an asynchronous copy of the tensor data from shared::cta
memory to global memory. This Op supports all the store modes specified in
<code>TMAStoreMode</code>.</p><p>The <code>l2CacheHint</code> operand is optional, and it is used to specify cache
eviction policy that may be used during the memory access.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#data-movement-and-conversion-instructions-cp-async-bulk-tensor>For more information, see PTX ISA</a></p><p>Traits: <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>BasicPtxBuilderInterface</code></p><h4 id=attributes-45>Attributes:&nbsp;<a class=headline-hash href=#attributes-45>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>mode</code></td><td>::mlir::NVVM::TMAStoreModeAttr</td><td>NVVM TMA Store Mode</td></tr></table><h4 id=operands-27>Operands:&nbsp;<a class=headline-hash href=#operands-27>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tmaDescriptor</code></td><td>LLVM pointer in address space 0</td></tr><tr><td style=text-align:center><code>srcMem</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>coordinates</code></td><td>variadic of 32-bit signless integer</td></tr><tr><td style=text-align:center><code>l2CacheHint</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>predicate</code></td><td>1-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncbulkwait_group-nvvmcpasyncbulkwaitgroupop><code>nvvm.cp.async.bulk.wait_group</code> (NVVM::CpAsyncBulkWaitGroupOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncbulkwait_group-nvvmcpasyncbulkwaitgroupop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.bulk.wait_group` $group attr-dict
</code></pre><p>Op waits for completion of the most recent bulk async-groups.</p><p>The <code>$group</code> operand tells waiting has to be done until for $group or fewer
of the most recent bulk async-groups. If <code>$group</code> is 0, the op wait until
all the most recent bulk async-groups have completed.</p><p>The <code>$read</code> indicates that the waiting has to be done until all the bulk
async operations in the specified bulk async-group have completed reading
from their source locations.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk-wait-group>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSM&lt;90></code></p><h4 id=attributes-46>Attributes:&nbsp;<a class=headline-hash href=#attributes-46>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>group</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute whose minimum value is 0</td></tr><tr><td><code>read</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h3 id=nvvmcpasynccommitgroup-nvvmcpasynccommitgroupop><code>nvvm.cp.async.commit.group</code> (NVVM::CpAsyncCommitGroupOp)&nbsp;<a class=headline-hash href=#nvvmcpasynccommitgroup-nvvmcpasynccommitgroupop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.commit.group` attr-dict
</code></pre><h3 id=nvvmcpasyncmbarrierarrive-nvvmcpasyncmbarrierarriveop><code>nvvm.cp.async.mbarrier.arrive</code> (NVVM::CpAsyncMBarrierArriveOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncmbarrierarrive-nvvmcpasyncmbarrierarriveop>¶</a></h3><p><em>NVVM Dialect Op for cp.async.mbarrier.arrive</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.mbarrier.arrive` $addr attr-dict `:` type(operands)
</code></pre><p>The <code>cp.async.mbarrier.arrive</code> Op makes the <em>mbarrier object</em> track
all prior cp.async operations initiated by the executing thread.
The <code>addr</code> operand specifies the address of the <em>mbarrier object</em>
in generic or shared::cta address space. When it is generic, the
underlying memory should fall within the shared::cta space;
otherwise the behavior is undefined. The <code>noinc</code> attr impacts
how the mbarrier&rsquo;s state is updated.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-cp-async-mbarrier-arrive>For more information, see PTX ISA</a></p><h4 id=attributes-47>Attributes:&nbsp;<a class=headline-hash href=#attributes-47>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>noinc</code></td><td>::mlir::IntegerAttr</td><td>1-bit signless integer attribute</td></tr></table><h4 id=operands-28>Operands:&nbsp;<a class=headline-hash href=#operands-28>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr></tbody></table><h3 id=nvvmcpasyncsharedglobal-nvvmcpasyncop><code>nvvm.cp.async.shared.global</code> (NVVM::CpAsyncOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncsharedglobal-nvvmcpasyncop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.shared.global` $dst `,` $src `,` $size `,` `cache` `=` $modifier (`,` $cpSize^)? attr-dict `:` type(operands)
</code></pre><h4 id=attributes-48>Attributes:&nbsp;<a class=headline-hash href=#attributes-48>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>size</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>modifier</code></td><td>::mlir::NVVM::LoadCacheModifierKindAttr</td><td><details><summary>NVVM load cache modifier kind</summary><pre><code>Enum attribute of the different kinds of cache operators for load instructions.
<p>
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#id62>For more information, see PTX ISA</a> <br>
</code></pre></p></details></td></tr></table><h4 id=operands-29>Operands:&nbsp;<a class=headline-hash href=#operands-29>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>src</code></td><td>LLVM pointer in address space 1</td></tr><tr><td style=text-align:center><code>cpSize</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmcpasyncwaitgroup-nvvmcpasyncwaitgroupop><code>nvvm.cp.async.wait.group</code> (NVVM::CpAsyncWaitGroupOp)&nbsp;<a class=headline-hash href=#nvvmcpasyncwaitgroup-nvvmcpasyncwaitgroupop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.cp.async.wait.group` $n attr-dict
</code></pre><h4 id=attributes-49>Attributes:&nbsp;<a class=headline-hash href=#attributes-49>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>n</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h3 id=nvvmdotaccumulate2way-nvvmdotaccumulate2wayop><code>nvvm.dot.accumulate.2way</code> (NVVM::DotAccumulate2WayOp)&nbsp;<a class=headline-hash href=#nvvmdotaccumulate2way-nvvmdotaccumulate2wayop>¶</a></h3><p><em>Two-way 16-bit to 8-bit dot product-accumulate instruction</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.dot.accumulate.2way` $a $a_type `,` $b $b_type `,` $c attr-dict `:` type($a) `,` type($b)
</code></pre><p>Performs a two-way 16-bit to 8-bit dot-product which is accumulated in a
32-bit result.
Operand <code>a</code> is a vector of two 16-bit elements and operand <code>b</code> a vector
of four 8-bit elements between which the dot product is computed.</p><p>The <code>a_type</code> and <code>b_type</code> attributes specify the type of the elements in <code>a</code>
and <code>b</code> respectively.
If <code>a_type</code> or <code>b_type</code> is <code>s</code>, then the elements in the corresponding
vector are sign-extended to 32-bit before the dot product is computed.
If <code>a_type</code> or <code>b_type</code> is <code>u</code>, then the elements in the corresponding
vector are zero-extended to 32-bit instead.</p><p>The <code>b_hi</code> boolean attribute specifies which two bytes of <code>b</code> are used for
the dot product. If <code>b_hi</code> is true, then the dot product is computed
between <code>a</code> and elements at indices 2 and 3 of <code>b</code>. If <code>b_hi</code> is false,
then the dot product is computed between <code>a</code> and elements at indices 0 and
1 of <code>b</code>.</p><p>Operand <code>c</code> is a 32-bit integer to which the result is accumulated. It is
treated as holding a signed integer if any of <code>a_type</code> or <code>b_type</code> is
signed.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#integer-arithmetic-instructions-dp2a>For more information, see PTX ISA</a></p><h4 id=attributes-50>Attributes:&nbsp;<a class=headline-hash href=#attributes-50>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>a_type</code></td><td>::mlir::NVVM::DotAccumulateTypeAttr</td><td>NVVM DotAccumulateType</td></tr><tr><td><code>b_type</code></td><td>::mlir::NVVM::DotAccumulateTypeAttr</td><td>NVVM DotAccumulateType</td></tr><tr><td><code>b_hi</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-30>Operands:&nbsp;<a class=headline-hash href=#operands-30>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>vector of 16-bit signless integer values of length 2</td></tr><tr><td style=text-align:center><code>b</code></td><td>vector of 8-bit signless integer values of length 4</td></tr><tr><td style=text-align:center><code>c</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-39>Results:&nbsp;<a class=headline-hash href=#results-39>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmdotaccumulate4way-nvvmdotaccumulate4wayop><code>nvvm.dot.accumulate.4way</code> (NVVM::DotAccumulate4WayOp)&nbsp;<a class=headline-hash href=#nvvmdotaccumulate4way-nvvmdotaccumulate4wayop>¶</a></h3><p><em>Four-way byte dot product-accumulate instruction</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.dot.accumulate.4way` $a $a_type `,` $b $b_type `,` $c attr-dict `:` type($a) `,` type($b)
</code></pre><p>Performs a four-way byte dot-product which is accumulated in a 32-bit
result.
Operand <code>a</code> and <code>b</code> are vectors of 4 bytes between which the dot product is
computed.</p><p>The <code>a_type</code> and <code>b_type</code> attributes specify the type of the elements in <code>a</code>
and <code>b</code> respectively.
If <code>a_type</code> or <code>b_type</code> is <code>signed</code>, then the elements in the corresponding
vector are sign-extended to 32-bit before the dot product is computed.
If <code>a_type</code> or <code>b_type</code> is <code>unsigned</code>, then the elements in the
corresponding vector are zero-extended to 32-bit instead.</p><p>Operand <code>c</code> is a 32-bit integer to which the result is accumulated. It is
treated as holding a signed integer if any of <code>a_type</code> or <code>b_type</code> is <code>s8</code>.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#integer-arithmetic-instructions-dp4a>For more information, see PTX ISA</a></p><h4 id=attributes-51>Attributes:&nbsp;<a class=headline-hash href=#attributes-51>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>a_type</code></td><td>::mlir::NVVM::DotAccumulateTypeAttr</td><td>NVVM DotAccumulateType</td></tr><tr><td><code>b_type</code></td><td>::mlir::NVVM::DotAccumulateTypeAttr</td><td>NVVM DotAccumulateType</td></tr></table><h4 id=operands-31>Operands:&nbsp;<a class=headline-hash href=#operands-31>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>vector of 8-bit signless integer values of length 4</td></tr><tr><td style=text-align:center><code>b</code></td><td>vector of 8-bit signless integer values of length 4</td></tr><tr><td style=text-align:center><code>c</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-40>Results:&nbsp;<a class=headline-hash href=#results-40>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmelectsync-nvvmelectsyncop><code>nvvm.elect.sync</code> (NVVM::ElectSyncOp)&nbsp;<a class=headline-hash href=#nvvmelectsync-nvvmelectsyncop>¶</a></h3><p><em>Elect one leader thread</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.elect.sync` ($membermask^)? attr-dict `-&gt;` type(results)
</code></pre><p>The <code>elect.sync</code> instruction elects one predicated active leader
thread from among a set of threads specified in the <code>membermask</code>.
When the <code>membermask</code> is not provided explicitly, a default value
of <code>0xFFFFFFFF</code> is used. The predicate result is set to <code>True</code> for
the leader thread, and <code>False</code> for all other threads.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-elect-sync>For more information, see PTX ISA</a></p><h4 id=operands-32>Operands:&nbsp;<a class=headline-hash href=#operands-32>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>membermask</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-41>Results:&nbsp;<a class=headline-hash href=#results-41>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>pred</code></td><td>1-bit signless integer</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg0-nvvmenvreg0op><code>nvvm.read.ptx.sreg.envreg0</code> (NVVM::EnvReg0Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg0-nvvmenvreg0op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg0` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-42>Results:&nbsp;<a class=headline-hash href=#results-42>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg10-nvvmenvreg10op><code>nvvm.read.ptx.sreg.envreg10</code> (NVVM::EnvReg10Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg10-nvvmenvreg10op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg10` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-43>Results:&nbsp;<a class=headline-hash href=#results-43>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg11-nvvmenvreg11op><code>nvvm.read.ptx.sreg.envreg11</code> (NVVM::EnvReg11Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg11-nvvmenvreg11op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg11` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-44>Results:&nbsp;<a class=headline-hash href=#results-44>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg12-nvvmenvreg12op><code>nvvm.read.ptx.sreg.envreg12</code> (NVVM::EnvReg12Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg12-nvvmenvreg12op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg12` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-45>Results:&nbsp;<a class=headline-hash href=#results-45>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg13-nvvmenvreg13op><code>nvvm.read.ptx.sreg.envreg13</code> (NVVM::EnvReg13Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg13-nvvmenvreg13op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg13` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-46>Results:&nbsp;<a class=headline-hash href=#results-46>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg14-nvvmenvreg14op><code>nvvm.read.ptx.sreg.envreg14</code> (NVVM::EnvReg14Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg14-nvvmenvreg14op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg14` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-47>Results:&nbsp;<a class=headline-hash href=#results-47>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg15-nvvmenvreg15op><code>nvvm.read.ptx.sreg.envreg15</code> (NVVM::EnvReg15Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg15-nvvmenvreg15op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg15` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-48>Results:&nbsp;<a class=headline-hash href=#results-48>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg16-nvvmenvreg16op><code>nvvm.read.ptx.sreg.envreg16</code> (NVVM::EnvReg16Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg16-nvvmenvreg16op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg16` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-49>Results:&nbsp;<a class=headline-hash href=#results-49>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg17-nvvmenvreg17op><code>nvvm.read.ptx.sreg.envreg17</code> (NVVM::EnvReg17Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg17-nvvmenvreg17op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg17` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-50>Results:&nbsp;<a class=headline-hash href=#results-50>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg18-nvvmenvreg18op><code>nvvm.read.ptx.sreg.envreg18</code> (NVVM::EnvReg18Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg18-nvvmenvreg18op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg18` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-51>Results:&nbsp;<a class=headline-hash href=#results-51>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg19-nvvmenvreg19op><code>nvvm.read.ptx.sreg.envreg19</code> (NVVM::EnvReg19Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg19-nvvmenvreg19op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg19` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-52>Results:&nbsp;<a class=headline-hash href=#results-52>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg1-nvvmenvreg1op><code>nvvm.read.ptx.sreg.envreg1</code> (NVVM::EnvReg1Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg1-nvvmenvreg1op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg1` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-53>Results:&nbsp;<a class=headline-hash href=#results-53>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg20-nvvmenvreg20op><code>nvvm.read.ptx.sreg.envreg20</code> (NVVM::EnvReg20Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg20-nvvmenvreg20op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg20` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-54>Results:&nbsp;<a class=headline-hash href=#results-54>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg21-nvvmenvreg21op><code>nvvm.read.ptx.sreg.envreg21</code> (NVVM::EnvReg21Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg21-nvvmenvreg21op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg21` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-55>Results:&nbsp;<a class=headline-hash href=#results-55>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg22-nvvmenvreg22op><code>nvvm.read.ptx.sreg.envreg22</code> (NVVM::EnvReg22Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg22-nvvmenvreg22op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg22` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-56>Results:&nbsp;<a class=headline-hash href=#results-56>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg23-nvvmenvreg23op><code>nvvm.read.ptx.sreg.envreg23</code> (NVVM::EnvReg23Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg23-nvvmenvreg23op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg23` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-57>Results:&nbsp;<a class=headline-hash href=#results-57>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg24-nvvmenvreg24op><code>nvvm.read.ptx.sreg.envreg24</code> (NVVM::EnvReg24Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg24-nvvmenvreg24op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg24` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-58>Results:&nbsp;<a class=headline-hash href=#results-58>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg25-nvvmenvreg25op><code>nvvm.read.ptx.sreg.envreg25</code> (NVVM::EnvReg25Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg25-nvvmenvreg25op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg25` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-59>Results:&nbsp;<a class=headline-hash href=#results-59>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg26-nvvmenvreg26op><code>nvvm.read.ptx.sreg.envreg26</code> (NVVM::EnvReg26Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg26-nvvmenvreg26op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg26` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-60>Results:&nbsp;<a class=headline-hash href=#results-60>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg27-nvvmenvreg27op><code>nvvm.read.ptx.sreg.envreg27</code> (NVVM::EnvReg27Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg27-nvvmenvreg27op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg27` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-61>Results:&nbsp;<a class=headline-hash href=#results-61>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg28-nvvmenvreg28op><code>nvvm.read.ptx.sreg.envreg28</code> (NVVM::EnvReg28Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg28-nvvmenvreg28op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg28` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-62>Results:&nbsp;<a class=headline-hash href=#results-62>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg29-nvvmenvreg29op><code>nvvm.read.ptx.sreg.envreg29</code> (NVVM::EnvReg29Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg29-nvvmenvreg29op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg29` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-63>Results:&nbsp;<a class=headline-hash href=#results-63>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg2-nvvmenvreg2op><code>nvvm.read.ptx.sreg.envreg2</code> (NVVM::EnvReg2Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg2-nvvmenvreg2op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg2` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-64>Results:&nbsp;<a class=headline-hash href=#results-64>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg30-nvvmenvreg30op><code>nvvm.read.ptx.sreg.envreg30</code> (NVVM::EnvReg30Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg30-nvvmenvreg30op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg30` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-65>Results:&nbsp;<a class=headline-hash href=#results-65>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg31-nvvmenvreg31op><code>nvvm.read.ptx.sreg.envreg31</code> (NVVM::EnvReg31Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg31-nvvmenvreg31op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg31` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-66>Results:&nbsp;<a class=headline-hash href=#results-66>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg3-nvvmenvreg3op><code>nvvm.read.ptx.sreg.envreg3</code> (NVVM::EnvReg3Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg3-nvvmenvreg3op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg3` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-67>Results:&nbsp;<a class=headline-hash href=#results-67>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg4-nvvmenvreg4op><code>nvvm.read.ptx.sreg.envreg4</code> (NVVM::EnvReg4Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg4-nvvmenvreg4op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg4` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-68>Results:&nbsp;<a class=headline-hash href=#results-68>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg5-nvvmenvreg5op><code>nvvm.read.ptx.sreg.envreg5</code> (NVVM::EnvReg5Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg5-nvvmenvreg5op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg5` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-69>Results:&nbsp;<a class=headline-hash href=#results-69>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg6-nvvmenvreg6op><code>nvvm.read.ptx.sreg.envreg6</code> (NVVM::EnvReg6Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg6-nvvmenvreg6op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg6` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-70>Results:&nbsp;<a class=headline-hash href=#results-70>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg7-nvvmenvreg7op><code>nvvm.read.ptx.sreg.envreg7</code> (NVVM::EnvReg7Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg7-nvvmenvreg7op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg7` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-71>Results:&nbsp;<a class=headline-hash href=#results-71>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg8-nvvmenvreg8op><code>nvvm.read.ptx.sreg.envreg8</code> (NVVM::EnvReg8Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg8-nvvmenvreg8op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg8` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-72>Results:&nbsp;<a class=headline-hash href=#results-72>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregenvreg9-nvvmenvreg9op><code>nvvm.read.ptx.sreg.envreg9</code> (NVVM::EnvReg9Op)&nbsp;<a class=headline-hash href=#nvvmreadptxsregenvreg9-nvvmenvreg9op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.envreg9` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-73>Results:&nbsp;<a class=headline-hash href=#results-73>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmexit-nvvmexit><code>nvvm.exit</code> (NVVM::Exit)&nbsp;<a class=headline-hash href=#nvvmexit-nvvmexit>¶</a></h3><p><em>Exit Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.exit` attr-dict
</code></pre><p>Ends execution of a thread.
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#control-flow-instructions-exit>For more information, see PTX ISA</a></p><h3 id=nvvmfencembarrierinit-nvvmfencembarrierinitop><code>nvvm.fence.mbarrier.init</code> (NVVM::FenceMbarrierInitOp)&nbsp;<a class=headline-hash href=#nvvmfencembarrierinit-nvvmfencembarrierinitop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.fence.mbarrier.init` attr-dict
</code></pre><p>Fence operation that applies on the prior nvvm.mbarrier.init</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-membar>For more information, see PTX ISA</a></p><h3 id=nvvmfenceproxyacquire-nvvmfenceproxyacquireop><code>nvvm.fence.proxy.acquire</code> (NVVM::FenceProxyAcquireOp)&nbsp;<a class=headline-hash href=#nvvmfenceproxyacquire-nvvmfenceproxyacquireop>¶</a></h3><p><em>Uni-directional proxy fence operation with acquire semantics</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.fence.proxy.acquire` $scope $addr `,` $size (`from_proxy` `=` $fromProxy^)? (`to_proxy` `=` $toProxy^)? attr-dict
</code></pre><p><code>fence.proxy.acquire</code> is a uni-directional fence used to establish ordering
between a prior memory access performed via the generic proxy and a
subsequent memory access performed via the tensormap proxy</p><p>The address operand <code>addr</code> and the operand <code>size</code> together specify the
memory range <code>[addr, addr+size)</code> on which the ordering guarantees on the
memory accesses across the proxies is to be provided. The only supported
value for the <code>size</code> operand is 128 and must be an immediate. Generic Addressing
is used unconditionally, and the address specified by the operand <code>addr</code> must
fall within the <code>.global</code> state space. Otherwise, the behavior is undefined</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-membar>For more information, see PTX ISA</a></p><h4 id=attributes-52>Attributes:&nbsp;<a class=headline-hash href=#attributes-52>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr><tr><td><code>fromProxy</code></td><td>::mlir::NVVM::ProxyKindAttr</td><td><details><summary>Proxy kind</summary><pre><code>ProxyKind attribute represents a memory proxy which is an abstract label
applied to a method of memory access. When two memory operations use distinct
methods of memory access, they are said to be different proxies.
</code></pre></details></td></tr><tr><td><code>toProxy</code></td><td>::mlir::NVVM::ProxyKindAttr</td><td><details><summary>Proxy kind</summary><pre><code>ProxyKind attribute represents a memory proxy which is an abstract label
applied to a method of memory access. When two memory operations use distinct
methods of memory access, they are said to be different proxies.
</code></pre></details></td></tr></table><h4 id=operands-33>Operands:&nbsp;<a class=headline-hash href=#operands-33>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0</td></tr><tr><td style=text-align:center><code>size</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmfenceproxy-nvvmfenceproxyop><code>nvvm.fence.proxy</code> (NVVM::FenceProxyOp)&nbsp;<a class=headline-hash href=#nvvmfenceproxy-nvvmfenceproxyop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.fence.proxy` attr-dict
</code></pre><p>Fence operation with proxy to establish an ordering between memory accesses
that may happen through different proxies.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-membar>For more information, see PTX ISA</a></p><h4 id=attributes-53>Attributes:&nbsp;<a class=headline-hash href=#attributes-53>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::ProxyKindAttr</td><td><details><summary>Proxy kind</summary><pre><code>ProxyKind attribute represents a memory proxy which is an abstract label
applied to a method of memory access. When two memory operations use distinct
methods of memory access, they are said to be different proxies.
</code></pre></details></td></tr><tr><td><code>space</code></td><td>::mlir::NVVM::SharedSpaceAttr</td><td>Shared memory space</td></tr></table><h3 id=nvvmfenceproxyrelease-nvvmfenceproxyreleaseop><code>nvvm.fence.proxy.release</code> (NVVM::FenceProxyReleaseOp)&nbsp;<a class=headline-hash href=#nvvmfenceproxyrelease-nvvmfenceproxyreleaseop>¶</a></h3><p><em>Uni-directional proxy fence operation with release semantics</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.fence.proxy.release` $scope (`from_proxy` `=` $fromProxy^)? (`to_proxy` `=` $toProxy^)? attr-dict
</code></pre><p><code>fence.proxy.release</code> is a uni-directional fence used to establish ordering
between a prior memory access performed via the generic proxy and a
subsequent memory access performed via the tensormap proxy. <code>fence.proxy.release</code>
operation can form a release sequence that synchronizes with an acquire
sequence that contains the fence.proxy.acquire proxy fence operation</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-membar>For more information, see PTX ISA</a></p><h4 id=attributes-54>Attributes:&nbsp;<a class=headline-hash href=#attributes-54>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr><tr><td><code>fromProxy</code></td><td>::mlir::NVVM::ProxyKindAttr</td><td><details><summary>Proxy kind</summary><pre><code>ProxyKind attribute represents a memory proxy which is an abstract label
applied to a method of memory access. When two memory operations use distinct
methods of memory access, they are said to be different proxies.
</code></pre></details></td></tr><tr><td><code>toProxy</code></td><td>::mlir::NVVM::ProxyKindAttr</td><td><details><summary>Proxy kind</summary><pre><code>ProxyKind attribute represents a memory proxy which is an abstract label
applied to a method of memory access. When two memory operations use distinct
methods of memory access, they are said to be different proxies.
</code></pre></details></td></tr></table><h3 id=nvvmfenceproxysync_restrict-nvvmfenceproxysyncrestrictop><code>nvvm.fence.proxy.sync_restrict</code> (NVVM::FenceProxySyncRestrictOp)&nbsp;<a class=headline-hash href=#nvvmfenceproxysync_restrict-nvvmfenceproxysyncrestrictop>¶</a></h3><p><em>Uni-directional proxy fence operation with sync_restrict</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.fence.proxy.sync_restrict` attr-dict
</code></pre><p>The <code>nvvm.fence.proxy.sync_restrict</code> Op used to establish
ordering between a prior memory access performed between proxies. Currently,
the ordering is only supported between async and generic proxies. <code>sync_restrict</code>
restricts <code>acquire</code> memory semantics to <code>shared_cluster</code> and <code>release</code> memory
semantics to <code>shared_cta</code> with cluster scope.
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-membar>For more information, see PTX ISA</a></p><h4 id=attributes-55>Attributes:&nbsp;<a class=headline-hash href=#attributes-55>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>order</code></td><td>::mlir::NVVM::MemOrderKindAttr</td><td>NVVM Memory Ordering kind</td></tr><tr><td><code>fromProxy</code></td><td>::mlir::NVVM::ProxyKindAttr</td><td><details><summary>Proxy kind</summary><pre><code>ProxyKind attribute represents a memory proxy which is an abstract label
applied to a method of memory access. When two memory operations use distinct
methods of memory access, they are said to be different proxies.
</code></pre></details></td></tr><tr><td><code>toProxy</code></td><td>::mlir::NVVM::ProxyKindAttr</td><td><details><summary>Proxy kind</summary><pre><code>ProxyKind attribute represents a memory proxy which is an abstract label
applied to a method of memory access. When two memory operations use distinct
methods of memory access, they are said to be different proxies.
</code></pre></details></td></tr></table><h3 id=nvvmfencesccluster-nvvmfencescclusterop><code>nvvm.fence.sc.cluster</code> (NVVM::FenceScClusterOp)&nbsp;<a class=headline-hash href=#nvvmfencesccluster-nvvmfencescclusterop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.fence.sc.cluster` attr-dict
</code></pre><h3 id=nvvmfencesync_restrict-nvvmfencesyncrestrictop><code>nvvm.fence.sync_restrict</code> (NVVM::FenceSyncRestrictOp)&nbsp;<a class=headline-hash href=#nvvmfencesync_restrict-nvvmfencesyncrestrictop>¶</a></h3><p><em>Uni-directional thread fence operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.fence.sync_restrict` attr-dict
</code></pre><p>The <code>nvvm.fence.sync_restrict</code> Op restricts the class of memory
operations for which the fence instruction provides the memory ordering guarantees.
<code>sync_restrict</code> restricts <code>acquire</code> memory semantics to <code>shared_cluster</code> and
<code>release</code> memory semantics to <code>shared_cta</code> with cluster scope.
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-membar>For more information, see PTX ISA</a></p><h4 id=attributes-56>Attributes:&nbsp;<a class=headline-hash href=#attributes-56>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>order</code></td><td>::mlir::NVVM::MemOrderKindAttr</td><td>NVVM Memory Ordering kind</td></tr></table><h3 id=nvvmreadptxsregglobaltimerlo-nvvmglobaltimerloop><code>nvvm.read.ptx.sreg.globaltimer.lo</code> (NVVM::GlobalTimerLoOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregglobaltimerlo-nvvmglobaltimerloop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.globaltimer.lo` attr-dict `:` type($res)
</code></pre><h4 id=results-74>Results:&nbsp;<a class=headline-hash href=#results-74>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregglobaltimer-nvvmglobaltimerop><code>nvvm.read.ptx.sreg.globaltimer</code> (NVVM::GlobalTimerOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregglobaltimer-nvvmglobaltimerop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.globaltimer` attr-dict `:` type($res)
</code></pre><h4 id=results-75>Results:&nbsp;<a class=headline-hash href=#results-75>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregnctaidx-nvvmgriddimxop><code>nvvm.read.ptx.sreg.nctaid.x</code> (NVVM::GridDimXOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregnctaidx-nvvmgriddimxop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.nctaid.x` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-57>Attributes:&nbsp;<a class=headline-hash href=#attributes-57>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-76>Results:&nbsp;<a class=headline-hash href=#results-76>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregnctaidy-nvvmgriddimyop><code>nvvm.read.ptx.sreg.nctaid.y</code> (NVVM::GridDimYOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregnctaidy-nvvmgriddimyop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.nctaid.y` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-58>Attributes:&nbsp;<a class=headline-hash href=#attributes-58>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-77>Results:&nbsp;<a class=headline-hash href=#results-77>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregnctaidz-nvvmgriddimzop><code>nvvm.read.ptx.sreg.nctaid.z</code> (NVVM::GridDimZOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregnctaidz-nvvmgriddimzop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.nctaid.z` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-59>Attributes:&nbsp;<a class=headline-hash href=#attributes-59>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-78>Results:&nbsp;<a class=headline-hash href=#results-78>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsreggridid-nvvmgrididop><code>nvvm.read.ptx.sreg.gridid</code> (NVVM::GridIdOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsreggridid-nvvmgrididop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.gridid` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-60>Attributes:&nbsp;<a class=headline-hash href=#attributes-60>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-79>Results:&nbsp;<a class=headline-hash href=#results-79>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmgriddepcontrol-nvvmgriddepcontrolop><code>nvvm.griddepcontrol</code> (NVVM::GriddepcontrolOp)&nbsp;<a class=headline-hash href=#nvvmgriddepcontrol-nvvmgriddepcontrolop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.griddepcontrol` $kind attr-dict
</code></pre><p>If the $kind attribute is set to <code>wait</code>, it causes the
executing thread to wait until all prerequisite grids in flight
have completed and all the memory operations from the prerequisite grids
are performed and made visible to the current grid.</p><p>When the $kind is launch_dependents, it signals that specific dependents
the runtime system designated to react to this instruction can be scheduled
as soon as all other CTAs in the grid issue the same instruction or have
completed.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-griddepcontrol>For more information, see PTX ISA</a></p><h4 id=attributes-61>Attributes:&nbsp;<a class=headline-hash href=#attributes-61>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::GridDepActionKindAttr</td><td><details><summary>Action kind for grid dependency control</summary><p>Enum cases:</p><ul><li>wait (<code>wait</code>)</li><li>launch_dependents (<code>launch_dependents</code>)</li></ul></details></td></tr></table><h3 id=nvvminline_ptx-nvvminlineptxop><code>nvvm.inline_ptx</code> (NVVM::InlinePtxOp)&nbsp;<a class=headline-hash href=#nvvminline_ptx-nvvminlineptxop>¶</a></h3><p><em>Inline PTX Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.inline_ptx` $ptxCode
              ( `ro` `(` $readOnlyArgs^ `:` type($readOnlyArgs) `)` )?
              ( `rw` `(` $readWriteArgs^ `:` type($readWriteArgs) `)` )?
              (`,` `predicate` `=` $predicate^)?
              attr-dict
              ( `-&gt;` type($writeOnlyArgs)^ )?
</code></pre><p>This op allows using PTX directly within the NVVM
dialect, while greatly simplifying llvm.inline_asm generation. It
automatically handles register size selection and sets the correct
read/write access for each operand. The operation leverages the
<code>BasicPtxBuilderInterface</code> to abstract away low-level details of
PTX assembly formatting.</p><pre><code>The `predicate` attribute is used to specify a predicate for the 
PTX instruction.

Example 1: Read-only Parameters
```mlir
nvvm.inline_ptx &quot;mbarrier.init.b64 [$0], $1;&quot; (%barrier_gen, %count) : !llvm.ptr, i32

// Lowers to:
llvm.inline_asm has_side_effects asm_dialect = att 
  &quot;mbarrier.init.b64 [$0], $1;&quot;, &quot;l,r&quot; %arg0, %arg2 : (!llvm.ptr, i32) -&gt; ()
```

Example 2: Read-only and Write-only Parameters
```mlir
%0 = nvvm.inline_ptx &quot;ex2.approx.ftz.f32 $0, $1;&quot; (%input) : f32 -&gt; f32

// Lowers to:
%0 = llvm.inline_asm has_side_effects asm_dialect = att 
  &quot;ex2.approx.ftz.f32 $0, $1;&quot;, &quot;=f,f&quot; %arg0 : (f32) -&gt; f32
```

Example 3: Predicate Usage
```mlir
nvvm.inline_ptx &quot;mbarrier.init.b64 [$0], $1;&quot; (%barrier_gen, %count), 
  predicate = %pred : !llvm.ptr, i32, i1

// Lowers to:
llvm.inline_asm has_side_effects asm_dialect = att 
  &quot;@$2 mbarrier.init.b64 [$0], $1;&quot;, &quot;l,r,b&quot; %arg0, %arg2, %arg3 
  : (!llvm.ptr, i32, i1) -&gt; ()
```
</code></pre><p>Traits: <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>BasicPtxBuilderInterface</code></p><h4 id=attributes-62>Attributes:&nbsp;<a class=headline-hash href=#attributes-62>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>ptxCode</code></td><td>::mlir::StringAttr</td><td>string attribute</td></tr></table><h4 id=operands-34>Operands:&nbsp;<a class=headline-hash href=#operands-34>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>readOnlyArgs</code></td><td>variadic of any type</td></tr><tr><td style=text-align:center><code>readWriteArgs</code></td><td>variadic of any type</td></tr><tr><td style=text-align:center><code>predicate</code></td><td>1-bit signless integer</td></tr></tbody></table><h4 id=results-80>Results:&nbsp;<a class=headline-hash href=#results-80>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>writeOnlyArgs</code></td><td>variadic of any type</td></tr></tbody></table><h3 id=nvvmreadptxsreglaneid-nvvmlaneidop><code>nvvm.read.ptx.sreg.laneid</code> (NVVM::LaneIdOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsreglaneid-nvvmlaneidop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.laneid` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-63>Attributes:&nbsp;<a class=headline-hash href=#attributes-63>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-81>Results:&nbsp;<a class=headline-hash href=#results-81>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsreglanemaskeq-nvvmlanemaskeqop><code>nvvm.read.ptx.sreg.lanemask.eq</code> (NVVM::LaneMaskEqOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsreglanemaskeq-nvvmlanemaskeqop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.lanemask.eq` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-82>Results:&nbsp;<a class=headline-hash href=#results-82>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsreglanemaskge-nvvmlanemaskgeop><code>nvvm.read.ptx.sreg.lanemask.ge</code> (NVVM::LaneMaskGeOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsreglanemaskge-nvvmlanemaskgeop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.lanemask.ge` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-83>Results:&nbsp;<a class=headline-hash href=#results-83>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsreglanemaskgt-nvvmlanemaskgtop><code>nvvm.read.ptx.sreg.lanemask.gt</code> (NVVM::LaneMaskGtOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsreglanemaskgt-nvvmlanemaskgtop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.lanemask.gt` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-84>Results:&nbsp;<a class=headline-hash href=#results-84>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsreglanemaskle-nvvmlanemaskleop><code>nvvm.read.ptx.sreg.lanemask.le</code> (NVVM::LaneMaskLeOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsreglanemaskle-nvvmlanemaskleop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.lanemask.le` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-85>Results:&nbsp;<a class=headline-hash href=#results-85>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsreglanemasklt-nvvmlanemaskltop><code>nvvm.read.ptx.sreg.lanemask.lt</code> (NVVM::LaneMaskLtOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsreglanemasklt-nvvmlanemaskltop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.lanemask.lt` attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-86>Results:&nbsp;<a class=headline-hash href=#results-86>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmldmatrix-nvvmldmatrixop><code>nvvm.ldmatrix</code> (NVVM::LdMatrixOp)&nbsp;<a class=headline-hash href=#nvvmldmatrix-nvvmldmatrixop>¶</a></h3><p><em>Cooperative matrix load</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.ldmatrix` $ptr attr-dict `:` functional-type($ptr, $res)
</code></pre><h4 id=attributes-64>Attributes:&nbsp;<a class=headline-hash href=#attributes-64>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>num</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>layout</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::LdStMatrixShapeAttr</td><td>Matrix shape for ldmatrix and stmatrix</td></tr><tr><td><code>eltType</code></td><td>::mlir::NVVM::LdStMatrixEltTypeAttr</td><td>Element type for ldmatrix and stmatrix</td></tr></table><h4 id=operands-35>Operands:&nbsp;<a class=headline-hash href=#operands-35>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>ptr</code></td><td>LLVM pointer in address space 3</td></tr></tbody></table><h4 id=results-87>Results:&nbsp;<a class=headline-hash href=#results-87>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>any type</td></tr></tbody></table><h3 id=nvvmmbarrierarrive_dropexpect_tx-nvvmmbarrierarrivedropexpecttxop><code>nvvm.mbarrier.arrive_drop.expect_tx</code> (NVVM::MBarrierArriveDropExpectTxOp)&nbsp;<a class=headline-hash href=#nvvmmbarrierarrive_dropexpect_tx-nvvmmbarrierarrivedropexpecttxop>¶</a></h3><p><em>MBarrier arrive_drop with expected transaction count</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.arrive_drop.expect_tx` $addr `,` $txcount attr-dict `:` type(operands) (`-&gt;` type($res)^)?
</code></pre><p>The <code>nvvm.mbarrier.arrive_drop.expect_tx</code> operation is similar to the
<code>nvvm.mbarrier.arrive.expect_tx</code> operation except that it performs an
<code>arrive_drop</code> operation instead of only an <code>arrive</code> operation.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop>For more information, see PTX ISA</a></p><h4 id=attributes-65>Attributes:&nbsp;<a class=headline-hash href=#attributes-65>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr><tr><td><code>relaxed</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-36>Operands:&nbsp;<a class=headline-hash href=#operands-36>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3 or LLVM pointer in address space 7</td></tr><tr><td style=text-align:center><code>txcount</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-88>Results:&nbsp;<a class=headline-hash href=#results-88>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarrierarrive_dropnocomplete-nvvmmbarrierarrivedropnocompleteop><code>nvvm.mbarrier.arrive_drop.nocomplete</code> (NVVM::MBarrierArriveDropNocompleteOp)&nbsp;<a class=headline-hash href=#nvvmmbarrierarrive_dropnocomplete-nvvmmbarrierarrivedropnocompleteop>¶</a></h3><p><em>MBarrier Arrive-Drop No-Complete Operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.arrive_drop.nocomplete` $addr `,` $count attr-dict `:` type(operands) `-&gt;` type($res)
</code></pre><p>The <code>nvvm.mbarrier.arrive_drop.nocomplete</code> operation decrements the expected
arrival count of the <em>mbarrier object</em> by the amount <code>count</code> and then performs
an arrive-on operation on the <em>mbarrier object</em> with the guarantee that it
will not cause the barrier to complete its current phase.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop>For more information, see PTX ISA</a></p><h4 id=operands-37>Operands:&nbsp;<a class=headline-hash href=#operands-37>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>count</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-89>Results:&nbsp;<a class=headline-hash href=#results-89>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarrierarrive_drop-nvvmmbarrierarrivedropop><code>nvvm.mbarrier.arrive_drop</code> (NVVM::MBarrierArriveDropOp)&nbsp;<a class=headline-hash href=#nvvmmbarrierarrive_drop-nvvmmbarrierarrivedropop>¶</a></h3><p><em>MBarrier Arrive-Drop Operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.arrive_drop` $addr (`,` $count^)? attr-dict `:` type($addr) (`-&gt;` type($res)^)?
</code></pre><p>The <code>nvvm.mbarrier.arrive_drop</code> operation decrements the expected arrival
count of the <em>mbarrier object</em> by <code>count</code> and then performs an arrive-on
operation. When <code>count</code> is not specified, it defaults to 1. The decrement
of the expected arrival count applies to all the subsequent phases of the
<em>mbarrier object</em>. The remaining semantics are identical to those of the
<code>nvvm.mbarrier.arrive</code> operation.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop>For more information, see PTX ISA</a></p><h4 id=attributes-66>Attributes:&nbsp;<a class=headline-hash href=#attributes-66>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr><tr><td><code>relaxed</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-38>Operands:&nbsp;<a class=headline-hash href=#operands-38>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3 or LLVM pointer in address space 7</td></tr><tr><td style=text-align:center><code>count</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-90>Results:&nbsp;<a class=headline-hash href=#results-90>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarrierarriveexpect_tx-nvvmmbarrierarriveexpecttxop><code>nvvm.mbarrier.arrive.expect_tx</code> (NVVM::MBarrierArriveExpectTxOp)&nbsp;<a class=headline-hash href=#nvvmmbarrierarriveexpect_tx-nvvmmbarrierarriveexpecttxop>¶</a></h3><p><em>MBarrier Arrive with Expected Transaction Count</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.arrive.expect_tx` $addr `,` $txcount (`,` `predicate` `=` $predicate^)? attr-dict `:` type(operands) (`-&gt;` type($res)^)?
</code></pre><p>The <code>nvvm.mbarrier.arrive.expect_tx</code> operation performs an expect-tx operation
followed by an arrive-on operation on the <em>mbarrier object</em>. Uses the default
<code>.release.cta</code> semantics. This release pattern establishes memory ordering for
operations occurring in program order before this arrive instruction by making
operations from the current thread visible to subsequent operations in other
threads within the CTA. When other threads perform corresponding acquire operations
(like &lsquo;mbarrier.test.wait&rsquo;), they synchronize with this release pattern.</p><p>This operation first performs an expect-tx operation with the specified transaction
count, then performs an arrive-on operation with an implicit count of 1. The
expect-tx operation increases the expect-count of the <em>mbarrier object</em> by the
specified value (i.e. <code>txcount</code>), setting the current phase to expect and track
the completion of additional asynchronous transactions.</p><p>The operation takes the following operands:</p><ul><li><code>addr</code>: A pointer to the memory location of the <em>mbarrier object</em>. Uses generic
addressing, but the address must still be in the shared memory space.</li><li><code>txcount</code>: An unsigned integer specifying the expected transaction count
for the expect-tx operation. This represents the number of asynchronous transactions
expected to complete before the barrier phase completes.</li><li><code>scope</code>: This specifies the set of threads that directly observe the memory
synchronizing effect of the <code>mbarrier.test.wait</code> operation.</li><li><code>relaxed</code>: When set to true, the <code>arrive</code> operation has relaxed memory semantics
and does not provide any ordering or visibility guarantees.</li><li><code>predicate</code>: Optional predicate for conditional execution used only when lowering to
inline-ptx.</li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop>For more information, see PTX ISA</a></p><p>Interfaces: <code>BasicPtxBuilderInterface</code></p><h4 id=attributes-67>Attributes:&nbsp;<a class=headline-hash href=#attributes-67>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr><tr><td><code>relaxed</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-39>Operands:&nbsp;<a class=headline-hash href=#operands-39>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3 or LLVM pointer in address space 7</td></tr><tr><td style=text-align:center><code>txcount</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>predicate</code></td><td>1-bit signless integer</td></tr></tbody></table><h4 id=results-91>Results:&nbsp;<a class=headline-hash href=#results-91>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarrierarrivenocomplete-nvvmmbarrierarrivenocompleteop><code>nvvm.mbarrier.arrive.nocomplete</code> (NVVM::MBarrierArriveNocompleteOp)&nbsp;<a class=headline-hash href=#nvvmmbarrierarrivenocomplete-nvvmmbarrierarrivenocompleteop>¶</a></h3><p><em>MBarrier Arrive No-Complete Operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.arrive.nocomplete` $addr `,` $count attr-dict `:` type(operands) `-&gt;` type($res)
</code></pre><p>The <code>nvvm.mbarrier.arrive.nocomplete</code> operation performs an arrive-on operation
on the <em>mbarrier object</em> with the guarantee that it will not cause the barrier to
complete its current phase. Uses the default <code>.release.cta</code> semantics. This release
pattern establishes memory ordering for operations occurring in program order before
this arrive instruction by making operations from the current thread visible to
subsequent operations in other threads within the CTA. When other threads perform
corresponding acquire operations (like &lsquo;mbarrier.test.wait&rsquo;), they synchronize with
this release pattern.</p><p>This operation causes the executing thread to signal its arrival at the barrier
with a specified count, but ensures that the barrier phase will not complete as
a result of this operation. The operation returns an opaque value that
captures the phase of the <em>mbarrier object</em> prior to the arrive-on operation.</p><p>The operation takes the following operands:</p><ul><li><code>addr</code>: A pointer to the memory location of the <em>mbarrier object</em>. The <code>addr</code>
must be a pointer to generic or shared::cta memory. When it is generic, the
underlying address must be within the shared::cta memory space; otherwise
the behavior is undefined.</li><li><code>count</code>: Integer specifying the count argument to the arrive-on operation.
Must be in the valid range as specified in the <em>mbarrier object</em> contents.</li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-arrive>For more information, see PTX ISA</a></p><h4 id=operands-40>Operands:&nbsp;<a class=headline-hash href=#operands-40>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>count</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-92>Results:&nbsp;<a class=headline-hash href=#results-92>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarrierarrive-nvvmmbarrierarriveop><code>nvvm.mbarrier.arrive</code> (NVVM::MBarrierArriveOp)&nbsp;<a class=headline-hash href=#nvvmmbarrierarrive-nvvmmbarrierarriveop>¶</a></h3><p><em>MBarrier Arrive Operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.arrive` $addr (`,` $count^)? attr-dict `:` type($addr) (`-&gt;` type($res)^)?
</code></pre><p>The <code>nvvm.mbarrier.arrive</code> operation performs an arrive-on operation on the
<em>mbarrier object</em> at the specified address. Uses the default <code>.release.cta</code> semantics.
This release pattern establishes memory ordering for operations occurring in program
order before this arrive instruction by making operations from the current thread
visible to subsequent operations in other threads within the CTA. When other threads
perform corresponding acquire operations (like &lsquo;mbarrier.test.wait&rsquo;), they synchronize
with this release pattern.</p><p>This operation causes the executing thread to signal its arrival at the barrier.</p><ul><li><code>res</code>: When the <code>space</code> is not shared_cluster, this operation returns an
opaque 64-bit value capturing the phase of the <em>mbarrier object</em> prior to
the arrive-on operation. The contents of this return value are
implementation-specific. An <em>mbarrier object</em> located in the shared_cluster
space cannot return a value.</li></ul><p>The operation takes the following operands:</p><ul><li><code>addr</code>: A pointer to the memory location of the <em>mbarrier object</em>. The <code>addr</code>
must be a pointer to generic or shared_cta or shared_cluster memory. When it
is generic, the underlying address must be within the shared_cta memory space;
otherwise the behavior is undefined.</li><li><code>count</code>: This specifies the amount by which the pending arrival count is
decremented. If the <code>count</code> argument is not specified, the pending arrival
count is decremented by 1.</li><li><code>scope</code>: This specifies the set of threads that directly observe the memory
synchronizing effect of the <code>mbarrier.arrive</code> operation.</li><li><code>space</code>: This indicates the memory space where the mbarrier object resides.</li><li><code>relaxed</code>: When set to true, the <code>arrive</code> operation has relaxed memory semantics
and does not provide any ordering or visibility guarantees.</li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-arrive>For more information, see PTX ISA</a></p><h4 id=attributes-68>Attributes:&nbsp;<a class=headline-hash href=#attributes-68>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr><tr><td><code>relaxed</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-41>Operands:&nbsp;<a class=headline-hash href=#operands-41>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3 or LLVM pointer in address space 7</td></tr><tr><td style=text-align:center><code>count</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-93>Results:&nbsp;<a class=headline-hash href=#results-93>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarriercomplete_tx-nvvmmbarriercompletetxop><code>nvvm.mbarrier.complete_tx</code> (NVVM::MBarrierCompleteTxOp)&nbsp;<a class=headline-hash href=#nvvmmbarriercomplete_tx-nvvmmbarriercompletetxop>¶</a></h3><p><em>MBarrier complete-tx Operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.complete_tx` $addr `,` $txcount attr-dict `:` type(operands)
</code></pre><p>The <code>nvvm.mbarrier.complete_tx</code> operation decrements the transaction
count of the <em>mbarrier object</em> at <code>addr</code> by <code>txcount</code>. It also signals
the completion of asynchronous transactions that were tracked by the
current phase. The <code>scope</code> specifies the set of threads that can directly
observe the memory synchronizing effect of the <code>mbarrier.complete_tx</code>
operation. <code>CTA</code> and <code>CLUSTER</code> are the only allowed values for <code>scope</code>.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx>For more information, see PTX ISA</a></p><h4 id=attributes-69>Attributes:&nbsp;<a class=headline-hash href=#attributes-69>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr></table><h4 id=operands-42>Operands:&nbsp;<a class=headline-hash href=#operands-42>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 3 or LLVM pointer in address space 7</td></tr><tr><td style=text-align:center><code>txcount</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarrierexpect_tx-nvvmmbarrierexpecttxop><code>nvvm.mbarrier.expect_tx</code> (NVVM::MBarrierExpectTxOp)&nbsp;<a class=headline-hash href=#nvvmmbarrierexpect_tx-nvvmmbarrierexpecttxop>¶</a></h3><p><em>MBarrier expect-tx Operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.expect_tx` $addr `,` $txcount attr-dict `:` type(operands)
</code></pre><p>The <code>nvvm.mbarrier.expect_tx</code> operation increases the transaction count
of the mbarrier located at <code>addr</code> by <code>txcount</code> amount. The <code>scope</code>
specifies the set of threads that can directly observe the memory
synchronizing effect of the <code>mbarrier.expect_tx</code> operation. <code>CTA</code>
and <code>CLUSTER</code> are the only allowed values for <code>scope</code>.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx>For more information, see PTX ISA</a></p><h4 id=attributes-70>Attributes:&nbsp;<a class=headline-hash href=#attributes-70>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr></table><h4 id=operands-43>Operands:&nbsp;<a class=headline-hash href=#operands-43>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 3 or LLVM pointer in address space 7</td></tr><tr><td style=text-align:center><code>txcount</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarrierinit-nvvmmbarrierinitop><code>nvvm.mbarrier.init</code> (NVVM::MBarrierInitOp)&nbsp;<a class=headline-hash href=#nvvmmbarrierinit-nvvmmbarrierinitop>¶</a></h3><p><em>MBarrier Initialization Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.init` $addr `,` $count (`,` `predicate` `=` $predicate^)? attr-dict `:` type(operands)
</code></pre><p>The <code>nvvm.mbarrier.init</code> operation initializes an <em>mbarrier object</em> at the specified
memory location.</p><p>This operation initializes the <em>mbarrier object</em> with the following state:</p><ul><li>Current phase: 0</li><li>Expected arrival count: <code>count</code></li><li>Pending arrival count: <code>count</code></li><li>Transaction count (tx-count): 0</li></ul><p>The operation takes the following operands:</p><ul><li><code>addr</code>: A pointer to the memory location of the <em>mbarrier object</em>. The <code>addr</code>
must be a pointer to generic or shared::cta memory. When it is generic, the
underlying address must be within the shared::cta memory space; otherwise
the behavior is undefined.</li><li><code>count</code>: Integer specifying the number of threads that will participate in barrier
synchronization. Must be in the range [1, 2²⁰ - 1].</li><li><code>predicate</code>: Optional predicate for conditional execution.</li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-init>For more information, see PTX ISA</a></p><p>Interfaces: <code>BasicPtxBuilderInterface</code></p><h4 id=operands-44>Operands:&nbsp;<a class=headline-hash href=#operands-44>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>count</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>predicate</code></td><td>1-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarrierinval-nvvmmbarrierinvalop><code>nvvm.mbarrier.inval</code> (NVVM::MBarrierInvalOp)&nbsp;<a class=headline-hash href=#nvvmmbarrierinval-nvvmmbarrierinvalop>¶</a></h3><p><em>MBarrier Invalidation Operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.inval` $addr attr-dict `:` type(operands)
</code></pre><p>The <code>nvvm.mbarrier.inval</code> operation invalidates an <em>mbarrier object</em> at the
specified memory location.</p><p>This operation marks the <em>mbarrier object</em> as invalid, making it safe to repurpose
the memory location for other uses or to reinitialize it as a new <em>mbarrier object</em>.
It is undefined behavior if the <em>mbarrier object</em> is already invalid.</p><p>The operation takes the following operand:</p><ul><li><code>addr</code>: A pointer to the memory location of the <em>mbarrier object</em>. The <code>addr</code>
must be a pointer to generic or shared::cta memory. When it is generic, the
underlying address must be within the shared::cta memory space; otherwise
the behavior is undefined.</li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-inval>For more information, see PTX ISA</a></p><h4 id=operands-45>Operands:&nbsp;<a class=headline-hash href=#operands-45>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr></tbody></table><h3 id=nvvmmbarriertestwait-nvvmmbarriertestwaitop><code>nvvm.mbarrier.test.wait</code> (NVVM::MBarrierTestWaitOp)&nbsp;<a class=headline-hash href=#nvvmmbarriertestwait-nvvmmbarriertestwaitop>¶</a></h3><p><em>MBarrier Non-Blocking Test Wait Operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.test.wait` $addr `,` $stateOrPhase attr-dict `:` type(operands) `-&gt;` type($res)
</code></pre><p>The <code>nvvm.mbarrier.test.wait</code> operation performs a non-blocking test for the
completion of a specific phase of an <em>mbarrier object</em>. It uses the default
<code>.acquire.cta</code> semantics. This acquire pattern establishes memory ordering for
operations occurring in program order after this wait instruction by making
operations from other threads in the CTA visible to subsequent operations in the current
thread. When this wait completes, it synchronizes with the corresponding release
pattern from the <code>mbarrier.arrive</code> operation, establishing memory ordering within
the CTA.</p><p>This operation tests whether the mbarrier phase specified by the state operand
has completed. It is a non-blocking instruction that immediately returns the
completion status without suspending the executing thread.</p><p>The operation takes the following operands:</p><ul><li><code>addr</code>: A pointer to the memory location of the <em>mbarrier object</em>. Uses generic
addressing, but the address must still be in the shared memory space.</li><li><code>stateOrPhase</code>: This argument represents a <code>state</code> when it is a 64-bit value
and represents a <code>phase</code> when it is a 32-bit value. The <code>state</code> is an opaque
value returned by a previous <code>mbarrier.arrive</code> operation on the same
<em>mbarrier object</em> during the current or immediately preceding phase.
The <code>phase</code> is an integer specifying the phase parity (0 or 1).
Even phases have parity 0, odd phases have parity 1.</li><li><code>scope</code>: This specifies the set of threads that directly observe the memory
synchronizing effect of the <code>mbarrier.test.wait</code> operation.</li><li><code>relaxed</code>: When set to true, the <code>arrive</code> operation has relaxed memory semantics
and does not provide any ordering or visibility guarantees.</li></ul><p>The operation returns a boolean value indicating whether the specified phase
has completed:</p><ul><li><code>true</code>: The immediately preceding phase has completed</li><li><code>false</code>: The phase is still incomplete (current phase)</li></ul><p><strong>Memory ordering guarantees</strong>: When this wait returns true, the following
ordering guarantees hold:</p><ol><li>All memory accesses (except async operations) requested prior to
<code>mbarrier.arrive</code> having release semantics by participating CTA threads
are visible to the executing thread.</li><li>All <code>cp.async</code> operations requested prior to <code>cp.async.mbarrier.arrive</code>
by participating CTA threads are visible to the executing thread.</li><li>All <code>cp.async.bulk</code> operations using the same <em>mbarrier object</em> requested
prior to <code>mbarrier.arrive</code> having release semantics by participating CTA
threads are visible to the executing thread.</li><li>Memory accesses requested after this wait are not visible to memory
accesses performed prior to <code>mbarrier.arrive</code> by other participating
threads.</li><li>No ordering guarantee exists for memory accesses by the same thread
between <code>mbarrier.arrive</code> and this wait.</li></ol><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait>For more information, see PTX ISA</a></p><h4 id=attributes-71>Attributes:&nbsp;<a class=headline-hash href=#attributes-71>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr><tr><td><code>relaxed</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-46>Operands:&nbsp;<a class=headline-hash href=#operands-46>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>stateOrPhase</code></td><td>64-bit signless integer or 32-bit signless integer</td></tr></tbody></table><h4 id=results-94>Results:&nbsp;<a class=headline-hash href=#results-94>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>1-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarriertry_wait-nvvmmbarriertrywaitop><code>nvvm.mbarrier.try_wait</code> (NVVM::MBarrierTryWaitOp)&nbsp;<a class=headline-hash href=#nvvmmbarriertry_wait-nvvmmbarriertrywaitop>¶</a></h3><p><em>MBarrier try wait on state or phase with an optional timelimit</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.try_wait` $addr `,` $stateOrPhase (`,` $ticks^)? attr-dict `:` type(operands) `-&gt;` type($res)
</code></pre><p>The <code>nvvm.mbarrier.try_wait</code> operation checks whether the specified
<em>mbarrier object</em> at <code>addr</code> has completed the given phase. Note that
unlike the <code>nvvm.mbarrier.test.wait</code> operation, the try_wait operation
is a potentially-blocking one. If the phase is not yet complete, the
calling thread may be suspended. A suspended thread resumes execution
once the phase completes or when a system-defined timeout occurs.
Optionally, the <code>ticks</code> operand can be used to provide a custom timeout
(in nanoseconds), overriding the system-defined one. The semantics of
this operation and its operands are otherwise similar to those of the
<code>nvvm.mbarrier.test.wait</code> Op.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait>For more information, see PTX ISA</a></p><h4 id=attributes-72>Attributes:&nbsp;<a class=headline-hash href=#attributes-72>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr><tr><td><code>relaxed</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-47>Operands:&nbsp;<a class=headline-hash href=#operands-47>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>stateOrPhase</code></td><td>64-bit signless integer or 32-bit signless integer</td></tr><tr><td style=text-align:center><code>ticks</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-95>Results:&nbsp;<a class=headline-hash href=#results-95>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>1-bit signless integer</td></tr></tbody></table><h3 id=nvvmmbarriertry_waitparity-nvvmmbarriertrywaitparityop><code>nvvm.mbarrier.try_wait.parity</code> (NVVM::MBarrierTryWaitParityOp)&nbsp;<a class=headline-hash href=#nvvmmbarriertry_waitparity-nvvmmbarriertrywaitparityop>¶</a></h3><p><em>MBarrier Potentially-Blocking Try Wait with Phase Parity</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mbarrier.try_wait.parity` $addr `,` $phase `,` $ticks attr-dict `:` type(operands)
</code></pre><p>The <code>nvvm.mbarrier.try_wait.parity</code> operation performs a potentially-blocking
test for the completion of a specific phase of an <em>mbarrier object</em> using phase
parity. It uses the default <code>.acquire.cta</code> semantics. This acquire pattern
establishes memory ordering for operations occurring in program order after this
wait instruction by making operations from other threads in the CTA visible to subsequent
operations in the current thread. When this wait completes, it synchronizes with
the corresponding release pattern from the <code>mbarrier.arrive</code> operation, establishing
memory ordering within the CTA.</p><p>This operation waits for the completion of the mbarrier phase indicated by the
phase parity. While it uses the underlying PTX <code>mbarrier.try_wait.parity</code>
instruction, this MLIR operation generates a loop that enforces the test to
complete before continuing execution, ensuring the barrier phase is actually
completed rather than potentially timing out.</p><p>The operation takes the following operands:</p><ul><li><code>addr</code>: A pointer to the memory location of the <em>mbarrier object</em>. Uses generic
addressing, but the address must still be in the shared memory space.</li><li><code>phase</code>: An integer specifying the phase parity (0 or 1). Even phases
have parity 0, odd phases have parity 1.</li><li><code>ticks</code>: An unsigned integer specifying the suspend time hint in
nanoseconds. This may be used instead of the system-dependent time limit.</li></ul><p><strong>Memory ordering guarantees</strong>: When this wait returns true, the following
ordering guarantees hold:</p><ol><li>All memory accesses (except async operations) requested prior to
<code>mbarrier.arrive</code> having release semantics by participating CTA threads
are visible to the executing thread.</li><li>All <code>cp.async</code> operations requested prior to <code>cp.async.mbarrier.arrive</code>
by participating CTA threads are visible to the executing thread.</li><li>All <code>cp.async.bulk</code> operations using the same <em>mbarrier object</em> requested
prior to <code>mbarrier.arrive</code> having release semantics by participating CTA
threads are visible to the executing thread.</li><li>Memory accesses requested after this wait are not visible to memory
accesses performed prior to <code>mbarrier.arrive</code> by other participating
threads.</li><li>No ordering guarantee exists for memory accesses by the same thread
between <code>mbarrier.arrive</code> and this wait.</li></ol><p><strong>Implementation behavior</strong>:
This operation generates a PTX loop that repeatedly calls the underlying
<code>mbarrier.try_wait.parity</code> instruction until the barrier phase completes.
Unlike the raw PTX instruction which may return without completion after a
timeout, this MLIR operation guarantees completion by continuing to loop until
the specified phase is reached.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait>For more information, see PTX ISA</a></p><p>Interfaces: <code>BasicPtxBuilderInterface</code></p><h4 id=operands-48>Operands:&nbsp;<a class=headline-hash href=#operands-48>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>phase</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>ticks</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmmapa-nvvmmapaop><code>nvvm.mapa</code> (NVVM::MapaOp)&nbsp;<a class=headline-hash href=#nvvmmapa-nvvmmapaop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.mapa` $a`,` $b attr-dict `:` type($a) `-&gt;` type($res)
</code></pre><p>Traits: <code>NVVMRequiresSM&lt;90></code></p><h4 id=operands-49>Operands:&nbsp;<a class=headline-hash href=#operands-49>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>b</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-96>Results:&nbsp;<a class=headline-hash href=#results-96>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM pointer in address space 0 or LLVM pointer in address space 7</td></tr></tbody></table><h3 id=nvvmmatchsync-nvvmmatchsyncop><code>nvvm.match.sync</code> (NVVM::MatchSyncOp)&nbsp;<a class=headline-hash href=#nvvmmatchsync-nvvmmatchsyncop>¶</a></h3><p><em>Broadcast and compare a value across threads in warp</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.match.sync` $kind $thread_mask `,` $val attr-dict `:` type($val) `-&gt;` type($res)
</code></pre><p>The <code>match.sync</code> op performs broadcast and compare of operand <code>val</code> across
all non-exited threads in <code>thread_mask</code> and returns a mask depending on the
kind and an optional predicate.</p><p>The matching operation kinds are:</p><ul><li><code>any</code>: Returns a mask corresponding to the non-exited threads in the
<code>thread_mask</code> that have the same value of operand <code>val</code>.</li><li><code>all</code>: Returns a mask and a predicate. If all non-exited threads in the
<code>thread_mask</code> have the same value of operand <code>val</code>, the predicate is set to
true and the mask corresponds to the non-exited threads in the
<code>thread_mask</code>. Otherwise, the predicate is set to false and the mask is 0.</li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-match-sync>For more information, see PTX ISA</a></p><h4 id=attributes-73>Attributes:&nbsp;<a class=headline-hash href=#attributes-73>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::MatchSyncKindAttr</td><td>NVVM match sync kind</td></tr></table><h4 id=operands-50>Operands:&nbsp;<a class=headline-hash href=#operands-50>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>thread_mask</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>val</code></td><td>32-bit signless integer or 64-bit signless integer</td></tr></tbody></table><h4 id=results-97>Results:&nbsp;<a class=headline-hash href=#results-97>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer or LLVM struct type</td></tr></tbody></table><h3 id=nvvmmemorybarrier-nvvmmembarop><code>nvvm.memory.barrier</code> (NVVM::MembarOp)&nbsp;<a class=headline-hash href=#nvvmmemorybarrier-nvvmmembarop>¶</a></h3><p><em>Memory barrier operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.memory.barrier` $scope attr-dict
</code></pre><p><code>membar</code> operation guarantees that prior memory accesses requested by this
thread are performed at the specified <code>scope</code>, before later memory
operations requested by this thread following the membar instruction.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-membar>For more information, see PTX ISA</a></p><h4 id=attributes-74>Attributes:&nbsp;<a class=headline-hash href=#attributes-74>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>scope</code></td><td>::mlir::NVVM::MemScopeKindAttr</td><td>NVVM Memory Scope kind</td></tr></table><h3 id=nvvmmmablock_scale-nvvmmmablockscaleop><code>nvvm.mma.block_scale</code> (NVVM::MmaBlockScaleOp)&nbsp;<a class=headline-hash href=#nvvmmmablock_scale-nvvmmmablockscaleop>¶</a></h3><p><em>Cooperative matrix-multiply and accumulate with block scaling</em></p><p>The <code>nvvm.mma.block_scale</code> operation collectively performs the operation
<code>D = matmul(A * SF_A, B * SF_B) + C</code> using all threads in a warp.</p><p>A, B, C and D are dense matrices and SF_A and SF_B are scaling factors.
Dimensions of SF_A and SF_B are based on scale vector sizes (x1, x2, x4),
and the data type must be either ue8m0 or ue4m3.</p><p>All the threads in the warp must execute the same <code>mma.block_scale</code> operation.</p><p>This operation follows the same design pattern as <code>nvvm.mma.sync</code>, with additional
scaling operands for both A and B matrices.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%d</span> <span class=p>=</span> nvvm<span class=p>.</span>mma<span class=p>.</span>block_scale A<span class=p>[</span><span class=nv>%a0</span><span class=p>,</span> <span class=nv>%a1</span><span class=p>]</span> B<span class=p>[</span><span class=nv>%b0</span><span class=p>,</span> <span class=nv>%b1</span><span class=p>]</span> C<span class=p>[</span><span class=nv>%c0</span><span class=p>,</span> <span class=nv>%c1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                          scaleA<span class=p>[</span><span class=nv>%scaleAData</span><span class=p>,</span> <span class=nv>%byteIdA</span><span class=p>,</span> <span class=nv>%threadIdA</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                          scaleB<span class=p>[</span><span class=nv>%scaleBData</span><span class=p>,</span> <span class=nv>%byteIdB</span><span class=p>,</span> <span class=nv>%threadIdB</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                          <span class=p>{</span><span class=nl>shape =</span> <span class=nv>#nvvm.shape</span><span class=p>&lt;</span><span class=nl>m =</span> <span class=m>16</span><span class=p>,</span> <span class=nl>n =</span> <span class=m>8</span><span class=p>,</span> <span class=nl>k =</span> <span class=m>64</span><span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                           <span class=nl>multiplicandAPtxType =</span> <span class=nv>#nvvm.mma_type</span><span class=p>&lt;</span>e2m1<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                           <span class=nl>multiplicandBPtxType =</span> <span class=nv>#nvvm.mma_type</span><span class=p>&lt;</span>e2m1<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                           <span class=nl>scaleVecSize =</span> <span class=nv>#nvvm.scale_vec_size</span><span class=p>&lt;</span>x2<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                           <span class=nl>blockScaleFormat =</span> <span class=nv>#nvvm.block_scale_format</span><span class=p>&lt;</span>ue8m0<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                           <span class=nl>kind =</span> <span class=nv>#nvvm.block_scale_kind</span><span class=p>&lt;</span>mxf4nvf4<span class=p>&gt;}</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=p>(</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=p>!</span>llvm<span class=p>.</span>struct<span class=p>&lt;(</span><span class=k>f32</span><span class=p>,</span> <span class=k>f32</span><span class=p>)&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-75>Attributes:&nbsp;<a class=headline-hash href=#attributes-75>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::MMAShapeAttr</td><td>Attribute for MMA operation shape.</td></tr><tr><td><code>multiplicandAPtxType</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr><tr><td><code>multiplicandBPtxType</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr><tr><td><code>scaleVecSize</code></td><td>::mlir::NVVM::ScaleVecSizeAttr</td><td>MMA Scale Vector Sizes</td></tr><tr><td><code>blockScaleFormat</code></td><td>::mlir::NVVM::BlockScaleFormatAttr</td><td>MMA Block Scale Format</td></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::MMABlockScaleKindAttr</td><td><details><summary>Block Scale Kind</summary><pre><code>The MMABlockScaleKind attribute describes the allowed set of types for matrix A and B in the *.mma.{sp}.block_scale Op. The following are supported types for each kind:
<pre tabindex=0><code>+--------------+-------------------------------------------+
| Matrix Kind  |      supported types for A / B            |
+--------------+-------------------------------------------+
| mxf8f6f4     | e4m3, e5m2, e2m3, e3m2, e2m1              |
| mxf4         | e2m1                                      |
| mxf4nvf4     | e2m1                                      |
+--------------+-------------------------------------------+
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=operands-51>Operands:&nbsp;<a class=headline-hash href=#operands-51>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operandA</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>operandB</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>operandC</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>scaleAData</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>byteIdA</code></td><td>16-bit signless integer</td></tr><tr><td style=text-align:center><code>threadIdA</code></td><td>16-bit signless integer</td></tr><tr><td style=text-align:center><code>scaleBData</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>byteIdB</code></td><td>16-bit signless integer</td></tr><tr><td style=text-align:center><code>threadIdB</code></td><td>16-bit signless integer</td></tr></tbody></table><h4 id=results-98>Results:&nbsp;<a class=headline-hash href=#results-98>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM structure type</td></tr></tbody></table><h3 id=nvvmmmasync-nvvmmmaop><code>nvvm.mma.sync</code> (NVVM::MmaOp)&nbsp;<a class=headline-hash href=#nvvmmmasync-nvvmmmaop>¶</a></h3><p><em>Cooperative matrix-multiply and accumulate</em></p><p>The <code>nvvm.mma.sync</code> operation collectively performs the operation
<code>D = matmul(A, B) + C</code> using all threads in a warp.</p><p>All the threads in the warp must execute the same <code>mma.sync</code> operation.</p><p>For each possible multiplicand PTX data type, there are one or more possible
instruction shapes given as &ldquo;mMnNkK&rdquo;. The below table describes the posssibilities
as well as the types required for the operands. Note that the data type for
C (the accumulator) and D (the result) can vary independently when there are
multiple possibilities in the &ldquo;C/D Type&rdquo; column.</p><p>When an optional attribute cannot be immediately inferred from the types of
the operands and the result during parsing or validation, an error will be
raised.</p><p><code>b1Op</code> is only relevant when the binary (b1) type is given to
<code>multiplicandDataType</code>. It specifies how the multiply-and-acumulate is
performed and is either <code>xor_popc</code> or <code>and_poc</code>. The default is <code>xor_popc</code>.</p><p><code>intOverflowBehavior</code> is only relevant when the <code>multiplicandType</code> attribute
is one of <code>u8, s8, u4, s4</code>, this attribute describes how overflow is handled
in the accumulator. When the attribute is <code>satfinite</code>, the accumulator values
are clamped in the int32 range on overflow. This is the default behavior.
Alternatively, accumulator behavior <code>wrapped</code> can also be specified, in
which case overflow wraps from one end of the range to the other.</p><p><code>layoutA</code> and <code>layoutB</code> are required and should generally be set to
<code>#nvvm.mma_layout&lt;row></code> and <code>#nvvm.mma_layout&lt;col></code> respectively, but other
combinations are possible for certain layouts according to the table below.</p><pre tabindex=0><code>| A/B Type | Shape     | ALayout | BLayout | A Type   | B Type   | C/D Type          |
|----------|-----------|---------|---------|----------|----------|-------------------|
| f64      | .m8n8k4   | row     | col     | 1x f64   | 1x f64   | 2x f64            |
| f16      | .m8n8k4   | row/col | row/col | 2x f16x2 | 2x f16x2 | 4x f16x2 or 8xf32 |
|          | .m16n8k8  | row     | col     | 2x f16x2 | 1x f16x2 | 2x f16x2 or 4 f32 |
|          | .m16n8k16 | row     | col     | 4x f16x2 | 2x f16x2 | 2x f16x2 or 4 f32 |
| bf16     | .m16n8k8  | row     | col     | 2x i32   | 1x i32   | 4x f32            |
|          | .m16n8k16 | row     | col     | 4x i32   | 2x i32   | 4x f32            |
| tf32     | .m16n8k4  | row     | col     | 2x i32   | 1x i32   | 4x f32            |
|          | .m16n8k8  | row     | col     | 4x i32   | 2x i32   | 2x f16x2 or 4 f32 |
| u8/s8    | .m8n8k16  | row     | col     | 1x i32   | 1x i32   | 2x i32            |
|          | .m16n8k16 | row     | col     | 2x i32   | 1x i32   | 4x i32            |
|          | .m16n8k32 | row     | col     | 4x i32   | 2x i32   | 4x i32            |
| u4/s4    | .m8n8k32  | row     | col     | 1x i32   | 1x i32   | 2x i32            |
|          | m16n8k32  | row     | col     | 2x i32   | 1x i32   | 4x i32            |
|          | m16n8k64  | row     | col     | 4x i32   | 2x i32   | 4x i32            |
| b1       | m8n8k128  | row     | col     | 1x i32   | 1x i32   | 2x i32            |
|          | m16n8k128 | row     | col     | 2x i32   | 1x i32   | 4x i32            |
</code></pre><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%128</span> <span class=p>=</span> nvvm<span class=p>.</span>mma<span class=p>.</span>sync A<span class=p>[</span><span class=nv>%120</span><span class=p>,</span> <span class=nv>%121</span><span class=p>,</span> <span class=nv>%122</span><span class=p>,</span> <span class=nv>%123</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                     B<span class=p>[</span><span class=nv>%124</span><span class=p>,</span> <span class=nv>%125</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                     C<span class=p>[</span><span class=nv>%126</span><span class=p>,</span> <span class=nv>%127</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                     <span class=p>{</span><span class=nl>layoutA =</span> <span class=nv>#nvvm.mma_layout</span><span class=p>&lt;</span>row<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                      <span class=nl>layoutB =</span> <span class=nv>#nvvm.mma_layout</span><span class=p>&lt;</span>col<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                      <span class=nl>shape =</span> <span class=p>{</span><span class=nl>k =</span> <span class=m>16</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span> <span class=nl>m =</span> <span class=m>16</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span> <span class=nl>n =</span> <span class=m>8</span> <span class=p>:</span> <span class=k>i32</span><span class=p>}}</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=p>(</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;)</span>
</span></span><span class=line><span class=cl>       <span class=p>-&gt;</span> <span class=p>!</span>llvm<span class=p>.</span>struct<span class=p>&lt;(</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;)&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-76>Attributes:&nbsp;<a class=headline-hash href=#attributes-76>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::MMAShapeAttr</td><td>Attribute for MMA operation shape.</td></tr><tr><td><code>b1Op</code></td><td>::mlir::NVVM::MMAB1OpAttr</td><td>MMA binary operations</td></tr><tr><td><code>intOverflowBehavior</code></td><td>::mlir::NVVM::MMAIntOverflowAttr</td><td>MMA overflow options</td></tr><tr><td><code>layoutA</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>layoutB</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>multiplicandAPtxType</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr><tr><td><code>multiplicandBPtxType</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr></table><h4 id=operands-52>Operands:&nbsp;<a class=headline-hash href=#operands-52>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operandA</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>operandB</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>operandC</code></td><td>variadic of LLVM dialect-compatible type</td></tr></tbody></table><h4 id=results-99>Results:&nbsp;<a class=headline-hash href=#results-99>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM structure type</td></tr></tbody></table><h3 id=nvvmmmaspblock_scale-nvvmmmaspblockscaleop><code>nvvm.mma.sp.block_scale</code> (NVVM::MmaSpBlockScaleOp)&nbsp;<a class=headline-hash href=#nvvmmmaspblock_scale-nvvmmmaspblockscaleop>¶</a></h3><p><em>Cooperative sparse matrix-multiply and accumulate with block scaling</em></p><p>The <code>nvvm.mma.sp.block_scale</code> operation collectively performs the operation
<code>D = matmul(A_sparse * SF_A, B * SF_B) + C</code> using all threads in a warp.</p><p>A is a sparse matrix, and B, C and D are dense matrices.
SF_A and SF_B are scaling factors.
Dimensions of SF_A and SF_B are based on scale vector sizes (x1, x2, x4),
and the data type must be either ue8m0 or ue4m3.</p><p>This operation is similar to <code>nvvm.mma.block_scale</code> but with structured sparsity
in the A operand. The sparsity follows the 2:4 structured sparse pattern
where 2 out of every 4 elements are non-zero.</p><p>All the threads in the warp must execute the same <code>mma.sp.block_scale</code> operation.</p><p>The <code>sparseMetadata</code> operand provides the sparsity indices that indicate
which elements in the A operand are non-zero. The <code>sparsitySelector</code>
controls how the indices are distributed among threads in the warp and
should typically be 0 or 1.</p><p>This operation follows the same design pattern as <code>nvvm.mma.sp.sync</code>, with additional
scaling operands for both A and B matrices. Note that sparse block scale operations
always use ordered metadata (sm_90+).</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%d</span> <span class=p>=</span> nvvm<span class=p>.</span>mma<span class=p>.</span>sp<span class=p>.</span>block_scale A<span class=p>[</span><span class=nv>%a0</span><span class=p>,</span> <span class=nv>%a1</span><span class=p>]</span> B<span class=p>[</span><span class=nv>%b0</span><span class=p>,</span> <span class=nv>%b1</span><span class=p>]</span> C<span class=p>[</span><span class=nv>%c0</span><span class=p>,</span> <span class=nv>%c1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                             sparseMetadata<span class=p>[</span><span class=nv>%meta</span><span class=p>]</span> selector<span class=p>[</span><span class=nv>%sel</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                             scaleA<span class=p>[</span><span class=nv>%scaleAData</span><span class=p>,</span> <span class=nv>%byteIdA</span><span class=p>,</span> <span class=nv>%threadIdA</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                             scaleB<span class=p>[</span><span class=nv>%scaleBData</span><span class=p>,</span> <span class=nv>%byteIdB</span><span class=p>,</span> <span class=nv>%threadIdB</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                             <span class=p>{</span><span class=nl>shape =</span> <span class=nv>#nvvm.shape</span><span class=p>&lt;</span><span class=nl>m =</span> <span class=m>16</span><span class=p>,</span> <span class=nl>n =</span> <span class=m>8</span><span class=p>,</span> <span class=nl>k =</span> <span class=m>128</span><span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                              <span class=nl>multiplicandAPtxType =</span> <span class=nv>#nvvm.mma_type</span><span class=p>&lt;</span>e2m1<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                              <span class=nl>multiplicandBPtxType =</span> <span class=nv>#nvvm.mma_type</span><span class=p>&lt;</span>e2m1<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                              <span class=nl>scaleVecSize =</span> <span class=nv>#nvvm.scale_vec_size</span><span class=p>&lt;</span>x2<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                              <span class=nl>blockScaleFormat =</span> <span class=nv>#nvvm.block_scale_format</span><span class=p>&lt;</span>ue8m0<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>                              <span class=nl>kind =</span> <span class=nv>#nvvm.block_scale_kind</span><span class=p>&lt;</span>mxf4<span class=p>&gt;}</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=p>(</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=p>!</span>llvm<span class=p>.</span>struct<span class=p>&lt;(</span><span class=k>f32</span><span class=p>,</span> <span class=k>f32</span><span class=p>)&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-77>Attributes:&nbsp;<a class=headline-hash href=#attributes-77>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::MMAShapeAttr</td><td>Attribute for MMA operation shape.</td></tr><tr><td><code>multiplicandAPtxType</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr><tr><td><code>multiplicandBPtxType</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr><tr><td><code>scaleVecSize</code></td><td>::mlir::NVVM::ScaleVecSizeAttr</td><td>MMA Scale Vector Sizes</td></tr><tr><td><code>blockScaleFormat</code></td><td>::mlir::NVVM::BlockScaleFormatAttr</td><td>MMA Block Scale Format</td></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::MMABlockScaleKindAttr</td><td><details><summary>Block Scale Kind</summary><pre><code>The MMABlockScaleKind attribute describes the allowed set of types for matrix A and B in the *.mma.{sp}.block_scale Op. The following are supported types for each kind:
<pre tabindex=0><code>+--------------+-------------------------------------------+
| Matrix Kind  |      supported types for A / B            |
+--------------+-------------------------------------------+
| mxf8f6f4     | e4m3, e5m2, e2m3, e3m2, e2m1              |
| mxf4         | e2m1                                      |
| mxf4nvf4     | e2m1                                      |
+--------------+-------------------------------------------+
</code></pre><p></code></pre></p></details></td></tr><tr><td><code>orderedMetadata</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h4 id=operands-53>Operands:&nbsp;<a class=headline-hash href=#operands-53>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operandA</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>operandB</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>operandC</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>sparseMetadata</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>sparsitySelector</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>scaleAData</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>byteIdA</code></td><td>16-bit signless integer</td></tr><tr><td style=text-align:center><code>threadIdA</code></td><td>16-bit signless integer</td></tr><tr><td style=text-align:center><code>scaleBData</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>byteIdB</code></td><td>16-bit signless integer</td></tr><tr><td style=text-align:center><code>threadIdB</code></td><td>16-bit signless integer</td></tr></tbody></table><h4 id=results-100>Results:&nbsp;<a class=headline-hash href=#results-100>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM structure type</td></tr></tbody></table><h3 id=nvvmmmaspsync-nvvmmmaspop><code>nvvm.mma.sp.sync</code> (NVVM::MmaSpOp)&nbsp;<a class=headline-hash href=#nvvmmmaspsync-nvvmmmaspop>¶</a></h3><p><em>Cooperative sparse matrix-multiply and accumulate</em></p><p>The <code>nvvm.mma.sp.sync</code> operation collectively performs the sparse operation
<code>D = matmul(A_sparse, B) + C</code> using all threads in a warp.</p><p>This operation is similar to <code>nvvm.mma.sync</code> but with structured sparsity
in the A operand. The sparsity follows the 2:4 structured sparse pattern
where 2 out of every 4 elements are non-zero.</p><p>All the threads in the warp must execute the same <code>mma.sp.sync</code> operation.</p><p>The <code>sparseMetadata</code> operand provides the sparsity indices that indicate
which elements in the A operand are non-zero. The <code>sparsitySelector</code>
controls how the indices are distributed among threads in the warp and
should typically be 0 or 1.</p><p>The optional <code>orderedMetadata</code> attribute specifies the metadata ordering:</p><ul><li>Absence (default): Uses standard sparse metadata ordering</li><li>Presence: Uses ordered metadata (PTX ISA 8.5+, sm_90+)</li></ul><p>The optional <code>kind</code> attribute specifies mixed-precision modes for FP8 operations:</p><ul><li><code>f8f6f4</code>: Enables e3m2, e2m3, e2m1 FP8 types and f16 accumulator (PTX ISA 8.7+, sm_90+)</li><li>Only valid with ordered metadata and m16n8k64 shape</li></ul><p>The shapes, layouts, and data types follow the same constraints as the
regular <code>nvvm.mma.sync</code> operation, but the A operand contains only the
non-zero elements in compressed format.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%d</span> <span class=p>=</span> nvvm<span class=p>.</span>mma<span class=p>.</span>sp<span class=p>.</span>sync A<span class=p>[</span><span class=nv>%a0</span><span class=p>,</span> <span class=nv>%a1</span><span class=p>]</span> B<span class=p>[</span><span class=nv>%b0</span><span class=p>,</span> <span class=nv>%b1</span><span class=p>]</span> C<span class=p>[</span><span class=nv>%c0</span><span class=p>,</span> <span class=nv>%c1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                      sparseMetadata<span class=p>[</span><span class=nv>%meta</span><span class=p>]</span> selector<span class=p>[</span><span class=nv>%sel</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                      <span class=p>{</span><span class=nl>shape =</span> <span class=p>{</span><span class=nl>k =</span> <span class=m>32</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span> <span class=nl>m =</span> <span class=m>16</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span> <span class=nl>n =</span> <span class=m>8</span> <span class=p>:</span> <span class=k>i32</span><span class=p>}}</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=p>(</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=p>!</span>llvm<span class=p>.</span>struct<span class=p>&lt;(</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;)&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// With ordered metadata:
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%d</span> <span class=p>=</span> nvvm<span class=p>.</span>mma<span class=p>.</span>sp<span class=p>.</span>sync A<span class=p>[</span><span class=nv>%a0</span><span class=p>,</span> <span class=nv>%a1</span><span class=p>]</span> B<span class=p>[</span><span class=nv>%b0</span><span class=p>,</span> <span class=nv>%b1</span><span class=p>]</span> C<span class=p>[</span><span class=nv>%c0</span><span class=p>,</span> <span class=nv>%c1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                      sparseMetadata<span class=p>[</span><span class=nv>%meta</span><span class=p>]</span> selector<span class=p>[</span><span class=nv>%sel</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                      <span class=p>{</span>orderedMetadata<span class=p>,</span> <span class=nl>shape =</span> <span class=p>{</span><span class=nl>k =</span> <span class=m>32</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span> <span class=nl>m =</span> <span class=m>16</span> <span class=p>:</span> <span class=k>i32</span><span class=p>,</span> <span class=nl>n =</span> <span class=m>8</span> <span class=p>:</span> <span class=k>i32</span><span class=p>}}</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=p>(</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;)</span> <span class=p>-&gt;</span> <span class=p>!</span>llvm<span class=p>.</span>struct<span class=p>&lt;(</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;)&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AttrSizedOperandSegments</code></p><h4 id=attributes-78>Attributes:&nbsp;<a class=headline-hash href=#attributes-78>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::MMAShapeAttr</td><td>Attribute for MMA operation shape.</td></tr><tr><td><code>intOverflowBehavior</code></td><td>::mlir::NVVM::MMAIntOverflowAttr</td><td>MMA overflow options</td></tr><tr><td><code>multiplicandAPtxType</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr><tr><td><code>multiplicandBPtxType</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr><tr><td><code>orderedMetadata</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::MMAKindAttr</td><td>MMA operation kind</td></tr></table><h4 id=operands-54>Operands:&nbsp;<a class=headline-hash href=#operands-54>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operandA</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>operandB</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>operandC</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>sparseMetadata</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>sparsitySelector</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-101>Results:&nbsp;<a class=headline-hash href=#results-101>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM structure type</td></tr></tbody></table><h3 id=nvvmnanosleep-nvvmnanosleepop><code>nvvm.nanosleep</code> (NVVM::NanosleepOp)&nbsp;<a class=headline-hash href=#nvvmnanosleep-nvvmnanosleepop>¶</a></h3><p><em>Suspends the thread for a specified duration.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.nanosleep` attr-dict $duration
</code></pre><p>The op suspends the thread for a sleep duration approximately close to the
delay <code>$duration</code>, specified in nanoseconds.</p><p>The sleep duration is approximated, but guaranteed to be in the
interval [0, 2*t]. The maximum sleep duration is 1 millisecond.
The implementation may reduce the sleep duration for individual threads
within a warp such that all sleeping threads in the warp wake up together.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#miscellaneous-instructions-nanosleep>For more information, see PTX ISA</a></p><h4 id=operands-55>Operands:&nbsp;<a class=headline-hash href=#operands-55>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>duration</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmpmevent-nvvmpmeventop><code>nvvm.pmevent</code> (NVVM::PMEventOp)&nbsp;<a class=headline-hash href=#nvvmpmevent-nvvmpmeventop>¶</a></h3><p><em>Trigger one or more Performance Monitor events.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.pmevent` attr-dict (`id` `=` $eventId^)? (`mask` `=` $maskedEventId^)?
</code></pre><p>Triggers one or more of a fixed number of performance monitor events, with
event index or mask specified by immediate operand.</p><p>Without <code>mask</code> it triggers a single performance monitor event indexed by
immediate operand a, in the range 0..15.</p><p>With <code>mask</code> it triggers one or more of the performance monitor events. Each
bit in the 16-bit immediate operand controls an event.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#miscellaneous-instructions-pmevent>For more information, see PTX ISA</a></p><h4 id=attributes-79>Attributes:&nbsp;<a class=headline-hash href=#attributes-79>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>maskedEventId</code></td><td>::mlir::IntegerAttr</td><td>16-bit signless integer attribute</td></tr><tr><td><code>eventId</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr></table><h3 id=nvvmprmt-nvvmpermuteop><code>nvvm.prmt</code> (NVVM::PermuteOp)&nbsp;<a class=headline-hash href=#nvvmprmt-nvvmpermuteop>¶</a></h3><p><em>Permute bytes from two 32-bit registers</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.prmt` $mode $selector `,` $lo  (`,` $hi^)?  attr-dict `:` type($res)
</code></pre><p>The <code>nvvm.prmt</code> operation constructs a permutation of the
bytes of the first one or two operands, selecting based on
the 2 least significant bits of the final operand.</p><p>The bytes in the first one or two source operands are numbered.
The first source operand (%lo) is numbered {b3, b2, b1, b0},
in the case of the &lsquo;<code>default</code>&rsquo;, &lsquo;<code>f4e</code>&rsquo; and &lsquo;<code>b4e</code>&rsquo; variants,
the second source operand (%hi) is numbered {b7, b6, b5, b4}.</p><p>Modes:</p><ul><li><code>default</code>: Index mode - each nibble in <code>selector</code> selects a byte from the 8-byte pool</li><li><code>f4e</code> : Forward 4 extract - extracts 4 contiguous bytes starting from position in <code>selector</code></li><li><code>b4e</code> : Backward 4 extract - extracts 4 contiguous bytes in reverse order</li><li><code>rc8</code> : Replicate 8 - replicates the lower 8 bits across the 32-bit result</li><li><code>ecl</code> : Edge clamp left - clamps out-of-range indices to the leftmost valid byte</li><li><code>ecr</code> : Edge clamp right - clamps out-of-range indices to the rightmost valid byte</li><li><code>rc16</code> : Replicate 16 - replicates the lower 16 bits across the 32-bit result</li></ul><p>Depending on the 2 least significant bits of the %selector operand, the result
of the permutation is defined as follows:</p><p>+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| Mode | %selector[1:0] | Output |
+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| &lsquo;<code>f4e</code>&rsquo; | 0 | {3, 2, 1, 0} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 1 | {4, 3, 2, 1} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 2 | {5, 4, 3, 2} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 3 | {6, 5, 4, 3} |
+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| &lsquo;<code>b4e</code>&rsquo; | 0 | {5, 6, 7, 0} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 1 | {6, 7, 0, 1} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 2 | {7, 0, 1, 2} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 3 | {0, 1, 2, 3} |
+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| &lsquo;<code>rc8</code>&rsquo; | 0 | {0, 0, 0, 0} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 1 | {1, 1, 1, 1} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 2 | {2, 2, 2, 2} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 3 | {3, 3, 3, 3} |
+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| &lsquo;<code>ecl</code>&rsquo; | 0 | {3, 2, 1, 0} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 1 | {3, 2, 1, 1} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 2 | {3, 2, 2, 2} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 3 | {3, 3, 3, 3} |
+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| &lsquo;<code>ecr</code>&rsquo; | 0 | {0, 0, 0, 0} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 1 | {1, 1, 1, 0} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 2 | {2, 2, 1, 0} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 3 | {3, 2, 1, 0} |
+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| &lsquo;<code>rc16</code>&rsquo; | 0 | {1, 0, 1, 0} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 1 | {3, 2, 3, 2} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 2 | {1, 0, 1, 0} |
| +&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+
| | 3 | {3, 2, 3, 2} |
+&mdash;&mdash;&mdash;&mdash;+&mdash;&mdash;&mdash;&mdash;&mdash;-+&mdash;&mdash;&mdash;&mdash;&ndash;+</p><p>[For more information, see PTX ISA]
(
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#data-movement-and-conversion-instructions-prmt>https://docs.nvidia.com/cuda/parallel-thread-execution/#data-movement-and-conversion-instructions-prmt</a>)</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-80>Attributes:&nbsp;<a class=headline-hash href=#attributes-80>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>mode</code></td><td>::mlir::NVVM::PermuteModeAttr</td><td>NVVM permute mode</td></tr></table><h4 id=operands-56>Operands:&nbsp;<a class=headline-hash href=#operands-56>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>lo</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>hi</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>selector</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-102>Results:&nbsp;<a class=headline-hash href=#results-102>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmprefetch-nvvmprefetchop><code>nvvm.prefetch</code> (NVVM::PrefetchOp)&nbsp;<a class=headline-hash href=#nvvmprefetch-nvvmprefetchop>¶</a></h3><p><em>Brings the cache line containing an address into the specified cache level</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.prefetch` (`level` `=` $cacheLevel^ (`uniform` $uniform^)? `,`)? (`tensormap` $tensormap^ (`in_param_space` $in_param_space^)? `,`)? (`evict_priority` `=` $evictPriority^ `,`)? $addr (`,` `predicate` `=` $predicate^)? attr-dict `:` type(operands)
</code></pre><p>Prefetches the cache line containing the address given by <code>addr</code>. The
operand may be a global, local, or generic pointer. When <code>tensormap</code> is
specified, the operand may instead be a constant or generic pointer. If the
address maps to shared memory, the operation has no effect.</p><p>At most one of <code>cacheLevel</code> or <code>tensormap</code> may be present. The <code>cacheLevel</code>
attribute selects the target cache level. When combined with <code>uniform</code>, the
prefetch is performed to the uniform cache, in which case <code>addr</code> must be a
generic pointer.</p><p>When <code>tensormap</code> is used, the line containing <code>addr</code> is brought from the
constant or parameter state space for later use by <code>cp.async.bulk.tensor</code>.
If <code>in_param_space</code> is specified, the generic pointer is interpreted as
referring to the parameter state space.</p><p><code>uniform</code> can be specified after the <code>cacheLevel</code> to indicate that the
prefetch is performed to the specified uniform cache level. If <code>uniform</code> is
specified, <code>addr</code> must be a generic address pointer and no operation is
performed if <code>addr</code> maps to a <code>const</code>, <code>local</code>, or <code>shared</code> memory location.</p><p>The <code>evictPriority</code> attribute is optional and specifies the cache eviction
priority when <code>cacheLevel</code> is L2.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#data-movement-and-conversion-instructions-prefetch-prefetchu>For more information, see PTX ISA</a></p><p>Interfaces: <code>BasicPtxBuilderInterface</code></p><h4 id=attributes-81>Attributes:&nbsp;<a class=headline-hash href=#attributes-81>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>cacheLevel</code></td><td>::mlir::NVVM::PrefetchCacheLevelAttr</td><td><details><summary>NVVM Prefetch Cache Level</summary><p>Enum cases:</p><ul><li>L1 (<code>L1</code>)</li><li>L2 (<code>L2</code>)</li></ul></details></td></tr><tr><td><code>evictPriority</code></td><td>::mlir::NVVM::CacheEvictionPriorityAttr</td><td><details><summary>NVVM Cache Eviction Priority</summary><p>Enum cases:</p><ul><li>evict_normal (<code>EvictNormal</code>)</li><li>evict_first (<code>EvictFirst</code>)</li><li>evict_last (<code>EvictLast</code>)</li><li>evict_unchanged (<code>EvictUnchanged</code>)</li><li>no_allocate (<code>NoAllocate</code>)</li></ul></details></td></tr><tr><td><code>tensormap</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>uniform</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>in_param_space</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h4 id=operands-57>Operands:&nbsp;<a class=headline-hash href=#operands-57>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer in address space 1 or LLVM pointer in address space 5 or LLVM pointer in address space 0 or LLVM pointer in address space 4</td></tr><tr><td style=text-align:center><code>predicate</code></td><td>1-bit signless integer</td></tr></tbody></table><h3 id=nvvmrcpapproxftzf-nvvmrcpapproxftzf32op><code>nvvm.rcp.approx.ftz.f</code> (NVVM::RcpApproxFtzF32Op)&nbsp;<a class=headline-hash href=#nvvmrcpapproxftzf-nvvmrcpapproxftzf32op>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.rcp.approx.ftz.f` $arg attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-58>Operands:&nbsp;<a class=headline-hash href=#operands-58>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>arg</code></td><td>32-bit float</td></tr></tbody></table><h4 id=results-103>Results:&nbsp;<a class=headline-hash href=#results-103>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit float</td></tr></tbody></table><h3 id=nvvmreduxsync-nvvmreduxop><code>nvvm.redux.sync</code> (NVVM::ReduxOp)&nbsp;<a class=headline-hash href=#nvvmreduxsync-nvvmreduxop>¶</a></h3><p><em>Redux Sync Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.redux.sync` $kind $val `,` $mask_and_clamp  attr-dict `:` type($val) `-&gt;` type($res)
</code></pre><p><code>redux.sync</code> performs a reduction operation <code>kind</code> of the 32 bit source
register across all non-exited threads in the membermask.</p><p>The <code>abs</code> and <code>nan</code> attributes can be used in the case of f32 input type,
where the <code>abs</code> attribute causes the absolute value of the input to be used
in the reduction operation, and the <code>nan</code> attribute causes the reduction
operation to return NaN if any of the inputs to participating threads are
NaN.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-redux-sync>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSM&lt;80></code></p><h4 id=attributes-82>Attributes:&nbsp;<a class=headline-hash href=#attributes-82>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::ReduxKindAttr</td><td>NVVM redux kind</td></tr><tr><td><code>abs</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>nan</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-59>Operands:&nbsp;<a class=headline-hash href=#operands-59>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>val</code></td><td>32-bit signless integer or 32-bit float</td></tr><tr><td style=text-align:center><code>mask_and_clamp</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-104>Results:&nbsp;<a class=headline-hash href=#results-104>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer or 32-bit float</td></tr></tbody></table><h3 id=nvvmsetmaxregister-nvvmsetmaxregisterop><code>nvvm.setmaxregister</code> (NVVM::SetMaxRegisterOp)&nbsp;<a class=headline-hash href=#nvvmsetmaxregister-nvvmsetmaxregisterop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.setmaxregister` $action $regCount attr-dict
</code></pre><h4 id=attributes-83>Attributes:&nbsp;<a class=headline-hash href=#attributes-83>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>regCount</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>action</code></td><td>::mlir::NVVM::SetMaxRegisterActionAttr</td><td>NVVM set max register action</td></tr></table><h3 id=nvvmshflsync-nvvmshflop><code>nvvm.shfl.sync</code> (NVVM::ShflOp)&nbsp;<a class=headline-hash href=#nvvmshflsync-nvvmshflop>¶</a></h3><p><em>NVVM Dialect Op for shfl.sync</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.shfl.sync` $kind $thread_mask `,` $val `,` $offset `,` $mask_and_clamp  attr-dict
              `:` type($val) `-&gt;` type($res)
</code></pre><p>The <code>shfl.sync</code> Op implements data shuffle within threads of a warp.
The <code>thread_mask</code> denotes the threads participating in the Op where
the bit position corresponds to a particular thread&rsquo;s laneid.
The <code>offset</code> specifies a source lane or source lane offset
(depending on <code>kind</code>). The <code>val</code> is the input value to be copied from
the source. The <code>mask_and_clamp</code> contains two packed values specifying
a mask for logically splitting warps into sub-segments and an upper bound
for clamping the source lane index.</p><p>The <code>return_value_and_is_valid</code> unit attribute can be specified to indicate
that the return value is a two-element struct, where the first element is
the result value and the second element is a predicate indicating if the
computed source lane index is valid.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#data-movement-and-conversion-instructions-shfl-sync>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSM&lt;30></code></p><h4 id=attributes-84>Attributes:&nbsp;<a class=headline-hash href=#attributes-84>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::ShflKindAttr</td><td>NVVM shuffle kind</td></tr><tr><td><code>return_value_and_is_valid</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h4 id=operands-60>Operands:&nbsp;<a class=headline-hash href=#operands-60>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>thread_mask</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>val</code></td><td>32-bit signless integer or 32-bit float</td></tr><tr><td style=text-align:center><code>offset</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>mask_and_clamp</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-105>Results:&nbsp;<a class=headline-hash href=#results-105>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer or 32-bit float or LLVM struct type</td></tr></tbody></table><h3 id=nvvmreadptxsregnsmid-nvvmsmdimop><code>nvvm.read.ptx.sreg.nsmid</code> (NVVM::SmDimOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregnsmid-nvvmsmdimop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.nsmid` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-85>Attributes:&nbsp;<a class=headline-hash href=#attributes-85>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-106>Results:&nbsp;<a class=headline-hash href=#results-106>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregsmid-nvvmsmidop><code>nvvm.read.ptx.sreg.smid</code> (NVVM::SmIdOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregsmid-nvvmsmidop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.smid` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-86>Attributes:&nbsp;<a class=headline-hash href=#attributes-86>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-107>Results:&nbsp;<a class=headline-hash href=#results-107>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmstmatrix-nvvmstmatrixop><code>nvvm.stmatrix</code> (NVVM::StMatrixOp)&nbsp;<a class=headline-hash href=#nvvmstmatrix-nvvmstmatrixop>¶</a></h3><p><em>Cooperative matrix store</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.stmatrix` $ptr `,` $sources attr-dict `:` type(operands)
</code></pre><p>Collectively store one or more matrices across all threads in a warp to the
location indicated by the address operand $ptr in shared memory.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-store-instruction-stmatrix>For more information, see PTX ISA</a></p><h4 id=attributes-87>Attributes:&nbsp;<a class=headline-hash href=#attributes-87>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>layout</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::LdStMatrixShapeAttr</td><td>Matrix shape for ldmatrix and stmatrix</td></tr><tr><td><code>eltType</code></td><td>::mlir::NVVM::LdStMatrixEltTypeAttr</td><td>Element type for ldmatrix and stmatrix</td></tr></table><h4 id=operands-61>Operands:&nbsp;<a class=headline-hash href=#operands-61>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>ptr</code></td><td>LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>sources</code></td><td>variadic of 32-bit signless integer</td></tr></tbody></table><h3 id=nvvmbarwarpsync-nvvmsyncwarpop><code>nvvm.bar.warp.sync</code> (NVVM::SyncWarpOp)&nbsp;<a class=headline-hash href=#nvvmbarwarpsync-nvvmsyncwarpop>¶</a></h3><p><em>Warp Barrier Synchronization Op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.bar.warp.sync` $mask attr-dict `:` type($mask)
</code></pre><p>The <code>nvvm.bar.warp.sync</code> operation performs barrier synchronization for threads
within a warp.</p><p>This operation causes the executing thread to wait until all threads corresponding
to the <code>mask</code> operand have executed a <code>bar.warp.sync</code> with the same mask value
before resuming execution.</p><p>The <code>mask</code> operand specifies the threads participating in the barrier, where each
bit position corresponds to the thread&rsquo;s lane ID within the warp. Only threads with
their corresponding bit set in the mask participate in the barrier synchronization.</p><p><strong>Important constraints</strong>:</p><ul><li>The behavior is undefined if the executing thread is not included in the mask
(i.e., the bit corresponding to the thread&rsquo;s lane ID is not set)</li><li>For compute capability sm_6x or below, all threads in the mask must execute
the same <code>bar.warp.sync</code> instruction in convergence</li></ul><p>This operation also guarantees memory ordering among participating threads.
Threads within the warp that wish to communicate via memory can store to memory,
execute <code>bar.warp.sync</code>, and then safely read values stored by other threads
in the warp.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-bar-warp-sync>For more information, see PTX ISA</a></p><h4 id=operands-62>Operands:&nbsp;<a class=headline-hash href=#operands-62>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>mask</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmtcgen05alloc-nvvmtcgen05allocop><code>nvvm.tcgen05.alloc</code> (NVVM::Tcgen05AllocOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05alloc-nvvmtcgen05allocop>¶</a></h3><p><em>Tcgen05 alloc operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.alloc` $addr `,` $nCols attr-dict `:` type(operands)
</code></pre><p>The <code>tcgen05.alloc</code> Op allocates tensor core memory for
the amount specified by <code>nCols</code> and writes the destination
address to the <code>addr</code> argument. The <code>nCols</code> operand specifies the
number of columns to be allocated and it must be a power-of-two.
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-memory-alloc-manage-instructions>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101></code></p><h4 id=attributes-88>Attributes:&nbsp;<a class=headline-hash href=#attributes-88>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>group</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr></table><h4 id=operands-63>Operands:&nbsp;<a class=headline-hash href=#operands-63>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer type or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>nCols</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmtcgen05commit-nvvmtcgen05commitop><code>nvvm.tcgen05.commit</code> (NVVM::Tcgen05CommitOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05commit-nvvmtcgen05commitop>¶</a></h3><p><em>Tcgen05 commit operations</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.commit` $addr (`,` `multicast_mask` `=` $multicastMask^)?
              attr-dict `:` type(operands)
</code></pre><p>The <code>tcgen05.commit</code> makes the <em>mbarrier object</em>, specified by
the operand <code>addr</code>, track the completion of all the prior
async-tcgen05 operations initiated by the executing thread.
The multicast variants allow signaling on the <em>mbarrier objects</em>
of multiple CTAs within the cluster. Operand <code>multicastMask</code>,
when present, specifies the destination CTAs in the cluster such
that each bit position in the 16-bit <code>multicastMask</code> operand
corresponds to the <code>nvvm.read.ptx.sreg.ctaid</code> of the destination CTA.
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen-async-sync-operations-commit>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101></code></p><h4 id=attributes-89>Attributes:&nbsp;<a class=headline-hash href=#attributes-89>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>group</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr></table><h4 id=operands-64>Operands:&nbsp;<a class=headline-hash href=#operands-64>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>addr</code></td><td>LLVM pointer type or LLVM pointer in address space 3</td></tr><tr><td style=text-align:center><code>multicastMask</code></td><td>16-bit signless integer</td></tr></tbody></table><h3 id=nvvmtcgen05cp-nvvmtcgen05cpop><code>nvvm.tcgen05.cp</code> (NVVM::Tcgen05CpOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05cp-nvvmtcgen05cpop>¶</a></h3><p><em>Tcgen05 copy operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.cp` $taddr`,` $smem_desc attr-dict
</code></pre><p>Instruction tcgen05.cp initiates an asynchronous copy operation from
shared memory to the location specified by the address operand <code>taddr</code>
in the Tensor Memory. The 64-bit register operand <code>smem_desc</code> specifies
the matrix descriptor representing the source matrix in the shared memory
that needs to be copied.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  nvvm<span class=p>.</span>tcgen05<span class=p>.</span>cp <span class=nv>%taddr</span><span class=p>,</span> <span class=nv>%smem_desc</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nl>group =</span> <span class=nv>#nvvm.tcgen05_group</span><span class=p>&lt;</span>cta_2<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>    <span class=nl>shape =</span> <span class=nv>#nvvm.tcgen05_cp_shape</span><span class=p>&lt;</span>shape_64x128b<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>    <span class=nl>multicast =</span> <span class=nv>#nvvm.tcgen05_cp_multicast</span><span class=p>&lt;</span>warpx2_01_23<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>    <span class=nl>srcFormat =</span> <span class=nv>#nvvm.tcgen05_cp_src_fmt</span><span class=p>&lt;</span>b6x16_p32<span class=p>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span></code></pre></div><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensorcore-5th-generation-instructions-tcgen05-cp>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101></code></p><h4 id=attributes-90>Attributes:&nbsp;<a class=headline-hash href=#attributes-90>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::Tcgen05CpShapeAttr</td><td>tcgen05 cp shapes</td></tr><tr><td><code>group</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr><tr><td><code>multicast</code></td><td>::mlir::NVVM::Tcgen05CpMulticastAttr</td><td>tcgen05 cp multicast</td></tr><tr><td><code>srcFormat</code></td><td>::mlir::NVVM::Tcgen05CpSrcFormatAttr</td><td>tcgen05 cp source format</td></tr></table><h4 id=operands-65>Operands:&nbsp;<a class=headline-hash href=#operands-65>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>taddr</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>smem_desc</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmtcgen05dealloc-nvvmtcgen05deallocop><code>nvvm.tcgen05.dealloc</code> (NVVM::Tcgen05DeallocOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05dealloc-nvvmtcgen05deallocop>¶</a></h3><p><em>Tcgen05 dealloc operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.dealloc` $taddr `,` $nCols attr-dict `:` type(operands)
</code></pre><p>The <code>tcgen05.dealloc</code> Op de-allocates the tensor core memory
specified by <code>tmemAddr</code>, which must be from a previous tensor
memory allocation. The <code>nCols</code> operand specifies the number
of columns to be de-allocated, and it must be a power-of-two.
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-memory-alloc-manage-instructions>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101></code></p><h4 id=attributes-91>Attributes:&nbsp;<a class=headline-hash href=#attributes-91>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>group</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr></table><h4 id=operands-66>Operands:&nbsp;<a class=headline-hash href=#operands-66>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>taddr</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>nCols</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmtcgen05fence-nvvmtcgen05fenceop><code>nvvm.tcgen05.fence</code> (NVVM::Tcgen05FenceOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05fence-nvvmtcgen05fenceop>¶</a></h3><p><em>Tcgen05 fence operations</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.fence` $kind attr-dict
</code></pre><p>The <code>tcgen05.fence&lt;before></code> orders all prior async tcgen05 operations
with respect to the subsequent tcgen05 and execution ordering operations.
The <code>tcgen05.fence&lt;after></code> orders all subsequent async tcgen05 operations
with respect to the prior tcgen05 and execution ordering operations.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tensorcore-5th-generation-instructions-tcgen05-fence>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101></code></p><h4 id=attributes-92>Attributes:&nbsp;<a class=headline-hash href=#attributes-92>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::Tcgen05FenceKindAttr</td><td>NVVM Tcgen05 fence kind</td></tr></table><h3 id=nvvmtcgen05ld-nvvmtcgen05ldop><code>nvvm.tcgen05.ld</code> (NVVM::Tcgen05LdOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05ld-nvvmtcgen05ldop>¶</a></h3><p><em>Tensor memory load instructions</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.ld` $tmemAddr (`,` $offset^)? (`pack` $pack^)? attr-dict `:` type($res)
</code></pre><p>Instruction <code>tcgen05.ld</code> asynchronously loads data from the Tensor Memory at
the location specified by the 32-bit address operand <code>tmemAddr</code> into the
destination register <code>res</code>, collectively across all threads of the warps.</p><p>The <code>shape</code> and the <code>num</code> attribute together determines the total
dimension of the data which is loaded from the Tensor Memory. The <code>shape</code>
attribute indicates the base dimension of data to be accessed as described
in the Data Movement Shape. The <code>num</code> attribute indicates the repeat
factor on the base dimension resulting in the total dimension of the data
that is accessed.</p><p>The shape <code>16x32bx2</code> performs two accesses into Tensor Memory of the shape
<code>16x32b</code>. The base address of the first access is specified by <code>tmemAddr</code>
and the base address of the second access is specified by
<code>tmemAddr + offset</code>, where <code>offset</code> is an immediate argument.</p><p>The unit attribute <code>pack</code> can be used to pack two 16-bit
elements from adjacent columns into a single 32-bit element during the load.</p><p>The following table describes the size of the vector for various combinations
of <code>num</code> and <code>shape</code> attributes:</p><pre tabindex=0><code>|=====================================================================|
| num/shape      |     16x32bx2/16x64b/32x32b |  16x128b   | 16x256b  |
|=====================================================================|
| x1             |          1                 |    2       |    4     |
| x2             |          2                 |    4       |    8     |
| x4             |          4                 |    8       |    16    |
| x8             |          8                 |    16      |    32    |
| x16            |          16                |    32      |    64    |
| x32            |          32                |    64      |    128   |
| x64            |          64                |    128     |    NA    |
| x128           |          128               |    NA      |    NA    |
|=====================================================================|
</code></pre><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  nvvm<span class=p>.</span>tcgen05<span class=p>.</span>ld <span class=nv>%tmemAddr</span><span class=p>,</span> <span class=nv>%offset</span> pack <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nl>shape =</span> <span class=nv>#nvvm.tcgen05_ldst_shape</span><span class=p>&lt;</span>shape_16x32bx2<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span> <span class=p>:</span> <span class=p>&lt;</span><span class=m>2x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instructions-tcgen05-st>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101></code></p><h4 id=attributes-93>Attributes:&nbsp;<a class=headline-hash href=#attributes-93>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>pack</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::Tcgen05LdStShapeAttr</td><td>allowed 32-bit signless integer cases: 0, 1, 2, 3, 4</td></tr></table><h4 id=operands-67>Operands:&nbsp;<a class=headline-hash href=#operands-67>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tmemAddr</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>offset</code></td><td>64-bit signless integer</td></tr></tbody></table><h4 id=results-108>Results:&nbsp;<a class=headline-hash href=#results-108>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer or vector of 32-bit signless integer values of length 2/4/8/16/32/64/128</td></tr></tbody></table><h3 id=nvvmtcgen05mmablock_scale-nvvmtcgen05mmablockscaleop><code>nvvm.tcgen05.mma.block_scale</code> (NVVM::Tcgen05MMABlockScaleOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05mmablock_scale-nvvmtcgen05mmablockscaleop>¶</a></h3><p><em>Performs block scaled MMA operation on 5th-gen tensor cores</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.mma.block_scale` $matrixD `,` $matrixA `,` $matrixB `,` $idesc `,` $enableInputD `,` $scaleA `,` $scaleB
              attr-dict `:` `(` type(operands) `)`
</code></pre><p>The <code>tcgen05.mma.block_scale</code> operation is an asynchronous tensor core instruction
that performs matrix multiplication, accumulation with block scaling in a
single fused operation. It targets 5th-generation tensor cores, providing
developers with fine-grained control over execution and scheduling.</p><pre tabindex=0><code>D = (A * scale_a)  * (B * scale_b)`      // if `enableInputD` is false
D = (A * scale_a)  * (B * scale_b) + D`
</code></pre><p>where:</p><ul><li>A is an M x (K / 2) matrix in tensor memory or described using shared memory descriptor</li><li>B is a K x N matrix described using shared memory descriptor</li><li>D is an M x N accumulator matrix in tensor memory</li><li><code>scale_a</code> and <code>scale_b</code> are matrices in tensor memory used to scale <code>A</code> and <code>B</code> respectively</li></ul><p>The <code>shared memory descriptor</code> can be generated using <code>tcgen05.mma_smem_desc</code> Op</p><ul><li><code>idesc</code> is a 32 bit value representing the
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instruction-descriptor>Instruction Descriptor</a></li></ul><p>Required Attributes:</p><ul><li><p><code>kind</code> is a MMABlockScaleKind attribute</p></li><li><p><code>ctaGroup</code> specifies CTA group configuration</p><ul><li>cta_1: MMA will be performed on the current thread&rsquo;s CTA</li><li>cta_2: MMA will be performed on the current thread and it&rsquo;s peer CTA</li></ul></li></ul><p>Default Attributes:</p><ul><li>collectorOp is a Tcgen05MMACollectorOp attribute with matrix A as the collector buffer</li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-mma-instructions-mma>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,110></code></p><h4 id=attributes-94>Attributes:&nbsp;<a class=headline-hash href=#attributes-94>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::MMABlockScaleKindAttr</td><td><details><summary>Block Scale Kind</summary><pre><code>The MMABlockScaleKind attribute describes the allowed set of types for matrix A and B in the *.mma.{sp}.block_scale Op. The following are supported types for each kind:
<pre tabindex=0><code>+--------------+-------------------------------------------+
| Matrix Kind  |      supported types for A / B            |
+--------------+-------------------------------------------+
| mxf8f6f4     | e4m3, e5m2, e2m3, e3m2, e2m1              |
| mxf4         | e2m1                                      |
| mxf4nvf4     | e2m1                                      |
+--------------+-------------------------------------------+
</code></pre><p></code></pre></p></details></td></tr><tr><td><code>ctaGroup</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr><tr><td><code>blockScale</code></td><td>::mlir::NVVM::Tcgen05MMABlockScaleAttr</td><td>tcgen05.mma block scale attribute</td></tr><tr><td><code>collectorOp</code></td><td>::mlir::NVVM::Tcgen05MMACollectorOpAttr</td><td><details><summary>tcgen05.mma Collector Buffer Operation</summary><pre><code>Tcgen05MMACollectorOp attribute specifies the collector buffer operations.
The following are the supported operations:
  * discard : Release buffer after use (default)
  * lastuse : Mark buffer for last use
  * fill    : Fill buffer
  * use     : Use buffer without modification
</code></pre></details></td></tr></table><h4 id=operands-68>Operands:&nbsp;<a class=headline-hash href=#operands-68>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>matrixD</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>matrixA</code></td><td>LLVM pointer in address space 6 or 64-bit signless integer</td></tr><tr><td style=text-align:center><code>matrixB</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>idesc</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>enableInputD</code></td><td>1-bit signless integer</td></tr><tr><td style=text-align:center><code>scaleA</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>scaleB</code></td><td>LLVM pointer in address space 6</td></tr></tbody></table><h3 id=nvvmtcgen05mma-nvvmtcgen05mmaop><code>nvvm.tcgen05.mma</code> (NVVM::Tcgen05MMAOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05mma-nvvmtcgen05mmaop>¶</a></h3><p><em>Performs MMA operation on 5th-gen tensor cores</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.mma` $matrixD `,` $matrixA `,` $matrixB `,` $idesc `,` $enableInputD (`scale` `=` $scaleInputD^)?
              (`mask` `=` $disableOutputLane^)? attr-dict `:` `(` type(operands) `)`
</code></pre><p>The <code>tcgen05.mma</code> operation is an asynchronous tensor core instruction that
performs matrix multiplication, accumulation in a single fused operation. It
targets 5th-generation tensor cores, providing developers with fine-grained
control over execution and scheduling.</p><pre tabindex=0><code>D = A * B + (D * 2^ -scaleInputD)    // if `scaleInputD` is provided
D = A * B                            // if `enableInputD` is false
D = A * B + D                        // otherwise
</code></pre><p>where:</p><ul><li>A is an <code>M x K</code> matrix in tensor memory or described using shared memory descriptor</li><li>B is a <code>K x N</code> matrix described using shared memory descriptor</li><li>D is an <code>M x N</code> accumulator matrix in tensor memory</li></ul><p>The <code>shared memory descriptor</code> can be generated using <code>tcgen05.mma_smem_desc</code> Op</p><ul><li>idesc is a 32-bit value representing the
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instruction-descriptor>Instruction Descriptor</a></li></ul><p>Optional Operands:</p><ul><li><p><code>scaleInputD</code> is an Immediate value operand used for scaling D matrix by 2 ^ (-scaleInputD). The valid range is [0, 15]</p></li><li><p><code>disableOutputLane</code> is a vector mask for selective output</p><ul><li>vector&lt;4 x i32> when ctaGroup is CTA_1</li><li>vector&lt;8 x i32> when ctaGroup is CTA_2</li></ul></li></ul><p>Required Attributes:</p><ul><li><p><code>kind</code> is a Tcgen05MMAKind attribute</p></li><li><p><code>ctaGroup</code> specifies CTA group configuration</p><ul><li>cta_1: MMA will be performed on the current thread&rsquo;s CTA</li><li>cta_2: MMA will be performed on the current thread and it&rsquo;s peer CTA</li></ul></li></ul><p>Default Attributes:</p><ul><li><p>collectorOp is a Tcgen05MMACollectorOp attribute with matrix A as the collector buffer</p></li><li><p><code>aShift</code> shifts the rows of the A matrix down by one row and can only be
applied if A is in tensor memory</p></li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-mma-instructions-mma>For more information, see PTX ISA</a></p><p>Traits: <code>AttrSizedOperandSegments</code>, <code>NVVMRequiresSMa&lt;100,110></code></p><h4 id=attributes-95>Attributes:&nbsp;<a class=headline-hash href=#attributes-95>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::Tcgen05MMAKindAttr</td><td><details><summary>tcgen05 MMA Supported Types</summary><pre><code>The Tcgen05MMAKind attribute describes the allowed set of types for matrix A and B in the tcgen05.mma.{sp} Op. The following are supported types for each kind:
<pre tabindex=0><code>+-------------+--------------------------------------------+
| Matrix Kind |      supported types for A / B             |
+-------------+--------------------------------------------+
| f16         | f16, bf16                                  |
| tf32        | tf32                                       |
| f8f6f4      | e4m3, e5m2, e2m3, e3m2, e2m1               |
| i8          | unsigned 8b, signed 8b                     |
+-------------+--------------------------------------------+
</code></pre><p></code></pre></p></details></td></tr><tr><td><code>ctaGroup</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr><tr><td><code>collectorOp</code></td><td>::mlir::NVVM::Tcgen05MMACollectorOpAttr</td><td><details><summary>tcgen05.mma Collector Buffer Operation</summary><pre><code>Tcgen05MMACollectorOp attribute specifies the collector buffer operations.
The following are the supported operations:
  * discard : Release buffer after use (default)
  * lastuse : Mark buffer for last use
  * fill    : Fill buffer
  * use     : Use buffer without modification
</code></pre></details></td></tr><tr><td><code>aShift</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h4 id=operands-69>Operands:&nbsp;<a class=headline-hash href=#operands-69>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>matrixD</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>matrixA</code></td><td>LLVM pointer in address space 6 or 64-bit signless integer</td></tr><tr><td style=text-align:center><code>matrixB</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>idesc</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>enableInputD</code></td><td>1-bit signless integer</td></tr><tr><td style=text-align:center><code>scaleInputD</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>disableOutputLane</code></td><td>fixed-length vector of 32-bit signless integer values of length 4/8</td></tr></tbody></table><h3 id=nvvmtcgen05mmaspblock_scale-nvvmtcgen05mmasparseblockscaleop><code>nvvm.tcgen05.mma.sp.block_scale</code> (NVVM::Tcgen05MMASparseBlockScaleOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05mmaspblock_scale-nvvmtcgen05mmasparseblockscaleop>¶</a></h3><p><em>Performs block scaled MMA operation with sparse A matrix on 5th-gen tensor cores</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.mma.sp.block_scale` $matrixD `,` $matrixA `,` $matrixB `,` $idesc `,` $enableInputD `,` $sparseMetadata `,`  $scaleA `,`  $scaleB
              attr-dict `:` `(` type(operands) `)`
</code></pre><p>The <code>tcgen05.mma.sp.block_scale</code> operation is an asynchronous tensor core
instruction that performs matrix multiplication, accumulation with block
scaling, and sparse <code>A</code> matrix in a single fused operation. It targets
5th-generation tensor cores, providing developers with fine-grained control
over execution, and scheduling.</p><pre tabindex=0><code>D = (A * scale_a)  * (B * scale_b)      // if `enableInputD` is specified
D = (A * scale_a)  * (B * scale_b) + D  // otherwise
</code></pre><p>where:</p><ul><li>A is an M x (K / 2) matrix in tensor memory or described using shared memory descriptor</li><li>B is a K x N matrix described using shared memory descriptor</li><li>D is an M x N accumulator matrix in tensor memory</li><li><code>scale_a</code> and <code>scale_b</code> are matrices in tensor memory used to scale <code>A</code> and <code>B</code> respectively</li></ul><p>Other attributes and operands are similar to that of tcgen05.mma.block_scale Op</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-mma-instructions-mma-sp>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,110></code></p><h4 id=attributes-96>Attributes:&nbsp;<a class=headline-hash href=#attributes-96>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::MMABlockScaleKindAttr</td><td><details><summary>Block Scale Kind</summary><pre><code>The MMABlockScaleKind attribute describes the allowed set of types for matrix A and B in the *.mma.{sp}.block_scale Op. The following are supported types for each kind:
<pre tabindex=0><code>+--------------+-------------------------------------------+
| Matrix Kind  |      supported types for A / B            |
+--------------+-------------------------------------------+
| mxf8f6f4     | e4m3, e5m2, e2m3, e3m2, e2m1              |
| mxf4         | e2m1                                      |
| mxf4nvf4     | e2m1                                      |
+--------------+-------------------------------------------+
</code></pre><p></code></pre></p></details></td></tr><tr><td><code>ctaGroup</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr><tr><td><code>blockScale</code></td><td>::mlir::NVVM::Tcgen05MMABlockScaleAttr</td><td>tcgen05.mma block scale attribute</td></tr><tr><td><code>collectorOp</code></td><td>::mlir::NVVM::Tcgen05MMACollectorOpAttr</td><td><details><summary>tcgen05.mma Collector Buffer Operation</summary><pre><code>Tcgen05MMACollectorOp attribute specifies the collector buffer operations.
The following are the supported operations:
  * discard : Release buffer after use (default)
  * lastuse : Mark buffer for last use
  * fill    : Fill buffer
  * use     : Use buffer without modification
</code></pre></details></td></tr></table><h4 id=operands-70>Operands:&nbsp;<a class=headline-hash href=#operands-70>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>matrixD</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>matrixA</code></td><td>LLVM pointer in address space 6 or 64-bit signless integer</td></tr><tr><td style=text-align:center><code>matrixB</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>idesc</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>enableInputD</code></td><td>1-bit signless integer</td></tr><tr><td style=text-align:center><code>sparseMetadata</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>scaleA</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>scaleB</code></td><td>LLVM pointer in address space 6</td></tr></tbody></table><h3 id=nvvmtcgen05mmasp-nvvmtcgen05mmasparseop><code>nvvm.tcgen05.mma.sp</code> (NVVM::Tcgen05MMASparseOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05mmasp-nvvmtcgen05mmasparseop>¶</a></h3><p><em>Performs MMA operation with sparse A matrix on 5th-gen tensor cores</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.mma.sp` $matrixD `,` $matrixA `,` $matrixB `,` $idesc `,` $enableInputD `,` $sparseMetadata (`scale` `=` $scaleInputD^)? (`mask` `=` $disableOutputLane^)? attr-dict `:` `(` type(operands) `)`
</code></pre><p>The <code>tcgen05.mma.sp</code> operation is an asynchronous tensor core instruction
that performs matrix multiplication, accumulation with sparse <code>A</code> matrix in
a single fused operation. It targets 5th-generation tensor cores, providing
developers with fine-grained control over execution and scheduling.</p><pre tabindex=0><code>D = A * B + (D * 2^ -scaleInputD)    // if `scaleInputD` is provided
D = A * B                            // if `enableInputD` is false
D = A * B + D                        // otherwise
</code></pre><p>where:</p><ul><li>A is an <code>M x (K / 2)</code> matrix in tensor memory or described using shared memory descriptor</li><li>B is a <code>K x N</code> matrix described using shared memory descriptor</li><li>D is an <code>M x N</code> accumulator matrix in tensor memory</li><li>sparseMetadata located in tensor memory specifies the mapping of the <code>K / 2</code>
non-zero elements to the K elements before performing the MMA operation</li></ul><p>Other attributes and operands are similar to that of tcgen05.mma Op</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-mma-instructions-mma-sp>For more information, see PTX ISA</a></p><p>Traits: <code>AttrSizedOperandSegments</code>, <code>NVVMRequiresSMa&lt;100,110></code></p><h4 id=attributes-97>Attributes:&nbsp;<a class=headline-hash href=#attributes-97>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::Tcgen05MMAKindAttr</td><td><details><summary>tcgen05 MMA Supported Types</summary><pre><code>The Tcgen05MMAKind attribute describes the allowed set of types for matrix A and B in the tcgen05.mma.{sp} Op. The following are supported types for each kind:
<pre tabindex=0><code>+-------------+--------------------------------------------+
| Matrix Kind |      supported types for A / B             |
+-------------+--------------------------------------------+
| f16         | f16, bf16                                  |
| tf32        | tf32                                       |
| f8f6f4      | e4m3, e5m2, e2m3, e3m2, e2m1               |
| i8          | unsigned 8b, signed 8b                     |
+-------------+--------------------------------------------+
</code></pre><p></code></pre></p></details></td></tr><tr><td><code>ctaGroup</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr><tr><td><code>collectorOp</code></td><td>::mlir::NVVM::Tcgen05MMACollectorOpAttr</td><td><details><summary>tcgen05.mma Collector Buffer Operation</summary><pre><code>Tcgen05MMACollectorOp attribute specifies the collector buffer operations.
The following are the supported operations:
  * discard : Release buffer after use (default)
  * lastuse : Mark buffer for last use
  * fill    : Fill buffer
  * use     : Use buffer without modification
</code></pre></details></td></tr><tr><td><code>aShift</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr></table><h4 id=operands-71>Operands:&nbsp;<a class=headline-hash href=#operands-71>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>matrixD</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>matrixA</code></td><td>LLVM pointer in address space 6 or 64-bit signless integer</td></tr><tr><td style=text-align:center><code>matrixB</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>idesc</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>enableInputD</code></td><td>1-bit signless integer</td></tr><tr><td style=text-align:center><code>sparseMetadata</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>scaleInputD</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>disableOutputLane</code></td><td>fixed-length vector of 32-bit signless integer values of length 4/8</td></tr></tbody></table><h3 id=nvvmtcgen05mmaws-nvvmtcgen05mmawsop><code>nvvm.tcgen05.mma.ws</code> (NVVM::Tcgen05MMAWsOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05mmaws-nvvmtcgen05mmawsop>¶</a></h3><p><em>Performs weight stationary convolution MMA operation on 5th-gen tensor cores</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.mma.ws` $matrixD `,` $matrixA `,` $matrixB `,` $idesc `,` $enableInputD (`,` $zeroColMask^)?
              attr-dict `:` `(` type(operands) `)`
</code></pre><p>The <code>tcgen05.mma.ws</code> operation is an asynchronous tensor core instruction
that performs weight stationary convolution matrix multiplication, accumulation
in a single fused operation. It targets 5th-generation tensor cores, providing
developers with fine-grained control over execution, and scheduling.</p><pre tabindex=0><code>D = A * B`      // if `enableInputD` is false
D = A * B + D`  // otherwise
</code></pre><p>where:</p><ul><li>A is an <code>M x K</code> matrix in tensor memory or described using shared memory descriptor</li><li>B is a <code>K x N</code> matrix described using shared memory descriptor</li><li>D is an <code>M x N</code> accumulator matrix in tensor memory</li></ul><p>The <code>shared memory descriptor</code> can be generated using <code>tcgen05.mma_smem_desc</code> Op</p><ul><li>idesc is a 32-bit value representing the
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instruction-descriptor>Instruction Descriptor</a></li></ul><p>Optional Operands:</p><ul><li>zeroColMask is a 64 bit value representing the
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-zero-column-mask-descriptor>Zero-column mask descriptor</a></li></ul><p>Required Attributes:</p><ul><li><code>kind</code> is a Tcgen05MMAKind attribute</li></ul><p>Default Valued Attributes:</p><ul><li><p>collectorBBuffer specifies collector buffer for matrix B: b0 (default), b1, b2, b3</p></li><li><p>collectorOp is a Tcgen05MMACollectorOp attribute with matrix B as the collector buffer</p></li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-mma-instructions-mma-ws>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,110></code></p><h4 id=attributes-98>Attributes:&nbsp;<a class=headline-hash href=#attributes-98>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::Tcgen05MMAKindAttr</td><td><details><summary>tcgen05 MMA Supported Types</summary><pre><code>The Tcgen05MMAKind attribute describes the allowed set of types for matrix A and B in the tcgen05.mma.{sp} Op. The following are supported types for each kind:
<pre tabindex=0><code>+-------------+--------------------------------------------+
| Matrix Kind |      supported types for A / B             |
+-------------+--------------------------------------------+
| f16         | f16, bf16                                  |
| tf32        | tf32                                       |
| f8f6f4      | e4m3, e5m2, e2m3, e3m2, e2m1               |
| i8          | unsigned 8b, signed 8b                     |
+-------------+--------------------------------------------+
</code></pre><p></code></pre></p></details></td></tr><tr><td><code>collectorBBuffer</code></td><td>::mlir::NVVM::Tcgen05MMACollectorBBufferAttr</td><td>tcgen05 MMA Collector Buffer B Attribute</td></tr><tr><td><code>collectorOp</code></td><td>::mlir::NVVM::Tcgen05MMACollectorOpAttr</td><td><details><summary>tcgen05.mma Collector Buffer Operation</summary><pre><code>Tcgen05MMACollectorOp attribute specifies the collector buffer operations.
The following are the supported operations:
  * discard : Release buffer after use (default)
  * lastuse : Mark buffer for last use
  * fill    : Fill buffer
  * use     : Use buffer without modification
</code></pre></details></td></tr></table><h4 id=operands-72>Operands:&nbsp;<a class=headline-hash href=#operands-72>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>matrixD</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>matrixA</code></td><td>LLVM pointer in address space 6 or 64-bit signless integer</td></tr><tr><td style=text-align:center><code>matrixB</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>idesc</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>enableInputD</code></td><td>1-bit signless integer</td></tr><tr><td style=text-align:center><code>zeroColMask</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmtcgen05mmawssp-nvvmtcgen05mmawssparseop><code>nvvm.tcgen05.mma.ws.sp</code> (NVVM::Tcgen05MMAWsSparseOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05mmawssp-nvvmtcgen05mmawssparseop>¶</a></h3><p><em>Performs weight stationary convolution MMA with sparse A matrix on 5th-gen tensor cores</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.mma.ws.sp` $matrixD `,` $matrixA `,` $matrixB `,` $idesc `,` $enableInputD `,` $sparseMetadata (`,` $zeroColMask^)? attr-dict `:` `(` type(operands) `)`
</code></pre><p>The <code>tcgen05.mma.ws.sp</code> operation is an asynchronous tensor core instruction
that performs weight stationary convolution matrix multiplication, accumulation
with sparse <code>A</code> matrix in a single fused operation. It targets 5th-generation
tensor cores, providing developers with fine-grained control over execution,
and scheduling.</p><pre tabindex=0><code>D = A * B`      // if `enableInputD` is false
D = A * B + D`  // otherwise
</code></pre><p>where:</p><ul><li>A is an M x (K / 2) matrix in memory or descriptor format</li><li>B is a K x N matrix</li><li>D is an M x N accumulator matrix</li><li>sparseMetadata located in tensor memory specifies the mapping of the <code>K / 2</code>
non-zero elements to the K elements before performing the MMA operation</li></ul><p>Other attributes and operands are similar to that of tcgen05.mma.ws Op</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-mma-instructions-mma-ws-sp>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,110></code></p><h4 id=attributes-99>Attributes:&nbsp;<a class=headline-hash href=#attributes-99>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::Tcgen05MMAKindAttr</td><td><details><summary>tcgen05 MMA Supported Types</summary><pre><code>The Tcgen05MMAKind attribute describes the allowed set of types for matrix A and B in the tcgen05.mma.{sp} Op. The following are supported types for each kind:
<pre tabindex=0><code>+-------------+--------------------------------------------+
| Matrix Kind |      supported types for A / B             |
+-------------+--------------------------------------------+
| f16         | f16, bf16                                  |
| tf32        | tf32                                       |
| f8f6f4      | e4m3, e5m2, e2m3, e3m2, e2m1               |
| i8          | unsigned 8b, signed 8b                     |
+-------------+--------------------------------------------+
</code></pre><p></code></pre></p></details></td></tr><tr><td><code>collectorBBuffer</code></td><td>::mlir::NVVM::Tcgen05MMACollectorBBufferAttr</td><td>tcgen05 MMA Collector Buffer B Attribute</td></tr><tr><td><code>collectorOp</code></td><td>::mlir::NVVM::Tcgen05MMACollectorOpAttr</td><td><details><summary>tcgen05.mma Collector Buffer Operation</summary><pre><code>Tcgen05MMACollectorOp attribute specifies the collector buffer operations.
The following are the supported operations:
  * discard : Release buffer after use (default)
  * lastuse : Mark buffer for last use
  * fill    : Fill buffer
  * use     : Use buffer without modification
</code></pre></details></td></tr></table><h4 id=operands-73>Operands:&nbsp;<a class=headline-hash href=#operands-73>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>matrixD</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>matrixA</code></td><td>LLVM pointer in address space 6 or 64-bit signless integer</td></tr><tr><td style=text-align:center><code>matrixB</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>idesc</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>enableInputD</code></td><td>1-bit signless integer</td></tr><tr><td style=text-align:center><code>sparseMetadata</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>zeroColMask</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmtcgen05mma_smem_desc-nvvmtcgen05mmasmemdescop><code>nvvm.tcgen05.mma_smem_desc</code> (NVVM::Tcgen05MmaSmemDescOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05mma_smem_desc-nvvmtcgen05mmasmemdescop>¶</a></h3><p><em>Constructs a Shared Memory descriptor for MMA Operands A or B</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.mma_smem_desc` `(` operands `)` attr-dict `:` `(` type(operands) `)` `-&gt;` type($res)
</code></pre><p>The <code>nvvm.tcgen05_mma_smem_desc</code> constructs a Shared Memory descriptor
for tcgen05.mma. This descriptor is a 64-bit value which describes the
properties of multiplicand matrix in shared memory including its location
in the shared memory of the current CTA.</p><pre tabindex=0><code>+-----------+------+------------------------------------------------------+
| Bit-field | Size | Description                                          |
+-----------+------+------------------------------------------------------+
| 0-13      | 14   | Matrix start address                                 |
| 14-15     | 2    | Reserved                                             |
| 16-29     | 14   | Leading dim relative-offset (or) absolute-address    |
| 30-31     | 2    | Reserved                                             |
| 32-45     | 14   | Stride dimension byte offset                         |
| 46-48     | 3    | Fixed constant value of 0b001                        |
| 49-51     | 3    | Matrix base offset                                   |
| 52        | 1    | Leading dimension stride mode:                       |
|           |      |   0: byte offset relative                            |
|           |      |   1: byte address absolute                           |
| 53-60     | 8    | Fixed constant value of 0xb00000000                  |
| 61-63     | 3    | Swizzling mode:                                      |
|           |      |   0: No swizzling                                    |
|           |      |   1: 128-Byte with 32B atomic swizzling              |
|           |      |   2: 128-Byte swizzling                              |
|           |      |   4: 64-Byte swizzling                               |
|           |      |   6: 32-Byte swizzling                               |
|           |      |   (Values 3, 5 and 7 are invalid)                    |
+-----------+------+------------------------------------------------------+    
</code></pre><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  <span class=nv>%desc</span> <span class=p>=</span> nvvm<span class=p>.</span>tcgen05<span class=p>.</span>mma_smem_desc <span class=p>(</span><span class=nv>%startAddr</span><span class=p>,</span> <span class=nv>%leadingDimOffset</span><span class=p>,</span> <span class=nv>%strideDimOffset</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                      <span class=nv>%baseOffset</span><span class=p>,</span> <span class=nv>%leadingDimMode</span><span class=p>,</span> <span class=nv>%swizzleMode</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>i32</span><span class=p>,</span> <span class=k>i32</span><span class=p>,</span> <span class=k>i32</span><span class=p>,</span> <span class=k>i8</span><span class=p>,</span> <span class=k>i1</span><span class=p>,</span> <span class=k>i8</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>i64</span>
</span></span></code></pre></div><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-shared-memory-descriptor>For more information, see PTX ISA</a></p><h4 id=operands-74>Operands:&nbsp;<a class=headline-hash href=#operands-74>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>startAddr</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>leadingDimOffset</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>strideDimOffset</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>baseOffset</code></td><td>8-bit signless integer</td></tr><tr><td style=text-align:center><code>leadingDimMode</code></td><td>1-bit signless integer</td></tr><tr><td style=text-align:center><code>swizzleMode</code></td><td>8-bit signless integer</td></tr></tbody></table><h4 id=results-109>Results:&nbsp;<a class=headline-hash href=#results-109>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmtcgen05relinquish_alloc_permit-nvvmtcgen05relinquishallocpermitop><code>nvvm.tcgen05.relinquish_alloc_permit</code> (NVVM::Tcgen05RelinquishAllocPermitOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05relinquish_alloc_permit-nvvmtcgen05relinquishallocpermitop>¶</a></h3><p><em>Tcgen05 Op to relinquish the right to allocate</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.relinquish_alloc_permit` attr-dict
</code></pre><p>The <code>tcgen05.relinquish_alloc_permit</code> Op specifies that the CTA
of the executing thread is relinquishing the right to allocate
Tensor Memory. So, it is illegal for a CTA to perform <code>tcgen05.alloc</code>
after any of its constituent threads execute <code>tcgen05.relinquish_alloc_permit</code>.
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-memory-alloc-manage-instructions>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101></code></p><h4 id=attributes-100>Attributes:&nbsp;<a class=headline-hash href=#attributes-100>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>group</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr></table><h3 id=nvvmtcgen05shift-nvvmtcgen05shiftop><code>nvvm.tcgen05.shift</code> (NVVM::Tcgen05ShiftOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05shift-nvvmtcgen05shiftop>¶</a></h3><p><em>Tcgen05 shift operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.shift` $taddr attr-dict `:` type(operands)
</code></pre><p>The <code>tcgen05.shift</code> is an asynchronous instruction which initiates
the shifting of 32-byte elements downwards across all the rows,
except the last, by one row. The operand <code>taddr</code> specifies the base
address of the matrix in Tensor Memory whose rows must be down shifted.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instructions-tcgen05-shift>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101,103></code></p><h4 id=attributes-101>Attributes:&nbsp;<a class=headline-hash href=#attributes-101>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>group</code></td><td>::mlir::NVVM::CTAGroupKindAttr</td><td>NVVM CTA group kind</td></tr></table><h4 id=operands-75>Operands:&nbsp;<a class=headline-hash href=#operands-75>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>taddr</code></td><td>LLVM pointer in address space 6</td></tr></tbody></table><h3 id=nvvmtcgen05st-nvvmtcgen05stop><code>nvvm.tcgen05.st</code> (NVVM::Tcgen05StOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05st-nvvmtcgen05stop>¶</a></h3><p><em>Tensor memory store instructions</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.st` $tmemAddr `,` $val (`,` $offset^)? (`unpack` $unpack^)? attr-dict `:` type($val)
</code></pre><p>Instruction <code>tcgen05.st</code> asynchronously stores data from the source register <code>r</code>
into the Tensor Memory at the location specified by the 32-bit address operand
<code>tmemAddr</code>, collectively across all threads of the warps.</p><p>The <code>shape</code> and the <code>num</code> attribute together determines the total dimension of
the data which is stored to the Tensor Memory. The <code>shape</code> indicates the base
dimension of data to be accessed. The <code>num</code> attribute indicates the repeat
factor on the base dimension resulting in the total dimension of the data that
is accessed.</p><p>The shape <code>16x32bx2</code> performs two accesses into Tensor Memory of the shape
<code>16x32b</code>. The base address of the first access is specified by <code>tmemAddr</code>
and the base address of the second access is specified by
<code>tmemAddr + offset</code>, where <code>offset</code> is an immediate argument.</p><p>The unit attribute <code>unpack</code> can be used to unpack a 32-bit element
in the register into two 16-bit elements and store them in adjacent columns.</p><p>The following table describes the size of the vector for various combinations
of <code>num</code> and <code>shape</code> attributes:</p><pre tabindex=0><code>|=====================================================================|
| num/shape      |     16x32bx2/16x64b/32x32b |  16x128b   | 16x256b  |
|=====================================================================|
| x1             |          1                 |    2       |    4     |
| x2             |          2                 |    4       |    8     |
| x4             |          4                 |    8       |    16    |
| x8             |          8                 |    16      |    32    |
| x16            |          16                |    32      |    64    |
| x32            |          32                |    64      |    128   |
| x64            |          64                |    128     |    NA    |
| x128           |          128               |    NA      |    NA    |
|=====================================================================|
</code></pre><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl>  nvvm<span class=p>.</span>tcgen05<span class=p>.</span>st <span class=nv>%tmemAddr</span><span class=p>,</span> <span class=nv>%val</span><span class=p>,</span> <span class=nv>%offset</span> unpack <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nl>shape =</span> <span class=nv>#nvvm.tcgen05_ldst_shape</span><span class=p>&lt;</span>shape_16x32bx2<span class=p>&gt;,</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span> <span class=p>:</span> <span class=p>&lt;</span><span class=m>2x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instructions-tcgen05-st>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101></code></p><h4 id=attributes-102>Attributes:&nbsp;<a class=headline-hash href=#attributes-102>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>unpack</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::Tcgen05LdStShapeAttr</td><td>allowed 32-bit signless integer cases: 0, 1, 2, 3, 4</td></tr></table><h4 id=operands-76>Operands:&nbsp;<a class=headline-hash href=#operands-76>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>tmemAddr</code></td><td>LLVM pointer in address space 6</td></tr><tr><td style=text-align:center><code>val</code></td><td>32-bit signless integer or vector of 32-bit signless integer values of length 2/4/8/16/32/64/128</td></tr><tr><td style=text-align:center><code>offset</code></td><td>64-bit signless integer</td></tr></tbody></table><h3 id=nvvmtcgen05wait-nvvmtcgen05waitop><code>nvvm.tcgen05.wait</code> (NVVM::Tcgen05WaitOp)&nbsp;<a class=headline-hash href=#nvvmtcgen05wait-nvvmtcgen05waitop>¶</a></h3><p><em>Tcgen05 wait operations</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.tcgen05.wait` $kind attr-dict
</code></pre><p>The <code>tcgen05.wait&lt;load></code> causes the executing thread to block until
all prior <code>tcgen05.ld</code> operations issued by the executing thread
have completed. Similarly, the <code>tcgen05.wait&lt;store></code> causes the executing
thread to block until all prior <code>tcgen05.st</code> operations issued by the
executing thread have completed.
<a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instructions-tcgen05-wait>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;100,101></code></p><h4 id=attributes-103>Attributes:&nbsp;<a class=headline-hash href=#attributes-103>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::Tcgen05WaitKindAttr</td><td>NVVM Tcgen05 wait kind</td></tr></table><h3 id=nvvmreadptxsregtidx-nvvmthreadidxop><code>nvvm.read.ptx.sreg.tid.x</code> (NVVM::ThreadIdXOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregtidx-nvvmthreadidxop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.tid.x` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-104>Attributes:&nbsp;<a class=headline-hash href=#attributes-104>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-110>Results:&nbsp;<a class=headline-hash href=#results-110>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregtidy-nvvmthreadidyop><code>nvvm.read.ptx.sreg.tid.y</code> (NVVM::ThreadIdYOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregtidy-nvvmthreadidyop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.tid.y` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-105>Attributes:&nbsp;<a class=headline-hash href=#attributes-105>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-111>Results:&nbsp;<a class=headline-hash href=#results-111>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregtidz-nvvmthreadidzop><code>nvvm.read.ptx.sreg.tid.z</code> (NVVM::ThreadIdZOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregtidz-nvvmthreadidzop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.tid.z` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-106>Attributes:&nbsp;<a class=headline-hash href=#attributes-106>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-112>Results:&nbsp;<a class=headline-hash href=#results-112>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmvotesync-nvvmvotesyncop><code>nvvm.vote.sync</code> (NVVM::VoteSyncOp)&nbsp;<a class=headline-hash href=#nvvmvotesync-nvvmvotesyncop>¶</a></h3><p><em>Vote across thread group</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.vote.sync` $kind $mask `,` $pred attr-dict `-&gt;` type($res)
</code></pre><p>The <code>vote.sync</code> op will cause executing thread to wait until all non-exited
threads corresponding to membermask have executed <code>vote.sync</code> with the same
qualifiers and same membermask value before resuming execution.</p><p>The vote operation kinds are:</p><ul><li><code>any</code>: True if source predicate is True for some thread in membermask.</li><li><code>all</code>: True if source predicate is True for all non-exited threads in
membermask.</li><li><code>uni</code>: True if source predicate has the same value in all non-exited
threads in membermask.</li><li><code>ballot</code>: In the ballot form, the destination result is a 32 bit integer.
In this form, the predicate from each thread in membermask are copied into
the corresponding bit position of the result, where the bit position
corresponds to the thread&rsquo;s lane id.</li></ul><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-vote-sync>For more information, see PTX ISA</a></p><h4 id=attributes-107>Attributes:&nbsp;<a class=headline-hash href=#attributes-107>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::NVVM::VoteSyncKindAttr</td><td>NVVM vote sync kind</td></tr></table><h4 id=operands-77>Operands:&nbsp;<a class=headline-hash href=#operands-77>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>mask</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>pred</code></td><td>1-bit signless integer</td></tr></tbody></table><h4 id=results-113>Results:&nbsp;<a class=headline-hash href=#results-113>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>32-bit signless integer or 1-bit signless integer</td></tr></tbody></table><h3 id=nvvmwmmaload-nvvmwmmaloadop><code>nvvm.wmma.load</code> (NVVM::WMMALoadOp)&nbsp;<a class=headline-hash href=#nvvmwmmaload-nvvmwmmaloadop>¶</a></h3><p><em>Warp synchronous matrix load</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.wmma.load` $ptr `,` $stride attr-dict `:` functional-type($ptr, $res)
</code></pre><h4 id=attributes-108>Attributes:&nbsp;<a class=headline-hash href=#attributes-108>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>m</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>n</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>k</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>layout</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>eltype</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr><tr><td><code>frag</code></td><td>::mlir::NVVM::MMAFragAttr</td><td>NVVM MMA frag type</td></tr></table><h4 id=operands-78>Operands:&nbsp;<a class=headline-hash href=#operands-78>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>ptr</code></td><td>LLVM pointer type</td></tr><tr><td style=text-align:center><code>stride</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-114>Results:&nbsp;<a class=headline-hash href=#results-114>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM structure type or 64-bit float</td></tr></tbody></table><h3 id=nvvmwmmamma-nvvmwmmammaop><code>nvvm.wmma.mma</code> (NVVM::WMMAMmaOp)&nbsp;<a class=headline-hash href=#nvvmwmmamma-nvvmwmmammaop>¶</a></h3><p><em>Warp synchronous matrix-multiply accumulate using tensor cores.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.wmma.mma` $args attr-dict `:` functional-type($args, $res)
</code></pre><h4 id=attributes-109>Attributes:&nbsp;<a class=headline-hash href=#attributes-109>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>m</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>n</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>k</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>layoutA</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>layoutB</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>eltypeA</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr><tr><td><code>eltypeB</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr></table><h4 id=operands-79>Operands:&nbsp;<a class=headline-hash href=#operands-79>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>args</code></td><td>variadic of LLVM dialect-compatible type</td></tr></tbody></table><h4 id=results-115>Results:&nbsp;<a class=headline-hash href=#results-115>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM structure type</td></tr></tbody></table><h3 id=nvvmwmmastore-nvvmwmmastoreop><code>nvvm.wmma.store</code> (NVVM::WMMAStoreOp)&nbsp;<a class=headline-hash href=#nvvmwmmastore-nvvmwmmastoreop>¶</a></h3><p><em>Warp synchronous matrix store</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.wmma.store` $ptr `,` $stride `,` $args attr-dict `:` qualified(type($ptr)) `,`
              type($args)
</code></pre><h4 id=attributes-110>Attributes:&nbsp;<a class=headline-hash href=#attributes-110>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>m</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>n</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>k</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr><tr><td><code>layout</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>eltype</code></td><td>::mlir::NVVM::MMATypesAttr</td><td>NVVM MMA types</td></tr></table><h4 id=operands-80>Operands:&nbsp;<a class=headline-hash href=#operands-80>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>ptr</code></td><td>LLVM pointer type</td></tr><tr><td style=text-align:center><code>args</code></td><td>variadic of LLVM dialect-compatible type</td></tr><tr><td style=text-align:center><code>stride</code></td><td>32-bit signless integer</td></tr></tbody></table><h3 id=nvvmreadptxsregnwarpid-nvvmwarpdimop><code>nvvm.read.ptx.sreg.nwarpid</code> (NVVM::WarpDimOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregnwarpid-nvvmwarpdimop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.nwarpid` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-111>Attributes:&nbsp;<a class=headline-hash href=#attributes-111>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-116>Results:&nbsp;<a class=headline-hash href=#results-116>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregwarpid-nvvmwarpidop><code>nvvm.read.ptx.sreg.warpid</code> (NVVM::WarpIdOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregwarpid-nvvmwarpidop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.warpid` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-112>Attributes:&nbsp;<a class=headline-hash href=#attributes-112>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-117>Results:&nbsp;<a class=headline-hash href=#results-117>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmreadptxsregwarpsize-nvvmwarpsizeop><code>nvvm.read.ptx.sreg.warpsize</code> (NVVM::WarpSizeOp)&nbsp;<a class=headline-hash href=#nvvmreadptxsregwarpsize-nvvmwarpsizeop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.read.ptx.sreg.warpsize` (`range` $range^)? attr-dict `:` type($res)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-113>Attributes:&nbsp;<a class=headline-hash href=#attributes-113>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>range</code></td><td>::mlir::LLVM::ConstantRangeAttr</td><td><details><summary>A range of two integers, corresponding to LLVM's ConstantRange</summary><pre><code>A pair of two integers, mapping to the ConstantRange structure in LLVM IR,
which is allowed to wrap or be empty.
<p>The range represented is [Lower, Upper), and is either signed or unsigned
depending on context.</p>
<p><code>lower</code> and <code>upper</code> must have the same width.</p>
<p>Syntax:</p>
<pre tabindex=0><code>`&amp;lt;` `i`(width($lower)) $lower `,` $upper `&amp;gt;`
</code></pre><p></code></pre></p></details></td></tr></table><h4 id=results-118>Results:&nbsp;<a class=headline-hash href=#results-118>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>LLVM dialect-compatible type</td></tr></tbody></table><h3 id=nvvmwgmmafencealigned-nvvmwgmmafencealignedop><code>nvvm.wgmma.fence.aligned</code> (NVVM::WgmmaFenceAlignedOp)&nbsp;<a class=headline-hash href=#nvvmwgmmafencealigned-nvvmwgmmafencealignedop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.wgmma.fence.aligned` attr-dict
</code></pre><p>Enforce an ordering of register accesses between warpgroup level matrix
multiplication and other operations.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions-wgmma-fence>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;90></code></p><h3 id=nvvmwgmmacommitgroupsyncaligned-nvvmwgmmagroupsyncalignedop><code>nvvm.wgmma.commit.group.sync.aligned</code> (NVVM::WgmmaGroupSyncAlignedOp)&nbsp;<a class=headline-hash href=#nvvmwgmmacommitgroupsyncaligned-nvvmwgmmagroupsyncalignedop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.wgmma.commit.group.sync.aligned` attr-dict
</code></pre><p>Commits all prior uncommitted warpgroup level matrix multiplication operations.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions-wgmma-commit-group>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;90></code></p><h3 id=nvvmwgmmamma_async-nvvmwgmmammaasyncop><code>nvvm.wgmma.mma_async</code> (NVVM::WgmmaMmaAsyncOp)&nbsp;<a class=headline-hash href=#nvvmwgmmamma_async-nvvmwgmmammaasyncop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.wgmma.mma_async` $descriptorA `,` $descriptorB `,` $inouts `,` $shape `,`
              `D` `[` $typeD `,` $scaleD (`,` $satfinite^)? `]` `,`
              `A` `[` $typeA `,` $scaleA `,` $layoutA `]` `,`
              `B` `[` $typeB `,` $scaleB `,` $layoutB `]`
              attr-dict `:`
              type($inouts) `-&gt;` type($results)
</code></pre><p>The warpgroup (128 threads) level matrix multiply and accumulate operation
has either of the following forms, where matrix D is called accumulator:
D = A * B + D
D = A * B, where the input from accumulator D is disabled.</p><p>Supported shapes:</p><pre tabindex=0><code>|--------------|--------------|------------|--------------|---------------|
|              |              |            |              |f16+=e4m3*e4m3 |
|              |              |            |              |f16+=e5m2*e5m2 |
|f32+=tf32*tf32|f16+=f16 *f16 | s32+=s8*s8 |s32 += b1 * b1|f16+=e5m2*e4m3 |
|              |f32+=f16 *f16 | s32+=u8*u8 |              |f16+=e4m3*e5m2 |
|              |f32+=bf16*bf16| s32+=u8*u8 |              |f16+=e4m3*e5m2 |
|              |f32+=bf16*bf16| s32+=s8*u8 |              |f32+=e4m3*e4m3 |
|              |              | s32+=u8*s8 |              |f32+=e5m2*e5m2 |
|              |              |            |              |f32+=e4m3*e5m2 |
|              |              |            |              |f32+=e4m3*e5m2 |
|--------------|--------------|------------|--------------|---------------|
|   .m64n8k8   |  .m64n8k16   | .m64n8k32  | .m64n8k256   | .m64n8k32     |
|   .m64n16k8  |  .m64n16k16  | .m64n16k32 | .m64n16k256  | .m64n16k32    |
|   .m64n24k8  |  .m64n24k16  | .m64n24k32 | .m64n24k256  | .m64n24k32    |
|   .m64n32k8  |  .m64n32k16  | .m64n32k32 | .m64n32k256  | .m64n32k32    |
|   .m64n40k8  |  .m64n40k16  | .m64n48k32 | .m64n48k256  | .m64n40k32    |
|   .m64n48k8  |  .m64n48k16  | .m64n64k32 | .m64n64k256  | .m64n48k32    |
|   .m64n56k8  |  .m64n56k16  | .m64n80k32 | .m64n80k256  | .m64n56k32    |
|   .m64n64k8  |  .m64n64k16  | .m64n96k32 | .m64n96k256  | .m64n64k32    |
|   .m64n72k8  |  .m64n72k16  | .m64n112k32| .m64n112k256 | .m64n72k32    |
|   .m64n80k8  |  .m64n80k16  | .m64n128k32| .m64n128k256 | .m64n80k32    |
|   .m64n88k8  |  .m64n88k16  | .m64n144k32| .m64n144k256 | .m64n88k32    |
|   .m64n96k8  |  .m64n96k16  | .m64n160k32| .m64n160k256 | .m64n96k32    |
|   .m64n104k8 |  .m64n104k16 | .m64n176k32| .m64n176k256 | .m64n104k32   |
|   .m64n112k8 |  .m64n112k16 | .m64n192k32| .m64n192k256 | .m64n112k32   |
|   .m64n120k8 |  .m64n120k16 | .m64n208k32| .m64n208k256 | .m64n120k32   |
|   .m64n128k8 |  .m64n128k16 | .m64n224k32| .m64n224k256 | .m64n128k32   |
|   .m64n136k8 |  .m64n136k16 | .m64n240k32| .m64n240k256 | .m64n136k32   |
|   .m64n144k8 |  .m64n144k16 | .m64n256k32| .m64n256k256 | .m64n144k32   |
|   .m64n152k8 |  .m64n152k16 |            |              | .m64n152k32   |
|   .m64n160k8 |  .m64n160k16 |            |              | .m64n160k32   |
|   .m64n168k8 |  .m64n168k16 |            |              | .m64n168k32   |
|   .m64n176k8 |  .m64n176k16 |            |              | .m64n176k32   |
|   .m64n184k8 |  .m64n184k16 |            |              | .m64n184k32   |
|   .m64n192k8 |  .m64n192k16 |            |              | .m64n192k32   |
|   .m64n200k8 |  .m64n200k16 |            |              | .m64n200k32   |
|   .m64n208k8 |  .m64n208k16 |            |              | .m64n208k32   |
|   .m64n216k8 |  .m64n216k16 |            |              | .m64n216k32   |
|   .m64n224k8 |  .m64n224k16 |            |              | .m64n224k32   |
|   .m64n232k8 |  .m64n232k16 |            |              | .m64n232k32   |
|   .m64n240k8 |  .m64n240k16 |            |              | .m64n240k32   |
|   .m64n248k8 |  .m64n248k16 |            |              | .m64n248k32   |
|   .m64n256k8 |  .m64n256k16 |            |              | .m64n256k32   |
|--------------|--------------|------------|--------------|---------------|
</code></pre><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions>For more information, see PTX ISA</a></p><p>Interfaces: <code>BasicPtxBuilderInterface</code></p><h4 id=attributes-114>Attributes:&nbsp;<a class=headline-hash href=#attributes-114>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>shape</code></td><td>::mlir::NVVM::MMAShapeAttr</td><td>Attribute for MMA operation shape.</td></tr><tr><td><code>typeA</code></td><td>::mlir::NVVM::WGMMATypesAttr</td><td>NVVM WGMMA types</td></tr><tr><td><code>typeB</code></td><td>::mlir::NVVM::WGMMATypesAttr</td><td>NVVM WGMMA types</td></tr><tr><td><code>typeD</code></td><td>::mlir::NVVM::WGMMATypesAttr</td><td>NVVM WGMMA types</td></tr><tr><td><code>scaleD</code></td><td>::mlir::NVVM::WGMMAScaleOutAttr</td><td>WGMMA input predicate</td></tr><tr><td><code>scaleA</code></td><td>::mlir::NVVM::WGMMAScaleInAttr</td><td>WGMMA overflow options</td></tr><tr><td><code>scaleB</code></td><td>::mlir::NVVM::WGMMAScaleInAttr</td><td>WGMMA overflow options</td></tr><tr><td><code>layoutA</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>layoutB</code></td><td>::mlir::NVVM::MMALayoutAttr</td><td>NVVM MMA layout</td></tr><tr><td><code>satfinite</code></td><td>::mlir::NVVM::MMAIntOverflowAttr</td><td>MMA overflow options</td></tr></table><h4 id=operands-81>Operands:&nbsp;<a class=headline-hash href=#operands-81>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>inouts</code></td><td>LLVM structure type</td></tr><tr><td style=text-align:center><code>descriptorA</code></td><td>64-bit signless integer</td></tr><tr><td style=text-align:center><code>descriptorB</code></td><td>64-bit signless integer</td></tr></tbody></table><h4 id=results-119>Results:&nbsp;<a class=headline-hash href=#results-119>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>LLVM structure type</td></tr></tbody></table><h3 id=nvvmwgmmawaitgroupsyncaligned-nvvmwgmmawaitgroupsyncop><code>nvvm.wgmma.wait.group.sync.aligned</code> (NVVM::WgmmaWaitGroupSyncOp)&nbsp;<a class=headline-hash href=#nvvmwgmmawaitgroupsyncaligned-nvvmwgmmawaitgroupsyncop>¶</a></h3><p>Syntax:</p><pre tabindex=0><code>operation ::= `nvvm.wgmma.wait.group.sync.aligned` attr-dict $group
</code></pre><p>Signal the completion of a preceding warpgroup operation.</p><p><a href=https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-instructions-wgmma-wait-group>For more information, see PTX ISA</a></p><p>Traits: <code>NVVMRequiresSMa&lt;90></code></p><h4 id=attributes-115>Attributes:&nbsp;<a class=headline-hash href=#attributes-115>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>group</code></td><td>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></table><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=https://mlir.llvm.org/docs/Dialects/NVGPU/ title="'nvgpu' Dialect"><i class="fas fa-arrow-left" aria-hidden=true></i> Prev - 'nvgpu' Dialect</a>
<a class="nav nav-next" href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/ title="'omp' Dialect">Next - 'omp' Dialect <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=https://mlir.llvm.org/governance/>Governance</a></li><li><a href=https://mlir.llvm.org/users/>Users of MLIR</a></li><li><a href=https://mlir.llvm.org/pubs/>MLIR Related Publications</a></li><li><a href=https://mlir.llvm.org/talks/>Talks</a></li><li><a href=https://mlir.llvm.org/deprecation/>Deprecations & Current Refactoring</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/getting_started/ReportingIssues/>Reporting Issues</a></li><li><a href=https://mlir.llvm.org/getting_started/Debugging/>Debugging Tips</a></li><li><a href=https://mlir.llvm.org/getting_started/Faq/>FAQ</a></li><li><a href=https://mlir.llvm.org/getting_started/Contributing/>How to Contribute</a></li><li><a href=https://mlir.llvm.org/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=https://mlir.llvm.org/getting_started/openprojects/>Open Projects</a></li><li><a href=https://mlir.llvm.org/getting_started/Glossary/>Glossary</a></li><li><a href=https://mlir.llvm.org/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-reduce/>MLIR Reduce</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-rewrite/>mlir-rewrite</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/OpenMPPasses/></a></li><li><a href=https://mlir.llvm.org/docs/TargetLLVMIRTransforms/></a></li><li><a href=https://mlir.llvm.org/docs/ActionTracing/>Action: Tracing and Debugging MLIR-based Compilers</a></li><li><a href=https://mlir.llvm.org/docs/Bufferization/>Bufferization</a></li><li><a href=https://mlir.llvm.org/docs/DataLayout/>Data Layout Modeling</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/DefiningDialects/>Defining Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Constraints/>Constraints</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Assembly/>Customizing Assembly Behavior</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Operations/>Operation Definition Specification (ODS)</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/DialectConversion/>Dialect Conversion</a></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/Dialects/>Dialects<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/XeGPUTransformOps/></a></li><li><a href=https://mlir.llvm.org/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMDGPU/>'amdgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArithOps/>'arith' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSME/>'ArmSME' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/BufferizationOps/>'bufferization' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/>'cf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/DLTIDialect/>'dlti' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/EmitC/>'emitc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Func/>'func' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IndexOps/>'index' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IRDL/>'irdl' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/Linalg/>'linalg' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/>Linalg OpDSL</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MLProgramOps/>'ml_program' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MPI/>'mpi' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVGPU/>'nvgpu' Dialect</a></li><li class=active><a href=https://mlir.llvm.org/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/>'omp' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/ODS/>ODS Documentation</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PtrOps/>'ptr' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Shard/>'shard' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SMT/>'smt' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/UBOps/>'ub' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/VCIXDialect/>'vcix' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/WasmSSAOps/>'wasmssa' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeGPU/>'xegpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeVMDialect/>'xevm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/>OpInterface definitions</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SPIR-V/>SPIR-V Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Transform/>Transform Dialect</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Interfaces/>Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/TargetLLVMIR/>LLVM IR Target</a></li><li><a href=https://mlir.llvm.org/docs/BytecodeFormat/>MLIR Bytecode Format</a></li><li><a href=https://mlir.llvm.org/docs/CAPI/>MLIR C API</a></li><li><a href=https://mlir.llvm.org/docs/LangRef/>MLIR Language Reference</a></li><li><a href=https://mlir.llvm.org/docs/ReleaseNotes/>MLIR Release Notes</a></li><li><a href=https://mlir.llvm.org/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=https://mlir.llvm.org/docs/OwnershipBasedBufferDeallocation/>Ownership-based Buffer Deallocation</a></li><li><a href=https://mlir.llvm.org/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/Passes/>Passes</a></li><li><a href=https://mlir.llvm.org/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=https://mlir.llvm.org/docs/PatternSearch/>Pattern Search</a></li><li><a href=https://mlir.llvm.org/docs/PDLL/>PDLL - PDL Language</a></li><li><a href=https://mlir.llvm.org/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/SideEffectsAndSpeculation/>Side Effects & Speculation</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Remarks/>Remark Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/ShapeInference/>Shape Inference</a></li><li><a href=https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=https://mlir.llvm.org/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=https://mlir.llvm.org/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Traits/>Traits<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Traits/Broadcastable/>The `Broadcastable` Trait</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/transform/>Transform Dialect Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch0/>Chapter 0: A Primer on “Structured” Linalg Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch1/>Chapter 1: Combining Existing Transformations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch2/>Chapter 2: Adding a Simple New Transformation Operation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch3/>Chapter 3: More than Simple Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch4/>Chapter 4: Matching Payload with Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/ChH/>Chapter H: Reproducing Halide Schedule</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/MlirOpt/>Using `mlir-opt`</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>