<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dialects on MLIR</title><link>https://mlir.llvm.org/docs/Dialects/</link><description>Recent content in Dialects on MLIR</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 01 Jan 1970 00:00:00 +0000</lastBuildDate><atom:link href="https://mlir.llvm.org/docs/Dialects/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://mlir.llvm.org/docs/Dialects/SMTExtensionOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SMTExtensionOps/</guid><description>source
transform.smt.constrain_params ( mlir::transform::smt ::ConstrainParamsOp) Express contraints on params interpreted as symbolic values
Syntax:
operation ::= `transform.smt.constrain_params` `(` $params `)` attr-dict `:` type(operands) $body Allows expressing constraints on params using the SMT dialect.
Each Transform dialect param provided as an operand has a corresponding argument of SMT-type in the region. The SMT-Dialect ops in the region use these arguments as operands.
The semantics of this op is that all the ops in the region together express a constraint on the params-interpreted-as-smt-vars.</description></item><item><title>'acc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</guid><description>The acc dialect is an MLIR dialect for representing the OpenACC programming model. OpenACC is a standardized directive-based model which is used with C, C++, and Fortran to enable programmers to expose parallelism in their code. The descriptive approach used by OpenACC allows targeting of parallel multicore and accelerator targets like GPUs by giving the compiler the freedom of how to parallelize for specific architectures. OpenACC also provides the ability to optimize the parallelism through increasingly more prescriptive clauses.</description></item><item><title>'affine' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Affine/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Affine/</guid><description>This dialect provides a powerful abstraction for affine operations and analyses.
Polyhedral Structures Dimensions and Symbols Restrictions on Dimensions and Symbols Affine Expressions Affine Maps Semi-affine maps Integer Sets Operations affine.apply (affine::AffineApplyOp) affine.delinearize_index (affine::AffineDelinearizeIndexOp) affine.for (affine::AffineForOp) affine.if (affine::AffineIfOp) affine.linearize_index (affine::AffineLinearizeIndexOp) affine.load (affine::AffineLoadOp) affine.max (affine::AffineMaxOp) affine.min (affine::AffineMinOp) affine.parallel (affine::AffineParallelOp) affine.prefetch (affine::AffinePrefetchOp) affine.store (affine::AffineStoreOp) affine.vector_load (affine::AffineVectorLoadOp) affine.vector_store (affine::AffineVectorStoreOp) affine.yield (affine::AffineYieldOp) affine.dma_start (mlir::AffineDmaStartOp) affine.dma_wait (mlir::AffineDmaWaitOp) Polyhedral Structures MLIR uses techniques from polyhedral compilation to make dependence analysis and loop transformations efficient and reliable.</description></item><item><title>'amdgpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AMDGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AMDGPU/</guid><description>The AMDGPU dialect provides wrappers around AMD-specific functionality and LLVM intrinsics. These wrappers should be used in conjunction with more generic dialects, such as gpu and vector, when generating LLVM IR that will eventually be executed on AMD hardware.
Operations amdgpu.dpp (amdgpu::DPPOp) amdgpu.ext_packed_fp8 (amdgpu::ExtPackedFp8Op) amdgpu.fat_raw_buffer_cast (amdgpu::FatRawBufferCastOp) amdgpu.gather_to_lds (amdgpu::GatherToLDSOp) amdgpu.lds_barrier (amdgpu::LDSBarrierOp) amdgpu.memory_counter_wait (amdgpu::MemoryCounterWaitOp) amdgpu.mfma (amdgpu::MFMAOp) amdgpu.packed_scaled_trunc (amdgpu::PackedScaledTruncOp) amdgpu.packed_stoch_round_fp8 (amdgpu::PackedStochRoundFp8Op) amdgpu.packed_trunc_2xfp8 (amdgpu::PackedTrunc2xFp8Op) amdgpu.permlane_swap (amdgpu::PermlaneSwapOp) amdgpu.raw_buffer_atomic_cmpswap (amdgpu::RawBufferAtomicCmpswapOp) amdgpu.raw_buffer_atomic_fadd (amdgpu::RawBufferAtomicFaddOp) amdgpu.raw_buffer_atomic_fmax (amdgpu::RawBufferAtomicFmaxOp) amdgpu.raw_buffer_atomic_smax (amdgpu::RawBufferAtomicSmaxOp) amdgpu.</description></item><item><title>'amx' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AMX/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AMX/</guid><description>The Intel Advanced Matrix Extensions (AMX) provide a tile matrix multiply unit (TMUL), a tile control register (TILECFG), and eight tile registers TMM0 through TMM7 (TILEDATA).
This AMX dialect provides a bridge between MLIR concepts such as vectors and memrefs and the lower level LLVM IR support of AMX.
Note that since configuration changes (implicit at dialect level) are costly, it is highly recommended to use the AMX dialect on same-shaped vectors, at least within a single method.</description></item><item><title>'arith' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArithOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArithOps/</guid><description>The arith dialect is intended to hold basic integer and floating point mathematical operations. This includes unary, binary, and ternary arithmetic ops, bitwise and shift ops, cast ops, and compare ops. Operations in this dialect also accept vectors and tensors of integers or floats. The dialect assumes integers are represented by bitvectors with a two&amp;rsquo;s complement representation. Unless otherwise stated, the operations within this dialect propagate poison values, i.e., if any of its inputs are poison, then the output is poison.</description></item><item><title>'arm_neon' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmNeon/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmNeon/</guid><description>Operations arm_neon.2d.sdot (arm_neon::Sdot2dOp) arm_neon.intr.bfmmla (arm_neon::BfmmlaOp) arm_neon.intr.sdot (arm_neon::SdotOp) arm_neon.intr.smmla (arm_neon::SmmlaOp) arm_neon.intr.smull (arm_neon::SMullOp) arm_neon.intr.ummla (arm_neon::UmmlaOp) arm_neon.intr.usmmla (arm_neon::UsmmlaOp) Operations source
arm_neon.2d.sdot (arm_neon::Sdot2dOp) Sdot op
Syntax:
operation ::= `arm_neon.2d.sdot` $a `,` $b `,` $c attr-dict `:` type($b) `,` type($c) `to` type($res) The two input vectors b and c have a 2D shape, consisting of either 2 or 4 rows, each row having length 4. This operation computes the pair-wise dot-products of the rows of b and c and accumulates them with the corresponding entry of a:</description></item><item><title>'arm_sve' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmSVE/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmSVE/</guid><description>Basic dialect to target Arm SVE architectures
This dialect contains the definitions necessary to target specific Arm SVE scalable vector operations.
Operations arm_sve.convert_from_svbool (arm_sve::ConvertFromSvboolOp) arm_sve.convert_to_svbool (arm_sve::ConvertToSvboolOp) arm_sve.dupq_lane (arm_sve::DupQLaneOp) arm_sve.intr.add (arm_sve::ScalableMaskedAddIIntrOp) arm_sve.intr.bfmmla (arm_sve::BfmmlaOp) arm_sve.intr.convert.from.svbool (arm_sve::ConvertFromSvboolIntrOp) arm_sve.intr.convert.to.svbool (arm_sve::ConvertToSvboolIntrOp) arm_sve.intr.dupq_lane (arm_sve::DupQLaneIntrOp) arm_sve.intr.fadd (arm_sve::ScalableMaskedAddFIntrOp) arm_sve.intr.fdiv (arm_sve::ScalableMaskedDivFIntrOp) arm_sve.intr.fmul (arm_sve::ScalableMaskedMulFIntrOp) arm_sve.intr.fsub (arm_sve::ScalableMaskedSubFIntrOp) arm_sve.intr.mul (arm_sve::ScalableMaskedMulIIntrOp) arm_sve.intr.psel (arm_sve::PselIntrOp) arm_sve.intr.sdiv (arm_sve::ScalableMaskedSDivIIntrOp) arm_sve.intr.sdot (arm_sve::SdotIntrOp) arm_sve.intr.smmla (arm_sve::SmmlaIntrOp) arm_sve.intr.sub (arm_sve::ScalableMaskedSubIIntrOp) arm_sve.intr.udiv (arm_sve::ScalableMaskedUDivIIntrOp) arm_sve.intr.udot (arm_sve::UdotIntrOp) arm_sve.intr.ummla (arm_sve::UmmlaIntrOp) arm_sve.intr.usmmla (arm_sve::UsmmlaIntrOp) arm_sve.intr.whilelt (arm_sve::WhileLTIntrOp) arm_sve.intr.zip.x2 (arm_sve::ZipX2IntrOp) arm_sve.</description></item><item><title>'ArmSME' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmSME/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmSME/</guid><description>Basic dialect to target Arm SME.
This dialect defines custom and LLVM IR intrinsic operations that are used to target Arm Scalable Matrix Extension. Through the available conversion and ArmSME passes you can, for example, lower a linalg.matmul operation to Arm SME FMOPA (floating-point outer product) operations. See one of the in-tree end-to-end integration tests for reference:
Linalg/CPU/ArmSME/matmul.mlir Vector/CPU/ArmSME/outerproduct-f64.mlir In order to run ArmSME integration tests, include these flags in the CMake invocation when configuring LLVM and MLIR:</description></item><item><title>'async' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</guid><description>Types and operations for async dialect
This dialect contains operations for modeling asynchronous execution.
Operations async.add_to_group (async::AddToGroupOp) async.await (async::AwaitOp) async.await_all (async::AwaitAllOp) async.call (async::CallOp) async.coro.begin (async::CoroBeginOp) async.coro.end (async::CoroEndOp) async.coro.free (async::CoroFreeOp) async.coro.id (async::CoroIdOp) async.coro.save (async::CoroSaveOp) async.coro.suspend (async::CoroSuspendOp) async.create_group (async::CreateGroupOp) async.execute (async::ExecuteOp) async.func (async::FuncOp) async.return (async::ReturnOp) async.runtime.add_ref (async::RuntimeAddRefOp) async.runtime.add_to_group (async::RuntimeAddToGroupOp) async.runtime.await (async::RuntimeAwaitOp) async.runtime.await_and_resume (async::RuntimeAwaitAndResumeOp) async.runtime.create (async::RuntimeCreateOp) async.runtime.create_group (async::RuntimeCreateGroupOp) async.runtime.drop_ref (async::RuntimeDropRefOp) async.runtime.is_error (async::RuntimeIsErrorOp) async.runtime.load (async::RuntimeLoadOp) async.runtime.num_worker_threads (async::RuntimeNumWorkerThreadsOp) async.runtime.resume (async::RuntimeResumeOp) async.runtime.set_available (async::RuntimeSetAvailableOp) async.runtime.set_error (async::RuntimeSetErrorOp) async.</description></item><item><title>'bufferization' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</guid><description>Bufferization in MLIR is the process of converting the tensor type to the memref type. Simply put, bufferization is the process of converting computations on the mathematical tensor construct to computations on physical memory buffers. The bufferization dialect contains operations/interfaces specific to the bufferization passes.
An overview of the bufferization infrastructure and important conceptual details related to using the MLIR dialect conversion infrastructure can be found in bufferization and ownership-based buffer deallocation.</description></item><item><title>'cf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</guid><description>This dialect contains low-level, i.e. non-region based, control flow constructs. These constructs generally represent control flow directly on SSA blocks of a control flow graph.
Operations cf.assert (cf::AssertOp) cf.br (cf::BranchOp) cf.cond_br (cf::CondBranchOp) cf.switch (cf::SwitchOp) Operations source
cf.assert (cf::AssertOp) Assert operation with message attribute
Syntax:
operation ::= `cf.assert` $arg `,` $msg attr-dict Assert operation at runtime with single boolean operand and an error message attribute. If the argument is true this operation has no effect.</description></item><item><title>'complex' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ComplexOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ComplexOps/</guid><description>The complex dialect is intended to hold complex numbers creation and arithmetic ops.
Operations complex.abs (complex::AbsOp) complex.add (complex::AddOp) complex.angle (complex::AngleOp) complex.atan2 (complex::Atan2Op) complex.bitcast (complex::BitcastOp) complex.conj (complex::ConjOp) complex.constant (complex::ConstantOp) complex.cos (complex::CosOp) complex.create (complex::CreateOp) complex.div (complex::DivOp) complex.eq (complex::EqualOp) complex.exp (complex::ExpOp) complex.expm1 (complex::Expm1Op) complex.im (complex::ImOp) complex.log (complex::LogOp) complex.log1p (complex::Log1pOp) complex.mul (complex::MulOp) complex.neg (complex::NegOp) complex.neq (complex::NotEqualOp) complex.pow (complex::PowOp) complex.powi (complex::PowiOp) complex.re (complex::ReOp) complex.rsqrt (complex::RsqrtOp) complex.sign (complex::SignOp) complex.sin (complex::SinOp) complex.sqrt (complex::SqrtOp) complex.sub (complex::SubOp) complex.tan (complex::TanOp) complex.</description></item><item><title>'dlti' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</guid><description>The Data Layout and Target Information (DLTI) dialect is intended to hold attributes and other components pertaining to descriptions of in-memory data layout and compilation targets.
Attributes DataLayoutEntryAttr DataLayoutSpecAttr FunctionPointerAlignmentAttr MapAttr TargetDeviceSpecAttr TargetSystemSpecAttr Attributes DataLayoutEntryAttr An attribute to represent an entry of a data layout specification.
A data layout entry attribute is a key-value pair where the key is a type or an identifier and the value is another attribute.</description></item><item><title>'emitc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/EmitC/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/EmitC/</guid><description>Dialect to generate C/C++ from MLIR.
The EmitC dialect allows to convert operations from other MLIR dialects to EmitC ops. Those can be translated to C/C++ via the Cpp emitter.
The following convention is followed:
If template arguments are passed to an emitc.call_opaque operation, C++ is generated. If tensors are used, C++ is generated. If multiple return values are used within in a functions or an emitc.call_opaque operation, C++11 is required.</description></item><item><title>'func' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Func/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Func/</guid><description>This dialect provides documentation for operations within the Func dialect.
This dialect contains operations surrounding high order function abstractions, such as calls.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations func.call_indirect (func::CallIndirectOp) func.call (func::CallOp) func.constant (func::ConstantOp) func.func (func::FuncOp) func.return (func::ReturnOp) Operations source
func.call_indirect (func::CallIndirectOp) Indirect call operation
Syntax:
operation ::= `func.call_indirect` $callee `(` $callee_operands `)` attr-dict `:` type($callee) The func.call_indirect operation represents an indirect call to a value of function type.</description></item><item><title>'gpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/GPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/GPU/</guid><description>Note: this dialect is more likely to change than others in the near future; use with caution.
This dialect provides middle-level abstractions for launching GPU kernels following a programming model similar to that of CUDA or OpenCL. It provides abstractions for kernel invocations (and may eventually provide those for device management) that are not present at the lower level (e.g., as LLVM IR intrinsics for GPUs). Its goal is to abstract away device- and driver-specific manipulations to launch a GPU kernel and provide a simple path towards GPU execution from MLIR.</description></item><item><title>'index' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/IndexOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/IndexOps/</guid><description>The Index dialect
The Index dialect contains operations for manipulating values of the builtin index type. The index type models target-specific values of pointer width, like intptr_t. Index values are typically used as loop bounds, array subscripts, tensor dimensions, etc.
The operations in this dialect operate exclusively on scalar index types. The dialect and its operations treat the index type as signless and contains signed and unsigned versions of certain operations where the distinction is meaningful.</description></item><item><title>'irdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/IRDL/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/IRDL/</guid><description>Basics Principles Constraints and combinators Motivating use cases Operations irdl.all_of (irdl::AllOfOp) irdl.any_of (irdl::AnyOfOp) irdl.any (irdl::AnyOp) irdl.attribute (irdl::AttributeOp) irdl.attributes (irdl::AttributesOp) irdl.base (irdl::BaseOp) irdl.c_pred (irdl::CPredOp) irdl.dialect (irdl::DialectOp) irdl.is (irdl::IsOp) irdl.operands (irdl::OperandsOp) irdl.operation (irdl::OperationOp) irdl.parameters (irdl::ParametersOp) irdl.parametric (irdl::ParametricOp) irdl.region (irdl::RegionOp) irdl.regions (irdl::RegionsOp) irdl.results (irdl::ResultsOp) irdl.type (irdl::TypeOp) Basics The IRDL (Intermediate Representation Definition Language) dialect allows defining MLIR dialects as MLIR programs. Nested operations are used to represent dialect structure: dialects contain operations, types and attributes, themselves containing type parameters, operands, results, etc.</description></item><item><title>'llvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/LLVM/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LLVM/</guid><description>This dialect maps LLVM IR into MLIR by defining the corresponding operations and types. LLVM IR metadata is usually represented as MLIR attributes, which offer additional structure verification.
We use &amp;ldquo;LLVM IR&amp;rdquo; to designate the intermediate representation of LLVM and &amp;ldquo;LLVM dialect&amp;rdquo; or &amp;ldquo;LLVM IR dialect&amp;rdquo; to refer to this MLIR dialect.
Unless explicitly stated otherwise, the semantics of the LLVM dialect operations must correspond to the semantics of LLVM IR instructions and any divergence is considered a bug.</description></item><item><title>'math' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MathOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MathOps/</guid><description>The math dialect is intended to hold mathematical operations on integer and floating types beyond simple arithmetics. Each operation works on scalar, vector or tensor type. On vector and tensor type operations apply elementwise unless explicitly specified otherwise. As an example, the floating point absolute value can be expressed as:
// Scalar absolute value. %a = math.absf %b : f64 // Vector elementwise absolute value. %f = math.absf %g : vector&amp;lt;4xf32&amp;gt; // Tensor elementwise absolute value.</description></item><item><title>'memref' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MemRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MemRef/</guid><description>This dialect provides documentation for operations within the MemRef dialect.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations memref.assume_alignment (memref::AssumeAlignmentOp) memref.atomic_rmw (memref::AtomicRMWOp) memref.atomic_yield (memref::AtomicYieldOp) memref.copy (memref::CopyOp) memref.generic_atomic_rmw (memref::GenericAtomicRMWOp) memref.load (memref::LoadOp) memref.alloc (memref::AllocOp) memref.alloca (memref::AllocaOp) memref.alloca_scope (memref::AllocaScopeOp) memref.alloca_scope.return (memref::AllocaScopeReturnOp) memref.cast (memref::CastOp) memref.collapse_shape (memref::CollapseShapeOp) memref.dealloc (memref::DeallocOp) memref.dim (memref::DimOp) memref.dma_start (memref::DmaStartOp) memref.dma_wait (memref::DmaWaitOp) memref.expand_shape (memref::ExpandShapeOp) memref.extract_aligned_pointer_as_index (memref::ExtractAlignedPointerAsIndexOp) memref.extract_strided_metadata (memref::ExtractStridedMetadataOp) memref.get_global (memref::GetGlobalOp) memref.global (memref::GlobalOp) memref.memory_space_cast (memref::MemorySpaceCastOp) memref.</description></item><item><title>'ml_program' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</guid><description>The MLProgram dialect contains structural operations and types for defining a compiled Machine-Learning program, as created from common ML frameworks, such as TensorFlow, PyTorch, JAX, etc. It does not itself define computation ops common to such frameworks but establishes a common programming model for establishing modules, functions, globals and memory model components appropriate for such an abstract level of detail.
This dialect is under active development, and while stability is an eventual goal, it is not guaranteed at this juncture.</description></item><item><title>'mpi' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MPI/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MPI/</guid><description>This dialect models the Message Passing Interface (MPI), version 4.0. It is meant to serve as an interfacing dialect that is targeted by higher-level dialects. The MPI dialect itself can be lowered to multiple MPI implementations and hide differences in ABI. The dialect models the functions of the MPI specification as close to 1:1 as possible while preserving SSA value semantics where it makes sense, and uses memref types instead of bare pointers.</description></item><item><title>'nvgpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVGPU/</guid><description>The NVGPU dialect provides a bridge between higher-level target-agnostic dialects (GPU and Vector) and the lower-level target-specific dialect (LLVM IR based NVVM dialect) for NVIDIA GPUs. This allow representing PTX specific operations while using MLIR high level dialects such as Memref and Vector for memory and target-specific register operands, respectively.
Operations nvgpu.device_async_copy (nvgpu::DeviceAsyncCopyOp) nvgpu.device_async_create_group (nvgpu::DeviceAsyncCreateGroupOp) nvgpu.device_async_wait (nvgpu::DeviceAsyncWaitOp) nvgpu.ldmatrix (nvgpu::LdMatrixOp) nvgpu.mbarrier.arrive (nvgpu::MBarrierArriveOp) nvgpu.mbarrier.arrive.expect_tx (nvgpu::MBarrierArriveExpectTxOp) nvgpu.mbarrier.arrive.nocomplete (nvgpu::MBarrierArriveNoCompleteOp) nvgpu.mbarrier.create (nvgpu::MBarrierCreateOp) nvgpu.mbarrier.get (nvgpu::MBarrierGetOp) nvgpu.</description></item><item><title>'nvvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</guid><description>The NVVM dialect that models NVIDIA&amp;rsquo;s public ISA
The NVVM dialect is MLIR&amp;rsquo;s LLVM-IR-based, NVIDIA-specific backend dialect. It models NVVM intrinsics and public ISA functionality and introduces NVIDIA extensions to the MLIR/LLVM type system and address spaces (e.g., global, shared, and cluster memory), enabling faithful lowering of GPU kernels to the NVPTX toolchain. While a NVVM op usually maps to a single LLVM IR intrinsic, the NVVM dialect uses type polymorphism and other attributes so that a single NVVM op can map to different LLVM intrinsics.</description></item><item><title>'pdl_interp' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</guid><description>Interpreted pattern execution dialect
The PDL Interpreter dialect provides a lower level abstraction compared to the PDL dialect, and is targeted towards low level optimization and interpreter code generation. The dialect operations encapsulates low-level pattern match and rewrite &amp;ldquo;primitives&amp;rdquo;, such as navigating the IR (Operation::getOperand), creating new operations (OpBuilder::create), etc. Many of the operations within this dialect also fuse branching control flow with some form of a predicate comparison operation.</description></item><item><title>'pdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLOps/</guid><description>High level pattern definition dialect
PDL presents a high level abstraction for the rewrite pattern infrastructure available in MLIR. This abstraction allows for representing patterns transforming MLIR, as MLIR. This allows for applying all of the benefits that the general MLIR infrastructure provides, to the infrastructure itself. This means that pattern matching can be more easily verified for correctness, targeted by frontends, and optimized.
PDL abstracts over various different aspects of patterns and core MLIR data structures.</description></item><item><title>'ptr' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PtrOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PtrOps/</guid><description>Pointer dialect
The pointer dialect provides types and operations for representing and interacting with pointer values in MLIR, such as loading and storing values from/to memory addresses.
The dialect&amp;rsquo;s main type is an opaque pointer (ptr) that can be parameterized by a memory space. This type represents a handle to an object in memory, or target-dependent values like nullptr. Further, the dialect assumes that the minimum addressable unit by a pointer is a byte.</description></item><item><title>'quant' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/QuantDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/QuantDialect/</guid><description>The quant dialect offers a framework for defining and manipulating quantized values. Central to this framework is the !quant.uniform data type, used to represent quantized values. This dialect also provides a suite of operations to handle and convert quantized values between their original floating-point representations and the optimized, lower bit-width integer representations. The quant dialect is instrumented with transformation passes to lower these operations into other core MLIR dialects, while also flattening all occurrences of quantized types into their integer counterparts.</description></item><item><title>'rocdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</guid><description>Operations rocdl.ballot (ROCDL::BallotOp) rocdl.barrier (ROCDL::BarrierOp) rocdl.cvt.f32.bf8 (ROCDL::CvtF32Bf8Op) rocdl.cvt.f32.fp8 (ROCDL::CvtF32Fp8Op) rocdl.cvt.pk.bf8.f32 (ROCDL::CvtPkBf8F32Op) rocdl.cvt.pk.f32.bf8 (ROCDL::CvtPkF32Bf8Op) rocdl.cvt.pk.f32.fp8 (ROCDL::CvtPkF32Fp8Op) rocdl.cvt.pk.fp8.f32 (ROCDL::CvtPkFp8F32Op) rocdl.cvt.pkrtz (ROCDL::CvtPkRtz) rocdl.cvt.scale.pk16.bf16.bf6 (ROCDL::CvtPkScalePk16Bf16Bf6Op) rocdl.cvt.scale.pk16.bf16.fp6 (ROCDL::CvtPkScalePk16Bf16Fp6Op) rocdl.cvt.scale.pk16.f16.bf6 (ROCDL::CvtPkScalePk16F16Bf6Op) rocdl.cvt.scale.pk16.f16.fp6 (ROCDL::CvtPkScalePk16F16Fp6Op) rocdl.cvt.scale.pk16.f32.bf6 (ROCDL::CvtPkScalePk16F32Bf6Op) rocdl.cvt.scale.pk16.f32.fp6 (ROCDL::CvtPkScalePk16F32Fp6Op) rocdl.cvt.scale.pk8.bf16.bf8 (ROCDL::CvtPkScalePk8Bf16Bf8Op) rocdl.cvt.scale.pk8.bf16.fp4 (ROCDL::CvtPkScalePk8Bf16Fp4Op) rocdl.cvt.scale.pk8.bf16.fp8 (ROCDL::CvtPkScalePk8Bf16Fp8Op) rocdl.cvt.scale.pk8.f16.bf8 (ROCDL::CvtPkScalePk8F16Bf8Op) rocdl.cvt.scale.pk8.f16.fp4 (ROCDL::CvtPkScalePk8F16Fp4Op) rocdl.cvt.scale.pk8.f16.fp8 (ROCDL::CvtPkScalePk8F16Fp8Op) rocdl.cvt.scale.pk8.f32.bf8 (ROCDL::CvtPkScalePk8F32Bf8Op) rocdl.cvt.scale.pk8.f32.fp4 (ROCDL::CvtPkScalePk8F32Fp4Op) rocdl.cvt.scale.pk8.f32.fp8 (ROCDL::CvtPkScalePk8F32Fp8Op) rocdl.cvt.scalef32.2xpk16.bf6.f32 (ROCDL::CvtScaleF322xPk16Bf6F32Op) rocdl.cvt.scalef32.2xpk16.fp6.f32 (ROCDL::CvtScaleF322xPk16Fp6F32Op) rocdl.cvt.scalef32.f16.bf8 (ROCDL::CvtScaleF32F16Bf8Op) rocdl.cvt.scalef32.f16.fp8 (ROCDL::CvtScaleF32F16Fp8Op) rocdl.cvt.scalef32.f32.bf8 (ROCDL::CvtScaleF32F32Bf8Op) rocdl.cvt.scalef32.f32.fp8 (ROCDL::CvtScaleF32F32Fp8Op) rocdl.cvt.scalef32.pk.bf16.bf8 (ROCDL::CvtScaleF32PkBf16Bf8Op) rocdl.cvt.scalef32.pk.bf16.fp4 (ROCDL::CvtScaleF32PkBf16Fp4Op) rocdl.cvt.scalef32.pk.bf16.fp8 (ROCDL::CvtScaleF32PkBf16Fp8Op) rocdl.cvt.scalef32.pk.bf8.bf16 (ROCDL::CvtScaleF32PkBf8Bf16Op) rocdl.</description></item><item><title>'scf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SCFDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SCFDialect/</guid><description>The scf (structured control flow) dialect contains operations that represent control flow constructs such as if and for. Being structured means that the control flow has a structure unlike, for example, gotos or asserts. Unstructured control flow operations are located in the cf (control flow) dialect.
Originally, this dialect was developed as a common lowering stage for the affine and linalg dialects. Both convert to SCF loops instead of targeting branch-based CFGs directly.</description></item><item><title>'shape' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</guid><description>Description of operations &amp;amp; types within the Shape dialect as well as their usage.
Types and operations for shape dialect
This dialect contains operations for shape inference.
Note: Unless explicitly stated, all functions that return a shape and take shapes as input, return the invalid shape if one of its operands is an invalid shape. This avoids flagging multiple errors for one verification failure. The dialect itself does not specify how errors should be combined (there are multiple different options, from always choosing first operand, concatting etc.</description></item><item><title>'shard' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Shard/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Shard/</guid><description>The &amp;lsquo;shard&amp;rsquo; dialect defines a set of attributes, operations, and interfaces for working with tensor sharding and device communication.
It’s inspired by [GSPMD](General and Scalable Parallelization for ML Computation Graphs).
Originally, the dialect was called mesh, but it was renamed to better reflect what it actually does.
Collective Communication Operations Device Groups In-group Devices Purity and Execution Model Operations shard.all_gather (shard::AllGatherOp) shard.all_reduce (shard::AllReduceOp) shard.all_slice (shard::AllSliceOp) shard.all_to_all (shard::AllToAllOp) shard.broadcast (shard::BroadcastOp) shard.gather (shard::GatherOp) shard.</description></item><item><title>'smt' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SMT/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SMT/</guid><description>A dialect that models satisfiability modulo theories
Operations smt.and (mlir::smt::AndOp) smt.apply_func (mlir::smt::ApplyFuncOp) smt.array.broadcast (mlir::smt::ArrayBroadcastOp) smt.array.select (mlir::smt::ArraySelectOp) smt.array.store (mlir::smt::ArrayStoreOp) smt.assert (mlir::smt::AssertOp) smt.bv.add (mlir::smt::BVAddOp) smt.bv.and (mlir::smt::BVAndOp) smt.bv.ashr (mlir::smt::BVAShrOp) smt.bv.cmp (mlir::smt::BVCmpOp) smt.bv.concat (mlir::smt::ConcatOp) smt.bv.constant (mlir::smt::BVConstantOp) smt.bv.extract (mlir::smt::ExtractOp) smt.bv.lshr (mlir::smt::BVLShrOp) smt.bv.mul (mlir::smt::BVMulOp) smt.bv.neg (mlir::smt::BVNegOp) smt.bv.not (mlir::smt::BVNotOp) smt.bv.or (mlir::smt::BVOrOp) smt.bv.repeat (mlir::smt::RepeatOp) smt.bv.sdiv (mlir::smt::BVSDivOp) smt.bv.shl (mlir::smt::BVShlOp) smt.bv.smod (mlir::smt::BVSModOp) smt.bv.srem (mlir::smt::BVSRemOp) smt.bv.udiv (mlir::smt::BVUDivOp) smt.bv.urem (mlir::smt::BVURemOp) smt.bv.xor (mlir::smt::BVXOrOp) smt.bv2int (mlir::smt::BV2IntOp) smt.check (mlir::smt::CheckOp) smt.constant (mlir::smt::BoolConstantOp) smt.declare_fun (mlir::smt::DeclareFunOp) smt.distinct (mlir::smt::DistinctOp) smt.</description></item><item><title>'sparse_tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</guid><description>The SparseTensor dialect supports all the attributes, types, operations, and passes that are required to make sparse tensor types first class citizens within the MLIR compiler infrastructure. The dialect forms a bridge between high-level operations on sparse tensors types and lower-level operations on the actual sparse storage schemes consisting of positions, coordinates, and values. Lower-level support may consist of fully generated code or may be provided by means of a small sparse runtime support library.</description></item><item><title>'tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TensorOps/</guid><description>The tensor dialect is intended to hold core tensor creation and manipulation ops, which are not strongly associated with any particular other dialect or domain abstraction. The aim for ops in this dialect is that they make sense for any tensor element type. When this is not the case, the op is left to live in other dialects. Examples of element types that could be supported by the tensor dialect include:</description></item><item><title>'ub' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/UBOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/UBOps/</guid><description>Operations ub.poison (ub::PoisonOp) Attributes PoisonAttr Operations source
ub.poison (ub::PoisonOp) Poisoned constant operation.
Syntax:
operation ::= `ub.poison` attr-dict (`&amp;lt;` $value^ `&amp;gt;`)? `:` type($result) The poison operation materializes a compile-time poisoned constant value to indicate deferred undefined behavior. value attribute is needed to indicate an optional additional poison semantics (e.g. partially poisoned vectors), default value indicates results is fully poisoned.
Examples:
// Short form %0 = ub.poison : i32 // Long form %1 = ub.</description></item><item><title>'vcix' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/VCIXDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/VCIXDialect/</guid><description>The SiFive Vector Coprocessor Interface (VCIX) provides a flexible mechanism to extend application processors with custom coprocessors and variable-latency arithmetic units. The interface offers throughput comparable to that of standard RISC-V vector instructions. To accelerate performance, system designers may use VCIX as a low-latency, high-throughput interface to a coprocessor
https://www.sifive.com/document-file/sifive-vector-coprocessor-interface-vcix-software
Operations vcix.v.iv (vcix::BinaryImmOp) vcix.v.sv (vcix::BinaryOp) Operations source
vcix.v.iv (vcix::BinaryImmOp) Binary VCIX operation with an immediate second operand
Binary VCIX operation with an immediate second operand.</description></item><item><title>'vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Vector/</guid><description>Please post an RFC on the forum before adding any operation in this dialect.
Positioning in the Codegen Infrastructure Components of a Generic Retargetable Vector-Level Dialect Short Description of the Existing Infrastructure LLVM level Hardware Vector Ops Virtual Vector Ops Virtual Vector Rewrite Patterns Virtual Vector to Hardware Vector Lowering Rationale Hardware as vector Machines of Minimum Granularity Transformations Problems Avoided The Big Out-Of-Scope Piece: Automatic Vectorization Bikeshed Naming Discussion 0D Vectors LLVM Lowering Tradeoffs Alternatives For Lowering an n-D Vector Type to LLVM Constraints Inherited from LLVM (see LangRef) Nested Aggregate Flattened 1-D Vector Type Discussion Relationship to LLVM matrix type proposal.</description></item><item><title>'wasmssa' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/WasmSSAOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/WasmSSAOps/</guid><description>The wasmssa dialect is intended to represent WebAssembly modules in SSA form for easier manipulation.
Operations wasmssa.abs (wasmssa::AbsOp) wasmssa.add (wasmssa::AddOp) wasmssa.and (wasmssa::AndOp) wasmssa.block (wasmssa::BlockOp) wasmssa.block_return (wasmssa::BlockReturnOp) wasmssa.branch_if (wasmssa::BranchIfOp) wasmssa.call (wasmssa::FuncCallOp) wasmssa.ceil (wasmssa::CeilOp) wasmssa.clz (wasmssa::ClzOp) wasmssa.const (wasmssa::ConstOp) wasmssa.convert_s (wasmssa::ConvertSOp) wasmssa.convert_u (wasmssa::ConvertUOp) wasmssa.copysign (wasmssa::CopySignOp) wasmssa.ctz (wasmssa::CtzOp) wasmssa.demote (wasmssa::DemoteOp) wasmssa.div (wasmssa::DivOp) wasmssa.div_si (wasmssa::DivSIOp) wasmssa.div_ui (wasmssa::DivUIOp) wasmssa.eq (wasmssa::EqOp) wasmssa.eqz (wasmssa::EqzOp) wasmssa.extend (wasmssa::ExtendLowBitsSOp) wasmssa.extend_i32_s (wasmssa::ExtendSI32Op) wasmssa.extend_i32_u (wasmssa::ExtendUI32Op) wasmssa.floor (wasmssa::FloorOp) wasmssa.func (wasmssa::FuncOp) wasmssa.ge (wasmssa::GeOp) wasmssa.ge_si (wasmssa::GeSIOp) wasmssa.</description></item><item><title>'x86vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/X86Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/X86Vector/</guid><description>Operations x86vector.avx.bcst_to_f32.packed (x86vector::BcstToPackedF32Op) x86vector.avx.cvt.packed.even.indexed_to_f32 (x86vector::CvtPackedEvenIndexedToF32Op) x86vector.avx.cvt.packed.odd.indexed_to_f32 (x86vector::CvtPackedOddIndexedToF32Op) x86vector.avx.dot.i8 (x86vector::DotInt8Op) x86vector.avx.intr.dot (x86vector::DotOp) x86vector.avx.rsqrt (x86vector::RsqrtOp) x86vector.avx512.cvt.packed.f32_to_bf16 (x86vector::CvtPackedF32ToBF16Op) x86vector.avx512.dot (x86vector::DotBF16Op) x86vector.avx512.mask.compress (x86vector::MaskCompressOp) x86vector.avx512.mask.rndscale (x86vector::MaskRndScaleOp) x86vector.avx512.mask.scalef (x86vector::MaskScaleFOp) x86vector.avx512.vp2intersect (x86vector::Vp2IntersectOp) Operations source
x86vector.avx.bcst_to_f32.packed (x86vector::BcstToPackedF32Op) AVX: Broadcasts BF16/F16 into packed F32 Data.
Syntax:
operation ::= `x86vector.avx.bcst_to_f32.packed` $a attr-dict`:` type($a)`-&amp;gt;` type($dst) From the Intel Intrinsics Guide: Convert scalar BF16 or F16 (16-bit) floating-point element stored at memory locations starting at location __A to a single-precision (32-bit) floating-point, broadcast it to packed single-precision (32-bit) floating-point elements, and store the results in dst.</description></item><item><title>'xegpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/XeGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/XeGPU/</guid><description>The XeGPU dialect that models Intel GPU&amp;rsquo;s ISA
The XeGPU dialect closely models a subset of the Xe GPU&amp;rsquo;s ISA, providing an abstraction to support high-performance GEMM code generation. It serves as a bridge dialect in the MLIR gradual lowering process, working with MLIR memref and vector types, and complements the Arith, Math, Vector, and Memref dialects. XeGPU operations are introduced for special Xe instructions not modeled by the LLVM/SPIR-V dialect, such as DPAS and 2D block load and store.</description></item><item><title>'xevm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/XeVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/XeVMDialect/</guid><description>The XeVM dialect that extends LLVM dialect and models Intel GPU&amp;rsquo;s hardware features.
The XeVM dialect is extension to the LLVM dialect that models hardware features of Intel GPUs. The dialect is designed to work with the Xe architecture for Intel GPUs, supporting advanced operations like 2D block loads, stores, prefetch and matrix multiply-add (MMA) operations.
Operations xevm.blockload (xevm::BlockLoadOp) xevm.blockload2d (xevm::BlockLoad2dOp) xevm.blockprefetch2d (xevm::BlockPrefetch2dOp) xevm.blockstore (xevm::BlockStoreOp) xevm.blockstore2d (xevm::BlockStore2dOp) xevm.memfence (xevm::MemfenceOp) xevm.</description></item><item><title>Builtin Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Builtin/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Builtin/</guid><description>The builtin dialect contains a core set of Attributes, Operations, and Types that have wide applicability across a very large number of domains and abstractions. Many of the components of this dialect are also instrumental in the implementation of the core IR. As such, this dialect is implicitly loaded in every MLIRContext, and available directly to all users of MLIR.
Given the far-reaching nature of this dialect and the fact that MLIR is extensible by design, any potential additions are heavily scrutinized.</description></item><item><title>OpInterface definitions</title><link>https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/</guid><description> MatchOpInterface (MatchOpInterface) Methods:</description></item><item><title>SPIR-V Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SPIR-V/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SPIR-V/</guid><description>This document describes the design of the SPIR-V dialect in MLIR. It lists various design choices we made for modeling different SPIR-V mechanisms, and their rationale.
This document also explains in a high-level manner how different components are organized and implemented in the code and gives steps to follow for extending them.
This document assumes familiarity with SPIR-V. SPIR-V is the Khronos Group’s binary intermediate language for representing graphics shaders and compute kernels.</description></item><item><title>Tensor Operator Set Architecture (TOSA) Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TOSA/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TOSA/</guid><description>Rationale TOSA and Tensor Level Expressiveness Complete Minimal Numerical Precision TOSA Operator Rationale COND_IF and WHILE_LOOP Using TOSA In A Compiler Quantization Parameters in Ops vs Tensors Operation definitions tosa.abs (mlir::tosa::AbsOp) tosa.add (mlir::tosa::AddOp) tosa.apply_scale (mlir::tosa::ApplyScaleOp) tosa.argmax (mlir::tosa::ArgMaxOp) tosa.arithmetic_right_shift (mlir::tosa::ArithmeticRightShiftOp) tosa.avg_pool2d (mlir::tosa::AvgPool2dOp) tosa.bitwise_and (mlir::tosa::BitwiseAndOp) tosa.bitwise_not (mlir::tosa::BitwiseNotOp) tosa.bitwise_or (mlir::tosa::BitwiseOrOp) tosa.bitwise_xor (mlir::tosa::BitwiseXorOp) tosa.cast (mlir::tosa::CastOp) tosa.ceil (mlir::tosa::CeilOp) tosa.clamp (mlir::tosa::ClampOp) tosa.clz (mlir::tosa::ClzOp) tosa.concat (mlir::tosa::ConcatOp) tosa.const (mlir::tosa::ConstOp) tosa.const_shape (mlir::tosa::ConstShapeOp) tosa.conv2d (mlir::tosa::Conv2DOp) tosa.conv3d (mlir::tosa::Conv3DOp) tosa.cos (mlir::tosa::CosOp) tosa.</description></item><item><title>Transform Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Transform/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Transform/</guid><description>Fine-grain transformation control dialect. See tutorial for more introductory information.
Overview Dialect Extension Mechanism Side Effects Execution Model Handle Invalidation Intended Use and Integrations Effects on the Infrastructure Type Definitions AffineMapParamType AnyOpType AnyParamType AnyValueType OperationType ParamType TypeParamType Core Operations transform.alternatives (transform::AlternativesOp) transform.annotate (transform::AnnotateOp) transform.apply_patterns.canonicalization (transform::ApplyCanonicalizationPatternsOp) transform.apply_cse (transform::ApplyCommonSubexpressionEliminationOp) transform.apply_conversion_patterns (transform::ApplyConversionPatternsOp) transform.apply_dce (transform::ApplyDeadCodeEliminationOp) transform.apply_licm (transform::ApplyLoopInvariantCodeMotionOp) transform.apply_patterns (transform::ApplyPatternsOp) transform.apply_registered_pass (transform::ApplyRegisteredPassOp) transform.apply_conversion_patterns.dialect_to_llvm (transform::ApplyToLLVMConversionPatternsOp) transform.cast (transform::CastOp) transform.collect_matching (transform::CollectMatchingOp) transform.foreach_match (transform::ForeachMatchOp) transform.foreach (transform::ForeachOp) transform.get_consumers_of_result (transform::GetConsumersOfResult) transform.get_defining_op (transform::GetDefiningOp) transform.</description></item></channel></rss>