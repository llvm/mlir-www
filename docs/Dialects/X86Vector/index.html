<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>'x86vector' Dialect - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.119.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Dialects/X86Vector/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script>
<link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script>
<script src=https://mlir.llvm.org/js/bundle.js></script>
<script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li></ul></li><li><a href="https://github.com/llvm/llvm-project/issues?q=is%3Aissue%20state%3Aopen%20label%3Amlir">Bugs</a></li><li><a href=https://github.com/llvm/mlir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/MLIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>'x86vector' Dialect</h1><p><nav id=TableOfContents><ul><li><a href=#operations>Operations</a><ul><li><a href=#x86vectoravxbcst_to_f32packed-x86vectorbcsttopackedf32op><code>x86vector.avx.bcst_to_f32.packed</code> (x86vector::BcstToPackedF32Op)</a></li><li><a href=#x86vectoravxcvtpackedevenindexed_to_f32-x86vectorcvtpackedevenindexedtof32op><code>x86vector.avx.cvt.packed.even.indexed_to_f32</code> (x86vector::CvtPackedEvenIndexedToF32Op)</a></li><li><a href=#x86vectoravxcvtpackedoddindexed_to_f32-x86vectorcvtpackedoddindexedtof32op><code>x86vector.avx.cvt.packed.odd.indexed_to_f32</code> (x86vector::CvtPackedOddIndexedToF32Op)</a></li><li><a href=#x86vectoravxdoti8-x86vectordotint8op><code>x86vector.avx.dot.i8</code> (x86vector::DotInt8Op)</a></li><li><a href=#x86vectoravxintrdot-x86vectordotop><code>x86vector.avx.intr.dot</code> (x86vector::DotOp)</a></li><li><a href=#x86vectoravxrsqrt-x86vectorrsqrtop><code>x86vector.avx.rsqrt</code> (x86vector::RsqrtOp)</a></li><li><a href=#x86vectoravx512cvtpackedf32_to_bf16-x86vectorcvtpackedf32tobf16op><code>x86vector.avx512.cvt.packed.f32_to_bf16</code> (x86vector::CvtPackedF32ToBF16Op)</a></li><li><a href=#x86vectoravx512dot-x86vectordotbf16op><code>x86vector.avx512.dot</code> (x86vector::DotBF16Op)</a></li><li><a href=#x86vectoravx512maskcompress-x86vectormaskcompressop><code>x86vector.avx512.mask.compress</code> (x86vector::MaskCompressOp)</a></li><li><a href=#x86vectoravx512maskrndscale-x86vectormaskrndscaleop><code>x86vector.avx512.mask.rndscale</code> (x86vector::MaskRndScaleOp)</a></li><li><a href=#x86vectoravx512maskscalef-x86vectormaskscalefop><code>x86vector.avx512.mask.scalef</code> (x86vector::MaskScaleFOp)</a></li><li><a href=#x86vectoravx512vp2intersect-x86vectorvp2intersectop><code>x86vector.avx512.vp2intersect</code> (x86vector::Vp2IntersectOp)</a></li></ul></li></ul></nav><h2 id=operations>Operations&nbsp;<a class=headline-hash href=#operations>¶</a></h2><p><a href=https://github.com/llvm/llvm-project/blob/main/mlir/include/mlir/Dialect/X86Vector/X86Vector.td>source</a></p><h3 id=x86vectoravxbcst_to_f32packed-x86vectorbcsttopackedf32op><code>x86vector.avx.bcst_to_f32.packed</code> (x86vector::BcstToPackedF32Op)&nbsp;<a class=headline-hash href=#x86vectoravxbcst_to_f32packed-x86vectorbcsttopackedf32op>¶</a></h3><p><em>AVX: Broadcasts BF16/F16 into packed F32 Data.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx.bcst_to_f32.packed` $a  attr-dict`:` type($a)`-&gt;` type($dst)
</code></pre><h4 id=from-the-intel-intrinsics-guide>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide>¶</a></h4><p>Convert scalar BF16 or F16 (16-bit) floating-point element stored at memory locations
starting at location <code>__A</code> to a single-precision (32-bit) floating-point,
broadcast it to packed single-precision (32-bit) floating-point elements,
and store the results in <code>dst</code>.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%dst</span> <span class=p>=</span> x86vector<span class=p>.</span>avx<span class=p>.</span>bcst_to_f32<span class=p>.</span>packed <span class=nv>%a</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>bf16</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%dst</span> <span class=p>=</span> x86vector<span class=p>.</span>avx<span class=p>.</span>bcst_to_f32<span class=p>.</span>packed <span class=nv>%a</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f16</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Interfaces: <code>MemoryEffectOpInterface (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{MemoryEffects::Read on ::mlir::SideEffects::DefaultResource}</code></p><h4 id=operands>Operands:&nbsp;<a class=headline-hash href=#operands>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>memref of bfloat16 type or 16-bit float values</td></tr></tbody></table><h4 id=results>Results:&nbsp;<a class=headline-hash href=#results>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 32-bit float values of length 4/8</td></tr></tbody></table><h3 id=x86vectoravxcvtpackedevenindexed_to_f32-x86vectorcvtpackedevenindexedtof32op><code>x86vector.avx.cvt.packed.even.indexed_to_f32</code> (x86vector::CvtPackedEvenIndexedToF32Op)&nbsp;<a class=headline-hash href=#x86vectoravxcvtpackedevenindexed_to_f32-x86vectorcvtpackedevenindexedtof32op>¶</a></h3><p><em>AVX: Convert packed BF16/F16 even-indexed elements into packed F32 Data.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx.cvt.packed.even.indexed_to_f32` $a  attr-dict`:` type($a)`-&gt;` type($dst)
</code></pre><h4 id=from-the-intel-intrinsics-guide-1>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide-1>¶</a></h4><p>Convert packed BF16 or F16 (16-bit) floating-point even-indexed elements stored at
memory locations starting at location <code>__A</code> to packed single-precision
(32-bit) floating-point elements, and store the results in <code>dst</code>.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%dst</span> <span class=p>=</span> x86vector<span class=p>.</span>avx<span class=p>.</span>cvt<span class=p>.</span>packed<span class=p>.</span>even<span class=p>.</span><span class=k>index</span>ed_to_f32 <span class=nv>%a</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>bf16</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%dst</span> <span class=p>=</span> x86vector<span class=p>.</span>avx<span class=p>.</span>cvt<span class=p>.</span>packed<span class=p>.</span>even<span class=p>.</span><span class=k>index</span>ed_to_f32 <span class=nv>%a</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f16</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Interfaces: <code>MemoryEffectOpInterface (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{MemoryEffects::Read on ::mlir::SideEffects::DefaultResource}</code></p><h4 id=operands-1>Operands:&nbsp;<a class=headline-hash href=#operands-1>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>memref of bfloat16 type or 16-bit float values</td></tr></tbody></table><h4 id=results-1>Results:&nbsp;<a class=headline-hash href=#results-1>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 32-bit float values of length 4/8</td></tr></tbody></table><h3 id=x86vectoravxcvtpackedoddindexed_to_f32-x86vectorcvtpackedoddindexedtof32op><code>x86vector.avx.cvt.packed.odd.indexed_to_f32</code> (x86vector::CvtPackedOddIndexedToF32Op)&nbsp;<a class=headline-hash href=#x86vectoravxcvtpackedoddindexed_to_f32-x86vectorcvtpackedoddindexedtof32op>¶</a></h3><p><em>AVX: Convert packed BF16/F16 odd-indexed elements into packed F32 Data.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx.cvt.packed.odd.indexed_to_f32` $a  attr-dict`:` type($a)`-&gt;` type($dst)
</code></pre><h4 id=from-the-intel-intrinsics-guide-2>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide-2>¶</a></h4><p>Convert packed BF16 or F16 (16-bit) floating-point odd-indexed elements stored at
memory locations starting at location <code>__A</code> to packed single-precision
(32-bit) floating-point elements, and store the results in <code>dst</code>.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%dst</span> <span class=p>=</span> x86vector<span class=p>.</span>avx<span class=p>.</span>cvt<span class=p>.</span>packed<span class=p>.</span>odd<span class=p>.</span><span class=k>index</span>ed_to_f32 <span class=nv>%a</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>bf16</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%dst</span> <span class=p>=</span> x86vector<span class=p>.</span>avx<span class=p>.</span>cvt<span class=p>.</span>packed<span class=p>.</span>odd<span class=p>.</span><span class=k>index</span>ed_to_f32 <span class=nv>%a</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f16</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Interfaces: <code>MemoryEffectOpInterface (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{MemoryEffects::Read on ::mlir::SideEffects::DefaultResource}</code></p><h4 id=operands-2>Operands:&nbsp;<a class=headline-hash href=#operands-2>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>memref of bfloat16 type or 16-bit float values</td></tr></tbody></table><h4 id=results-2>Results:&nbsp;<a class=headline-hash href=#results-2>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 32-bit float values of length 4/8</td></tr></tbody></table><h3 id=x86vectoravxdoti8-x86vectordotint8op><code>x86vector.avx.dot.i8</code> (x86vector::DotInt8Op)&nbsp;<a class=headline-hash href=#x86vectoravxdoti8-x86vectordotint8op>¶</a></h3><p><em>Dot Int8 op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx.dot.i8` $w `,` $a `,` $b attr-dict `:` type($a) `-&gt;` type($w)
</code></pre><p>The <code>dot</code> op is an AVX2-Int8 specific op that can lower to the proper
LLVMAVX2-INT8 operation <code>llvm.vpdpbssd</code> depending on the width of MLIR
vectors it is applied to.</p><h4 id=from-the-intel-intrinsics-guide-3>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide-3>¶</a></h4><p>Multiply groups of 4 adjacent pairs of signed 8-bit integers in <code>a</code> with
corresponding signed 8-bit integers in <code>b</code>, producing 4 intermediate signed 16-bit
results. Sum these 4 results with the corresponding 32-bit integer in <code>w</code>, and
store the packed 32-bit results in <code>dst</code>.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%dst</span> <span class=p>=</span> x86vector<span class=p>.</span>avx<span class=p>.</span>dot<span class=p>.</span><span class=k>i8</span> <span class=nv>%w</span><span class=p>,</span> <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>i8</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-3>Operands:&nbsp;<a class=headline-hash href=#operands-3>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>w</code></td><td>vector of 32-bit signless integer values of length 4/8</td></tr><tr><td style=text-align:center><code>a</code></td><td>vector of 8-bit signless integer values of length 16/32</td></tr><tr><td style=text-align:center><code>b</code></td><td>vector of 8-bit signless integer values of length 16/32</td></tr></tbody></table><h4 id=results-3>Results:&nbsp;<a class=headline-hash href=#results-3>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 32-bit signless integer values of length 4/8</td></tr></tbody></table><h3 id=x86vectoravxintrdot-x86vectordotop><code>x86vector.avx.intr.dot</code> (x86vector::DotOp)&nbsp;<a class=headline-hash href=#x86vectoravxintrdot-x86vectordotop>¶</a></h3><p><em>Dot</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx.intr.dot` $a `,` $b attr-dict `:` type($res)
</code></pre><p>Computes the 4-way dot products of the lower and higher parts of the source
vectors and broadcasts the two results to the lower and higher elements of
the destination vector, respectively. Adding one element of the lower part
to one element of the higher part in the destination vector yields the full
dot product of the two source vectors.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%0</span> <span class=p>=</span> x86vector<span class=p>.</span>avx<span class=p>.</span>intr<span class=p>.</span>dot <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=k>f32</span> from <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=nv>%i4</span><span class=p>]</span> <span class=p>:</span> <span class=k>f32</span> from <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%d</span> <span class=p>=</span> arith<span class=p>.</span>addf <span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span> <span class=p>:</span> <span class=k>f32</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>SameOperandsAndResultType</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-4>Operands:&nbsp;<a class=headline-hash href=#operands-4>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>vector of 32-bit float values of length 8</td></tr><tr><td style=text-align:center><code>b</code></td><td>vector of 32-bit float values of length 8</td></tr></tbody></table><h4 id=results-4>Results:&nbsp;<a class=headline-hash href=#results-4>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>vector of 32-bit float values of length 8</td></tr></tbody></table><h3 id=x86vectoravxrsqrt-x86vectorrsqrtop><code>x86vector.avx.rsqrt</code> (x86vector::RsqrtOp)&nbsp;<a class=headline-hash href=#x86vectoravxrsqrt-x86vectorrsqrtop>¶</a></h3><p><em>Rsqrt</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx.rsqrt` $a attr-dict `:` type($a)
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>SameOperandsAndResultType</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-5>Operands:&nbsp;<a class=headline-hash href=#operands-5>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>vector of 32-bit float values of length 8</td></tr></tbody></table><h4 id=results-5>Results:&nbsp;<a class=headline-hash href=#results-5>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>b</code></td><td>vector of 32-bit float values of length 8</td></tr></tbody></table><h3 id=x86vectoravx512cvtpackedf32_to_bf16-x86vectorcvtpackedf32tobf16op><code>x86vector.avx512.cvt.packed.f32_to_bf16</code> (x86vector::CvtPackedF32ToBF16Op)&nbsp;<a class=headline-hash href=#x86vectoravx512cvtpackedf32_to_bf16-x86vectorcvtpackedf32tobf16op>¶</a></h3><p><em>Convert packed F32 to packed BF16 Data.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx512.cvt.packed.f32_to_bf16` $a attr-dict `:` type($a) `-&gt;` type($dst)
</code></pre><p>The <code>convert_f32_to_bf16</code> op is an AVX512-BF16 specific op that can lower
to the proper LLVMAVX512BF16 operation <code>llvm.cvtneps2bf16</code> depending on
the width of MLIR vectors it is applied to.</p><h4 id=from-the-intel-intrinsics-guide-4>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide-4>¶</a></h4><p>Convert packed single-precision (32-bit) floating-point elements in <code>a</code> to
packed BF16 (16-bit) floating-point elements, and store the results in <code>dst</code>.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%dst</span> <span class=p>=</span> x86vector<span class=p>.</span>avx512<span class=p>.</span>cvt<span class=p>.</span>packed<span class=p>.</span><span class=k>f32</span>_to_bf16 <span class=nv>%a</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>bf16</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-6>Operands:&nbsp;<a class=headline-hash href=#operands-6>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>vector of 32-bit float values of length 8/16</td></tr></tbody></table><h4 id=results-6>Results:&nbsp;<a class=headline-hash href=#results-6>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of bfloat16 type values of length 8/16</td></tr></tbody></table><h3 id=x86vectoravx512dot-x86vectordotbf16op><code>x86vector.avx512.dot</code> (x86vector::DotBF16Op)&nbsp;<a class=headline-hash href=#x86vectoravx512dot-x86vectordotbf16op>¶</a></h3><p><em>Dot BF16 op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx512.dot` $src `,` $a `,` $b attr-dict `:` type($a) `-&gt;` type($src)
</code></pre><p>The <code>dot</code> op is an AVX512-BF16 specific op that can lower to the proper
LLVMAVX512BF16 operation <code>llvm.dpbf16ps</code> depending on the width of MLIR
vectors it is applied to.</p><h4 id=from-the-intel-intrinsics-guide-5>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide-5>¶</a></h4><p>Compute dot-product of BF16 (16-bit) floating-point pairs in <code>a</code> and <code>b</code>,
accumulating the intermediate single-precision (32-bit) floating-point
elements with elements in <code>src</code>, and store the results in <code>dst</code>.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%dst</span> <span class=p>=</span> x86vector<span class=p>.</span>avx512<span class=p>.</span>dot <span class=nv>%src</span><span class=p>,</span> <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>bf16</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-7>Operands:&nbsp;<a class=headline-hash href=#operands-7>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>vector of 32-bit float values of length 4/8/16</td></tr><tr><td style=text-align:center><code>a</code></td><td>vector of bfloat16 type values of length 8/16/32</td></tr><tr><td style=text-align:center><code>b</code></td><td>vector of bfloat16 type values of length 8/16/32</td></tr></tbody></table><h4 id=results-7>Results:&nbsp;<a class=headline-hash href=#results-7>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 32-bit float values of length 4/8/16</td></tr></tbody></table><h3 id=x86vectoravx512maskcompress-x86vectormaskcompressop><code>x86vector.avx512.mask.compress</code> (x86vector::MaskCompressOp)&nbsp;<a class=headline-hash href=#x86vectoravx512maskcompress-x86vectormaskcompressop>¶</a></h3><p><em>Masked compress op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx512.mask.compress` $k `,` $a (`,` $src^)? attr-dict `:` type($dst) (`,` type($src)^)?
</code></pre><p>The mask.compress op is an AVX512 specific op that can lower to the
<code>llvm.mask.compress</code> instruction. Instead of <code>src</code>, a constant vector
vector attribute <code>constant_src</code> may be specified. If neither <code>src</code> nor
<code>constant_src</code> is specified, the remaining elements in the result vector are
set to zero.</p><h4 id=from-the-intel-intrinsics-guide-6>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide-6>¶</a></h4><p>Contiguously store the active integer/floating-point elements in <code>a</code> (those
with their respective bit set in writemask <code>k</code>) to <code>dst</code>, and pass through the
remaining elements from <code>src</code>.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes>Attributes:&nbsp;<a class=headline-hash href=#attributes>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>constant_src</code></td><td>::mlir::ElementsAttr</td><td>constant vector/tensor attribute</td></tr></table><h4 id=operands-8>Operands:&nbsp;<a class=headline-hash href=#operands-8>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>k</code></td><td>vector of 1-bit signless integer values of length 16/8</td></tr><tr><td style=text-align:center><code>a</code></td><td>vector of 32-bit float or 32-bit signless integer or 64-bit float or 64-bit signless integer values of length 16/8</td></tr><tr><td style=text-align:center><code>src</code></td><td>vector of 32-bit float or 32-bit signless integer or 64-bit float or 64-bit signless integer values of length 16/8</td></tr></tbody></table><h4 id=results-8>Results:&nbsp;<a class=headline-hash href=#results-8>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 32-bit float or 32-bit signless integer or 64-bit float or 64-bit signless integer values of length 16/8</td></tr></tbody></table><h3 id=x86vectoravx512maskrndscale-x86vectormaskrndscaleop><code>x86vector.avx512.mask.rndscale</code> (x86vector::MaskRndScaleOp)&nbsp;<a class=headline-hash href=#x86vectoravx512maskrndscale-x86vectormaskrndscaleop>¶</a></h3><p><em>Masked roundscale op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx512.mask.rndscale` $src `,` $k `,` $a `,` $imm `,` $rounding attr-dict `:` type($dst)
</code></pre><p>The mask.rndscale op is an AVX512 specific op that can lower to the proper
LLVMAVX512 operation: <code>llvm.mask.rndscale.ps.512</code> or
<code>llvm.mask.rndscale.pd.512</code> instruction depending on the type of vectors it
is applied to.</p><h4 id=from-the-intel-intrinsics-guide-7>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide-7>¶</a></h4><p>Round packed floating-point elements in <code>a</code> to the number of fraction bits
specified by <code>imm</code>, and store the results in <code>dst</code> using writemask <code>k</code>
(elements are copied from src when the corresponding mask bit is not set).</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-9>Operands:&nbsp;<a class=headline-hash href=#operands-9>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>vector of 32-bit float or 64-bit float values of length 16/8</td></tr><tr><td style=text-align:center><code>k</code></td><td>32-bit signless integer</td></tr><tr><td style=text-align:center><code>a</code></td><td>vector of 32-bit float or 64-bit float values of length 16/8</td></tr><tr><td style=text-align:center><code>imm</code></td><td>16-bit signless integer or 8-bit signless integer</td></tr><tr><td style=text-align:center><code>rounding</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-9>Results:&nbsp;<a class=headline-hash href=#results-9>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 32-bit float or 64-bit float values of length 16/8</td></tr></tbody></table><h3 id=x86vectoravx512maskscalef-x86vectormaskscalefop><code>x86vector.avx512.mask.scalef</code> (x86vector::MaskScaleFOp)&nbsp;<a class=headline-hash href=#x86vectoravx512maskscalef-x86vectormaskscalefop>¶</a></h3><p><em>ScaleF op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx512.mask.scalef` $src `,` $a `,` $b `,` $k `,` $rounding attr-dict `:` type($dst)
</code></pre><p>The <code>mask.scalef</code> op is an AVX512 specific op that can lower to the proper
LLVMAVX512 operation: <code>llvm.mask.scalef.ps.512</code> or
<code>llvm.mask.scalef.pd.512</code> depending on the type of MLIR vectors it is
applied to.</p><h4 id=from-the-intel-intrinsics-guide-8>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide-8>¶</a></h4><p>Scale the packed floating-point elements in <code>a</code> using values from <code>b</code>, and
store the results in <code>dst</code> using writemask <code>k</code> (elements are copied from src
when the corresponding mask bit is not set).</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-10>Operands:&nbsp;<a class=headline-hash href=#operands-10>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>src</code></td><td>vector of 32-bit float or 64-bit float values of length 16/8</td></tr><tr><td style=text-align:center><code>a</code></td><td>vector of 32-bit float or 64-bit float values of length 16/8</td></tr><tr><td style=text-align:center><code>b</code></td><td>vector of 32-bit float or 64-bit float values of length 16/8</td></tr><tr><td style=text-align:center><code>k</code></td><td>16-bit signless integer or 8-bit signless integer</td></tr><tr><td style=text-align:center><code>rounding</code></td><td>32-bit signless integer</td></tr></tbody></table><h4 id=results-10>Results:&nbsp;<a class=headline-hash href=#results-10>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dst</code></td><td>vector of 32-bit float or 64-bit float values of length 16/8</td></tr></tbody></table><h3 id=x86vectoravx512vp2intersect-x86vectorvp2intersectop><code>x86vector.avx512.vp2intersect</code> (x86vector::Vp2IntersectOp)&nbsp;<a class=headline-hash href=#x86vectoravx512vp2intersect-x86vectorvp2intersectop>¶</a></h3><p><em>Vp2Intersect op</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `x86vector.avx512.vp2intersect` $a `,` $b attr-dict `:` type($a)
</code></pre><p>The <code>vp2intersect</code> op is an AVX512 specific op that can lower to the proper
LLVMAVX512 operation: <code>llvm.vp2intersect.d.512</code> or
<code>llvm.vp2intersect.q.512</code> depending on the type of MLIR vectors it is
applied to.</p><h4 id=from-the-intel-intrinsics-guide-9>From the Intel Intrinsics Guide:&nbsp;<a class=headline-hash href=#from-the-intel-intrinsics-guide-9>¶</a></h4><p>Compute intersection of packed integer vectors <code>a</code> and <code>b</code>, and store
indication of match in the corresponding bit of two mask registers
specified by <code>k1</code> and <code>k2</code>. A match in corresponding elements of <code>a</code> and
<code>b</code> is indicated by a set bit in the corresponding bit of the mask
registers.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OneToOneIntrinsicOpInterface</code>, <code>X86IntrinsicOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-11>Operands:&nbsp;<a class=headline-hash href=#operands-11>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>a</code></td><td>vector of 32-bit signless integer or 64-bit signless integer values of length 16/8</td></tr><tr><td style=text-align:center><code>b</code></td><td>vector of 32-bit signless integer or 64-bit signless integer values of length 16/8</td></tr></tbody></table><h4 id=results-11>Results:&nbsp;<a class=headline-hash href=#results-11>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>k1</code></td><td>vector of 1-bit signless integer values of length 16/8</td></tr><tr><td style=text-align:center><code>k2</code></td><td>vector of 1-bit signless integer values of length 16/8</td></tr></tbody></table><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=https://mlir.llvm.org/docs/Dialects/Vector/ title="'vector' Dialect"><i class="fas fa-arrow-left" aria-hidden=true></i> Prev - 'vector' Dialect</a>
<a class="nav nav-next" href=https://mlir.llvm.org/docs/Dialects/XeGPU/ title="'xegpu' Dialect">Next - 'xegpu' Dialect <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=https://mlir.llvm.org/governance/>Governance</a></li><li><a href=https://mlir.llvm.org/users/>Users of MLIR</a></li><li><a href=https://mlir.llvm.org/pubs/>MLIR Related Publications</a></li><li><a href=https://mlir.llvm.org/talks/>Talks</a></li><li><a href=https://mlir.llvm.org/deprecation/>Deprecations & Current Refactoring</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/getting_started/ReportingIssues/>Reporting Issues</a></li><li><a href=https://mlir.llvm.org/getting_started/Debugging/>Debugging Tips</a></li><li><a href=https://mlir.llvm.org/getting_started/Faq/>FAQ</a></li><li><a href=https://mlir.llvm.org/getting_started/Contributing/>How to Contribute</a></li><li><a href=https://mlir.llvm.org/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=https://mlir.llvm.org/getting_started/openprojects/>Open Projects</a></li><li><a href=https://mlir.llvm.org/getting_started/Glossary/>Glossary</a></li><li><a href=https://mlir.llvm.org/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-reduce/>MLIR Reduce</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-rewrite/>mlir-rewrite</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/ActionTracing/>Action: Tracing and Debugging MLIR-based Compilers</a></li><li><a href=https://mlir.llvm.org/docs/Bufferization/>Bufferization</a></li><li><a href=https://mlir.llvm.org/docs/DataLayout/>Data Layout Modeling</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/DefiningDialects/>Defining Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Constraints/>Constraints</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Assembly/>Customizing Assembly Behavior</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Operations/>Operation Definition Specification (ODS)</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/DialectConversion/>Dialect Conversion</a></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/Dialects/>Dialects<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMDGPU/>'amdgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArithOps/>'arith' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSME/>'ArmSME' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/BufferizationOps/>'bufferization' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/>'cf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/DLTIDialect/>'dlti' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/EmitC/>'emitc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Func/>'func' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IndexOps/>'index' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IRDL/>'irdl' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/Linalg/>'linalg' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/>Linalg OpDSL</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MLProgramOps/>'ml_program' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MPI/>'mpi' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVGPU/>'nvgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/>'omp' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/ODS/>ODS Documentation</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PtrOps/>'ptr' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Shard/>'shard' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SMT/>'smt' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/UBOps/>'ub' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/VCIXDialect/>'vcix' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Vector/>'vector' Dialect</a></li><li class=active><a href=https://mlir.llvm.org/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeGPU/>'xegpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeVMDialect/>'xevm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/>OpInterface definitions</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SPIR-V/>SPIR-V Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Transform/>Transform Dialect</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Interfaces/>Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/TargetLLVMIR/>LLVM IR Target</a></li><li><a href=https://mlir.llvm.org/docs/BytecodeFormat/>MLIR Bytecode Format</a></li><li><a href=https://mlir.llvm.org/docs/CAPI/>MLIR C API</a></li><li><a href=https://mlir.llvm.org/docs/LangRef/>MLIR Language Reference</a></li><li><a href=https://mlir.llvm.org/docs/ReleaseNotes/>MLIR Release Notes</a></li><li><a href=https://mlir.llvm.org/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=https://mlir.llvm.org/docs/OwnershipBasedBufferDeallocation/>Ownership-based Buffer Deallocation</a></li><li><a href=https://mlir.llvm.org/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/Passes/>Passes</a></li><li><a href=https://mlir.llvm.org/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=https://mlir.llvm.org/docs/PDLL/>PDLL - PDL Language</a></li><li><a href=https://mlir.llvm.org/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/SideEffectsAndSpeculation/>Side Effects & Speculation</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/ShapeInference/>Shape Inference</a></li><li><a href=https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=https://mlir.llvm.org/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=https://mlir.llvm.org/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Traits/>Traits<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Traits/Broadcastable/>The `Broadcastable` Trait</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/transform/>Transform Dialect Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch0/>Chapter 0: A Primer on “Structured” Linalg Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch1/>Chapter 1: Combining Existing Transformations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch2/>Chapter 2: Adding a Simple New Transformation Operation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch3/>Chapter 3: More than Simple Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch4/>Chapter 4: Matching Payload with Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/ChH/>Chapter H: Reproducing Halide Schedule</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/MlirOpt/>Using `mlir-opt`</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>