<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>'vector' Dialect - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.119.0"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Dialects/Vector/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script>
<link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script>
<script src=https://mlir.llvm.org/js/bundle.js></script>
<script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type=text/x-mathjax-config>
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
    }
  });
</script><link rel=apple-touch-icon sizes=180x180 href="/apple-touch-icon.png?v=1"><link rel=icon type=image/png sizes=32x32 href="/favicon-32x32.png?v=1"><link rel=icon type=image/png sizes=16x16 href="/favicon-16x16.png?v=1"><link rel=manifest href="/site.webmanifest?v=1"><link rel=mask-icon href="/safari-pinned-tab.svg?v=1" color=#3775e0><link rel="shortcut icon" href="/favicon.ico?v=1"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#ffffff"><link rel=icon href=/favicon.svg type=image/svg+xml sizes=any><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging Tips</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/main/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/main/mlir>GitHub</a></li></ul></li><li><a href="https://github.com/llvm/llvm-project/issues?q=is%3Aissue%20state%3Aopen%20label%3Amlir">Bugs</a></li><li><a href=https://github.com/llvm/mlir-www/tree/main/website/static/LogoAssets>Logo Assets</a></li><li><a href=https://www.youtube.com/MLIRCompiler>Youtube Channel</a></li></ul></nav></div><div class=content-container><main><h1>'vector' Dialect</h1><p><strong>Please post an RFC on the
<a href=https://llvm.discourse.group/c/mlir/31>forum</a>
before adding any operation in this dialect.</strong></p><p><nav id=TableOfContents><ul><li><a href=#positioning-in-the-codegen-infrastructure>Positioning in the Codegen Infrastructure</a></li><li><a href=#components-of-a-generic-retargetable-vector-level-dialect>Components of a Generic Retargetable Vector-Level Dialect</a></li><li><a href=#short-description-of-the-existing-infrastructure>Short Description of the Existing Infrastructure</a><ul><li><a href=#llvm-level>LLVM level</a></li><li><a href=#hardware-vector-ops>Hardware Vector Ops</a></li><li><a href=#virtual-vector-ops>Virtual Vector Ops</a></li><li><a href=#virtual-vector-rewrite-patterns>Virtual Vector Rewrite Patterns</a></li><li><a href=#virtual-vector-to-hardware-vector-lowering>Virtual Vector to Hardware Vector Lowering</a></li></ul></li><li><a href=#rationale>Rationale</a><ul><li><a href=#hardware-as-vector-machines-of-minimum-granularity>Hardware as <code>vector</code> Machines of Minimum Granularity</a></li><li><a href=#transformations-problems-avoided>Transformations Problems Avoided</a></li><li><a href=#the-big-out-of-scope-piece-automatic-vectorization>The Big Out-Of-Scope Piece: Automatic Vectorization</a></li></ul></li><li><a href=#bikeshed-naming-discussion>Bikeshed Naming Discussion</a></li><li><a href=#0d-vectors>0D Vectors</a></li><li><a href=#llvm-lowering-tradeoffs>LLVM Lowering Tradeoffs</a><ul><li><a href=#alternatives-for-lowering-an-n-d-vector-type-to-llvm>Alternatives For Lowering an n-D Vector Type to LLVM</a></li><li><a href=#constraints-inherited-from-llvm-see-langref>Constraints Inherited from LLVM (see LangRef)</a></li><li><a href=#nested-aggregate>Nested Aggregate</a></li><li><a href=#flattened-1-d-vector-type>Flattened 1-D Vector Type</a></li><li><a href=#discussion>Discussion</a></li><li><a href=#relationship-to-llvm-matrix-type-proposal>Relationship to LLVM matrix type proposal.</a></li><li><a href=#conclusion>Conclusion</a></li></ul></li><li><a href=#operations>Operations</a><ul><li><a href=#vectorvscale-vectorvectorscaleop><code>vector.vscale</code> (vector::VectorScaleOp)</a></li><li><a href=#vectorbitcast-vectorbitcastop><code>vector.bitcast</code> (vector::BitCastOp)</a></li><li><a href=#vectorbroadcast-vectorbroadcastop><code>vector.broadcast</code> (vector::BroadcastOp)</a></li><li><a href=#vectorcompressstore-vectorcompressstoreop><code>vector.compressstore</code> (vector::CompressStoreOp)</a></li><li><a href=#vectorconstant_mask-vectorconstantmaskop><code>vector.constant_mask</code> (vector::ConstantMaskOp)</a></li><li><a href=#vectorcontract-vectorcontractionop><code>vector.contract</code> (vector::ContractionOp)</a></li><li><a href=#vectorcreate_mask-vectorcreatemaskop><code>vector.create_mask</code> (vector::CreateMaskOp)</a></li><li><a href=#vectordeinterleave-vectordeinterleaveop><code>vector.deinterleave</code> (vector::DeinterleaveOp)</a></li><li><a href=#vectorexpandload-vectorexpandloadop><code>vector.expandload</code> (vector::ExpandLoadOp)</a></li><li><a href=#vectorextract-vectorextractop><code>vector.extract</code> (vector::ExtractOp)</a></li><li><a href=#vectorextract_strided_slice-vectorextractstridedsliceop><code>vector.extract_strided_slice</code> (vector::ExtractStridedSliceOp)</a></li><li><a href=#vectorfma-vectorfmaop><code>vector.fma</code> (vector::FMAOp)</a></li><li><a href=#vectorfrom_elements-vectorfromelementsop><code>vector.from_elements</code> (vector::FromElementsOp)</a></li><li><a href=#vectorgather-vectorgatherop><code>vector.gather</code> (vector::GatherOp)</a></li><li><a href=#vectorinsert-vectorinsertop><code>vector.insert</code> (vector::InsertOp)</a></li><li><a href=#vectorinsert_strided_slice-vectorinsertstridedsliceop><code>vector.insert_strided_slice</code> (vector::InsertStridedSliceOp)</a></li><li><a href=#vectorinterleave-vectorinterleaveop><code>vector.interleave</code> (vector::InterleaveOp)</a></li><li><a href=#vectorload-vectorloadop><code>vector.load</code> (vector::LoadOp)</a></li><li><a href=#vectormask-vectormaskop><code>vector.mask</code> (vector::MaskOp)</a></li><li><a href=#vectormaskedload-vectormaskedloadop><code>vector.maskedload</code> (vector::MaskedLoadOp)</a></li><li><a href=#vectormaskedstore-vectormaskedstoreop><code>vector.maskedstore</code> (vector::MaskedStoreOp)</a></li><li><a href=#vectormulti_reduction-vectormultidimreductionop><code>vector.multi_reduction</code> (vector::MultiDimReductionOp)</a></li><li><a href=#vectorouterproduct-vectorouterproductop><code>vector.outerproduct</code> (vector::OuterProductOp)</a></li><li><a href=#vectorprint-vectorprintop><code>vector.print</code> (vector::PrintOp)</a></li><li><a href=#vectorreduction-vectorreductionop><code>vector.reduction</code> (vector::ReductionOp)</a></li><li><a href=#vectorscalableextract-vectorscalableextractop><code>vector.scalable.extract</code> (vector::ScalableExtractOp)</a></li><li><a href=#vectorscalableinsert-vectorscalableinsertop><code>vector.scalable.insert</code> (vector::ScalableInsertOp)</a></li><li><a href=#vectorscan-vectorscanop><code>vector.scan</code> (vector::ScanOp)</a></li><li><a href=#vectorscatter-vectorscatterop><code>vector.scatter</code> (vector::ScatterOp)</a></li><li><a href=#vectorshape_cast-vectorshapecastop><code>vector.shape_cast</code> (vector::ShapeCastOp)</a></li><li><a href=#vectorshuffle-vectorshuffleop><code>vector.shuffle</code> (vector::ShuffleOp)</a></li><li><a href=#vectorsplat-vectorsplatop><code>vector.splat</code> (vector::SplatOp)</a></li><li><a href=#vectorstep-vectorstepop><code>vector.step</code> (vector::StepOp)</a></li><li><a href=#vectorstore-vectorstoreop><code>vector.store</code> (vector::StoreOp)</a></li><li><a href=#vectorto_elements-vectortoelementsop><code>vector.to_elements</code> (vector::ToElementsOp)</a></li><li><a href=#vectortransfer_read-vectortransferreadop><code>vector.transfer_read</code> (vector::TransferReadOp)</a></li><li><a href=#vectortransfer_write-vectortransferwriteop><code>vector.transfer_write</code> (vector::TransferWriteOp)</a></li><li><a href=#vectortranspose-vectortransposeop><code>vector.transpose</code> (vector::TransposeOp)</a></li><li><a href=#vectortype_cast-vectortypecastop><code>vector.type_cast</code> (vector::TypeCastOp)</a></li><li><a href=#vectoryield-vectoryieldop><code>vector.yield</code> (vector::YieldOp)</a></li></ul></li></ul></nav><p>MLIR supports multi-dimensional <code>vector</code> types and custom operations on those
types. A generic, retargetable, higher-order <code>vector</code> type (<code>n-D</code> with <code>n > 1</code>)
is a structured type, that carries semantic information useful for
transformations. This document discusses retargetable abstractions that exist in
MLIR today and operate on ssa-values of type <code>vector</code> along with pattern
rewrites and lowerings that enable targeting specific instructions on concrete
targets. These abstractions serve to separate concerns between operations on
<code>memref</code> (a.k.a buffers) and operations on <code>vector</code> values. This is not a new
proposal but rather a textual documentation of existing MLIR components along
with a rationale.</p><h2 id=positioning-in-the-codegen-infrastructure>Positioning in the Codegen Infrastructure&nbsp;<a class=headline-hash href=#positioning-in-the-codegen-infrastructure>¶</a></h2><p>The following diagram, recently presented with the
<a href=https://drive.google.com/corp/drive/u/0/folders/1sRAsgsd8Bvpm_IxREmZf2agsGU2KvrK->StructuredOps abstractions</a>,
captures the current codegen paths implemented in MLIR in the various existing
lowering paths.
<img src=https://user-images.githubusercontent.com/10148468/71177417-f78e4d80-2239-11ea-92ef-700f42ea503f.png alt></p><p>The following diagram seeks to isolate <code>vector</code> dialects from the complexity of
the codegen paths and focus on the payload-carrying ops that operate on std and
<code>vector</code> types. This diagram is not to be taken as set in stone and
representative of what exists today but rather illustrates the layering of
abstractions in MLIR.</p><p><img src=https://user-images.githubusercontent.com/10148468/71176949-e85ad000-2238-11ea-9806-200843bc4943.png alt="vector Abstractions in MLIR"></p><p>This  separates concerns related to (a) defining efficient operations on
<code>vector</code> types from (b) program analyses + transformations on <code>memref</code>, loops
and other types of structured ops (be they <code>HLO</code>, <code>LHLO</code>, <code>Linalg</code> or other ).
Looking a bit forward in time, we can put a stake in the ground and venture that
the higher level of <code>vector</code>-level primitives we build and target from codegen
(or some user/language level), the simpler our task will be, the more complex
patterns can be expressed and the better performance will be.</p><h2 id=components-of-a-generic-retargetable-vector-level-dialect>Components of a Generic Retargetable Vector-Level Dialect&nbsp;<a class=headline-hash href=#components-of-a-generic-retargetable-vector-level-dialect>¶</a></h2><p>The existing MLIR <code>vector</code>-level dialects are related to the following bottom-up
abstractions:</p><ol><li>Representation in <code>LLVMIR</code> via data structures, instructions and intrinsics.
This is referred to as the <code>LLVM</code> level.</li><li>Set of machine-specific operations and types that are built to translate
almost 1-1 with the HW ISA. This is referred to as the Hardware Vector
level; a.k.a <code>HWV</code>. For instance, we have (a) the <code>NVVM</code> dialect (for
<code>CUDA</code>) with tensor core ops, (b) accelerator-specific dialects (internal),
a potential (future) <code>CPU</code> dialect to capture <code>LLVM</code> intrinsics more closely
and other dialects for specific hardware. Ideally this should be
auto-generated as much as possible from the <code>LLVM</code> level.</li><li>Set of virtual, machine-agnostic, operations that are informed by costs at
the <code>HWV</code>-level. This is referred to as the Virtual Vector level; a.k.a
<code>VV</code>. This is the level that higher-level abstractions (codegen, automatic
vectorization, potential vector language, &mldr;) targets.</li></ol><p>The existing generic, retargetable, <code>vector</code>-level dialect is related to the
following top-down rewrites and conversions:</p><ol><li>MLIR Rewrite Patterns applied by the MLIR <code>PatternRewrite</code> infrastructure to
progressively lower to implementations that match closer and closer to the
<code>HWV</code>. Some patterns are &ldquo;in-dialect&rdquo; <code>VV -> VV</code> and some are conversions
<code>VV -> HWV</code>.</li><li><code>Virtual Vector -> Hardware Vector</code> lowering is specified as a set of MLIR
lowering patterns that are specified manually for now.</li><li><code>Hardware Vector -> LLVM</code> lowering is a mechanical process that is written
manually at the moment and that should be automated, following the <code>LLVM -> Hardware Vector</code> ops generation as closely as possible.</li></ol><h2 id=short-description-of-the-existing-infrastructure>Short Description of the Existing Infrastructure&nbsp;<a class=headline-hash href=#short-description-of-the-existing-infrastructure>¶</a></h2><h3 id=llvm-level>LLVM level&nbsp;<a class=headline-hash href=#llvm-level>¶</a></h3><p>On CPU, the <code>n-D</code> <code>vector</code> type currently lowers to <code>!llvm&lt;array&lt;vector>></code>.
More concretely,</p><ul><li><code>vector&lt;4x8x128xf32></code> lowers to <code>!llvm&lt;[4 x [ 8 x &lt; 128 x float >]]></code> (fixed-width vector), and</li><li><code>vector&lt;4x8x[128]xf32></code> lowers to <code>!llvm&lt;[4 x [ 8 x &lt; vscale x 128 x float >]]></code> (scalable vector).</li></ul><p>There are tradeoffs involved related to how one can access subvectors and how
one uses <code>llvm.extractelement</code>, <code>llvm.insertelement</code> and <code>llvm.shufflevector</code>.
The section on
<a href=#llvm-lowering-tradeoffs>LLVM Lowering Tradeoffs</a> offers a
deeper dive into the current design choices and tradeoffs.</p><p>Note, while LLVM supports arrarys of scalable vectors, these are required to be
fixed-width arrays of 1-D scalable vectors. This means scalable vectors with a
non-trailing scalable dimension (e.g. <code>vector&lt;4x[8]x128xf32</code>) are not
convertible to LLVM.</p><p>Finally, MLIR takes the same view on scalable Vectors as LLVM (c.f.
<a href=https://llvm.org/docs/LangRef.html#vector-type>VectorType</a>):</p><blockquote><p>For scalable vectors, the total number of elements is a constant multiple
(called vscale) of the specified number of elements; vscale is a positive
integer that is unknown at compile time and the same hardware-dependent
constant for all scalable vectors at run time. The size of a specific
scalable vector type is thus constant within IR, even if the exact size in
bytes cannot be determined until run time.</p></blockquote><h3 id=hardware-vector-ops>Hardware Vector Ops&nbsp;<a class=headline-hash href=#hardware-vector-ops>¶</a></h3><p>Hardware Vector Ops are implemented as one dialect per target. For internal
hardware, we are auto-generating the specific HW dialects. For <code>GPU</code>, the <code>NVVM</code>
dialect adds operations such as <code>mma.sync</code>, <code>shfl</code> and tests. For <code>CPU</code> things
are somewhat in-flight because the abstraction is close to <code>LLVMIR</code>. The jury is
still out on  whether a generic <code>CPU</code> dialect is concretely needed, but it seems
reasonable to have the same levels of abstraction for all targets and perform
cost-based lowering decisions in MLIR even for <code>LLVM</code>. Specialized <code>CPU</code>
dialects that would capture specific features not well captured by LLVM peephole
optimizations of on different types that core MLIR supports (e.g. Scalable
Vectors) are welcome future extensions.</p><h3 id=virtual-vector-ops>Virtual Vector Ops&nbsp;<a class=headline-hash href=#virtual-vector-ops>¶</a></h3><p>Some existing Arith and Vector Dialect on <code>n-D</code> <code>vector</code> types comprise:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// Produces a vector&lt;3x7x8xf32&gt;
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%a</span> <span class=p>=</span> arith<span class=p>.</span>addf <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x7x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// Produces a vector&lt;3x7x8xf32&gt;
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%b</span> <span class=p>=</span> arith<span class=p>.</span>mulf <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x7x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// Produces a vector&lt;3x7x8xf32&gt;
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%c</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>splat <span class=nv>%1</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x7x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%d</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=m>1</span><span class=p>]:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>7x8x</span><span class=k>f32</span><span class=p>&gt;</span> from <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x7x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%e</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>5</span><span class=p>]:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span> from <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x7x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%f</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>outerproduct <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>      <span class=c>// -&gt; vector&lt;4x8xf32&gt;
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%g</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>outerproduct <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>  <span class=c>// fma when adding %2
</span></span></span><span class=line><span class=cl><span class=c></span>
</span></span><span class=line><span class=cl><span class=c>// Returns a slice of type vector&lt;2x2x16xf32&gt;
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%h</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>strided_slice <span class=nv>%0</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nl>offsets =</span> <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>2</span><span class=p>],</span> <span class=nl>sizes =</span> <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>2</span><span class=p>],</span> <span class=nl>strides =</span> <span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>1</span><span class=p>]}:</span>
</span></span><span class=line><span class=cl>  <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%i</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transfer_read <span class=nv>%A</span><span class=p>[</span><span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nl>permutation_map =</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0<span class=p>)}:</span>
</span></span><span class=line><span class=cl>  <span class=kt>memref</span><span class=p>&lt;</span><span class=m>7x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>transfer_write <span class=nv>%f1</span><span class=p>,</span> <span class=nv>%A</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>,</span> <span class=nv>%i2</span><span class=p>,</span> <span class=nv>%i3</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nl>permutation_map =</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>,</span> d2<span class=p>,</span> d3<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d3<span class=p>,</span> d1<span class=p>,</span> d0<span class=p>)}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=kt>vector</span><span class=p>&lt;</span><span class=m>5x4x3x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>The list of Vector is currently undergoing evolutions and is best kept track of
by following the evolution of the
<a href=https://github.com/llvm/llvm-project/blob/main/mlir/include/mlir/Dialect/Vector/IR/VectorOps.td>VectorOps.td</a>
ODS file (markdown documentation is automatically generated locally when
building and populates the
<a href=https://github.com/llvm/llvm-project/blob/main/mlir/docs/Dialects/Vector.md>Vector doc</a>).
Recent extensions are driven by concrete use cases of interest. A notable such
use case is the <code>vector.contract</code> op which applies principles of the
StructuredOps abstraction to <code>vector</code> types.</p><h3 id=virtual-vector-rewrite-patterns>Virtual Vector Rewrite Patterns&nbsp;<a class=headline-hash href=#virtual-vector-rewrite-patterns>¶</a></h3><p>The following rewrite patterns exist at the <code>VV->VV</code> level:</p><ol><li>The now retired <code>MaterializeVector</code> pass used to legalize ops on a
coarse-grained virtual <code>vector</code> to a finer-grained virtual <code>vector</code> by
unrolling. This has been rewritten as a retargetable unroll-and-jam pattern
on <code>vector</code> ops and <code>vector</code> types.</li><li>The lowering of <code>vector_transfer</code> ops legalizes <code>vector</code> load/store ops to
permuted loops over scalar load/stores. This should evolve to loops over
<code>vector</code> load/stores + <code>mask</code> operations as they become available <code>vector</code>
ops at the <code>VV</code> level.</li></ol><p>The general direction is to add more Virtual Vector level ops and implement more
useful <code>VV -> VV</code> rewrites as composable patterns that the PatternRewrite
infrastructure can apply iteratively.</p><h3 id=virtual-vector-to-hardware-vector-lowering>Virtual Vector to Hardware Vector Lowering&nbsp;<a class=headline-hash href=#virtual-vector-to-hardware-vector-lowering>¶</a></h3><p>For now, <code>VV -> HWV</code> are specified in C++ (see for instance the
<a href=https://github.com/tensorflow/mlir/commit/0a0c4867c6a6fcb0a2f17ef26a791c1d551fe33d>SplatOpLowering for n-D vectors</a>
or the
<a href=https://github.com/tensorflow/mlir/commit/957b1ca9680b4aacabb3a480fbc4ebd2506334b8>VectorOuterProductOp lowering</a>).</p><p>Simple
<a href=https://github.com/llvm/llvm-project/blob/main/mlir/test/Conversion/VectorToLLVM/vector-to-llvm.mlir>conversion tests</a>
are available for the <code>LLVM</code> target starting from the Virtual Vector Level.</p><h2 id=rationale>Rationale&nbsp;<a class=headline-hash href=#rationale>¶</a></h2><h3 id=hardware-as-vector-machines-of-minimum-granularity>Hardware as <code>vector</code> Machines of Minimum Granularity&nbsp;<a class=headline-hash href=#hardware-as-vector-machines-of-minimum-granularity>¶</a></h3><p>Higher-dimensional <code>vector</code>s are ubiquitous in modern HPC hardware. One way to
think about Generic Retargetable <code>vector</code>-Level Dialect is that it operates on
<code>vector</code> types that are multiples of a &ldquo;good&rdquo; <code>vector</code> size so the HW can
efficiently implement a set of high-level primitives (e.g.
<code>vector&lt;8x8x8x16xf32></code> when HW <code>vector</code> size is say <code>vector&lt;4x8xf32></code>).</p><p>Some notable <code>vector</code> sizes of interest include:</p><ol><li>CPU: <code>vector&lt;HW_vector_size * k></code>, <code>vector&lt;core_count * k’ x HW_vector_size * k></code> and <code>vector&lt;socket_count x core_count * k’ x HW_vector_size * k></code></li><li>GPU: <code>vector&lt;warp_size * k></code>, <code>vector&lt;warp_size * k x float4></code> and
<code>vector&lt;warp_size * k x 4 x 4 x 4></code> for tensor_core sizes,</li><li>Other accelerators: n-D <code>vector</code> as first-class citizens in the HW.</li></ol><p>Depending on the target, ops on sizes that are not multiples of the HW <code>vector</code>
size may either produce slow code (e.g. by going through <code>LLVM</code> legalization) or
may not legalize at all (e.g. some unsupported accelerator X combination of ops
and types).</p><h3 id=transformations-problems-avoided>Transformations Problems Avoided&nbsp;<a class=headline-hash href=#transformations-problems-avoided>¶</a></h3><p>A <code>vector&lt;16x32x64xf32></code> virtual <code>vector</code> is a coarse-grained type that can be
“unrolled” to HW-specific sizes. The multi-dimensional unrolling factors are
carried in the IR by the <code>vector</code> type. After unrolling, traditional
instruction-level scheduling can be run.</p><p>The following key transformations (along with the supporting analyses and
structural constraints) are completely avoided by operating on a <code>vector</code>
<code>ssa-value</code> abstraction:</p><ol><li>Loop unroll and unroll-and-jam.</li><li>Loop and load-store restructuring for register reuse.</li><li>Load to store forwarding and Mem2reg.</li><li>Coarsening (raising) from finer-grained <code>vector</code> form.</li></ol><p>Note that “unrolling” in the context of <code>vector</code>s corresponds to partial loop
unroll-and-jam and not full unrolling. As a consequence this is expected to
compose with SW pipelining where applicable and does not result in ICache blow
up.</p><h3 id=the-big-out-of-scope-piece-automatic-vectorization>The Big Out-Of-Scope Piece: Automatic Vectorization&nbsp;<a class=headline-hash href=#the-big-out-of-scope-piece-automatic-vectorization>¶</a></h3><p>One important piece not discussed here is automatic vectorization (automatically
raising from scalar to n-D <code>vector</code> ops and types). The TL;DR is that when the
first &ldquo;super-vectorization&rdquo; prototype was implemented, MLIR was nowhere near as
mature as it is today. As we continue building more abstractions in <code>VV -> HWV</code>,
there is an opportunity to revisit vectorization in MLIR.</p><p>Since this topic touches on codegen abstractions, it is technically out of the
scope of this survey document but there is a lot to discuss in light of
structured op type representations and how a vectorization transformation can be
reused across dialects. In particular, MLIR allows the definition of dialects at
arbitrary levels of granularity and lends itself favorably to progressive
lowering. The argument can be made that automatic vectorization on a loops + ops
abstraction is akin to raising structural information that has been lost.
Instead, it is possible to revisit vectorization as simple pattern rewrites,
provided the IR is in a suitable form. For instance, vectorizing a
<code>linalg.generic</code> op whose semantics match a <code>matmul</code> can be done
<a href=https://github.com/tensorflow/mlir/commit/bff722d6b59ab99b998f0c2b9fccd0267d9f93b5>quite easily with a pattern</a>.
In fact this pattern is trivial to generalize to any type of contraction when
targeting the <code>vector.contract</code> op, as well as to any field (<code>+/*</code>, <code>min/+</code>,
<code>max/+</code>, <code>or/and</code>, <code>logsumexp/+</code> &mldr;) . In other words, by operating on a higher
level of generic abstractions than affine loops, non-trivial transformations
become significantly simpler and composable at a finer granularity.</p><p>Irrespective of the existence of an auto-vectorizer, one can build a notional
vector language based on the VectorOps dialect and build end-to-end models with
expressing <code>vector</code>s in the IR directly and simple pattern-rewrites.
<a href=https://github.com/llvm/llvm-project/blob/main/mlir/docs/EDSC.md>EDSC</a>s
provide a simple way of driving such a notional language directly in C++.</p><h2 id=bikeshed-naming-discussion>Bikeshed Naming Discussion&nbsp;<a class=headline-hash href=#bikeshed-naming-discussion>¶</a></h2><p>There are arguments against naming an n-D level of abstraction <code>vector</code> because
most people associate it with 1-D <code>vector</code>s. On the other hand, <code>vector</code>s are
first-class n-D values in MLIR. The alternative name Tile has been proposed,
which conveys higher-D meaning. But it also is one of the most overloaded terms
in compilers and hardware. For now, we generally use the <code>n-D</code> <code>vector</code> name and
are open to better suggestions.</p><h2 id=0d-vectors>0D Vectors&nbsp;<a class=headline-hash href=#0d-vectors>¶</a></h2><p>Vectors of dimension 0 (or <em>0-D vectors</em> or <em>0D vectors</em>) are allowed inside
MLIR. For instance, a <code>f32</code> vector containing one scalar can be denoted as
<code>vector&lt;f32></code>. This is similar to the <code>tensor&lt;f32></code> type that is available in
TensorFlow or the <code>memref&lt;f32></code> type that is available in MLIR.</p><p>Generally, a 0D <code>vector</code> can be interpreted as a scalar. The benefit of 0D
<code>vector</code>s, <code>tensor</code>s, and <code>memref</code>s is that they make it easier to lower code
from various frontends such as TensorFlow and make it easier to handle corner
cases such as unrolling a loop from 1D to 0D.</p><h2 id=llvm-lowering-tradeoffs>LLVM Lowering Tradeoffs&nbsp;<a class=headline-hash href=#llvm-lowering-tradeoffs>¶</a></h2><p>This section describes the tradeoffs involved in lowering the MLIR n-D vector
type and operations on it to LLVM-IR. Putting aside the
<a href=http://lists.llvm.org/pipermail/llvm-dev/2018-October/126871.html>LLVM Matrix</a>
proposal for now, this assumes LLVM only has built-in support for 1-D vector.
The relationship with the LLVM Matrix proposal is discussed at the end of this
document.</p><p>LLVM instructions are prefixed by the <code>llvm.</code> dialect prefix (e.g.
<code>llvm.insertvalue</code>). Such ops operate exclusively on 1-D vectors and aggregates
following the
<a href=https://llvm.org/docs/LangRef.html>LLVM LangRef</a>. MLIR
operations are prefixed by the <code>vector.</code> dialect prefix (e.g.
<code>vector.insert</code>). Such ops operate exclusively on MLIR <code>n-D</code> <code>vector</code>
types.</p><h3 id=alternatives-for-lowering-an-n-d-vector-type-to-llvm>Alternatives For Lowering an n-D Vector Type to LLVM&nbsp;<a class=headline-hash href=#alternatives-for-lowering-an-n-d-vector-type-to-llvm>¶</a></h3><p>Consider a vector of rank n with static sizes <code>{s_0, ... s_{n-1}}</code> (i.e. an MLIR
<code>vector&lt;s_0x...s_{n-1}xf32></code>). Lowering such an <code>n-D</code> MLIR vector type to an
LLVM descriptor can be done by either:</p><ol><li>Nested aggregate type of <code>1-D</code> vector:
<code>!llvm."[s_0x[s_1x[...&lt;s_{n-1}xf32>]]]"></code> in the MLIR LLVM dialect (current
lowering in MLIR).</li><li>Flattening to a <code>1-D</code> vector: <code>!llvm&lt;"(s_0*...*s_{n-1})xfloat"></code> in the MLIR
LLVM dialect.</li><li>A mix of both.</li></ol><p>There are multiple tradeoffs involved in choosing one or the other that we
discuss. It is important to note that “a mix of both” immediately reduces to
“nested aggregate type of 1-D vector” with a <code>vector.cast %0: vector&lt;4x8x16x32xf32> to vector&lt;4x4096xf32></code> operation, that flattens the most
&ldquo;k&rdquo; minor dimensions.</p><h3 id=constraints-inherited-from-llvm-see-langref>Constraints Inherited from LLVM (see LangRef)&nbsp;<a class=headline-hash href=#constraints-inherited-from-llvm-see-langref>¶</a></h3><p>The first constraint was already mentioned: LLVM only supports <code>1-D</code> <code>vector</code>
types natively. Additional constraints are related to the difference in LLVM
between vector and
<a href=https://llvm.org/docs/LangRef.html#aggregate-types>aggregate types</a>:</p><blockquote><p>Aggregate Types are a subset of derived types that can contain multiple
member types. Arrays and structs are aggregate types. Vectors are not
considered to be aggregate types.</p></blockquote><p>This distinction is also reflected in some of the operations. For <code>1-D</code> vectors,
the operations <code>llvm.extractelement</code>, <code>llvm.insertelement</code>, and
<code>llvm.shufflevector</code> apply, with direct support for dynamic indices. For <code>n-D</code>
vectors with <code>n>1</code>, and thus aggregate types at LLVM level, the more restrictive
operations <code>llvm.extractvalue</code> and <code>llvm.insertvalue</code> apply, which only accept
static indices. There is no direct shuffling support for aggregate types.</p><p>The next sentence (cf. LangRef
<a href=https://llvm.org/docs/LangRef.html#structure-type>structure
type</a>) illustrates a
recurrent tradeoff, also found in MLIR, between
“value types” (subject to SSA use-def chains) and “memory types” (subject to
aliasing and side-effects):</p><blockquote><p>Structures in memory are accessed using ‘load’ and ‘store’ by getting a
pointer to a field with the llvm.getelementptr instruction. Structures in
registers are accessed using the llvm.extractvalue and llvm.insertvalue
instructions.</p></blockquote><p>When transposing this to MLIR, <code>llvm.getelementptr</code> works on pointers to <code>n-D</code>
vectors in memory. For <code>n-D</code>, vectors values that live in registers we can use
<code>vector.extract</code> and <code>vector.insert</code> which do not accept dynamic indices. Note
that this is consistent with hardware considerations as discussed below.</p><p>An alternative is to use an LLVM <code>1-D</code> <code>vector</code> type for which one can use
<code>llvm.extractelement</code>, <code>llvm.insertelement</code> and <code>llvm.shufflevector</code>. These
operations accept dynamic indices. The implication is that one has to use a
flattened lowering of an MLIR n-D vector to an LLVM 1-D vector.</p><p>There are multiple tradeoffs involved that mix implications on the programming
model, execution on actual HW and what is visible or hidden from codegen. They
are discussed in the following sections.</p><h3 id=nested-aggregate>Nested Aggregate&nbsp;<a class=headline-hash href=#nested-aggregate>¶</a></h3><p>Pros:</p><ol><li>Natural encoding n-D vector -> (n-1)-D aggregate over 1-D vector.</li><li>No need for linearization / delinearization logic inserted everywhere.</li><li><code>llvm.insertvalue</code>, <code>llvm.extractvalue</code> of <code>(n-k)-D</code> aggregate is natural.</li><li><code>llvm.insertelement</code>, <code>llvm.extractelement</code>, <code>llvm.shufflevector</code> over <code>1-D</code>
vector type is natural.</li></ol><p>Cons:</p><ol><li><code>llvm.insertvalue</code> / <code>llvm.extractvalue</code> does not accept dynamic indices but
only static ones.</li><li>Dynamic indexing on the non-most-minor dimension requires roundtrips to
memory.</li><li>Special intrinsics and native instructions in LLVM operate on <code>1-D</code> vectors.
This is not expected to be a practical limitation thanks to a <code>vector.cast %0: vector&lt;4x8x16x32xf32> to vector&lt;4x4096xf32></code> operation, that flattens
the most minor dimensions (see the bigger picture in implications on
codegen).</li></ol><h3 id=flattened-1-d-vector-type>Flattened 1-D Vector Type&nbsp;<a class=headline-hash href=#flattened-1-d-vector-type>¶</a></h3><p>Pros:</p><ol><li><code>insertelement</code> / <code>extractelement</code> / <code>shufflevector</code> with dynamic indexing
is possible over the whole lowered <code>n-D</code> vector type.</li><li>Supports special intrinsics and native operations.</li></ol><p>Cons:</p><ol><li>Requires linearization/delinearization logic everywhere, translations are
complex.</li><li>Hides away the real HW structure behind dynamic indexing: at the end of the
day, HW vector sizes are generally fixed and multiple vectors will be needed
to hold a vector that is larger than the HW.</li><li>Unlikely peephole optimizations will result in good code: arbitrary dynamic
accesses, especially at HW vector boundaries unlikely to result in regular
patterns.</li></ol><h3 id=discussion>Discussion&nbsp;<a class=headline-hash href=#discussion>¶</a></h3><h4 id=hw-vectors-and-implications-on-the-sw-and-the-programming-model>HW Vectors and Implications on the SW and the Programming Model&nbsp;<a class=headline-hash href=#hw-vectors-and-implications-on-the-sw-and-the-programming-model>¶</a></h4><p>As of today, the LLVM model only support <code>1-D</code> vector types. This is
unsurprising because historically, the vast majority of HW only supports <code>1-D</code>
vector registers. We note that multiple HW vendors are in the process of
evolving to higher-dimensional physical vectors.</p><p>In the following discussion, let&rsquo;s assume the HW vector size is <code>1-D</code> and the SW
vector size is <code>n-D</code>, with <code>n >= 1</code>. The same discussion would apply with <code>2-D</code>
HW <code>vector</code> size and <code>n >= 2</code>. In this context, most HW exhibit a vector
register file. The number of such vectors is fixed. Depending on the rank and
sizes of the SW vector abstraction and the HW vector sizes and number of
registers, an <code>n-D</code> SW vector type may be materialized by a mix of multiple
<code>1-D</code> HW vector registers + memory locations at a given point in time.</p><p>The implication of the physical HW constraints on the programming model are that
one cannot index dynamically across hardware registers: a register file can
generally not be indexed dynamically. This is because the register number is
fixed and one either needs to unroll explicitly to obtain fixed register numbers
or go through memory. This is a constraint familiar to CUDA programmers: when
declaring a <code>private float a[4]</code>; and subsequently indexing with a <em>dynamic</em>
value results in so-called <strong>local memory</strong> usage (i.e. roundtripping to
memory).</p><h4 id=implication-on-codegen>Implication on codegen&nbsp;<a class=headline-hash href=#implication-on-codegen>¶</a></h4><p>MLIR <code>n-D</code> vector types are currently represented as <code>(n-1)-D</code> arrays of <code>1-D</code>
vectors when lowered to LLVM. This introduces the consequences on static vs
dynamic indexing discussed previously: <code>extractelement</code>, <code>insertelement</code> and
<code>shufflevector</code> on <code>n-D</code> vectors in MLIR only support static indices. Dynamic
indices are only supported on the most minor <code>1-D</code> vector but not the outer
<code>(n-1)-D</code>. For other cases, explicit load / stores are required.</p><p>The implications on codegen are as follows:</p><ol><li>Loops around <code>vector</code> values are indirect addressing of vector values, they
must operate on explicit load / store operations over <code>n-D</code> vector types.</li><li>Once an <code>n-D</code> <code>vector</code> type is loaded into an SSA value (that may or may not
live in <code>n</code> registers, with or without spilling, when eventually lowered),
it may be unrolled to smaller <code>k-D</code> <code>vector</code> types and operations that
correspond to the HW. This level of MLIR codegen is related to register
allocation and spilling that occur much later in the LLVM pipeline.</li><li>HW may support >1-D vectors with intrinsics for indirect addressing within
these vectors. These can be targeted thanks to explicit <code>vector_cast</code>
operations from MLIR <code>k-D</code> vector types and operations to LLVM <code>1-D</code>
vectors + intrinsics.</li></ol><p>Alternatively, we argue that directly lowering to a linearized abstraction hides
away the codegen complexities related to memory accesses by giving a false
impression of magical dynamic indexing across registers. Instead we prefer to
make those very explicit in MLIR and allow codegen to explore tradeoffs.
Different HW will require different tradeoffs in the sizes involved in steps 1.,
2. and 3.</p><p>Decisions made at the MLIR level will have implications at a much later stage in
LLVM (after register allocation). We do not envision to expose concerns related
to modeling of register allocation and spilling to MLIR explicitly. Instead,
each target will expose a set of &ldquo;good&rdquo; target operations and <code>n-D</code> vector
types, associated with costs that <code>PatterRewriters</code> at the MLIR level will be
able to target. Such costs at the MLIR level will be abstract and used for
ranking, not for accurate performance modeling. In the future such costs will be
learned.</p><h4 id=implication-on-lowering-to-accelerators>Implication on Lowering to Accelerators&nbsp;<a class=headline-hash href=#implication-on-lowering-to-accelerators>¶</a></h4><p>To target accelerators that support higher dimensional vectors natively, we can
start from either <code>1-D</code> or <code>n-D</code> vectors in MLIR and use <code>vector.cast</code> to
flatten the most minor dimensions to <code>1-D</code> <code>vector&lt;Kxf32></code> where <code>K</code> is an
appropriate constant. Then, the existing lowering to LLVM-IR immediately
applies, with extensions for accelerator-specific intrinsics.</p><p>It is the role of an Accelerator-specific vector dialect (see codegen flow in
the figure above) to lower the <code>vector.cast</code>. Accelerator -> LLVM lowering would
then consist of a bunch of <code>Accelerator -> Accelerator</code> rewrites to perform the
casts composed with <code>Accelerator -> LLVM</code> conversions + intrinsics that operate
on <code>1-D</code> <code>vector&lt;Kxf32></code>.</p><p>Some of those rewrites may need extra handling, especially if a reduction is
involved. For example, <code>vector.cast %0: vector&lt;K1x...xKnxf32> to vector&lt;Kxf32></code>
when <code>K != K1 * … * Kn</code> and some arbitrary irregular <code>vector.cast %0: vector&lt;4x4x17xf32> to vector&lt;Kxf32></code> may introduce masking and intra-vector
shuffling that may not be worthwhile or even feasible, i.e. infinite cost.</p><p>However <code>vector.cast %0: vector&lt;K1x...xKnxf32> to vector&lt;Kxf32></code> when <code>K = K1 * … * Kn</code> should be close to a noop.</p><p>As we start building accelerator-specific abstractions, we hope to achieve
retargetable codegen: the same infra is used for CPU, GPU and accelerators with
extra MLIR patterns and costs.</p><h4 id=implication-on-calling-external-functions-that-operate-on-vectors>Implication on calling external functions that operate on vectors&nbsp;<a class=headline-hash href=#implication-on-calling-external-functions-that-operate-on-vectors>¶</a></h4><p>It is possible (likely) that we additionally need to linearize when calling an
external function.</p><h3 id=relationship-to-llvm-matrix-type-proposal>Relationship to LLVM matrix type proposal.&nbsp;<a class=headline-hash href=#relationship-to-llvm-matrix-type-proposal>¶</a></h3><p>The LLVM matrix proposal was formulated 1 year ago but seemed to be somewhat
stalled until recently. In its current form, it is limited to 2-D matrix types
and operations are implemented with LLVM intrinsics. In contrast, MLIR sits at a
higher level of abstraction and allows the lowering of generic operations on
generic n-D vector types from MLIR to aggregates of 1-D LLVM vectors. In the
future, it could make sense to lower to the LLVM matrix abstraction also for CPU
even though MLIR will continue needing higher level abstractions.</p><p>On the other hand, one should note that as MLIR is moving to LLVM, this document
could become the unifying abstraction that people should target for 1-D vectors
and the LLVM matrix proposal can be viewed as a subset of this work.</p><h3 id=conclusion>Conclusion&nbsp;<a class=headline-hash href=#conclusion>¶</a></h3><p>The flattened 1-D vector design in the LLVM matrix proposal is good in a
HW-specific world with special intrinsics. This is a good abstraction for
register allocation, Instruction-Level-Parallelism and
SoftWare-Pipelining/Modulo Scheduling optimizations at the register level.
However MLIR codegen operates at a higher level of abstraction where we want to
target operations on coarser-grained vectors than the HW size and on which
unroll-and-jam is applied and patterns across multiple HW vectors can be
matched.</p><p>This makes “nested aggregate type of 1-D vector” an appealing abstraction for
lowering from MLIR because:</p><ol><li>it does not hide complexity related to the buffer vs value semantics and the
memory subsystem and</li><li>it does not rely on LLVM to magically make all the things work from a too
low-level abstraction.</li></ol><p>The use of special intrinsics in a <code>1-D</code> LLVM world is still available thanks to
an explicit <code>vector.cast</code> op.</p><h2 id=operations>Operations&nbsp;<a class=headline-hash href=#operations>¶</a></h2><p><a href=https://github.com/llvm/llvm-project/blob/main/mlir/include/mlir/Dialect/Vector/IR/VectorOps.td>source</a></p><h3 id=vectorvscale-vectorvectorscaleop><code>vector.vscale</code> (vector::VectorScaleOp)&nbsp;<a class=headline-hash href=#vectorvscale-vectorvectorscaleop>¶</a></h3><p><em>Load vector scale size</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.vscale` attr-dict
</code></pre><p>The <code>vscale</code> op returns the scale of the scalable vectors, a positive
integer value that is constant at runtime but unknown at compile-time.
The scale of the vector indicates the multiplicity of the vectors and
vector operations. For example, a <code>vector&lt;[4]xi32></code> is equivalent to
<code>vscale</code> consecutive <code>vector&lt;4xi32></code>; and an operation on a
<code>vector&lt;[4]xi32></code> is equivalent to performing that operation <code>vscale</code>
times, once on each <code>&lt;4xi32></code> segment of the scalable vector. The <code>vscale</code>
op can be used to calculate the step in vector-length agnostic (VLA) loops.
Right now we only support one contiguous set of scalable dimensions, all of
them grouped and scaled with the value returned by &lsquo;vscale&rsquo;.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>OpAsmOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results>Results:&nbsp;<a class=headline-hash href=#results>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res</code></td><td>index</td></tr></tbody></table><h3 id=vectorbitcast-vectorbitcastop><code>vector.bitcast</code> (vector::BitCastOp)&nbsp;<a class=headline-hash href=#vectorbitcast-vectorbitcastop>¶</a></h3><p><em>Bitcast casts between vectors</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.bitcast` $source attr-dict `:` type($source) `to` type($result)
</code></pre><p>The bitcast operation casts between vectors of the same rank, the minor 1-D
vector size is casted to a vector with a different element type but same
bitwidth. In case of 0-D vectors, the bitwidth of element types must be
equal.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// Example casting to a smaller element type.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>bitcast <span class=nv>%0</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>5x1x4x3x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>5x1x4x6x</span><span class=k>i16</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Example casting to a bigger element type.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>bitcast <span class=nv>%2</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>10x12x8x</span><span class=k>i8</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>10x12x2x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Example casting to an element type of the same size.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%5</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>bitcast <span class=nv>%4</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>5x1x4x3x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>5x1x4x3x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Example casting of 0-D vectors.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%7</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>bitcast <span class=nv>%6</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands>Operands:&nbsp;<a class=headline-hash href=#operands>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-1>Results:&nbsp;<a class=headline-hash href=#results-1>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorbroadcast-vectorbroadcastop><code>vector.broadcast</code> (vector::BroadcastOp)&nbsp;<a class=headline-hash href=#vectorbroadcast-vectorbroadcastop>¶</a></h3><p><em>Broadcast operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.broadcast` $source attr-dict `:` type($source) `to` type($vector)
</code></pre><p>Broadcasts the scalar or k-D vector value in the source operand
to a n-D result vector such that the broadcast makes sense, i.e.,
the source operand is duplicated to match the given rank and sizes
in the result vector. The legality rules are:</p><ul><li>the source operand must have the same element type as the result type</li><li>a k-D vector &lt;s_1 x .. x s_k x type> can be broadcast to
a n-D vector &lt;t_1 x .. x t_n x type> if<ul><li>k &lt;= n, and</li><li>the sizes in the trailing dimensions n-k &lt; i &lt;= n with j=i+k-n
match exactly as s_j = t_i or s_j = 1:</li></ul><pre tabindex=0><code>    t_1 x   ..  t_n-k x t_n-k+1 x .. x t_i x .. x t_n
                        s_1     x .. x s_j x .. x s_k
        &lt;duplication&gt;         &lt;potential stretch&gt;
</code></pre><ul><li>in addition, any scalable unit dimension, <code>[1]</code>, must match exactly.</li></ul></li></ul><p>The source operand is duplicated over all the missing leading dimensions
and stretched over the trailing dimensions where the source has a non-equal
dimension of 1 (stretching a trailing dimension is also referred to as
&ldquo;dim-1&rdquo; broadcasting). These rules imply that any scalar broadcast (k=0) to
any shaped vector with the same element type is always legal.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%0</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0.0</span> <span class=p>:</span> <span class=k>f32</span>
</span></span><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>broadcast <span class=nv>%0</span> <span class=p>:</span> <span class=k>f32</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>broadcast <span class=nv>%1</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>VectorUnrollOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-1>Operands:&nbsp;<a class=headline-hash href=#operands-1>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>any type</td></tr></tbody></table><h4 id=results-2>Results:&nbsp;<a class=headline-hash href=#results-2>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>vector</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorcompressstore-vectorcompressstoreop><code>vector.compressstore</code> (vector::CompressStoreOp)&nbsp;<a class=headline-hash href=#vectorcompressstore-vectorcompressstoreop>¶</a></h3><p><em>Writes elements selectively from a vector as defined by a mask</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.compressstore` $base `[` $indices `]` `,` $mask `,` $valueToStore attr-dict `:` type($base) `,` type($mask) `,` type($valueToStore)
</code></pre><p>The compress store operation writes elements from a vector into memory as
defined by a base with indices and a mask vector. Compression only applies
to the innermost dimension. When the mask is set, the corresponding element
from the vector is written next to memory. Otherwise, no action is taken
for the element. Informally the semantics are:</p><pre tabindex=0><code>index = i
if (mask[0]) base[index++] = value[0]
if (mask[1]) base[index++] = value[1]
etc.
</code></pre><p>Note that the index increment is done conditionally.</p><p>If a mask bit is set and the corresponding index is out-of-bounds for the
given base, the behavior is undefined. If a mask bit is not set, no value
is stored regardless of the index, and the index is allowed to be
out-of-bounds.</p><p>The compress store can be used directly where applicable, or can be used
during progressively lowering to bring other memory operations closer to
hardware ISA support for a compress. The semantics of the operation closely
correspond to those of the <code>llvm.masked.compressstore</code>
<a href=https://llvm.org/docs/LangRef.html#llvm-masked-compressstore-intrinsics>intrinsic</a>.</p><p>Note, at the moment this Op is only available for fixed-width vectors.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>compressstore <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%value</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>compressstore <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%value</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><h4 id=operands-2>Operands:&nbsp;<a class=headline-hash href=#operands-2>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>mask</code></td><td>fixed-length vector of 1-bit signless integer values</td></tr><tr><td style=text-align:center><code>valueToStore</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorconstant_mask-vectorconstantmaskop><code>vector.constant_mask</code> (vector::ConstantMaskOp)&nbsp;<a class=headline-hash href=#vectorconstant_mask-vectorconstantmaskop>¶</a></h3><p><em>Creates a constant vector mask</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.constant_mask` $mask_dim_sizes attr-dict `:` type(results)
</code></pre><p>Creates and returns a vector mask where elements of the result vector
are set to &lsquo;0&rsquo; or &lsquo;1&rsquo;, based on whether the element indices are contained
within a hyper-rectangular region specified by the &lsquo;mask_dim_sizes&rsquo;
array attribute argument. Each element of the &lsquo;mask_dim_sizes&rsquo; array,
specifies an exclusive upper bound [0, mask-dim-size-element-value)
for a unique dimension in the vector result. The conjunction of the ranges
define a hyper-rectangular region within which elements values are set to 1
(otherwise element values are set to 0). Each value of &lsquo;mask_dim_sizes&rsquo; must
be non-negative and not greater than the size of the corresponding vector
dimension (as opposed to vector.create_mask which allows this). Sizes that
correspond to scalable dimensions are implicitly multiplied by vscale,
though currently only zero (none set) or the size of the dim/vscale
(all set) are supported.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// create a constant vector mask of size 4x3xi1 with elements in range
</span></span></span><span class=line><span class=cl><span class=c>// 0 &lt;= row &lt;= 2 and 0 &lt;= col &lt;= 1 are set to 1 (others to 0).
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span><span class=kt>constant</span>_mask <span class=p>[</span><span class=m>3</span><span class=p>,</span> <span class=m>2</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x3x</span><span class=k>i1</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>print <span class=nv>%1</span>
</span></span><span class=line><span class=cl>              columns
</span></span><span class=line><span class=cl>            <span class=m>0</span>    <span class=m>1</span>    <span class=m>2</span>
</span></span><span class=line><span class=cl>          <span class=err>|------------</span>
</span></span><span class=line><span class=cl>        <span class=m>0</span> <span class=err>|</span> <span class=m>1</span>    <span class=m>1</span>    <span class=m>0</span>
</span></span><span class=line><span class=cl>  rows  <span class=m>1</span> <span class=err>|</span> <span class=m>1</span>    <span class=m>1</span>    <span class=m>0</span>
</span></span><span class=line><span class=cl>        <span class=m>2</span> <span class=err>|</span> <span class=m>1</span>    <span class=m>1</span>    <span class=m>0</span>
</span></span><span class=line><span class=cl>        <span class=m>3</span> <span class=err>|</span> <span class=m>0</span>    <span class=m>0</span>    <span class=m>0</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes>Attributes:&nbsp;<a class=headline-hash href=#attributes>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>mask_dim_sizes</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></table><h4 id=results-3>Results:&nbsp;<a class=headline-hash href=#results-3>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>«unnamed»</td><td>vector of 1-bit signless integer values</td></tr></tbody></table><h3 id=vectorcontract-vectorcontractionop><code>vector.contract</code> (vector::ContractionOp)&nbsp;<a class=headline-hash href=#vectorcontract-vectorcontractionop>¶</a></h3><p><em>Vector contraction operation</em></p><p>Computes the sum of products of vector elements along contracting
dimension pairs from 2 vectors of rank M and N respectively, adds this
intermediate result to the accumulator argument of rank K, and returns a
vector result of rank K (where K = num_lhs_free_dims + num_rhs_free_dims +
num_batch_dims (see dimension type descriptions below)). For K = 0 (no
free or batch dimensions), the accumulator and output are a scalar.</p><p>If operands and the result have types of different bitwidths, operands are
promoted to have the same bitwidth as the result before performing the
contraction. For integer types, only signless integer types are supported,
and the promotion happens via sign extension.</p><p>An iterator type attribute list must be specified, where each element of
the list represents an iterator with one of the following types:</p><ul><li><p>&ldquo;reduction&rdquo;: reduction dimensions are present in the lhs and rhs
arguments but not in the output (and accumulator
argument). These are the dimensions along which the vector
contraction op computes the sum of products, and
contracting dimension pair dimension sizes must match
between lhs/rhs.</p></li><li><p>&ldquo;parallel&rdquo;: Batch dimensions are iterator type &ldquo;parallel&rdquo;, and
are non-contracting dimensions present in the lhs, rhs and
output. The lhs/rhs co-iterate along the batch dimensions,
which should be expressed in their indexing maps.</p><p>Free dimensions are iterator type &ldquo;parallel&rdquo;, and are
non-contraction, non-batch dimensions accessed by either the
lhs or rhs (but not both). The lhs and rhs free dimensions
are unrelated to each other and do not co-iterate, which
should be expressed in their indexing maps.</p></li></ul><p>An indexing map attribute list must be specified with an entry for lhs, rhs
and acc arguments. An indexing map attribute specifies a mapping from each
iterator in the iterator type list, to each dimension of an N-D vector.</p><p>An optional kind attribute may be used to specify the combining function
between the intermediate result and accumulator argument of rank K. This
attribute can take the values <code>add</code>/<code>mul</code>/<code>minsi</code>/<code>minui</code>/<code>maxsi</code>/<code>maxui</code>
/<code>and</code>/<code>or</code>/<code>xor</code> for integers, and <code>add</code>/<code>mul</code>/<code>minnumf</code>/<code>maxnumf</code>
/<code>minimumf</code>/<code>maximumf</code> for floats. The default is <code>add</code>.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// Simple DOT product (K = 0).
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>#contraction_accesses</span> <span class=p>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl> affine_map<span class=p>&lt;(</span>i<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>)&gt;,</span>
</span></span><span class=line><span class=cl> affine_map<span class=p>&lt;(</span>i<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>)&gt;,</span>
</span></span><span class=line><span class=cl> affine_map<span class=p>&lt;(</span>i<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>()&gt;</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nv>#contraction_trait</span> <span class=p>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nl>indexing_maps =</span> <span class=nv>#contraction_accesses</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;reduction&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>contract <span class=nv>#contraction_trait</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=k>f32</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// 2D vector contraction with one contracting dimension (matmul, K = 2).
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>#contraction_accesses</span> <span class=p>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>  affine_map<span class=p>&lt;(</span>i<span class=p>,</span> j<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>,</span> k<span class=p>)&gt;,</span>
</span></span><span class=line><span class=cl>  affine_map<span class=p>&lt;(</span>i<span class=p>,</span> j<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>k<span class=p>,</span> j<span class=p>)&gt;,</span>
</span></span><span class=line><span class=cl>  affine_map<span class=p>&lt;(</span>i<span class=p>,</span> j<span class=p>,</span> k<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>,</span> j<span class=p>)&gt;</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nv>#contraction_trait</span> <span class=p>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nl>indexing_maps =</span> <span class=nv>#contraction_accesses</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;parallel&#34;</span><span class=p>,</span> <span class=s>&#34;parallel&#34;</span><span class=p>,</span> <span class=s>&#34;reduction&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>contract <span class=nv>#contraction_trait</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x3x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x7x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x7x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// 4D to 3D vector contraction with two contracting dimensions and
</span></span></span><span class=line><span class=cl><span class=c>// one batch dimension (K = 3).
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>#contraction_accesses</span> <span class=p>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>  affine_map<span class=p>&lt;(</span>b0<span class=p>,</span> f0<span class=p>,</span> f1<span class=p>,</span> c0<span class=p>,</span> c1<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>c0<span class=p>,</span> b0<span class=p>,</span> c1<span class=p>,</span> f0<span class=p>)&gt;,</span>
</span></span><span class=line><span class=cl>  affine_map<span class=p>&lt;(</span>b0<span class=p>,</span> f0<span class=p>,</span> f1<span class=p>,</span> c0<span class=p>,</span> c1<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>b0<span class=p>,</span> c1<span class=p>,</span> c0<span class=p>,</span> f1<span class=p>)&gt;,</span>
</span></span><span class=line><span class=cl>  affine_map<span class=p>&lt;(</span>b0<span class=p>,</span> f0<span class=p>,</span> f1<span class=p>,</span> c0<span class=p>,</span> c1<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>b0<span class=p>,</span> f0<span class=p>,</span> f1<span class=p>)&gt;</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nv>#contraction_trait</span> <span class=p>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nl>indexing_maps =</span> <span class=nv>#contraction_accesses</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;parallel&#34;</span><span class=p>,</span> <span class=s>&#34;parallel&#34;</span><span class=p>,</span> <span class=s>&#34;parallel&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s>&#34;reduction&#34;</span><span class=p>,</span> <span class=s>&#34;reduction&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%4</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>contract <span class=nv>#contraction_trait</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>7x8x16x15x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x16x7x5x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x15x5x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Vector contraction with mixed typed. lhs/rhs have different element
</span></span></span><span class=line><span class=cl><span class=c>// types than accumulator/result.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%5</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>contract <span class=nv>#contraction_trait</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f16</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f16</span><span class=p>&gt;</span> into <span class=k>f32</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Contract with max (K = 0).
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>#contraction_accesses</span> <span class=p>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl> affine_map<span class=p>&lt;(</span>i<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>)&gt;,</span>
</span></span><span class=line><span class=cl> affine_map<span class=p>&lt;(</span>i<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i<span class=p>)&gt;,</span>
</span></span><span class=line><span class=cl> affine_map<span class=p>&lt;(</span>i<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>()&gt;</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nv>#contraction_trait</span> <span class=p>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nl>indexing_maps =</span> <span class=nv>#contraction_accesses</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;reduction&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=nl>kind =</span> <span class=nv>#vector.kind</span><span class=p>&lt;</span>maxnumf<span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=nv>%6</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>contract <span class=nv>#contraction_trait</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>10x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=k>f32</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>IndexingMapOpInterface</code>, <code>MaskableOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>VectorUnrollOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-1>Attributes:&nbsp;<a class=headline-hash href=#attributes-1>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>indexing_maps</code></td><td>::mlir::ArrayAttr</td><td>array attribute</td></tr><tr><td><code>iterator_types</code></td><td>::mlir::ArrayAttr</td><td>Iterator type should be an enum.</td></tr><tr><td><code>kind</code></td><td>::mlir::vector::CombiningKindAttr</td><td>Kind of combining function for contractions and reductions</td></tr></table><h4 id=operands-3>Operands:&nbsp;<a class=headline-hash href=#operands-3>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>lhs</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>rhs</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>acc</code></td><td>any type</td></tr></tbody></table><h4 id=results-4>Results:&nbsp;<a class=headline-hash href=#results-4>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>«unnamed»</td><td>any type</td></tr></tbody></table><h3 id=vectorcreate_mask-vectorcreatemaskop><code>vector.create_mask</code> (vector::CreateMaskOp)&nbsp;<a class=headline-hash href=#vectorcreate_mask-vectorcreatemaskop>¶</a></h3><p><em>Creates a vector mask</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.create_mask` $operands attr-dict `:` type(results)
</code></pre><p>Creates and returns a vector mask where elements of the result vector
are set to &lsquo;0&rsquo; or &lsquo;1&rsquo;, based on whether the element indices are contained
within a hyper-rectangular region specified by the operands. Specifically,
each operand specifies a range [0, operand-value) for a unique dimension in
the vector result. The conjunction of the operand ranges define a
hyper-rectangular region within which elements values are set to 1
(otherwise element values are set to 0). If operand-value is negative, it is
treated as if it were zero, and if it is greater than the corresponding
dimension size, it is treated as if it were equal to the dimension size.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// create a vector mask of size 4x3xi1 where elements in range
</span></span></span><span class=line><span class=cl><span class=c>// 0 &lt;= row &lt;= 2 and 0 &lt;= col &lt;= 1 are set to 1 (others to 0).
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>create_mask <span class=nv>%c3</span><span class=p>,</span> <span class=nv>%c2</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x3x</span><span class=k>i1</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>print <span class=nv>%1</span>
</span></span><span class=line><span class=cl>              columns
</span></span><span class=line><span class=cl>            <span class=m>0</span>    <span class=m>1</span>    <span class=m>2</span>
</span></span><span class=line><span class=cl>          <span class=err>|------------</span>
</span></span><span class=line><span class=cl>        <span class=m>0</span> <span class=err>|</span> <span class=m>1</span>    <span class=m>1</span>    <span class=m>0</span>
</span></span><span class=line><span class=cl>  rows  <span class=m>1</span> <span class=err>|</span> <span class=m>1</span>    <span class=m>1</span>    <span class=m>0</span>
</span></span><span class=line><span class=cl>        <span class=m>2</span> <span class=err>|</span> <span class=m>1</span>    <span class=m>1</span>    <span class=m>0</span>
</span></span><span class=line><span class=cl>        <span class=m>3</span> <span class=err>|</span> <span class=m>0</span>    <span class=m>0</span>    <span class=m>0</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-4>Operands:&nbsp;<a class=headline-hash href=#operands-4>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operands</code></td><td>variadic of index</td></tr></tbody></table><h4 id=results-5>Results:&nbsp;<a class=headline-hash href=#results-5>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>«unnamed»</td><td>vector of 1-bit signless integer values</td></tr></tbody></table><h3 id=vectordeinterleave-vectordeinterleaveop><code>vector.deinterleave</code> (vector::DeinterleaveOp)&nbsp;<a class=headline-hash href=#vectordeinterleave-vectordeinterleaveop>¶</a></h3><p><em>Constructs two vectors by deinterleaving an input vector</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.deinterleave` $source attr-dict `:` type($source) `-&gt;` type($res1)
</code></pre><p>The deinterleave operation constructs two vectors from a single input
vector. The first result vector contains the elements from even indexes
of the input, and the second contains elements from odd indexes. This is
the inverse of a <code>vector.interleave</code> operation.</p><p>Each output&rsquo;s trailing dimension is half of the size of the input
vector&rsquo;s trailing dimension. This operation requires the input vector
to have a rank > 0 and an even number of elements in its trailing
dimension.</p><p>The operation supports scalable vectors.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>deinterleave <span class=nv>%a</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>i8</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>i8</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%2</span><span class=p>,</span> <span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>deinterleave <span class=nv>%b</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x8x</span><span class=k>i8</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x4x</span><span class=k>i8</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%4</span><span class=p>,</span> <span class=nv>%5</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>deinterleave <span class=nv>%c</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x8x4x</span><span class=k>i8</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x8x2x</span><span class=k>i8</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%6</span><span class=p>,</span> <span class=nv>%7</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>deinterleave <span class=nv>%d</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>8</span><span class=p>]</span>xf32<span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>4</span><span class=p>]</span>xf32<span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%8</span><span class=p>,</span> <span class=nv>%9</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>deinterleave <span class=nv>%e</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=p>[</span><span class=m>6</span><span class=p>]</span>xf64<span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=p>[</span><span class=m>3</span><span class=p>]</span>xf64<span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%10</span><span class=p>,</span> <span class=nv>%11</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>deinterleave <span class=nv>%f</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x4x</span><span class=p>[</span><span class=m>6</span><span class=p>]</span>xf64<span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x4x</span><span class=p>[</span><span class=m>3</span><span class=p>]</span>xf64<span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-5>Operands:&nbsp;<a class=headline-hash href=#operands-5>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-6>Results:&nbsp;<a class=headline-hash href=#results-6>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>res1</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>res2</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorexpandload-vectorexpandloadop><code>vector.expandload</code> (vector::ExpandLoadOp)&nbsp;<a class=headline-hash href=#vectorexpandload-vectorexpandloadop>¶</a></h3><p><em>Reads elements from memory and spreads them into a vector as defined by a mask</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.expandload` $base `[` $indices `]` `,` $mask `,` $pass_thru attr-dict `:` type($base) `,` type($mask) `,` type($pass_thru) `into` type($result)
</code></pre><p>The expand load reads elements from memory into a vector as defined by a
base with indices and a mask vector. Expansion only applies to the innermost
dimension. When the mask is set, the next element is read from memory.
Otherwise, the corresponding element is taken from a pass-through vector.
Informally the semantics are:</p><pre tabindex=0><code>index = i
result[0] := if mask[0] then base[index++] else pass_thru[0]
result[1] := if mask[1] then base[index++] else pass_thru[1]
etc.
</code></pre><p>Note that the index increment is done conditionally.</p><p>If a mask bit is set and the corresponding index is out-of-bounds for the
given base, the behavior is undefined. If a mask bit is not set, the value
comes from the pass-through vector regardless of the index, and the index is
allowed to be out-of-bounds.</p><p>The expand load can be used directly where applicable, or can be used
during progressively lowering to bring other memory operations closer to
hardware ISA support for an expand. The semantics of the operation closely
correspond to those of the <code>llvm.masked.expandload</code>
<a href=https://llvm.org/docs/LangRef.html#llvm-masked-expandload-intrinsics>intrinsic</a>.</p><p>Note, at the moment this Op is only available for fixed-width vectors.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>expandload <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%pass_thru</span>
</span></span><span class=line><span class=cl>   <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>expandload <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%pass_thru</span>
</span></span><span class=line><span class=cl>   <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><h4 id=operands-6>Operands:&nbsp;<a class=headline-hash href=#operands-6>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>mask</code></td><td>fixed-length vector of 1-bit signless integer values</td></tr><tr><td style=text-align:center><code>pass_thru</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-7>Results:&nbsp;<a class=headline-hash href=#results-7>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorextract-vectorextractop><code>vector.extract</code> (vector::ExtractOp)&nbsp;<a class=headline-hash href=#vectorextract-vectorextractop>¶</a></h3><p><em>Extract operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.extract` $vector ``
              custom&lt;DynamicIndexList&gt;($dynamic_position, $static_position)
              attr-dict `:` type($result) `from` type($vector)
</code></pre><p>Extracts an (n − k)-D result sub-vector from an n-D source vector at a
specified k-D position. When n = k, the result degenerates to a scalar
element.</p><p>Static and dynamic indices must be greater or equal to zero and less than
the size of the corresponding dimension. The result is undefined if any
index is out-of-bounds. The value <code>-1</code> represents a poison index, which
specifies that the extracted element is poison.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=m>3</span><span class=p>]:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x16x</span><span class=k>f32</span><span class=p>&gt;</span> from <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>1</span><span class=p>,</span> <span class=m>3</span><span class=p>]:</span> <span class=k>f32</span> from <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%4</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>,</span> <span class=nv>%c</span><span class=p>]:</span> <span class=k>f32</span> from <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%5</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=nv>%b</span><span class=p>]:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span> from <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%6</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract <span class=nv>%10</span><span class=p>[</span><span class=m>-1</span><span class=p>,</span> <span class=nv>%c</span><span class=p>]:</span> <span class=k>f32</span> from <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>InferTypeOpAdaptor</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-2>Attributes:&nbsp;<a class=headline-hash href=#attributes-2>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>static_position</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></table><h4 id=operands-7>Operands:&nbsp;<a class=headline-hash href=#operands-7>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>vector</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>dynamic_position</code></td><td>variadic of index</td></tr></tbody></table><h4 id=results-8>Results:&nbsp;<a class=headline-hash href=#results-8>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>any type</td></tr></tbody></table><h3 id=vectorextract_strided_slice-vectorextractstridedsliceop><code>vector.extract_strided_slice</code> (vector::ExtractStridedSliceOp)&nbsp;<a class=headline-hash href=#vectorextract_strided_slice-vectorextractstridedsliceop>¶</a></h3><p><em>Extract_strided_slice operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.extract_strided_slice` $vector attr-dict `:` type($vector) `to` type(results)
</code></pre><p>Takes an n-D vector, k-D <code>offsets</code> integer array attribute, a k-sized
<code>sizes</code> integer array attribute, a k-sized <code>strides</code> integer array
attribute and extracts the n-D subvector at the proper offset.</p><p>At the moment strides must contain only 1s.</p><p>Returns an n-D vector where the first k-D dimensions match the <code>sizes</code>
attribute. The returned subvector contains the elements starting at offset
<code>offsets</code> and ending at <code>offsets + sizes</code>.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract_strided_slice <span class=nv>%0</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nl>offsets =</span> <span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>2</span><span class=p>],</span> <span class=nl>sizes =</span> <span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>4</span><span class=p>],</span> <span class=nl>strides =</span> <span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>1</span><span class=p>]}:</span>
</span></span><span class=line><span class=cl>  <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x4x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// TODO: Evolve to a range form syntax similar to:
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>extract_strided_slice <span class=nv>%0</span><span class=p>[</span><span class=m>0</span><span class=p>:</span><span class=m>2</span><span class=p>:</span><span class=m>1</span><span class=p>][</span><span class=m>2</span><span class=p>:</span><span class=m>4</span><span class=p>:</span><span class=m>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x4x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>TODO: Implement support for poison indices.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-3>Attributes:&nbsp;<a class=headline-hash href=#attributes-3>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>offsets</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td><code>sizes</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td><code>strides</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr></table><h4 id=operands-8>Operands:&nbsp;<a class=headline-hash href=#operands-8>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>vector</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-9>Results:&nbsp;<a class=headline-hash href=#results-9>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>«unnamed»</td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorfma-vectorfmaop><code>vector.fma</code> (vector::FMAOp)&nbsp;<a class=headline-hash href=#vectorfma-vectorfmaop>¶</a></h3><p><em>Vector fused multiply-add</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.fma` $lhs `,` $rhs `,` $acc attr-dict `:` type($lhs)
</code></pre><p>Multiply-add expressions operate on n-D vectors and compute a fused
pointwise multiply-and-accumulate: <code>$result = $lhs * $rhs + $acc</code>.
All operands and result have the same vector type. The semantics
of the operation correspond to those of the <code>llvm.fma</code>
<a href=https://llvm.org/docs/LangRef.html#int-fma>intrinsic</a>. In the
particular case of lowering to LLVM, this is guaranteed to lower
to the <code>llvm.fma.*</code> intrinsic.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>fma <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>Elementwise</code>, <code>Scalarizable</code>, <code>Tensorizable</code>, <code>Vectorizable</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>VectorUnrollOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-9>Operands:&nbsp;<a class=headline-hash href=#operands-9>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>lhs</code></td><td>vector of floating-point values</td></tr><tr><td style=text-align:center><code>rhs</code></td><td>vector of floating-point values</td></tr><tr><td style=text-align:center><code>acc</code></td><td>vector of floating-point values</td></tr></tbody></table><h4 id=results-10>Results:&nbsp;<a class=headline-hash href=#results-10>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of floating-point values</td></tr></tbody></table><h3 id=vectorfrom_elements-vectorfromelementsop><code>vector.from_elements</code> (vector::FromElementsOp)&nbsp;<a class=headline-hash href=#vectorfrom_elements-vectorfromelementsop>¶</a></h3><p><em>Operation that defines a vector from scalar elements</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.from_elements` $elements attr-dict `:` type($dest)
</code></pre><p>This operation defines a vector from one or multiple scalar elements. The
scalar elements are arranged in row-major within the vector. The number of
elements must match the number of elements in the result type. All elements
must have the same type, which must match the element type of the result
vector type. Scalable vectors are not supported.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// Define a 0-D vector.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>from_elements <span class=nv>%f1</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// [%f1]
</span></span></span><span class=line><span class=cl><span class=c></span>
</span></span><span class=line><span class=cl><span class=c>// Define a 1-D vector.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>from_elements <span class=nv>%f1</span><span class=p>,</span> <span class=nv>%f2</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// [%f1, %f2]
</span></span></span><span class=line><span class=cl><span class=c></span>
</span></span><span class=line><span class=cl><span class=c>// Define a 2-D vector.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>from_elements <span class=nv>%f1</span><span class=p>,</span> <span class=nv>%f2</span><span class=p>,</span> <span class=nv>%f3</span><span class=p>,</span> <span class=nv>%f4</span><span class=p>,</span> <span class=nv>%f5</span><span class=p>,</span> <span class=nv>%f6</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x3x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// [[%f1, %f2, %f3], [%f4, %f5, %f6]]
</span></span></span><span class=line><span class=cl><span class=c></span>
</span></span><span class=line><span class=cl><span class=c>// Define a 3-D vector.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>from_elements <span class=nv>%f1</span><span class=p>,</span> <span class=nv>%f2</span><span class=p>,</span> <span class=nv>%f3</span><span class=p>,</span> <span class=nv>%f4</span><span class=p>,</span> <span class=nv>%f5</span><span class=p>,</span> <span class=nv>%f6</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x1x2x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// [[[%f1, %f2]], [[%f3, %f4]], [[%f5, %f6]]]
</span></span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-10>Operands:&nbsp;<a class=headline-hash href=#operands-10>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>elements</code></td><td>variadic of any type</td></tr></tbody></table><h4 id=results-11>Results:&nbsp;<a class=headline-hash href=#results-11>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dest</code></td><td>fixed-length vector of any type values</td></tr></tbody></table><h3 id=vectorgather-vectorgatherop><code>vector.gather</code> (vector::GatherOp)&nbsp;<a class=headline-hash href=#vectorgather-vectorgatherop>¶</a></h3><p><em>Gathers elements from memory or ranked tensor into a vector as defined by an
index vector and a mask vector</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.gather` $base `[` $indices `]` `[` $index_vec `]` `,` $mask `,` $pass_thru attr-dict `:` type($base) `,` type($index_vec)  `,` type($mask) `,` type($pass_thru) `into` type($result)
</code></pre><p>The gather operation returns an n-D vector whose elements are either loaded
from memory or ranked tensor, or taken from a pass-through vector, depending
on the values of an n-D mask vector.
If a mask bit is set, the corresponding result element is defined by the base
with indices and the n-D index vector (each index is a 1-D offset on the base).
Otherwise, the corresponding element is taken from the n-D pass-through vector.
Informally the semantics are:</p><pre tabindex=0><code>result[0] := if mask[0] then base[index[0]] else pass_thru[0]
result[1] := if mask[1] then base[index[1]] else pass_thru[1]
etc.
</code></pre><p>If a mask bit is set and the corresponding index is out-of-bounds for the
given base, the behavior is undefined. If a mask bit is not set, the value
comes from the pass-through vector regardless of the index, and the index is
allowed to be out-of-bounds.</p><p>The gather operation can be used directly where applicable, or can be used
during progressively lowering to bring other memory operations closer to
hardware ISA support for a gather.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>gather <span class=nv>%base</span><span class=p>[</span><span class=nv>%c0</span><span class=p>][</span><span class=nv>%v</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%pass_thru</span>
</span></span><span class=line><span class=cl>   <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x16x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x16x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x16x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>gather <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>][</span><span class=nv>%v</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%pass_thru</span>
</span></span><span class=line><span class=cl>   <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x16x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Interfaces: <code>MaskableOpInterface</code>, <code>VectorUnrollOpInterface</code></p><h4 id=operands-11>Operands:&nbsp;<a class=headline-hash href=#operands-11>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>Tensor or MemRef of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>index_vec</code></td><td>vector of integer or index values</td></tr><tr><td style=text-align:center><code>mask</code></td><td>vector of 1-bit signless integer values</td></tr><tr><td style=text-align:center><code>pass_thru</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-12>Results:&nbsp;<a class=headline-hash href=#results-12>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorinsert-vectorinsertop><code>vector.insert</code> (vector::InsertOp)&nbsp;<a class=headline-hash href=#vectorinsert-vectorinsertop>¶</a></h3><p><em>Insert operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.insert` $valueToStore `,` $dest custom&lt;DynamicIndexList&gt;($dynamic_position, $static_position)
              attr-dict `:` type($valueToStore) `into` type($dest)
</code></pre><p>Inserts an (n - k)-D sub-vector (value-to-store) into an n-D destination
vector at a specified k-D position. When n = 0, value-to-store degenerates
to a scalar element inserted into the n-D destination vector.</p><p>Static and dynamic indices must be greater or equal to zero and less than
the size of the corresponding dimension. The result is undefined if any
index is out-of-bounds. The value <code>-1</code> represents a poison index, which
specifies that the resulting vector is poison.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>insert <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=m>3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x16x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%5</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>insert <span class=nv>%3</span><span class=p>,</span> <span class=nv>%4</span><span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=m>1</span><span class=p>,</span> <span class=m>3</span><span class=p>]</span> <span class=p>:</span> <span class=k>f32</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%11</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>insert <span class=nv>%9</span><span class=p>,</span> <span class=nv>%10</span><span class=p>[</span><span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>,</span> <span class=nv>%c</span><span class=p>]</span> <span class=p>:</span> <span class=k>f32</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%12</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>insert <span class=nv>%4</span><span class=p>,</span> <span class=nv>%10</span><span class=p>[</span><span class=m>2</span><span class=p>,</span> <span class=nv>%b</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%13</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>insert <span class=nv>%20</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=m>-1</span><span class=p>,</span> <span class=nv>%c</span><span class=p>]</span> <span class=p>:</span> <span class=k>f32</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-4>Attributes:&nbsp;<a class=headline-hash href=#attributes-4>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>static_position</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></table><h4 id=operands-12>Operands:&nbsp;<a class=headline-hash href=#operands-12>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>valueToStore</code></td><td>any type</td></tr><tr><td style=text-align:center><code>dest</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>dynamic_position</code></td><td>variadic of index</td></tr></tbody></table><h4 id=results-13>Results:&nbsp;<a class=headline-hash href=#results-13>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorinsert_strided_slice-vectorinsertstridedsliceop><code>vector.insert_strided_slice</code> (vector::InsertStridedSliceOp)&nbsp;<a class=headline-hash href=#vectorinsert_strided_slice-vectorinsertstridedsliceop>¶</a></h3><p><em>Strided_slice operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.insert_strided_slice` $valueToStore `,` $dest attr-dict `:` type($valueToStore) `into` type($dest)
</code></pre><p>Takes a k-D valueToStore vector, an n-D destination vector (n >= k), n-sized
<code>offsets</code> integer array attribute, a k-sized <code>strides</code> integer array attribute
and inserts the k-D valueToStore vector as a strided subvector at the proper offset
into the n-D destination vector.</p><p>At the moment strides must contain only 1s.</p><p>Returns an n-D vector that is a copy of the n-D destination vector in which
the last k-D dimensions contain the k-D valueToStore vector elements strided at
the proper location as specified by the offsets.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>insert_strided_slice <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=nl>offsets =</span> <span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=m>2</span><span class=p>],</span> <span class=nl>strides =</span> <span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>1</span><span class=p>]}:</span>
</span></span><span class=line><span class=cl>  <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x4x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x4x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-5>Attributes:&nbsp;<a class=headline-hash href=#attributes-5>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>offsets</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr><tr><td><code>strides</code></td><td>::mlir::ArrayAttr</td><td>64-bit integer array attribute</td></tr></table><h4 id=operands-13>Operands:&nbsp;<a class=headline-hash href=#operands-13>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>valueToStore</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>dest</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-14>Results:&nbsp;<a class=headline-hash href=#results-14>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorinterleave-vectorinterleaveop><code>vector.interleave</code> (vector::InterleaveOp)&nbsp;<a class=headline-hash href=#vectorinterleave-vectorinterleaveop>¶</a></h3><p><em>Constructs a vector by interleaving two input vectors</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.interleave` $lhs `,` $rhs  attr-dict `:` type($lhs) `-&gt;` type($result)
</code></pre><p>The interleave operation constructs a new vector by interleaving the
elements from the trailing (or final) dimension of two input vectors,
returning a new vector where the trailing dimension is twice the size.</p><p>Note that for the n-D case this differs from the interleaving possible with
<code>vector.shuffle</code>, which would only operate on the leading dimension.</p><p>Another key difference is this operation supports scalable vectors, though
currently a general LLVM lowering is limited to the case where only the
trailing dimension is scalable.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%a</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> dense<span class=p>&lt;[</span><span class=m>0</span><span class=p>,</span> <span class=m>1</span><span class=p>]&gt;</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%b</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> dense<span class=p>&lt;[</span><span class=m>2</span><span class=p>,</span> <span class=m>3</span><span class=p>]&gt;</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// The value of `%0` is `[0, 2, 1, 3]`.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>interleave <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>i32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>i32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Examples showing allowed input and result types.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>interleave <span class=nv>%c</span><span class=p>,</span> <span class=nv>%d</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=k>f16</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f16</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>interleave <span class=nv>%e</span><span class=p>,</span> <span class=nv>%f</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>6x3x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>6x6x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>interleave <span class=nv>%g</span><span class=p>,</span> <span class=nv>%h</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>4</span><span class=p>]</span>xi32<span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>8</span><span class=p>]</span>xi32<span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%4</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>interleave <span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x4x</span><span class=p>[</span><span class=m>2</span><span class=p>]</span>xf64<span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x4x</span><span class=p>[</span><span class=m>4</span><span class=p>]</span>xf64<span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-14>Operands:&nbsp;<a class=headline-hash href=#operands-14>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>lhs</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>rhs</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-15>Results:&nbsp;<a class=headline-hash href=#results-15>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorload-vectorloadop><code>vector.load</code> (vector::LoadOp)&nbsp;<a class=headline-hash href=#vectorload-vectorloadop>¶</a></h3><p><em>Reads an n-D slice of memory into an n-D vector</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.load` $base `[` $indices `]` attr-dict `:` type($base) `,` type($result)
</code></pre><p>The &lsquo;vector.load&rsquo; operation reads an n-D slice of memory into an n-D
vector. It takes a &lsquo;base&rsquo; memref, an index for each memref dimension and a
result vector type as arguments. It returns a value of the result vector
type. The &lsquo;base&rsquo; memref and indices determine the start memory address from
which to read. Each index provides an offset for each memref dimension
based on the element type of the memref. The shape of the result vector
type determines the shape of the slice read from the start memory address.
The elements along each dimension of the slice are strided by the memref
strides. When loading more than 1 element, only unit strides are allowed
along the most minor memref dimension. These constraints guarantee that
elements read along the first dimension of the slice are contiguous in
memory.</p><p>The memref element type can be a scalar or a vector type. If the memref
element type is a scalar, it should match the element type of the result
vector. If the memref element type is vector, it should match the result
vector type.</p><p>Example: 0-D vector load on a scalar memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%result</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>load <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x100x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: 1-D vector load on a scalar memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%result</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>load <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>100x100x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: 1-D vector load on a vector memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%result</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>load <span class=nv>%memref</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>200x100x</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: 2-D vector load on a scalar memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%result</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>load <span class=nv>%memref</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>200x100x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: 2-D vector load on a vector memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%result</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>load <span class=nv>%memref</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>200x100x</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x</span><span class=k>f32</span><span class=p>&gt;&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Representation-wise, the &lsquo;vector.load&rsquo; operation permits out-of-bounds
reads. Support and implementation of out-of-bounds vector loads is
target-specific. No assumptions should be made on the value of elements
loaded out of bounds. Not all targets may support out-of-bounds vector
loads.</p><p>Example: Potential out-of-bound vector load.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%result</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>load <span class=nv>%memref</span><span class=p>[</span><span class=nv>%index</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: Explicit out-of-bound vector load.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%result</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>load <span class=nv>%memref</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>7x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>An optional <code>alignment</code> attribute allows to specify the byte alignment of the
load operation. It must be a positive power of 2. The operation must access
memory at an address aligned to this boundary. Violations may lead to
architecture-specific faults or performance penalties.
A value of 0 indicates no specific alignment requirement.</p><p>Interfaces: <code>VectorUnrollOpInterface</code></p><h4 id=attributes-6>Attributes:&nbsp;<a class=headline-hash href=#attributes-6>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>nontemporal</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>alignment</code></td><td>::mlir::IntegerAttr</td><td>64-bit signless integer attribute whose value is positive and whose value is a power of two > 0</td></tr></table><h4 id=operands-15>Operands:&nbsp;<a class=headline-hash href=#operands-15>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr></tbody></table><h4 id=results-16>Results:&nbsp;<a class=headline-hash href=#results-16>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectormask-vectormaskop><code>vector.mask</code> (vector::MaskOp)&nbsp;<a class=headline-hash href=#vectormask-vectormaskop>¶</a></h3><p><em>Predicates a maskable vector operation</em></p><p>The <code>vector.mask</code> is a <code>MaskingOpInterface</code> operation that predicates the
execution of another operation. It takes an <code>i1</code> vector mask and an
optional passthru vector as arguments.</p><p>A implicitly <code>vector.yield</code>-terminated region encloses the operation to be
masked. Values used within the region are captured from above. Only one
<em>maskable</em> operation can be masked with a <code>vector.mask</code> operation at a time.
An operation is <em>maskable</em> if it implements the <code>MaskableOpInterface</code>. The
terminator yields all results from the maskable operation to the result of
this operation. No other values are allowed to be yielded.</p><p>An empty <code>vector.mask</code> operation is currently legal to enable optimizations
across the <code>vector.mask</code> region. However, this might change in the future
once vector transformations gain better support for <code>vector.mask</code>.
TODO: Consider making empty <code>vector.mask</code> illegal.</p><p>The vector mask argument holds a bit for each vector lane and determines
which vector lanes should execute the maskable operation and which ones
should not. The <code>vector.mask</code> operation returns the value produced by the
masked execution of the nested operation, if any. The masked-off lanes in
the result vector are taken from the corresponding lanes of the pass-thru
argument, if provided, or left unmodified, otherwise. At this point, 0-D
vectors are not supported by <code>vector.mask</code>. They may be supported in the
future.</p><p>The <code>vector.mask</code> operation does not prescribe how a maskable operation
should be masked or how a masked operation should be lowered. Masking
constraints and some semantic details are provided by each maskable
operation through the <code>MaskableOpInterface</code>. Lowering of masked operations
is implementation defined. For instance, scalarizing the masked operation
or executing the operation for the masked-off lanes are valid lowerings as
long as the execution of masked-off lanes does not change the observable
behavior of the program.</p><p>Examples:</p><pre tabindex=0><code>  %0 = vector.mask %mask { vector.reduction &lt;add&gt;, %a : vector&lt;8xi32&gt; into i32 } : vector&lt;8xi1&gt; -&gt; i32
</code></pre><pre tabindex=0><code>  %0 = vector.mask %mask, %passthru { arith.divsi %a, %b : vector&lt;8xi32&gt; } : vector&lt;8xi1&gt; -&gt; vector&lt;8xi32&gt;
</code></pre><pre tabindex=0><code>  vector.mask %mask { vector.transfer_write %val, %t0[%idx] : vector&lt;16xf32&gt;, memref&lt;?xf32&gt; } : vector&lt;16xi1&gt;
</code></pre><pre tabindex=0><code>  vector.mask %mask { vector.transfer_write %val, %t0[%idx] : vector&lt;16xf32&gt;, tensor&lt;?xf32&gt; } : vector&lt;16xi1&gt; -&gt; tensor&lt;?xf32&gt;
</code></pre><p>Traits: <code>NoRegionArguments</code>, <code>RecursiveMemoryEffects</code>, <code>SingleBlockImplicitTerminator&lt;vector::YieldOp></code>, <code>SingleBlock</code></p><p>Interfaces: <code>MaskingOpInterface</code></p><h4 id=operands-16>Operands:&nbsp;<a class=headline-hash href=#operands-16>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>mask</code></td><td>vector of 1-bit signless integer values</td></tr><tr><td style=text-align:center><code>passthru</code></td><td>any type</td></tr></tbody></table><h4 id=results-17>Results:&nbsp;<a class=headline-hash href=#results-17>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>results</code></td><td>variadic of any type</td></tr></tbody></table><h3 id=vectormaskedload-vectormaskedloadop><code>vector.maskedload</code> (vector::MaskedLoadOp)&nbsp;<a class=headline-hash href=#vectormaskedload-vectormaskedloadop>¶</a></h3><p><em>Loads elements from memory into a vector as defined by a mask vector</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.maskedload` $base `[` $indices `]` `,` $mask `,` $pass_thru attr-dict `:` type($base) `,` type($mask) `,` type($pass_thru) `into` type($result)
</code></pre><p>The masked load reads elements from memory into a vector as defined
by a base with indices and a mask vector. When the mask is set, the
element is read from memory. Otherwise, the corresponding element is taken
from a pass-through vector. Informally the semantics are:</p><pre tabindex=0><code>result[0] := if mask[0] then base[i + 0] else pass_thru[0]
result[1] := if mask[1] then base[i + 1] else pass_thru[1]
etc.
</code></pre><p>If a mask bit is set and the corresponding index is out-of-bounds for the
given base, the behavior is undefined. If a mask bit is not set, the value
comes from the pass-through vector regardless of the index, and the index is
allowed to be out-of-bounds.</p><p>The masked load can be used directly where applicable, or can be used
during progressively lowering to bring other memory operations closer to
hardware ISA support for a masked load. The semantics of the operation
closely correspond to those of the <code>llvm.masked.load</code>
<a href=https://llvm.org/docs/LangRef.html#llvm-masked-load-intrinsics>intrinsic</a>.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>maskedload <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%pass_thru</span>
</span></span><span class=line><span class=cl>   <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>maskedload <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%pass_thru</span>
</span></span><span class=line><span class=cl>   <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><h4 id=operands-17>Operands:&nbsp;<a class=headline-hash href=#operands-17>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>mask</code></td><td>vector of 1-bit signless integer values</td></tr><tr><td style=text-align:center><code>pass_thru</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-18>Results:&nbsp;<a class=headline-hash href=#results-18>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectormaskedstore-vectormaskedstoreop><code>vector.maskedstore</code> (vector::MaskedStoreOp)&nbsp;<a class=headline-hash href=#vectormaskedstore-vectormaskedstoreop>¶</a></h3><p><em>Stores elements from a vector into memory as defined by a mask vector</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.maskedstore` $base `[` $indices `]` `,` $mask `,` $valueToStore attr-dict `:` type($base) `,` type($mask) `,` type($valueToStore)
</code></pre><p>The masked store operation writes elements from a vector into memory
as defined by a base with indices and a mask vector. When the mask is
set, the corresponding element from the vector is written to memory. Otherwise,
no action is taken for the element. Informally the semantics are:</p><pre tabindex=0><code>if (mask[0]) base[i+0] = value[0]
if (mask[1]) base[i+1] = value[1]
etc.
</code></pre><p>If a mask bit is set and the corresponding index is out-of-bounds for the
given base, the behavior is undefined. If a mask bit is not set, no value
is stored regardless of the index, and the index is allowed to be
out-of-bounds.</p><p>The masked store can be used directly where applicable, or can be used
during progressively lowering to bring other memory operations closer to
hardware ISA support for a masked store. The semantics of the operation
closely correspond to those of the <code>llvm.masked.store</code>
<a href=https://llvm.org/docs/LangRef.html#llvm-masked-store-intrinsics>intrinsic</a>.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>maskedstore <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%value</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>maskedstore <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%value</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><h4 id=operands-18>Operands:&nbsp;<a class=headline-hash href=#operands-18>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>mask</code></td><td>vector of 1-bit signless integer values</td></tr><tr><td style=text-align:center><code>valueToStore</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectormulti_reduction-vectormultidimreductionop><code>vector.multi_reduction</code> (vector::MultiDimReductionOp)&nbsp;<a class=headline-hash href=#vectormulti_reduction-vectormultidimreductionop>¶</a></h3><p><em>Multi-dimensional reduction operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.multi_reduction` $kind `,` $source `,` $acc attr-dict $reduction_dims `:` type($source) `to` type($dest)
</code></pre><p>Reduces an n-D vector into an (n-k)-D vector (or a scalar when k == n)
using the given operation: <code>add</code>/<code>mul</code>/<code>minsi</code>/<code>minui</code>/<code>maxsi</code>/<code>maxui</code>
/<code>and</code>/<code>or</code>/<code>xor</code> for integers, and <code>add</code>/<code>mul</code>/<code>minnumf</code>/<code>maxnumf</code>/<code>minimumf</code>
/<code>maximumf</code> for floats.
Takes an initial accumulator operand.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>multi_reduction <span class=p>&lt;</span>add<span class=p>&gt;,</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%acc0</span> <span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>3</span><span class=p>]</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x32x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>multi_reduction <span class=p>&lt;</span>add<span class=p>&gt;,</span> <span class=nv>%1</span><span class=p>,</span> <span class=nv>%acc1</span> <span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>1</span><span class=p>]</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x16x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=k>f32</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>MaskableOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>VectorUnrollOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-7>Attributes:&nbsp;<a class=headline-hash href=#attributes-7>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::vector::CombiningKindAttr</td><td>Kind of combining function for contractions and reductions</td></tr><tr><td><code>reduction_dims</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></table><h4 id=operands-19>Operands:&nbsp;<a class=headline-hash href=#operands-19>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>acc</code></td><td>any type</td></tr></tbody></table><h4 id=results-19>Results:&nbsp;<a class=headline-hash href=#results-19>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dest</code></td><td>any type</td></tr></tbody></table><h3 id=vectorouterproduct-vectorouterproductop><code>vector.outerproduct</code> (vector::OuterProductOp)&nbsp;<a class=headline-hash href=#vectorouterproduct-vectorouterproductop>¶</a></h3><p><em>Vector outerproduct with optional fused add</em></p><p>Takes 2 1-D vectors and returns the 2-D vector containing the outer-product,
as illustrated below:</p><pre tabindex=0><code> outer |   [c, d]
 ------+------------
   [a, | [ [a*c, a*d],
    b] |   [b*c, b*d] ]
</code></pre><p>This operation also accepts a 1-D vector lhs and a scalar rhs. In this
case a simple AXPY operation is performed, which returns a 1-D vector.</p><pre tabindex=0><code>    [a, b] * c = [a*c, b*c]
</code></pre><p>An optional extra vector argument with the same shape as the output
vector may be specified in which case the operation returns the sum of
the outer-product and the extra vector. In this multiply-accumulate
scenario for floating-point arguments, the rounding mode is enforced
by guaranteeing that a fused-multiply add operation is emitted. When
lowered to the LLVMIR dialect, this form emits <code>llvm.intr.fma</code>, which
is guaranteed to lower to actual <code>fma</code> instructions on x86.</p><p>An optional kind attribute may be specified to be: <code>add</code>/<code>mul</code>/<code>minsi</code>
/<code>minui</code>/<code>maxsi</code>/<code>maxui</code>/<code>and</code>/<code>or</code>/<code>xor</code> for integers, and <code>add</code>/<code>mul</code>
/<code>minnumf</code>/<code>maxnumf</code>/<code>minimumf</code>/<code>maximumf</code> for floats. The default is
<code>add</code>.</p><p>Example:</p><pre tabindex=0><code>%2 = vector.outerproduct %0, %1: vector&lt;4xf32&gt;, vector&lt;8xf32&gt;
return %2: vector&lt;4x8xf32&gt;

%3 = vector.outerproduct %0, %1, %2:
  vector&lt;4xf32&gt;, vector&lt;8xf32&gt;, vector&lt;4x8xf32&gt;
return %3: vector&lt;4x8xf32&gt;

%4 = vector.outerproduct %0, %1, %2 {kind = #vector.kind&lt;maxnumf&gt;}:
  vector&lt;4xf32&gt;, vector&lt;8xf32&gt;, vector&lt;4x8xf32&gt;
return %3: vector&lt;4x8xf32&gt;

%6 = vector.outerproduct %4, %5: vector&lt;10xf32&gt;, f32
return %6: vector&lt;10xf32&gt;
</code></pre><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>MaskableOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-8>Attributes:&nbsp;<a class=headline-hash href=#attributes-8>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::vector::CombiningKindAttr</td><td>Kind of combining function for contractions and reductions</td></tr></table><h4 id=operands-20>Operands:&nbsp;<a class=headline-hash href=#operands-20>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>lhs</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>rhs</code></td><td>any type</td></tr><tr><td style=text-align:center><code>acc</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-20>Results:&nbsp;<a class=headline-hash href=#results-20>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center>«unnamed»</td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorprint-vectorprintop><code>vector.print</code> (vector::PrintOp)&nbsp;<a class=headline-hash href=#vectorprint-vectorprintop>¶</a></h3><p><em>Print operation (for testing and debugging)</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.print` ($source^ `:` type($source))?
              oilist(
              `str` $stringLiteral
              | `punctuation` $punctuation)
              attr-dict
</code></pre><p>Prints the source vector (or scalar) to stdout in a human-readable format
(for testing and debugging). No return value.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%v</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> dense<span class=p>&lt;</span><span class=m>0.0</span><span class=p>&gt;</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>print <span class=nv>%v</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>When lowered to LLVM, the vector print is decomposed into elementary
printing method calls that at runtime will yield:</p><pre tabindex=0><code>( 0.0, 0.0, 0.0, 0.0 )
</code></pre><p>This is printed to stdout via a small runtime support library, which only
needs to provide a few printing methods (single value for all data
types, opening/closing bracket, comma, newline).</p><p>By default <code>vector.print</code> adds a newline after the vector, but this can be
controlled by the <code>punctuation</code> attribute. For example, to print a comma
after instead do:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>print <span class=nv>%v</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span> punctuation <span class=p>&lt;</span>comma<span class=p>&gt;</span>
</span></span></code></pre></div><p>Note that it is possible to use the punctuation attribute alone. The
following will print a single newline:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>print punctuation <span class=p>&lt;</span>newline<span class=p>&gt;</span>
</span></span></code></pre></div><p>Additionally, to aid with debugging and testing <code>vector.print</code> can also
print constant strings:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>print str <span class=s>&#34;Hello, World!&#34;</span>
</span></span></code></pre></div><p>Interfaces: <code>MemoryEffectOpInterface (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{MemoryEffects::Write on ::mlir::SideEffects::DefaultResource}</code></p><h4 id=attributes-9>Attributes:&nbsp;<a class=headline-hash href=#attributes-9>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>punctuation</code></td><td>::mlir::vector::PrintPunctuationAttr</td><td>Punctuation for separating vectors or vector elements</td></tr><tr><td><code>stringLiteral</code></td><td>::mlir::StringAttr</td><td><details><summary>An Attribute containing a string</summary><pre><code>Syntax:
<pre tabindex=0><code>string-attribute ::= string-literal (`:` type)?
</code></pre><p>A string attribute is an attribute that represents a string literal value.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=err>&amp;</span>quot<span class=err>;</span>An important string<span class=err>&amp;</span>quot<span class=err>;</span>
</span></span><span class=line><span class=cl><span class=err>&amp;</span>quot<span class=err>;</span>string with a type<span class=err>&amp;</span>quot<span class=err>;</span> <span class=p>:</span> <span class=p>!</span>dialect<span class=p>.</span>string
</span></span></code></pre></div><p></code></pre></p></details></td></tr></table><h4 id=operands-21>Operands:&nbsp;<a class=headline-hash href=#operands-21>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td></td></tr></tbody></table><h3 id=vectorreduction-vectorreductionop><code>vector.reduction</code> (vector::ReductionOp)&nbsp;<a class=headline-hash href=#vectorreduction-vectorreductionop>¶</a></h3><p><em>Reduction operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.reduction` $kind `,` $vector (`,` $acc^)? (`fastmath` `` $fastmath^)? attr-dict `:` type($vector) `into` type($dest)
</code></pre><p>Reduces an 1-D vector &ldquo;horizontally&rdquo; into a scalar using the given
operation: <code>add</code>/<code>mul</code>/<code>minsi</code>/<code>minui</code>/<code>maxsi</code>/<code>maxui</code>/<code>and</code>/<code>or</code>/<code>xor</code> for
integers, and <code>add</code>/<code>mul</code>/<code>minnumf</code>/<code>maxnumf</code>/<code>minimumf</code>/<code>maximumf</code> for
floats. Reductions also allow an optional fused accumulator.</p><p>Note that these operations are restricted to 1-D vectors to remain
close to the corresponding LLVM intrinsics:</p><p><a href=http://llvm.org/docs/LangRef.html#vector-reduction-intrinsics>http://llvm.org/docs/LangRef.html#vector-reduction-intrinsics</a></p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>reduction <span class=p>&lt;</span>add<span class=p>&gt;,</span> <span class=nv>%0</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=k>f32</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>reduction <span class=p>&lt;</span>xor<span class=p>&gt;,</span> <span class=nv>%2</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>i32</span><span class=p>&gt;</span> into <span class=k>i32</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nv>%4</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>reduction <span class=p>&lt;</span>mul<span class=p>&gt;,</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=k>f32</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ArithFastMathInterface</code>, <code>ConditionallySpeculatable</code>, <code>MaskableOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>VectorUnrollOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-10>Attributes:&nbsp;<a class=headline-hash href=#attributes-10>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::vector::CombiningKindAttr</td><td>Kind of combining function for contractions and reductions</td></tr><tr><td><code>fastmath</code></td><td>::mlir::arith::FastMathFlagsAttr</td><td>Floating point fast math flags</td></tr></table><h4 id=operands-22>Operands:&nbsp;<a class=headline-hash href=#operands-22>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>vector</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>acc</code></td><td>any type</td></tr></tbody></table><h4 id=results-21>Results:&nbsp;<a class=headline-hash href=#results-21>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dest</code></td><td>any type</td></tr></tbody></table><h3 id=vectorscalableextract-vectorscalableextractop><code>vector.scalable.extract</code> (vector::ScalableExtractOp)&nbsp;<a class=headline-hash href=#vectorscalableextract-vectorscalableextractop>¶</a></h3><p><em>Extract subvector from scalable vector operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.scalable.extract` $source `[` $pos `]` attr-dict `:` type($result) `from` type($source)
</code></pre><p>Takes rank-1 source vector and a position <code>pos</code> within the source
vector, and extracts a subvector starting from that position.</p><p>The extraction position must be a multiple of the minimum size of the result
vector. For the operation to be well defined, the destination vector must
fit within the source vector from the specified position. Since the source
vector is scalable and its runtime length is unknown, the validity of the
operation can&rsquo;t be verified nor guaranteed at compile time.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>scalable<span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=m>8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span> from <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>8</span><span class=p>]</span>xf32<span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>scalable<span class=p>.</span>extract <span class=nv>%2</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>4</span><span class=p>]</span>xf32<span class=p>&gt;</span> from <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>8</span><span class=p>]</span>xf32<span class=p>&gt;</span>
</span></span></code></pre></div><p>Invalid example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>scalable<span class=p>.</span>extract <span class=nv>%0</span><span class=p>[</span><span class=m>5</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span> from <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>16</span><span class=p>]</span>xf32<span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-11>Attributes:&nbsp;<a class=headline-hash href=#attributes-11>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>pos</code></td><td>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></table><h4 id=operands-23>Operands:&nbsp;<a class=headline-hash href=#operands-23>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>of ranks 1</td></tr></tbody></table><h4 id=results-22>Results:&nbsp;<a class=headline-hash href=#results-22>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>of ranks 1</td></tr></tbody></table><h3 id=vectorscalableinsert-vectorscalableinsertop><code>vector.scalable.insert</code> (vector::ScalableInsertOp)&nbsp;<a class=headline-hash href=#vectorscalableinsert-vectorscalableinsertop>¶</a></h3><p><em>Insert subvector into scalable vector operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.scalable.insert` $valueToStore `,` $dest `[` $pos `]` attr-dict `:` type($valueToStore) `into` type($dest)
</code></pre><p>This operations takes a rank-1 fixed-length or scalable subvector and
inserts it within the destination scalable vector starting from the
position specificed by <code>pos</code>. If the source vector is scalable, the
insertion position will be scaled by the runtime scaling factor of the
source subvector.</p><p>The insertion position must be a multiple of the minimum size of the source
vector. For the operation to be well defined, the source vector must fit in
the destination vector from the specified position. Since the destination
vector is scalable and its runtime length is unknown, the validity of the
operation can&rsquo;t be verified nor guaranteed at compile time.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>scalable<span class=p>.</span>insert <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=m>8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>16</span><span class=p>]</span>xf32<span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%5</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>scalable<span class=p>.</span>insert <span class=nv>%3</span><span class=p>,</span> <span class=nv>%4</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>4</span><span class=p>]</span>xf32<span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%8</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>scalable<span class=p>.</span>insert <span class=nv>%6</span><span class=p>,</span> <span class=nv>%7</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>4</span><span class=p>]</span>xf32<span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>8</span><span class=p>]</span>xf32<span class=p>&gt;</span>
</span></span></code></pre></div><p>Invalid example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>scalable<span class=p>.</span>insert <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=m>5</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span> into <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>16</span><span class=p>]</span>xf32<span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-12>Attributes:&nbsp;<a class=headline-hash href=#attributes-12>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>pos</code></td><td>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr></table><h4 id=operands-24>Operands:&nbsp;<a class=headline-hash href=#operands-24>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>valueToStore</code></td><td>of ranks 1</td></tr><tr><td style=text-align:center><code>dest</code></td><td>of ranks 1</td></tr></tbody></table><h4 id=results-23>Results:&nbsp;<a class=headline-hash href=#results-23>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>of ranks 1</td></tr></tbody></table><h3 id=vectorscan-vectorscanop><code>vector.scan</code> (vector::ScanOp)&nbsp;<a class=headline-hash href=#vectorscan-vectorscanop>¶</a></h3><p><em>Scan operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.scan` $kind `,` $source `,` $initial_value attr-dict `:` type($source) `,` type($initial_value)
</code></pre><p>Performs an inclusive/exclusive scan on an n-D vector along a single
dimension returning an n-D result vector using the given
operation (<code>add</code>/<code>mul</code>/<code>minsi</code>/<code>minui</code>/<code>maxsi</code>/<code>maxui</code>/<code>and</code>/<code>or</code>/<code>xor</code> for
integers, and <code>add</code>/<code>mul</code>/<code>minnumf</code>/<code>maxnumf</code>/<code>minimumf</code>/<code>maximumf</code> for
floats), and a specified value for the initial value. The operator returns
the result of scan as well as the result of the last reduction in the scan.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span><span class=p>:</span><span class=nl>2 =</span> <span class=kt>vector</span><span class=p>.</span>scan <span class=p>&lt;</span>add<span class=p>&gt;,</span> <span class=nv>%0</span><span class=p>,</span> <span class=nv>%acc</span> <span class=p>{</span><span class=nl>inclusive =</span> false<span class=p>,</span> <span class=nl>reduction_dim =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i64</span><span class=p>}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x16x32x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x16x32x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-13>Attributes:&nbsp;<a class=headline-hash href=#attributes-13>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>kind</code></td><td>::mlir::vector::CombiningKindAttr</td><td>Kind of combining function for contractions and reductions</td></tr><tr><td><code>reduction_dim</code></td><td>::mlir::IntegerAttr</td><td>64-bit signless integer attribute</td></tr><tr><td><code>inclusive</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr></table><h4 id=operands-25>Operands:&nbsp;<a class=headline-hash href=#operands-25>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>initial_value</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-24>Results:&nbsp;<a class=headline-hash href=#results-24>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>dest</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>accumulated_value</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorscatter-vectorscatterop><code>vector.scatter</code> (vector::ScatterOp)&nbsp;<a class=headline-hash href=#vectorscatter-vectorscatterop>¶</a></h3><p><em>Scatters elements from a vector into memory as defined by an index vector
and a mask vector</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.scatter` $base `[` $indices `]` `[` $index_vec `]` `,` $mask `,` $valueToStore attr-dict `:` type($base) `,` type($index_vec)  `,` type($mask) `,` type($valueToStore)
</code></pre><p>The scatter operation stores elements from a n-D vector into memory as
defined by a base with indices and an additional n-D index vector, but
only if the corresponding bit in a n-D mask vector is set. Otherwise, no
action is taken for that element. Informally the semantics are:</p><pre tabindex=0><code>if (mask[0]) base[index[0]] = value[0]
if (mask[1]) base[index[1]] = value[1]
etc.
</code></pre><p>If a mask bit is set and the corresponding index is out-of-bounds for the
given base, the behavior is undefined. If a mask bit is not set, no value
is stored regardless of the index, and the index is allowed to be
out-of-bounds.</p><p>If the index vector contains two or more duplicate indices, the behavior is
undefined. Underlying implementation may enforce strict sequential
semantics.
TODO: always enforce strict sequential semantics?</p><p>The scatter operation can be used directly where applicable, or can be used
during progressively lowering to bring other memory operations closer to
hardware ISA support for a scatter. The semantics of the operation closely
correspond to those of the <code>llvm.masked.scatter</code>
<a href=https://llvm.org/docs/LangRef.html#llvm-masked-scatter-intrinsics>intrinsic</a>.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>scatter <span class=nv>%base</span><span class=p>[</span><span class=nv>%c0</span><span class=p>][</span><span class=nv>%v</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%value</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>scatter <span class=nv>%base</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>][</span><span class=nv>%v</span><span class=p>],</span> <span class=nv>%mask</span><span class=p>,</span> <span class=nv>%value</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x16x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>i1</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><h4 id=operands-26>Operands:&nbsp;<a class=headline-hash href=#operands-26>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>index_vec</code></td><td>vector of integer or index values</td></tr><tr><td style=text-align:center><code>mask</code></td><td>vector of 1-bit signless integer values</td></tr><tr><td style=text-align:center><code>valueToStore</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorshape_cast-vectorshapecastop><code>vector.shape_cast</code> (vector::ShapeCastOp)&nbsp;<a class=headline-hash href=#vectorshape_cast-vectorshapecastop>¶</a></h3><p><em>Shape_cast casts between vector shapes</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.shape_cast` $source attr-dict `:` type($source) `to` type($result)
</code></pre><p>Casts to a vector with the same number of elements, element type, and
number of scalable dimensions.</p><p>It is currently assumed that this operation does not require moving data,
and that it will be folded away before lowering vector operations.</p><p>There is an exception to the folding expectation when targeting
llvm.intr.matrix operations. We need a type conversion back and forth from a
2-D MLIR vector to a 1-D flattened LLVM vector.shape_cast lowering to LLVM
is supported in that particular case, for now.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>shape_cast <span class=nv>%0</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x3x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x2x2x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// with 2 scalable dimensions (number of which must be preserved).
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>shape_cast <span class=nv>%2</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>2</span><span class=p>]</span>x3x<span class=p>[</span><span class=m>4</span><span class=p>]</span>xi8<span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x</span><span class=p>[</span><span class=m>1</span><span class=p>]x[</span><span class=m>8</span><span class=p>]</span>xi8<span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-27>Operands:&nbsp;<a class=headline-hash href=#operands-27>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-25>Results:&nbsp;<a class=headline-hash href=#results-25>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorshuffle-vectorshuffleop><code>vector.shuffle</code> (vector::ShuffleOp)&nbsp;<a class=headline-hash href=#vectorshuffle-vectorshuffleop>¶</a></h3><p><em>Shuffle operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.shuffle` operands $mask attr-dict `:` type(operands)
</code></pre><p>The shuffle operation constructs a permutation (or duplication) of elements
from two input vectors, returning a vector with the same element type as
the input and a length that is the same as the shuffle mask. The two input
vectors must have the same element type, same rank, and trailing dimension
sizes and shuffles their values in the leading dimension (which may differ
in size) according to the given mask. The legality rules are:</p><ul><li>the two operands must have the same element type as the result<ul><li>Either, the two operands and the result must have the same
rank and trailing dimension sizes, viz. given two k-D operands
v1 : &lt;s_1 x s_2 x .. x s_k x type> and
v2 : &lt;t_1 x t_2 x .. x t_k x type>
we have s_i = t_i for all 1 &lt; i &lt;= k</li><li>Or, the two operands must be 0-D vectors and the result is a 1-D vector.</li></ul></li><li>the mask length equals the leading dimension size of the result</li><li>numbering the input vector indices left to right across the operands, all
mask values must be within range, viz. given two k-D operands v1 and v2
above, all mask values are in the range [0,s_1+t_1). The value <code>-1</code>
represents a poison mask value, which specifies that the selected element
is poison.</li></ul><p>Note, scalable vectors are not supported.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>shuffle <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>3</span><span class=p>]</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>       <span class=err>;</span> yields <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>shuffle <span class=nv>%c</span><span class=p>,</span> <span class=nv>%b</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>1</span><span class=p>,</span> <span class=m>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x16x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>1x16x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=err>;</span> yields <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%2</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>shuffle <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>[</span><span class=m>3</span><span class=p>,</span> <span class=m>2</span><span class=p>,</span> <span class=m>1</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>       <span class=err>;</span> yields <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>shuffle <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span>           <span class=err>;</span> yields <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%4</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>shuffle <span class=nv>%a</span><span class=p>,</span> <span class=nv>%b</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>4</span><span class=p>,</span> <span class=m>-1</span><span class=p>,</span> <span class=m>-1</span><span class=p>,</span> <span class=m>-1</span><span class=p>,</span> <span class=m>-1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>           <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>f32</span><span class=p>&gt;</span>       <span class=err>;</span> yields <span class=kt>vector</span><span class=p>&lt;</span><span class=m>6x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>InferTypeOpAdaptor</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferTypeOpInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-14>Attributes:&nbsp;<a class=headline-hash href=#attributes-14>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>mask</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></table><h4 id=operands-28>Operands:&nbsp;<a class=headline-hash href=#operands-28>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>v1</code></td><td>fixed-length vector of any type values</td></tr><tr><td style=text-align:center><code>v2</code></td><td>fixed-length vector of any type values</td></tr></tbody></table><h4 id=results-26>Results:&nbsp;<a class=headline-hash href=#results-26>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>vector</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorsplat-vectorsplatop><code>vector.splat</code> (vector::SplatOp)&nbsp;<a class=headline-hash href=#vectorsplat-vectorsplatop>¶</a></h3><p><em>Vector splat or broadcast operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.splat` $input attr-dict `:` type($aggregate)
</code></pre><p>Note: This operation is deprecated. Please use vector.broadcast.</p><p>Broadcast the operand to all elements of the result vector. The type of the
operand must match the element type of the vector type.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%s</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>10.1</span> <span class=p>:</span> <span class=k>f32</span>
</span></span><span class=line><span class=cl><span class=nv>%t</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>splat <span class=nv>%s</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>This operation is deprecated, the preferred representation of the above is:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%s</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>10.1</span> <span class=p>:</span> <span class=k>f32</span>
</span></span><span class=line><span class=cl><span class=nv>%t</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>broadcast <span class=nv>%s</span> <span class=p>:</span> <span class=k>f32</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-29>Operands:&nbsp;<a class=headline-hash href=#operands-29>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>input</code></td><td>any type</td></tr></tbody></table><h4 id=results-27>Results:&nbsp;<a class=headline-hash href=#results-27>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>aggregate</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectorstep-vectorstepop><code>vector.step</code> (vector::StepOp)&nbsp;<a class=headline-hash href=#vectorstep-vectorstepop>¶</a></h3><p><em>A linear sequence of values from 0 to N</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.step` attr-dict `:` type($result)
</code></pre><p>A <code>step</code> operation produces an index vector, i.e. a 1-D vector of values of
index type that represents a linear sequence from 0 to N-1, where N is the
number of elements in the <code>result</code> vector.</p><p>Supports fixed-width and scalable vectors.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>step <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x</span><span class=k>index</span><span class=p>&gt;</span> <span class=err>;</span> <span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>1</span><span class=p>,</span> <span class=m>2</span><span class=p>,</span> <span class=m>3</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>step <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;[</span><span class=m>4</span><span class=p>]</span>xindex<span class=p>&gt;</span> <span class=err>;</span> <span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>1</span><span class=p>,</span> <span class=p>..,</span> <span class=p>&lt;</span>vscale <span class=p>*</span> <span class=m>4</span> <span class=err>-</span> <span class=m>1</span><span class=p>&gt;]</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=results-28>Results:&nbsp;<a class=headline-hash href=#results-28>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of index values of ranks 1</td></tr></tbody></table><h3 id=vectorstore-vectorstoreop><code>vector.store</code> (vector::StoreOp)&nbsp;<a class=headline-hash href=#vectorstore-vectorstoreop>¶</a></h3><p><em>Writes an n-D vector to an n-D slice of memory</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.store` $valueToStore `,` $base `[` $indices `]` attr-dict `:` type($base) `,` type($valueToStore)
</code></pre><p>The &lsquo;vector.store&rsquo; operation writes an n-D vector to an n-D slice of memory.
It takes the vector value to be stored, a &lsquo;base&rsquo; memref and an index for
each memref dimension. The &lsquo;base&rsquo; memref and indices determine the start
memory address from which to write. Each index provides an offset for each
memref dimension based on the element type of the memref. The shape of the
vector value to store determines the shape of the slice written from the
start memory address. The elements along each dimension of the slice are
strided by the memref strides. When storing more than 1 element, only unit
strides are allowed along the most minor memref dimension. These constraints
guarantee that elements written along the first dimension of the slice are
contiguous in memory.</p><p>The memref element type can be a scalar or a vector type. If the memref
element type is a scalar, it should match the element type of the value
to store. If the memref element type is vector, it should match the type
of the value to store.</p><p>Example: 0-D vector store on a scalar memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>store <span class=nv>%valueToStore</span><span class=p>,</span> <span class=nv>%memref</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>200x100x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: 1-D vector store on a scalar memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>store <span class=nv>%valueToStore</span><span class=p>,</span> <span class=nv>%memref</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>200x100x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: 1-D vector store on a vector memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>store <span class=nv>%valueToStore</span><span class=p>,</span> <span class=nv>%memref</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>200x100x</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: 2-D vector store on a scalar memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>store <span class=nv>%valueToStore</span><span class=p>,</span> <span class=nv>%memref</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>200x100x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: 2-D vector store on a vector memref.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>store <span class=nv>%valueToStore</span><span class=p>,</span> <span class=nv>%memref</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>200x100x</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x</span><span class=k>f32</span><span class=p>&gt;&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Representation-wise, the &lsquo;vector.store&rsquo; operation permits out-of-bounds
writes. Support and implementation of out-of-bounds vector stores are
target-specific. No assumptions should be made on the memory written out of
bounds. Not all targets may support out-of-bounds vector stores.</p><p>Example: Potential out-of-bounds vector store.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>store <span class=nv>%valueToStore</span><span class=p>,</span> <span class=nv>%memref</span><span class=p>[</span><span class=nv>%index</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Example: Explicit out-of-bounds vector store.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>store <span class=nv>%valueToStore</span><span class=p>,</span> <span class=nv>%memref</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>7x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>8x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>An optional <code>alignment</code> attribute allows to specify the byte alignment of the
store operation. It must be a positive power of 2. The operation must access
memory at an address aligned to this boundary. Violations may lead to
architecture-specific faults or performance penalties.
A value of 0 indicates no specific alignment requirement.</p><p>Interfaces: <code>VectorUnrollOpInterface</code></p><h4 id=attributes-15>Attributes:&nbsp;<a class=headline-hash href=#attributes-15>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>nontemporal</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr><tr><td><code>alignment</code></td><td>::mlir::IntegerAttr</td><td>64-bit signless integer attribute whose value is positive and whose value is a power of two > 0</td></tr></table><h4 id=operands-30>Operands:&nbsp;<a class=headline-hash href=#operands-30>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>valueToStore</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>base</code></td><td>memref of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr></tbody></table><h3 id=vectorto_elements-vectortoelementsop><code>vector.to_elements</code> (vector::ToElementsOp)&nbsp;<a class=headline-hash href=#vectorto_elements-vectortoelementsop>¶</a></h3><p><em>Operation that decomposes a vector into all its scalar elements</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.to_elements` $source attr-dict `:` type($source)
</code></pre><p>This operation decomposes all the scalar elements from a vector. The
decomposed scalar elements are returned in row-major order. The number of
scalar results must match the number of elements in the input vector type.
All the result elements have the same result type, which must match the
element type of the input vector. Scalable vectors are not supported.</p><p>Examples:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// Decompose a 0-D vector.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>to_elements <span class=nv>%v0</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// %0 = %v0[0]
</span></span></span><span class=line><span class=cl><span class=c></span>
</span></span><span class=line><span class=cl><span class=c>// Decompose a 1-D vector.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%0</span><span class=p>:</span><span class=nl>2 =</span> <span class=kt>vector</span><span class=p>.</span>to_elements <span class=nv>%v1</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// %0#0 = %v1[0]
</span></span></span><span class=line><span class=cl><span class=c>// %0#1 = %v1[1]
</span></span></span><span class=line><span class=cl><span class=c></span>
</span></span><span class=line><span class=cl><span class=c>// Decompose a 2-D.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%0</span><span class=p>:</span><span class=nl>6 =</span> <span class=kt>vector</span><span class=p>.</span>to_elements <span class=nv>%v2</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x3x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// %0#0 = %v2[0, 0]
</span></span></span><span class=line><span class=cl><span class=c>// %0#1 = %v2[0, 1]
</span></span></span><span class=line><span class=cl><span class=c>// %0#2 = %v2[0, 2]
</span></span></span><span class=line><span class=cl><span class=c>// %0#3 = %v2[1, 0]
</span></span></span><span class=line><span class=cl><span class=c>// %0#4 = %v2[1, 1]
</span></span></span><span class=line><span class=cl><span class=c>// %0#5 = %v2[1, 2]
</span></span></span><span class=line><span class=cl><span class=c></span>
</span></span><span class=line><span class=cl><span class=c>// Decompose a 3-D vector.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%0</span><span class=p>:</span><span class=nl>6 =</span> <span class=kt>vector</span><span class=p>.</span>to_elements <span class=nv>%v3</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x1x2x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=c>// %0#0 = %v3[0, 0, 0]
</span></span></span><span class=line><span class=cl><span class=c>// %0#1 = %v3[0, 0, 1]
</span></span></span><span class=line><span class=cl><span class=c>// %0#2 = %v3[1, 0, 0]
</span></span></span><span class=line><span class=cl><span class=c>// %0#3 = %v3[1, 0, 1]
</span></span></span><span class=line><span class=cl><span class=c>// %0#4 = %v3[2, 0, 0]
</span></span></span><span class=line><span class=cl><span class=c>// %0#5 = %v3[2, 0, 1]
</span></span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-31>Operands:&nbsp;<a class=headline-hash href=#operands-31>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>source</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-29>Results:&nbsp;<a class=headline-hash href=#results-29>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>elements</code></td><td>variadic of any type</td></tr></tbody></table><h3 id=vectortransfer_read-vectortransferreadop><code>vector.transfer_read</code> (vector::TransferReadOp)&nbsp;<a class=headline-hash href=#vectortransfer_read-vectortransferreadop>¶</a></h3><p><em>Reads a supervector from memory into an SSA vector value.</em></p><p>The <code>vector.transfer_read</code> op performs a read from a slice within a
<a href=/docs/LangRef/>MemRef</a> or a Ranked
<a href=/docs/LangRef/>Tensor</a> supplied as its first operand
into a
<a href=/docs/LangRef/>vector</a> of the same base elemental type.</p><p>A memref/tensor operand with vector element type, must have its vector
element type match a suffix (shape and element type) of the vector (e.g.
memref&lt;3x2x6x4x3xf32>, vector&lt;1x1x4x3xf32>).</p><p>The slice is further defined by a full-rank index within the MemRef/Tensor,
supplied as the operands <code>[1 .. 1 + rank(memref/tensor))</code> that defines the
starting point of the transfer (e.g. <code>%A[%i0, %i1, %i2]</code>).</p><p>The permutation_map
<a href=/docs/LangRef/>attribute</a> is an
<a href=/docs/Dialects/Affine/>affine-map</a> which specifies the transposition on the
slice to match the vector shape. The permutation map may be implicit and
omitted from parsing and printing if it is the canonical minor identity map
(i.e. if it does not permute or broadcast any dimension).</p><p>The size of the slice is specified by the size of the vector, given as the
return type.</p><p>An SSA value <code>padding</code> of the same elemental type as the MemRef/Tensor is
provided to specify a fallback value in the case of out-of-bounds accesses
and/or masking.</p><p>An optional SSA value <code>mask</code> may be specified to mask out elements read from
the MemRef/Tensor. The <code>mask</code> type is an <code>i1</code> vector with a shape that
matches how elements are read from the MemRef/Tensor, <em>before</em> any
permutation or broadcasting. Elements whose corresponding mask element is
<code>0</code> are masked out and replaced with <code>padding</code>.</p><p>For every vector dimension, the boolean array attribute <code>in_bounds</code>
specifies if the transfer is guaranteed to be within the source bounds. If
set to &ldquo;false&rdquo;, accesses (including the starting point) may run
out-of-bounds along the respective vector dimension as the index increases.
Non-vector dimensions <em>must</em> always be in-bounds. The <code>in_bounds</code> array
length has to be equal to the vector rank. This attribute has a default
value: <code>false</code> (i.e. &ldquo;out-of-bounds&rdquo;). When skipped in the textual IR, the
default value is assumed. Similarly, the OP printer will omit this
attribute when all dimensions are out-of-bounds (i.e. the default value is
used).</p><p>A <code>vector.transfer_read</code> can be lowered to a simple load if all dimensions
are specified to be within bounds and no <code>mask</code> was specified.</p><p>This operation is called &lsquo;read&rsquo; by opposition to &rsquo;load&rsquo; because the
super-vector granularity is generally not representable with a single
hardware register. A <code>vector.transfer_read</code> is thus a mid-level abstraction
that supports super-vectorization with non-effecting padding for full-tile
only operations.</p><p>More precisely, let&rsquo;s dive deeper into the permutation_map for the following
MLIR:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=kt>vector</span><span class=p>.</span>transfer_read <span class=nv>%A</span><span class=p>[</span><span class=nv>%expr1</span><span class=p>,</span> <span class=nv>%expr2</span><span class=p>,</span> <span class=nv>%expr3</span><span class=p>,</span> <span class=nv>%expr4</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span> permutation_map <span class=p>:</span> <span class=p>(</span>d0<span class=p>,</span>d1<span class=p>,</span>d2<span class=p>,</span>d3<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d2<span class=p>,</span><span class=m>0</span><span class=p>,</span>d0<span class=p>)</span> <span class=p>}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>This operation always reads a slice starting at <code>%A[%expr1, %expr2, %expr3, %expr4]</code>. The size of the slice can be inferred from the resulting vector
shape and walking back through the permutation map: 3 along d2 and 5 along
d0, so the slice is: <code>%A[%expr1 : %expr1 + 5, %expr2, %expr3:%expr3 + 3, %expr4]</code></p><p>That slice needs to be read into a <code>vector&lt;3x4x5xf32></code>. Since the
permutation map is not full rank, there must be a broadcast along vector
dimension <code>1</code>.</p><p>A notional lowering of vector.transfer_read could generate code resembling:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// %expr1, %expr2, %expr3, %expr4 defined before this point
</span></span></span><span class=line><span class=cl><span class=c>// alloc a temporary buffer for performing the &#34;gather&#34; of the slice.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%tmp</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;&gt;</span>
</span></span><span class=line><span class=cl>for <span class=nv>%i</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>3</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  affine<span class=p>.</span>for <span class=nv>%j</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>4</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    affine<span class=p>.</span>for <span class=nv>%k</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>5</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=c>// Note that this load does not involve %j.
</span></span></span><span class=line><span class=cl><span class=c></span>      <span class=nv>%a</span> <span class=p>=</span> load <span class=nv>%A</span><span class=p>[</span><span class=nv>%expr1</span> <span class=err>+</span> <span class=nv>%k</span><span class=p>,</span> <span class=nv>%expr2</span><span class=p>,</span> <span class=nv>%expr3</span> <span class=err>+</span> <span class=nv>%i</span><span class=p>,</span> <span class=nv>%expr4</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=c>// Update the temporary gathered slice with the individual element
</span></span></span><span class=line><span class=cl><span class=c></span>      <span class=nv>%slice</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>load <span class=nv>%tmp</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nv>%updated</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>insert <span class=nv>%a</span><span class=p>,</span> <span class=nv>%slice</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=nv>%j</span><span class=p>,</span> <span class=nv>%k</span><span class=p>]</span> <span class=p>:</span> <span class=k>f32</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=kt>memref</span><span class=p>.</span>store <span class=nv>%updated</span><span class=p>,</span> <span class=nv>%tmp</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;&gt;</span>
</span></span><span class=line><span class=cl><span class=p>}}}</span>
</span></span><span class=line><span class=cl><span class=c>// At this point we gathered the elements from the original
</span></span></span><span class=line><span class=cl><span class=c>// memref into the desired vector layout, stored in the `%tmp` allocation.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%vec</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>load <span class=nv>%tmp</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>On a GPU one could then map <code>i</code>, <code>j</code>, <code>k</code> to blocks and threads. Notice that
the temporary storage footprint could conceptually be only <code>3 * 5</code> values but
<code>3 * 4 * 5</code> values are actually transferred between <code>%A</code> and <code>%tmp</code>.</p><p>Alternatively, if a notional vector broadcast operation were available, we
could avoid the loop on <code>%j</code> and the lowered code would resemble:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// %expr1, %expr2, %expr3, %expr4 defined before this point
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%tmp</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;&gt;</span>
</span></span><span class=line><span class=cl>for <span class=nv>%i</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>3</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  affine<span class=p>.</span>for <span class=nv>%k</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>5</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>%a</span> <span class=p>=</span> load <span class=nv>%A</span><span class=p>[</span><span class=nv>%expr1</span> <span class=err>+</span> <span class=nv>%k</span><span class=p>,</span> <span class=nv>%expr2</span><span class=p>,</span> <span class=nv>%expr3</span> <span class=err>+</span> <span class=nv>%i</span><span class=p>,</span> <span class=nv>%expr4</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nv>%slice</span> <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>load <span class=nv>%tmp</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=c>// Here we only store to the first element in dimension one
</span></span></span><span class=line><span class=cl><span class=c></span>    <span class=nv>%updated</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>insert <span class=nv>%a</span><span class=p>,</span> <span class=nv>%slice</span><span class=p>[</span><span class=nv>%i</span><span class=p>,</span> <span class=m>0</span><span class=p>,</span> <span class=nv>%k</span><span class=p>]</span> <span class=p>:</span> <span class=k>f32</span> into <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=kt>memref</span><span class=p>.</span>store <span class=nv>%updated</span><span class=p>,</span> <span class=nv>%tmp</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;&gt;</span>
</span></span><span class=line><span class=cl><span class=p>}}</span>
</span></span><span class=line><span class=cl><span class=c>// At this point we gathered the elements from the original
</span></span></span><span class=line><span class=cl><span class=c>// memref into the desired vector layout, stored in the `%tmp` allocation.
</span></span></span><span class=line><span class=cl><span class=c>// However we haven&#39;t replicated them alongside the first dimension, we need
</span></span></span><span class=line><span class=cl><span class=c>// to broadcast now.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%partialVec</span> <span class=p>=</span> load <span class=nv>%tmp</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%vec</span> <span class=p>=</span> broadcast <span class=nv>%tmpvec</span><span class=p>,</span> <span class=m>1</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x4x5x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>where <code>broadcast</code> broadcasts from element 0 to all others along the
specified dimension. This time, the number of loaded element is <code>3 * 5</code>
values.
An additional <code>1</code> broadcast is required. On a GPU this broadcast could be
implemented using a warp-shuffle if loop <code>j</code> were mapped to <code>threadIdx.x</code>.</p><p>Syntax</p><pre tabindex=0><code>operation ::= ssa-id `=` `vector.transfer_read` ssa-use-list
  `{` attribute-entry `} :` memref-type `,` vector-type
</code></pre><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// Read the slice `%A[%i0, %i1:%i1+256, %i2:%i2+32]` into vector&lt;32x256xf32&gt;
</span></span></span><span class=line><span class=cl><span class=c>// and pad with %f0 to handle the boundary case:
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%f0</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0.0</span>f <span class=p>:</span> <span class=k>f32</span>
</span></span><span class=line><span class=cl>affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%1</span> step <span class=m>256</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    affine<span class=p>.</span>for <span class=nv>%i2</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%2</span> step <span class=m>32</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nv>%v</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transfer_read <span class=nv>%A</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>,</span> <span class=nv>%i2</span><span class=p>],</span> <span class=p>(</span><span class=nv>%f0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>           <span class=p>{</span>permutation_map<span class=p>:</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>,</span> d2<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d2<span class=p>,</span> d1<span class=p>)}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>           <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x256x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>}}}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// or equivalently (rewrite with vector.transpose)
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%f0</span> <span class=p>=</span> arith<span class=p>.</span><span class=kt>constant</span> <span class=m>0.0</span>f <span class=p>:</span> <span class=k>f32</span>
</span></span><span class=line><span class=cl>affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%1</span> step <span class=m>256</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    affine<span class=p>.</span>for <span class=nv>%i2</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%2</span> step <span class=m>32</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nv>%v0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transfer_read <span class=nv>%A</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>,</span> <span class=nv>%i2</span><span class=p>],</span> <span class=p>(</span><span class=nv>%f0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>           <span class=p>{</span>permutation_map<span class=p>:</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>,</span> d2<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d1<span class=p>,</span> d2<span class=p>)}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>           <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>256x32x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nv>%v</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transpose <span class=nv>%v0</span><span class=p>,</span> <span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=kt>vector</span><span class=p>&lt;</span><span class=m>256x32x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x256</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>}}}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Read the slice `%A[%i0, %i1]` (i.e. the element `%A[%i0, %i1]`) into
</span></span></span><span class=line><span class=cl><span class=c>// vector&lt;128xf32&gt;. The underlying implementation will require a 1-D vector
</span></span></span><span class=line><span class=cl><span class=c>// broadcast:
</span></span></span><span class=line><span class=cl><span class=c></span>affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%1</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nv>%3</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transfer_read <span class=nv>%A</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>         <span class=p>{</span>permutation_map<span class=p>:</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=m>0</span><span class=p>)}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>         <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>128x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Read from a memref with vector element type.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%4</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transfer_read <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%c3</span><span class=p>,</span> <span class=nv>%c3</span><span class=p>],</span> <span class=nv>%vf0</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span><span class=nl>permutation_map =</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)-&gt;(</span>d0<span class=p>,</span> d1<span class=p>)}</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x3x</span><span class=k>f32</span><span class=p>&gt;&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>1x1x4x3x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Read from a tensor with vector element type.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%4</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transfer_read <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%c3</span><span class=p>,</span> <span class=nv>%c3</span><span class=p>],</span> <span class=nv>%vf0</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span><span class=nl>permutation_map =</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)-&gt;(</span>d0<span class=p>,</span> d1<span class=p>)}</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x3x</span><span class=k>f32</span><span class=p>&gt;&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>1x1x4x3x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Special encoding for 0-d transfer with 0-d tensor/memref, vector shape
</span></span></span><span class=line><span class=cl><span class=c>// {1} and permutation_map () -&gt; (0).
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%0</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transfer_read <span class=nv>%arg0</span><span class=p>[],</span> <span class=nv>%f0</span> <span class=p>{</span><span class=nl>permutation_map =</span> affine_map<span class=p>&lt;()-&gt;(</span><span class=m>0</span><span class=p>)&gt;}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=kt>tensor</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>DestinationStyleOpInterface</code>, <code>MaskableOpInterface</code>, <code>MemoryEffectOpInterface</code>, <code>VectorTransferOpInterface</code>, <code>VectorUnrollOpInterface</code></p><h4 id=attributes-16>Attributes:&nbsp;<a class=headline-hash href=#attributes-16>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>permutation_map</code></td><td>::mlir::AffineMapAttr</td><td>AffineMap attribute</td></tr><tr><td><code>in_bounds</code></td><td>::mlir::ArrayAttr</td><td>1-bit boolean array attribute</td></tr></table><h4 id=operands-32>Operands:&nbsp;<a class=headline-hash href=#operands-32>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>base</code></td><td>shaped of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>padding</code></td><td>any type</td></tr><tr><td style=text-align:center><code>mask</code></td><td>vector of 1-bit signless integer values</td></tr></tbody></table><h4 id=results-30>Results:&nbsp;<a class=headline-hash href=#results-30>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>vector</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectortransfer_write-vectortransferwriteop><code>vector.transfer_write</code> (vector::TransferWriteOp)&nbsp;<a class=headline-hash href=#vectortransfer_write-vectortransferwriteop>¶</a></h3><p><em>The vector.transfer_write op writes a supervector to memory.</em></p><p>The <code>vector.transfer_write</code> op performs a write from a
<a href=/docs/LangRef/>vector</a>, supplied as its first operand, into a
slice within a
<a href=/docs/LangRef/>MemRef</a> or a Ranked
<a href=/docs/LangRef/>Tensor</a> of the same base elemental type,
supplied as its second operand.</p><p>A vector memref/tensor operand must have its vector element type match a
suffix (shape and element type) of the vector (e.g. memref&lt;3x2x6x4x3xf32>,
vector&lt;1x1x4x3xf32>). If the operand is a tensor, the operation returns a
new tensor of the same type.</p><p>The slice is further defined by a full-rank index within the MemRef/Tensor,
supplied as the operands <code>[2 .. 2 + rank(memref/tensor))</code> that defines the
starting point of the transfer (e.g. <code>%A[%i0, %i1, %i2, %i3]</code>).</p><p>The permutation_map
<a href=/docs/LangRef/>attribute</a> is an
<a href=/docs/Dialects/Affine/>affine-map</a> which specifies the transposition on the
slice to match the vector shape. The permutation map may be implicit and
omitted from parsing and printing if it is the canonical minor identity map
(i.e. if it does not permute any dimension). In contrast to <code>transfer_read</code>,
write ops cannot have broadcast dimensions.</p><p>The size of the slice is specified by the size of the vector.</p><p>An optional SSA value <code>mask</code> may be specified to mask out elements written
to the MemRef/Tensor. The <code>mask</code> type is an <code>i1</code> vector with a shape that
matches how elements are written into the MemRef/Tensor, <em>after</em> applying
any permutation. Elements whose corresponding mask element is <code>0</code> are
masked out.</p><p>For every vector dimension, the boolean array attribute <code>in_bounds</code>
specifies if the transfer is guaranteed to be within the source bounds. If
set to &ldquo;false&rdquo;, accesses (including the starting point) may run
out-of-bounds along the respective vector dimension as the index increases.
Non-vector dimensions <em>must</em> always be in-bounds. The <code>in_bounds</code> array
length has to be equal to the vector rank. This attribute has a default
value: <code>false</code> (i.e. &ldquo;out-of-bounds&rdquo;). When skipped in the textual IR, the
default value is assumed. Similarly, the OP printer will omit this
attribute when all dimensions are out-of-bounds (i.e. the default value is
used).</p><p>A <code>vector.transfer_write</code> can be lowered to a simple store if all
dimensions are specified to be within bounds and no <code>mask</code> was specified.</p><p>This operation is called &lsquo;write&rsquo; by opposition to &lsquo;store&rsquo; because the
super-vector granularity is generally not representable with a single
hardware register. A <code>vector.transfer_write</code> is thus a
mid-level abstraction that supports super-vectorization with non-effecting
padding for full-tile-only code. It is the responsibility of
<code>vector.transfer_write</code>&rsquo;s implementation to ensure the memory writes are
valid. Different lowerings may be pertinent depending on the hardware
support.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=c>// write vector&lt;16x32x64xf32&gt; into the slice
</span></span></span><span class=line><span class=cl><span class=c>//   `%A[%i0, %i1:%i1+32, %i2:%i2+64, %i3:%i3+16]`:
</span></span></span><span class=line><span class=cl><span class=c></span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%1</span> step <span class=m>32</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    affine<span class=p>.</span>for <span class=nv>%i2</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%2</span> step <span class=m>64</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      affine<span class=p>.</span>for <span class=nv>%i3</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%3</span> step <span class=m>16</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nv>%val</span> <span class=p>=</span> <span class=err>`</span>ssa<span class=err>-</span>value<span class=err>`</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x32x64x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>        <span class=kt>vector</span><span class=p>.</span>transfer_write <span class=nv>%val</span><span class=p>,</span> <span class=nv>%A</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>,</span> <span class=nv>%i2</span><span class=p>,</span> <span class=nv>%i3</span><span class=p>]</span>
</span></span><span class=line><span class=cl>          <span class=p>{</span>permutation_map<span class=p>:</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>,</span> d2<span class=p>,</span> d3<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d3<span class=p>,</span> d1<span class=p>,</span> d2<span class=p>)}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x32x64x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>}}}}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// or equivalently (rewrite with vector.transpose)
</span></span></span><span class=line><span class=cl><span class=c></span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%0</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%1</span> step <span class=m>32</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    affine<span class=p>.</span>for <span class=nv>%i2</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%2</span> step <span class=m>64</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      affine<span class=p>.</span>for <span class=nv>%i3</span> <span class=p>=</span> <span class=m>0</span> to <span class=nv>%3</span> step <span class=m>16</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nv>%val</span> <span class=p>=</span> <span class=err>`</span>ssa<span class=err>-</span>value<span class=err>`</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x32x64x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>        <span class=nv>%valt</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transpose <span class=nv>%val</span><span class=p>,</span> <span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>2</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>              <span class=kt>vector</span><span class=p>&lt;</span><span class=m>16x32x64x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>-&gt;</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x64x16x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>        <span class=kt>vector</span><span class=p>.</span>transfer_write <span class=nv>%valt</span><span class=p>,</span> <span class=nv>%A</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>,</span> <span class=nv>%i2</span><span class=p>,</span> <span class=nv>%i3</span><span class=p>]</span>
</span></span><span class=line><span class=cl>          <span class=p>{</span>permutation_map<span class=p>:</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>,</span> d2<span class=p>,</span> d3<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d1<span class=p>,</span> d2<span class=p>,</span> d3<span class=p>)}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=kt>vector</span><span class=p>&lt;</span><span class=m>32x64x16x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x?x?x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>}}}}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// write to a memref with vector element type.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=kt>vector</span><span class=p>.</span>transfer_write <span class=nv>%4</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%c3</span><span class=p>,</span> <span class=nv>%c3</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span><span class=nl>permutation_map =</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)-&gt;(</span>d0<span class=p>,</span> d1<span class=p>)}</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>1x1x4x3x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x3x</span><span class=k>f32</span><span class=p>&gt;&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// return a tensor where the vector is inserted into the source tensor.
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%5</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transfer_write <span class=nv>%4</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%c3</span><span class=p>,</span> <span class=nv>%c3</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span><span class=nl>permutation_map =</span> <span class=p>(</span>d0<span class=p>,</span> d1<span class=p>)-&gt;(</span>d0<span class=p>,</span> d1<span class=p>)}</span>
</span></span><span class=line><span class=cl>    <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>1x1x4x3x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=m>?x?x</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>4x3x</span><span class=k>f32</span><span class=p>&gt;&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c>// Special encoding for 0-d transfer with 0-d tensor/memref, vector shape
</span></span></span><span class=line><span class=cl><span class=c>// {1} and permutation_map () -&gt; (0).
</span></span></span><span class=line><span class=cl><span class=c></span><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transfer_write <span class=nv>%0</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>[]</span> <span class=p>{</span><span class=nl>permutation_map =</span> affine_map<span class=p>&lt;()-&gt;(</span><span class=m>0</span><span class=p>)&gt;}</span> <span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=kt>vector</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;,</span> <span class=kt>tensor</span><span class=p>&lt;</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AttrSizedOperandSegments</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>DestinationStyleOpInterface</code>, <code>MaskableOpInterface</code>, <code>MemoryEffectOpInterface</code>, <code>VectorTransferOpInterface</code>, <code>VectorUnrollOpInterface</code></p><h4 id=attributes-17>Attributes:&nbsp;<a class=headline-hash href=#attributes-17>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>permutation_map</code></td><td>::mlir::AffineMapAttr</td><td>AffineMap attribute</td></tr><tr><td><code>in_bounds</code></td><td>::mlir::ArrayAttr</td><td>1-bit boolean array attribute</td></tr></table><h4 id=operands-33>Operands:&nbsp;<a class=headline-hash href=#operands-33>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>valueToStore</code></td><td>vector of any type values</td></tr><tr><td style=text-align:center><code>base</code></td><td>shaped of any type values</td></tr><tr><td style=text-align:center><code>indices</code></td><td>variadic of index</td></tr><tr><td style=text-align:center><code>mask</code></td><td>vector of 1-bit signless integer values</td></tr></tbody></table><h4 id=results-31>Results:&nbsp;<a class=headline-hash href=#results-31>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>ranked tensor of any type values</td></tr></tbody></table><h3 id=vectortranspose-vectortransposeop><code>vector.transpose</code> (vector::TransposeOp)&nbsp;<a class=headline-hash href=#vectortranspose-vectortransposeop>¶</a></h3><p><em>Vector transpose operation</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.transpose` $vector `,` $permutation attr-dict `:` type($vector) `to` type($result)
</code></pre><p>Takes a n-D vector and returns the transposed n-D vector defined by
the permutation of ranks in the n-sized integer array attribute (in case
of 0-D vectors the array attribute must be empty).</p><p>In the operation</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transpose <span class=nv>%0</span><span class=p>,</span> <span class=p>[</span>i_1<span class=p>,</span> <span class=p>..,</span> i_n<span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span>d_1 <span class=p>x</span> <span class=p>..</span> <span class=p>x</span> d_n <span class=p>x</span> <span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>  to <span class=kt>vector</span><span class=p>&lt;</span>d_trans<span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>x</span> <span class=p>..</span> <span class=p>x</span> d_trans<span class=p>[</span>n<span class=m>-1</span><span class=p>]</span> <span class=p>x</span> <span class=k>f32</span><span class=p>&gt;</span>
</span></span></code></pre></div><p>the <code>permutation</code> array [i_1, .., i_n] must be a permutation of [0, .., n-1].</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%1</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>transpose <span class=nv>%0</span><span class=p>,</span> <span class=p>[</span><span class=m>1</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>vector</span><span class=p>&lt;</span><span class=m>2x3x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>vector</span><span class=p>&lt;</span><span class=m>3x2x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> <span class=p>[</span> <span class=p>[</span>a<span class=p>,</span> b<span class=p>,</span> c<span class=p>],</span>       <span class=p>[</span> <span class=p>[</span>a<span class=p>,</span> d<span class=p>],</span>
</span></span><span class=line><span class=cl>   <span class=p>[</span>d<span class=p>,</span> e<span class=p>,</span> f<span class=p>]</span> <span class=p>]</span>  <span class=p>-&gt;</span>    <span class=p>[</span>b<span class=p>,</span> e<span class=p>],</span>
</span></span><span class=line><span class=cl>                      <span class=p>[</span>c<span class=p>,</span> f<span class=p>]</span> <span class=p>]</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>InferIntRangeInterface</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>VectorUnrollOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=attributes-18>Attributes:&nbsp;<a class=headline-hash href=#attributes-18>¶</a></h4><table><tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr><tr><td><code>permutation</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr></table><h4 id=operands-34>Operands:&nbsp;<a class=headline-hash href=#operands-34>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>vector</code></td><td>vector of any type values</td></tr></tbody></table><h4 id=results-32>Results:&nbsp;<a class=headline-hash href=#results-32>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>vector of any type values</td></tr></tbody></table><h3 id=vectortype_cast-vectortypecastop><code>vector.type_cast</code> (vector::TypeCastOp)&nbsp;<a class=headline-hash href=#vectortype_cast-vectortypecastop>¶</a></h3><p><em>Type_cast op converts a scalar memref to a vector memref</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.type_cast` $memref attr-dict `:` type($memref) `to` type($result)
</code></pre><p>Performs a conversion from a memref with scalar element to a memref with a
<em>single</em> vector element, copying the shape of the memref to the vector. This
is the minimal viable operation that is required to makeke
super-vectorization operational. It can be seen as a special case of the
<code>view</code> operation but scoped in the super-vectorization context.</p><p>Example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-mlir data-lang=mlir><span class=line><span class=cl><span class=nv>%A</span>  <span class=p>=</span> <span class=kt>memref</span><span class=p>.</span>alloc<span class=p>()</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>5x4x3x</span><span class=k>f32</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=nv>%VA</span> <span class=p>=</span> <span class=kt>vector</span><span class=p>.</span>type_cast <span class=nv>%A</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>5x4x3x</span><span class=k>f32</span><span class=p>&gt;</span> to <span class=kt>memref</span><span class=p>&lt;</span><span class=kt>vector</span><span class=p>&lt;</span><span class=m>5x4x3x</span><span class=k>f32</span><span class=p>&gt;&gt;</span>
</span></span></code></pre></div><p>Traits: <code>AlwaysSpeculatableImplTrait</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>ViewLikeOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-35>Operands:&nbsp;<a class=headline-hash href=#operands-35>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>memref</code></td><td>statically shaped memref of any type values</td></tr></tbody></table><h4 id=results-33>Results:&nbsp;<a class=headline-hash href=#results-33>¶</a></h4><table><thead><tr><th style=text-align:center>Result</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>result</code></td><td>memref of any type values</td></tr></tbody></table><h3 id=vectoryield-vectoryieldop><code>vector.yield</code> (vector::YieldOp)&nbsp;<a class=headline-hash href=#vectoryield-vectoryieldop>¶</a></h3><p><em>Terminates and yields values from vector regions.</em></p><p>Syntax:</p><pre tabindex=0><code>operation ::= `vector.yield` attr-dict ($operands^ `:` type($operands))?
</code></pre><p>&ldquo;vector.yield&rdquo; yields an SSA value from the Vector dialect op region and
terminates the regions. The semantics of how the values are yielded is
defined by the parent operation.
If &ldquo;vector.yield&rdquo; has any operands, the operands must correspond to the
parent operation&rsquo;s results.
If the parent operation defines no value the vector.yield may be omitted
when printing the region.</p><p>Traits: <code>AlwaysSpeculatableImplTrait</code>, <code>ReturnLike</code>, <code>Terminator</code></p><p>Interfaces: <code>ConditionallySpeculatable</code>, <code>NoMemoryEffect (MemoryEffectOpInterface)</code>, <code>RegionBranchTerminatorOpInterface</code></p><p>Effects: <code>MemoryEffects::Effect{}</code></p><h4 id=operands-36>Operands:&nbsp;<a class=headline-hash href=#operands-36>¶</a></h4><table><thead><tr><th style=text-align:center>Operand</th><th>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>operands</code></td><td>variadic of any type</td></tr></tbody></table><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=https://mlir.llvm.org/docs/Dialects/VCIXDialect/ title="'vcix' Dialect"><i class="fas fa-arrow-left" aria-hidden=true></i> Prev - 'vcix' Dialect</a>
<a class="nav nav-next" href=https://mlir.llvm.org/docs/Dialects/X86Vector/ title="'x86vector' Dialect">Next - 'x86vector' Dialect <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=https://mlir.llvm.org/governance/>Governance</a></li><li><a href=https://mlir.llvm.org/users/>Users of MLIR</a></li><li><a href=https://mlir.llvm.org/pubs/>MLIR Related Publications</a></li><li><a href=https://mlir.llvm.org/talks/>Talks</a></li><li><a href=https://mlir.llvm.org/deprecation/>Deprecations & Current Refactoring</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/getting_started/ReportingIssues/>Reporting Issues</a></li><li><a href=https://mlir.llvm.org/getting_started/Debugging/>Debugging Tips</a></li><li><a href=https://mlir.llvm.org/getting_started/Faq/>FAQ</a></li><li><a href=https://mlir.llvm.org/getting_started/Contributing/>How to Contribute</a></li><li><a href=https://mlir.llvm.org/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=https://mlir.llvm.org/getting_started/openprojects/>Open Projects</a></li><li><a href=https://mlir.llvm.org/getting_started/Glossary/>Glossary</a></li><li><a href=https://mlir.llvm.org/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tools/>Tools<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tools/MLIRLSP/>MLIR : Language Server Protocol</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-reduce/>MLIR Reduce</a></li><li><a href=https://mlir.llvm.org/docs/Tools/mlir-rewrite/>mlir-rewrite</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/ActionTracing/>Action: Tracing and Debugging MLIR-based Compilers</a></li><li><a href=https://mlir.llvm.org/docs/Bufferization/>Bufferization</a></li><li><a href=https://mlir.llvm.org/docs/DataLayout/>Data Layout Modeling</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/DefiningDialects/>Defining Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Constraints/>Constraints</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Assembly/>Customizing Assembly Behavior</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=https://mlir.llvm.org/docs/DefiningDialects/Operations/>Operation Definition Specification (ODS)</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/DialectConversion/>Dialect Conversion</a></li><li class="parent has-sub-menu"><a href=https://mlir.llvm.org/docs/Dialects/>Dialects<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMDGPU/>'amdgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AMX/>'amx' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArithOps/>'arith' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSVE/>'arm_sve' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ArmSME/>'ArmSME' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/BufferizationOps/>'bufferization' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/>'cf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ComplexOps/>'complex' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/DLTIDialect/>'dlti' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/EmitC/>'emitc' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Func/>'func' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IndexOps/>'index' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/IRDL/>'irdl' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/Linalg/>'linalg' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/>Linalg OpDSL</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MathOps/>'math' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MemRef/>'memref' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MLProgramOps/>'ml_program' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MPI/>'mpi' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVGPU/>'nvgpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/>'omp' Dialect<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Dialects/OpenMPDialect/ODS/>ODS Documentation</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/PtrOps/>'ptr' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Shard/>'shard' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SMT/>'smt' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SparseTensorOps/>'sparse_tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/UBOps/>'ub' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/VCIXDialect/>'vcix' Dialect</a></li><li class=active><a href=https://mlir.llvm.org/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/X86Vector/>'x86vector' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeGPU/>'xegpu' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/XeVMDialect/>'xevm' Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Builtin/>Builtin Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/>OpInterface definitions</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/SPIR-V/>SPIR-V Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Dialects/Transform/>Transform Dialect</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Interfaces/>Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/TargetLLVMIR/>LLVM IR Target</a></li><li><a href=https://mlir.llvm.org/docs/BytecodeFormat/>MLIR Bytecode Format</a></li><li><a href=https://mlir.llvm.org/docs/CAPI/>MLIR C API</a></li><li><a href=https://mlir.llvm.org/docs/LangRef/>MLIR Language Reference</a></li><li><a href=https://mlir.llvm.org/docs/ReleaseNotes/>MLIR Release Notes</a></li><li><a href=https://mlir.llvm.org/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=https://mlir.llvm.org/docs/OwnershipBasedBufferDeallocation/>Ownership-based Buffer Deallocation</a></li><li><a href=https://mlir.llvm.org/docs/PassManagement/>Pass Infrastructure</a></li><li><a href=https://mlir.llvm.org/docs/Passes/>Passes</a></li><li><a href=https://mlir.llvm.org/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=https://mlir.llvm.org/docs/PDLL/>PDLL - PDL Language</a></li><li><a href=https://mlir.llvm.org/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/SideEffectsAndSpeculation/>Side Effects & Speculation</a></li><li><a href=https://mlir.llvm.org/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/ShapeInference/>Shape Inference</a></li><li><a href=https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=https://mlir.llvm.org/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=https://mlir.llvm.org/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Traits/>Traits<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Traits/Broadcastable/>The `Broadcastable` Trait</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li class=has-sub-menu><a href=https://mlir.llvm.org/docs/Tutorials/transform/>Transform Dialect Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch0/>Chapter 0: A Primer on “Structured” Linalg Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch1/>Chapter 1: Combining Existing Transformations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch2/>Chapter 2: Adding a Simple New Transformation Operation</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch3/>Chapter 3: More than Simple Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/Ch4/>Chapter 4: Matching Payload with Transform Operations</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/transform/ChH/>Chapter H: Reproducing Halide Schedule</a></li></ul></li><li><a href=https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/MlirOpt/>Using `mlir-opt`</a></li><li><a href=https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/>Writing DataFlow Analyses in MLIR</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i>
<i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>