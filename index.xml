<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MLIR</title><link>https://mlir.llvm.org/</link><description>Recent content on MLIR</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 19 Oct 2017 15:26:15 +0000</lastBuildDate><atom:link href="https://mlir.llvm.org/index.xml" rel="self" type="application/rss+xml"/><item><title>Reporting Issues</title><link>https://mlir.llvm.org/getting_started/ReportingIssues/</link><pubDate>Wed, 27 Apr 2022 10:30:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/ReportingIssues/</guid><description>Issues with MLIR can be reported through GitHub. Report the issue for the llvm-project repository at https://github.com/llvm/llvm-project/issues/new. If possible, attach the &amp;ldquo;mlir&amp;rdquo; label (label management may be limited to accounts that have a contribution history). Several other labels prefixed with &amp;ldquo;mlir:&amp;rdquo; are available if the issue can be classified further, for example, &amp;ldquo;mlir:core&amp;rdquo; can be used for issues with MLIR core libraries (mlir/lib/IR, mlir/lib/Interfaces, etc.) and &amp;ldquo;mlir:affine&amp;rdquo; can be used for issues with MLIR Affine dialect.</description></item><item><title>Debugging Tips</title><link>https://mlir.llvm.org/getting_started/Debugging/</link><pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Debugging/</guid><description>Inspecting compilation There&amp;rsquo;s no silver bullet for debugging the compilation process. Standard debugging techniques (printf debugging, gdb/lldb, IDE graphical debuggers, etc.) are of course applicable, but below are MLIR-specific facilities that are quite useful before diving into a generic debug flow. These facilities assume that you have reduced your problem to a form that can be reproduced with mlir-opt or another program that hooks into MLIR&amp;rsquo;s option parsing, if this is not the case, see section &amp;ldquo;Isolating test case&amp;rdquo; below.</description></item><item><title>FAQ</title><link>https://mlir.llvm.org/getting_started/Faq/</link><pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Faq/</guid><description>How to refer to MLIR in publications? Is there an accompanying paper? MLIR has been presented in the 2021 IEEE/ACM International Symposium on Code Generation and Optimization, the full text of the paper is available from IEEE. A pre-publication draft is available on arXiv but may be missing improvements and corrections. Please also note that MLIR keeps evolving and IR snippets presented in the paper may no longer use modern syntax, refer to the MLIR documentation for the new syntax.</description></item><item><title>How to Contribute</title><link>https://mlir.llvm.org/getting_started/Contributing/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Contributing/</guid><description>Everyone is welcome to contribute to MLIR. There are several ways of getting involved and contributing including reporting bugs, improving documentation and tutorials.
Community Guidelines Please be mindful of the LLVM Code of Conduct, which pledges to foster an open and welcoming environment.
Contributing code Please send pull-request on GitHub. If you don&amp;rsquo;t have write access to the repo, just leave a comment asking the reviewer to hit the merge button it for you.</description></item><item><title>Developer Guide</title><link>https://mlir.llvm.org/getting_started/DeveloperGuide/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/DeveloperGuide/</guid><description>This document attempts to describe a few developer policies used in MLIR (such as coding standards used) as well as development approach (such as, testing methods).
Style guide MLIR follows the LLVM style guide. We also adhere to the following (which deviate from or are not specified in the LLVM style guide):
Adopts camelBack; Uses Doxygen-style (///) comments for top-level and class member definitions, regardless of them being visible as public APIs.</description></item><item><title>Open Projects</title><link>https://mlir.llvm.org/getting_started/openprojects/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/openprojects/</guid><description>Below is a list of projects that can be suitable for Google Summer of Code (GSOC) or just for someone to get started with contributing to MLIR. See also the &amp;ldquo;beginner&amp;rdquo; issues on the bugtracker. If you&amp;rsquo;re interested in one of these projects, feel free to discuss it on the MLIR section of the LLVM forums or on the MLIR channel of the LLVM discord server. The mentors are indicative and suggestion of first point of contact for starting on these projects.</description></item><item><title>Glossary</title><link>https://mlir.llvm.org/getting_started/Glossary/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/Glossary/</guid><description>This glossary contains definitions of MLIR-specific terminology. It is intended to be a quick reference document. For terms which are well-documented elsewhere, definitions are kept brief and the header links to the more in-depth documentation.
Block A sequential list of operations without control flow.
Also called a basic block.
Conversion The transformation of code represented in one dialect into a semantically equivalent representation in another dialect (i.e. inter-dialect conversion) or the same dialect (i.</description></item><item><title>Testing Guide</title><link>https://mlir.llvm.org/getting_started/TestingGuide/</link><pubDate>Fri, 29 Nov 2019 15:26:15 +0000</pubDate><guid>https://mlir.llvm.org/getting_started/TestingGuide/</guid><description>Quickstart commands Run all MLIR tests: Run integration tests (requires -DMLIR_INCLUDE_INTEGRATION_TESTS=ON): Run C++ unit tests: Run lit tests in a specific directory Run a specific lit test file Test categories lit and FileCheck tests Diagnostic tests Integration tests C++ Unit tests Contributor guidelines FileCheck best practices Test Formatting Best Practices Test Documentation Best Practices Quickstart commands These commands are explained below in more detail. All commands are run from the cmake build directory build/, after building the project.</description></item><item><title>'acc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</guid><description>The acc dialect is an MLIR dialect for representing the OpenACC programming model. OpenACC is a standardized directive-based model which is used with C, C++, and Fortran to enable programmers to expose parallelism in their code. The descriptive approach used by OpenACC allows targeting of parallel multicore and accelerator targets like GPUs by giving the compiler the freedom of how to parallelize for specific architectures. OpenACC also provides the ability to optimize the parallelism through increasingly more prescriptive clauses.</description></item><item><title>'affine' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Affine/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Affine/</guid><description>This dialect provides a powerful abstraction for affine operations and analyses.
Polyhedral Structures Dimensions and Symbols Restrictions on Dimensions and Symbols Affine Expressions Affine Maps Semi-affine maps Integer Sets Operations affine.apply (affine::AffineApplyOp) affine.delinearize_index (affine::AffineDelinearizeIndexOp) affine.for (affine::AffineForOp) affine.if (affine::AffineIfOp) affine.linearize_index (affine::AffineLinearizeIndexOp) affine.load (affine::AffineLoadOp) affine.max (affine::AffineMaxOp) affine.min (affine::AffineMinOp) affine.parallel (affine::AffineParallelOp) affine.prefetch (affine::AffinePrefetchOp) affine.store (affine::AffineStoreOp) affine.vector_load (affine::AffineVectorLoadOp) affine.vector_store (affine::AffineVectorStoreOp) affine.yield (affine::AffineYieldOp) affine.dma_start (mlir::AffineDmaStartOp) affine.dma_wait (mlir::AffineDmaWaitOp) Polyhedral Structures MLIR uses techniques from polyhedral compilation to make dependence analysis and loop transformations efficient and reliable.</description></item><item><title>'amdgpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AMDGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AMDGPU/</guid><description>The AMDGPU dialect provides wrappers around AMD-specific functionality and LLVM intrinsics. These wrappers should be used in conjunction with more generic dialects, such as gpu and vector, when generating LLVM IR that will eventually be executed on AMD hardware.
Operations amdgpu.dpp (amdgpu::DPPOp) amdgpu.ext_packed_fp8 (amdgpu::ExtPackedFp8Op) amdgpu.fat_raw_buffer_cast (amdgpu::FatRawBufferCastOp) amdgpu.gather_to_lds (amdgpu::GatherToLDSOp) amdgpu.lds_barrier (amdgpu::LDSBarrierOp) amdgpu.memory_counter_wait (amdgpu::MemoryCounterWaitOp) amdgpu.mfma (amdgpu::MFMAOp) amdgpu.packed_scaled_trunc (amdgpu::PackedScaledTruncOp) amdgpu.packed_stoch_round_fp8 (amdgpu::PackedStochRoundFp8Op) amdgpu.packed_trunc_2xfp8 (amdgpu::PackedTrunc2xFp8Op) amdgpu.raw_buffer_atomic_cmpswap (amdgpu::RawBufferAtomicCmpswapOp) amdgpu.raw_buffer_atomic_fadd (amdgpu::RawBufferAtomicFaddOp) amdgpu.raw_buffer_atomic_fmax (amdgpu::RawBufferAtomicFmaxOp) amdgpu.raw_buffer_atomic_smax (amdgpu::RawBufferAtomicSmaxOp) amdgpu.raw_buffer_atomic_umin (amdgpu::RawBufferAtomicUminOp) amdgpu.</description></item><item><title>'amx' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AMX/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AMX/</guid><description>The Intel Advanced Matrix Extensions (AMX) provide a tile matrix multiply unit (TMUL), a tile control register (TILECFG), and eight tile registers TMM0 through TMM7 (TILEDATA).
This AMX dialect provides a bridge between MLIR concepts such as vectors and memrefs and the lower level LLVM IR support of AMX.
Note that since configuration changes (implicit at dialect level) are costly, it is highly recommended to use the AMX dialect on same-shaped vectors, at least within a single method.</description></item><item><title>'arith' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArithOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArithOps/</guid><description>The arith dialect is intended to hold basic integer and floating point mathematical operations. This includes unary, binary, and ternary arithmetic ops, bitwise and shift ops, cast ops, and compare ops. Operations in this dialect also accept vectors and tensors of integers or floats. The dialect assumes integers are represented by bitvectors with a two&amp;rsquo;s complement representation. Unless otherwise stated, the operations within this dialect propagate poison values, i.e., if any of its inputs are poison, then the output is poison.</description></item><item><title>'arm_neon' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmNeon/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmNeon/</guid><description>Operations arm_neon.2d.sdot (arm_neon::Sdot2dOp) arm_neon.intr.bfmmla (arm_neon::BfmmlaOp) arm_neon.intr.sdot (arm_neon::SdotOp) arm_neon.intr.smmla (arm_neon::SmmlaOp) arm_neon.intr.smull (arm_neon::SMullOp) arm_neon.intr.ummla (arm_neon::UmmlaOp) arm_neon.intr.usmmla (arm_neon::UsmmlaOp) Operations source
arm_neon.2d.sdot (arm_neon::Sdot2dOp) Sdot op
Syntax:
operation ::= `arm_neon.2d.sdot` $a `,` $b `,` $c attr-dict `:` type($b) `,` type($c) `to` type($res) The two input vectors b and c have a 2D shape, consisting of either 2 or 4 rows, each row having length 4. This operation computes the pair-wise dot-products of the rows of b and c and accumulates them with the corresponding entry of a:</description></item><item><title>'arm_sve' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmSVE/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmSVE/</guid><description>Basic dialect to target Arm SVE architectures
This dialect contains the definitions necessary to target specific Arm SVE scalable vector operations.
Operations arm_sve.convert_from_svbool (arm_sve::ConvertFromSvboolOp) arm_sve.convert_to_svbool (arm_sve::ConvertToSvboolOp) arm_sve.dupq_lane (arm_sve::DupQLaneOp) arm_sve.intr.add (arm_sve::ScalableMaskedAddIIntrOp) arm_sve.intr.bfmmla (arm_sve::BfmmlaOp) arm_sve.intr.convert.from.svbool (arm_sve::ConvertFromSvboolIntrOp) arm_sve.intr.convert.to.svbool (arm_sve::ConvertToSvboolIntrOp) arm_sve.intr.dupq_lane (arm_sve::DupQLaneIntrOp) arm_sve.intr.fadd (arm_sve::ScalableMaskedAddFIntrOp) arm_sve.intr.fdiv (arm_sve::ScalableMaskedDivFIntrOp) arm_sve.intr.fmul (arm_sve::ScalableMaskedMulFIntrOp) arm_sve.intr.fsub (arm_sve::ScalableMaskedSubFIntrOp) arm_sve.intr.mul (arm_sve::ScalableMaskedMulIIntrOp) arm_sve.intr.psel (arm_sve::PselIntrOp) arm_sve.intr.sdiv (arm_sve::ScalableMaskedSDivIIntrOp) arm_sve.intr.sdot (arm_sve::SdotIntrOp) arm_sve.intr.smmla (arm_sve::SmmlaIntrOp) arm_sve.intr.sub (arm_sve::ScalableMaskedSubIIntrOp) arm_sve.intr.udiv (arm_sve::ScalableMaskedUDivIIntrOp) arm_sve.intr.udot (arm_sve::UdotIntrOp) arm_sve.intr.ummla (arm_sve::UmmlaIntrOp) arm_sve.intr.usmmla (arm_sve::UsmmlaIntrOp) arm_sve.intr.whilelt (arm_sve::WhileLTIntrOp) arm_sve.intr.zip.x2 (arm_sve::ZipX2IntrOp) arm_sve.</description></item><item><title>'ArmSME' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmSME/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmSME/</guid><description>Basic dialect to target Arm SME.
This dialect defines custom and LLVM IR intrinsic operations that are used to target Arm Scalable Matrix Extension. Through the available conversion and ArmSME passes you can, for example, lower a linalg.matmul operation to Arm SME FMOPA (floating-point outer product) operations. See one of the in-tree end-to-end integration tests for reference:
Linalg/CPU/ArmSME/matmul.mlir Vector/CPU/ArmSME/outerproduct-f64.mlir In order to run ArmSME integration tests, include these flags in the CMake invocation when configuring LLVM and MLIR:</description></item><item><title>'async' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</guid><description>Types and operations for async dialect
This dialect contains operations for modeling asynchronous execution.
Operations async.add_to_group (async::AddToGroupOp) async.await (async::AwaitOp) async.await_all (async::AwaitAllOp) async.call (async::CallOp) async.coro.begin (async::CoroBeginOp) async.coro.end (async::CoroEndOp) async.coro.free (async::CoroFreeOp) async.coro.id (async::CoroIdOp) async.coro.save (async::CoroSaveOp) async.coro.suspend (async::CoroSuspendOp) async.create_group (async::CreateGroupOp) async.execute (async::ExecuteOp) async.func (async::FuncOp) async.return (async::ReturnOp) async.runtime.add_ref (async::RuntimeAddRefOp) async.runtime.add_to_group (async::RuntimeAddToGroupOp) async.runtime.await (async::RuntimeAwaitOp) async.runtime.await_and_resume (async::RuntimeAwaitAndResumeOp) async.runtime.create (async::RuntimeCreateOp) async.runtime.create_group (async::RuntimeCreateGroupOp) async.runtime.drop_ref (async::RuntimeDropRefOp) async.runtime.is_error (async::RuntimeIsErrorOp) async.runtime.load (async::RuntimeLoadOp) async.runtime.num_worker_threads (async::RuntimeNumWorkerThreadsOp) async.runtime.resume (async::RuntimeResumeOp) async.runtime.set_available (async::RuntimeSetAvailableOp) async.runtime.set_error (async::RuntimeSetErrorOp) async.</description></item><item><title>'bufferization' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</guid><description>Bufferization in MLIR is the process of converting the tensor type to the memref type. Simply put, bufferization is the process of converting computations on the mathematical tensor construct to computations on physical memory buffers. The bufferization dialect contains operations/interfaces specific to the bufferization passes.
An overview of the bufferization infrastructure and important conceptual details related to using the MLIR dialect conversion infrastructure can be found in bufferization and ownership-based buffer deallocation.</description></item><item><title>'cf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</guid><description>This dialect contains low-level, i.e. non-region based, control flow constructs. These constructs generally represent control flow directly on SSA blocks of a control flow graph.
Operations cf.assert (cf::AssertOp) cf.br (cf::BranchOp) cf.cond_br (cf::CondBranchOp) cf.switch (cf::SwitchOp) Operations source
cf.assert (cf::AssertOp) Assert operation with message attribute
Syntax:
operation ::= `cf.assert` $arg `,` $msg attr-dict Assert operation at runtime with single boolean operand and an error message attribute. If the argument is true this operation has no effect.</description></item><item><title>'complex' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ComplexOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ComplexOps/</guid><description>The complex dialect is intended to hold complex numbers creation and arithmetic ops.
Operations complex.abs (complex::AbsOp) complex.add (complex::AddOp) complex.angle (complex::AngleOp) complex.atan2 (complex::Atan2Op) complex.bitcast (complex::BitcastOp) complex.conj (complex::ConjOp) complex.constant (complex::ConstantOp) complex.cos (complex::CosOp) complex.create (complex::CreateOp) complex.div (complex::DivOp) complex.eq (complex::EqualOp) complex.exp (complex::ExpOp) complex.expm1 (complex::Expm1Op) complex.im (complex::ImOp) complex.log (complex::LogOp) complex.log1p (complex::Log1pOp) complex.mul (complex::MulOp) complex.neg (complex::NegOp) complex.neq (complex::NotEqualOp) complex.pow (complex::PowOp) complex.re (complex::ReOp) complex.rsqrt (complex::RsqrtOp) complex.sign (complex::SignOp) complex.sin (complex::SinOp) complex.sqrt (complex::SqrtOp) complex.sub (complex::SubOp) complex.tan (complex::TanOp) complex.tanh (complex::TanhOp) Enums CmpFPredicate CmpIPredicate IntegerOverflowFlags RoundingMode AtomicRMWKind ComplexRangeFlags FastMathFlags Operations source</description></item><item><title>'dlti' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</guid><description>The Data Layout and Target Information (DLTI) dialect is intended to hold attributes and other components pertaining to descriptions of in-memory data layout and compilation targets.
Attributes DataLayoutEntryAttr DataLayoutSpecAttr FunctionPointerAlignmentAttr MapAttr TargetDeviceSpecAttr TargetSystemSpecAttr Attributes DataLayoutEntryAttr An attribute to represent an entry of a data layout specification.
A data layout entry attribute is a key-value pair where the key is a type or an identifier and the value is another attribute.</description></item><item><title>'emitc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/EmitC/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/EmitC/</guid><description>Dialect to generate C/C++ from MLIR.
The EmitC dialect allows to convert operations from other MLIR dialects to EmitC ops. Those can be translated to C/C++ via the Cpp emitter.
The following convention is followed:
If template arguments are passed to an emitc.call_opaque operation, C++ is generated. If tensors are used, C++ is generated. If multiple return values are used within in a functions or an emitc.call_opaque operation, C++11 is required.</description></item><item><title>'func' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Func/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Func/</guid><description>This dialect provides documentation for operations within the Func dialect.
This dialect contains operations surrounding high order function abstractions, such as calls.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations func.call_indirect (func::CallIndirectOp) func.call (func::CallOp) func.constant (func::ConstantOp) func.func (func::FuncOp) func.return (func::ReturnOp) Operations source
func.call_indirect (func::CallIndirectOp) Indirect call operation
Syntax:
operation ::= `func.call_indirect` $callee `(` $callee_operands `)` attr-dict `:` type($callee) The func.call_indirect operation represents an indirect call to a value of function type.</description></item><item><title>'gpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/GPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/GPU/</guid><description>Note: this dialect is more likely to change than others in the near future; use with caution.
This dialect provides middle-level abstractions for launching GPU kernels following a programming model similar to that of CUDA or OpenCL. It provides abstractions for kernel invocations (and may eventually provide those for device management) that are not present at the lower level (e.g., as LLVM IR intrinsics for GPUs). Its goal is to abstract away device- and driver-specific manipulations to launch a GPU kernel and provide a simple path towards GPU execution from MLIR.</description></item><item><title>'index' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/IndexOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/IndexOps/</guid><description>The Index dialect
The Index dialect contains operations for manipulating values of the builtin index type. The index type models target-specific values of pointer width, like intptr_t. Index values are typically used as loop bounds, array subscripts, tensor dimensions, etc.
The operations in this dialect operate exclusively on scalar index types. The dialect and its operations treat the index type as signless and contains signed and unsigned versions of certain operations where the distinction is meaningful.</description></item><item><title>'irdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/IRDL/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/IRDL/</guid><description>IR Definition Language Dialect
IRDL is an SSA-based declarative representation of dynamic dialects. It allows the definition of dialects, operations, attributes, and types, with a declarative description of their verifiers. IRDL code is meant to be generated and not written by hand. As such, the design focuses on ease of generation/analysis instead of ease of writing/reading.
Users can define a new dialect with irdl.dialect, operations with irdl.operation, types with irdl.</description></item><item><title>'llvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/LLVM/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LLVM/</guid><description>This dialect maps LLVM IR into MLIR by defining the corresponding operations and types. LLVM IR metadata is usually represented as MLIR attributes, which offer additional structure verification.
We use &amp;ldquo;LLVM IR&amp;rdquo; to designate the intermediate representation of LLVM and &amp;ldquo;LLVM dialect&amp;rdquo; or &amp;ldquo;LLVM IR dialect&amp;rdquo; to refer to this MLIR dialect.
Unless explicitly stated otherwise, the semantics of the LLVM dialect operations must correspond to the semantics of LLVM IR instructions and any divergence is considered a bug.</description></item><item><title>'math' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MathOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MathOps/</guid><description>The math dialect is intended to hold mathematical operations on integer and floating types beyond simple arithmetics. Each operation works on scalar, vector or tensor type. On vector and tensor type operations apply elementwise unless explicitly specified otherwise. As an example, the floating point absolute value can be expressed as:
// Scalar absolute value. %a = math.absf %b : f64 // Vector elementwise absolute value. %f = math.absf %g : vector&amp;lt;4xf32&amp;gt; // Tensor elementwise absolute value.</description></item><item><title>'memref' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MemRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MemRef/</guid><description>This dialect provides documentation for operations within the MemRef dialect.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations memref.assume_alignment (memref::AssumeAlignmentOp) memref.atomic_rmw (memref::AtomicRMWOp) memref.atomic_yield (memref::AtomicYieldOp) memref.copy (memref::CopyOp) memref.generic_atomic_rmw (memref::GenericAtomicRMWOp) memref.load (memref::LoadOp) memref.alloc (memref::AllocOp) memref.alloca (memref::AllocaOp) memref.alloca_scope (memref::AllocaScopeOp) memref.alloca_scope.return (memref::AllocaScopeReturnOp) memref.cast (memref::CastOp) memref.collapse_shape (memref::CollapseShapeOp) memref.dealloc (memref::DeallocOp) memref.dim (memref::DimOp) memref.dma_start (memref::DmaStartOp) memref.dma_wait (memref::DmaWaitOp) memref.expand_shape (memref::ExpandShapeOp) memref.extract_aligned_pointer_as_index (memref::ExtractAlignedPointerAsIndexOp) memref.extract_strided_metadata (memref::ExtractStridedMetadataOp) memref.get_global (memref::GetGlobalOp) memref.global (memref::GlobalOp) memref.memory_space_cast (memref::MemorySpaceCastOp) memref.</description></item><item><title>'ml_program' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</guid><description>The MLProgram dialect contains structural operations and types for defining a compiled Machine-Learning program, as created from common ML frameworks, such as TensorFlow, PyTorch, JAX, etc. It does not itself define computation ops common to such frameworks but establishes a common programming model for establishing modules, functions, globals and memory model components appropriate for such an abstract level of detail.
This dialect is under active development, and while stability is an eventual goal, it is not guaranteed at this juncture.</description></item><item><title>'mpi' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MPI/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MPI/</guid><description>This dialect models the Message Passing Interface (MPI), version 4.0. It is meant to serve as an interfacing dialect that is targeted by higher-level dialects. The MPI dialect itself can be lowered to multiple MPI implementations and hide differences in ABI. The dialect models the functions of the MPI specification as close to 1:1 as possible while preserving SSA value semantics where it makes sense, and uses memref types instead of bare pointers.</description></item><item><title>'nvgpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVGPU/</guid><description>The NVGPU dialect provides a bridge between higher-level target-agnostic dialects (GPU and Vector) and the lower-level target-specific dialect (LLVM IR based NVVM dialect) for NVIDIA GPUs. This allow representing PTX specific operations while using MLIR high level dialects such as Memref and Vector for memory and target-specific register operands, respectively.
Operations nvgpu.device_async_copy (nvgpu::DeviceAsyncCopyOp) nvgpu.device_async_create_group (nvgpu::DeviceAsyncCreateGroupOp) nvgpu.device_async_wait (nvgpu::DeviceAsyncWaitOp) nvgpu.ldmatrix (nvgpu::LdMatrixOp) nvgpu.mbarrier.arrive (nvgpu::MBarrierArriveOp) nvgpu.mbarrier.arrive.expect_tx (nvgpu::MBarrierArriveExpectTxOp) nvgpu.mbarrier.arrive.nocomplete (nvgpu::MBarrierArriveNoCompleteOp) nvgpu.mbarrier.create (nvgpu::MBarrierCreateOp) nvgpu.mbarrier.get (nvgpu::MBarrierGetOp) nvgpu.</description></item><item><title>'nvvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</guid><description>Operations nvvm.bar.warp.sync (NVVM::SyncWarpOp) nvvm.barrier (NVVM::BarrierOp) nvvm.barrier.arrive (NVVM::BarrierArriveOp) nvvm.barrier0 (NVVM::Barrier0Op) nvvm.breakpoint (NVVM::Breakpoint) nvvm.cluster.arrive (NVVM::ClusterArriveOp) nvvm.cluster.arrive.relaxed (NVVM::ClusterArriveRelaxedOp) nvvm.cluster.wait (NVVM::ClusterWaitOp) nvvm.convert.bf16x2.to.f8x2 (NVVM::ConvertBF16x2ToF8x2Op) nvvm.convert.f16x2.to.f8x2 (NVVM::ConvertF16x2ToF8x2Op) nvvm.convert.f32x2.to.f6x2 (NVVM::ConvertF32x2ToF6x2Op) nvvm.convert.f32x2.to.f8x2 (NVVM::ConvertF32x2ToF8x2Op) nvvm.convert.float.to.tf32 (NVVM::ConvertFloatToTF32Op) nvvm.cp.async.bulk.commit.group (NVVM::CpAsyncBulkCommitGroupOp) nvvm.cp.async.bulk.global.shared.cta (NVVM::CpAsyncBulkSharedCTAToGlobalOp) nvvm.cp.async.bulk.prefetch (NVVM::CpAsyncBulkPrefetchOp) nvvm.cp.async.bulk.shared.cluster.global (NVVM::CpAsyncBulkGlobalToSharedClusterOp) nvvm.cp.async.bulk.shared.cluster.shared.cta (NVVM::CpAsyncBulkSharedCTAToSharedClusterOp) nvvm.cp.async.bulk.tensor.global.shared.cta (NVVM::CpAsyncBulkTensorSharedCTAToGlobalOp) nvvm.cp.async.bulk.tensor.prefetch (NVVM::CpAsyncBulkTensorPrefetchOp) nvvm.cp.async.bulk.tensor.reduce (NVVM::CpAsyncBulkTensorReduceOp) nvvm.cp.async.bulk.tensor.shared.cluster.global (NVVM::CpAsyncBulkTensorGlobalToSharedClusterOp) nvvm.cp.async.bulk.wait_group (NVVM::CpAsyncBulkWaitGroupOp) nvvm.cp.async.commit.group (NVVM::CpAsyncCommitGroupOp) nvvm.cp.async.mbarrier.arrive (NVVM::CpAsyncMBarrierArriveOp) nvvm.cp.async.mbarrier.arrive.shared (NVVM::CpAsyncMBarrierArriveSharedOp) nvvm.cp.async.shared.global (NVVM::CpAsyncOp) nvvm.cp.async.wait.group (NVVM::CpAsyncWaitGroupOp) nvvm.dot.accumulate.2way (NVVM::DotAccumulate2WayOp) nvvm.dot.accumulate.4way (NVVM::DotAccumulate4WayOp) nvvm.elect.sync (NVVM::ElectSyncOp) nvvm.exit (NVVM::Exit) nvvm.fence.mbarrier.init (NVVM::FenceMbarrierInitOp) nvvm.fence.proxy (NVVM::FenceProxyOp) nvvm.</description></item><item><title>'pdl_interp' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</guid><description>Interpreted pattern execution dialect
The PDL Interpreter dialect provides a lower level abstraction compared to the PDL dialect, and is targeted towards low level optimization and interpreter code generation. The dialect operations encapsulates low-level pattern match and rewrite &amp;ldquo;primitives&amp;rdquo;, such as navigating the IR (Operation::getOperand), creating new operations (OpBuilder::create), etc. Many of the operations within this dialect also fuse branching control flow with some form of a predicate comparison operation.</description></item><item><title>'pdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLOps/</guid><description>High level pattern definition dialect
PDL presents a high level abstraction for the rewrite pattern infrastructure available in MLIR. This abstraction allows for representing patterns transforming MLIR, as MLIR. This allows for applying all of the benefits that the general MLIR infrastructure provides, to the infrastructure itself. This means that pattern matching can be more easily verified for correctness, targeted by frontends, and optimized.
PDL abstracts over various different aspects of patterns and core MLIR data structures.</description></item><item><title>'ptr' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PtrOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PtrOps/</guid><description>Pointer dialect
Operations ptr.from_ptr (ptr::FromPtrOp) ptr.get_metadata (ptr::GetMetadataOp) ptr.ptr_add (ptr::PtrAddOp) ptr.to_ptr (ptr::ToPtrOp) ptr.type_offset (ptr::TypeOffsetOp) Attributes GenericSpaceAttr SpecAttr Types PtrMetadataType PtrType Enums AtomicBinOp AtomicOrdering PtrAddFlags Operations source
ptr.from_ptr (ptr::FromPtrOp) Casts a !ptr.ptr value to a ptr-like value.
Syntax:
operation ::= `ptr.from_ptr` $ptr (`metadata` $metadata^)? attr-dict `:` type($ptr) `-&amp;gt;` type($result) The from_ptr operation casts a ptr value to a ptr-like object. It&amp;rsquo;s important to note that:
The ptr-like object cannot be a !</description></item><item><title>'quant' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/QuantDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/QuantDialect/</guid><description>The quant dialect offers a framework for defining and manipulating quantized values. Central to this framework is the !quant.uniform data type, used to represent quantized values. This dialect also provides a suite of operations to handle and convert quantized values between their original floating-point representations and the optimized, lower bit-width integer representations. The quant dialect is instrumented with transformation passes to lower these operations into other core MLIR dialects, while also flattening all occurrences of quantized types into their integer counterparts.</description></item><item><title>'rocdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</guid><description>Operations rocdl.ballot (ROCDL::BallotOp) rocdl.barrier (ROCDL::BarrierOp) rocdl.cvt.f32.bf8 (ROCDL::CvtF32Bf8Op) rocdl.cvt.f32.fp8 (ROCDL::CvtF32Fp8Op) rocdl.cvt.pk.bf8.f32 (ROCDL::CvtPkBf8F32Op) rocdl.cvt.pk.f32.bf8 (ROCDL::CvtPkF32Bf8Op) rocdl.cvt.pk.f32.fp8 (ROCDL::CvtPkF32Fp8Op) rocdl.cvt.pk.fp8.f32 (ROCDL::CvtPkFp8F32Op) rocdl.cvt.pkrtz (ROCDL::CvtPkRtz) rocdl.cvt.scalef32.2xpk16.bf6.f32 (ROCDL::CvtScaleF322xPk16Bf6F32Op) rocdl.cvt.scalef32.2xpk16.fp6.f32 (ROCDL::CvtScaleF322xPk16Fp6F32Op) rocdl.cvt.scalef32.f16.bf8 (ROCDL::CvtScaleF32F16Bf8Op) rocdl.cvt.scalef32.f16.fp8 (ROCDL::CvtScaleF32F16Fp8Op) rocdl.cvt.scalef32.f32.bf8 (ROCDL::CvtScaleF32F32Bf8Op) rocdl.cvt.scalef32.f32.fp8 (ROCDL::CvtScaleF32F32Fp8Op) rocdl.cvt.scalef32.pk.bf16.bf8 (ROCDL::CvtScaleF32PkBf16Bf8Op) rocdl.cvt.scalef32.pk.bf16.fp4 (ROCDL::CvtScaleF32PkBf16Fp4Op) rocdl.cvt.scalef32.pk.bf16.fp8 (ROCDL::CvtScaleF32PkBf16Fp8Op) rocdl.cvt.scalef32.pk.bf8.bf16 (ROCDL::CvtScaleF32PkBf8Bf16Op) rocdl.cvt.scalef32.pk.bf8.f16 (ROCDL::CvtScaleF32PkBf8F16Op) rocdl.cvt.scalef32.pk.bf8.f32 (ROCDL::CvtScaleF32PkBf8F32Op) rocdl.cvt.scalef32.pk.f16.bf8 (ROCDL::CvtScaleF32PkF16Bf8Op) rocdl.cvt.scalef32.pk.f16.fp4 (ROCDL::CvtScaleF32PkF16Fp4Op) rocdl.cvt.scalef32.pk.f16.fp8 (ROCDL::CvtScaleF32PkF16Fp8Op) rocdl.cvt.scalef32.pk.f32.bf8 (ROCDL::CvtScaleF32PkF32Bf8Op) rocdl.cvt.scalef32.pk.f32.fp4 (ROCDL::CvtScaleF32PkF32Fp4Op) rocdl.cvt.scalef32.pk.f32.fp8 (ROCDL::CvtScaleF32PkF32Fp8Op) rocdl.cvt.scalef32.pk.fp4.bf16 (ROCDL::CvtScaleF32PkFp4Bf16Op) rocdl.cvt.scalef32.pk.fp4.f16 (ROCDL::CvtScaleF32PkFp4F16Op) rocdl.cvt.scalef32.pk.fp4.f32 (ROCDL::CvtScaleF32PkFp4F32Op) rocdl.cvt.scalef32.pk.fp8.bf16 (ROCDL::CvtScaleF32PkFp8Bf16Op) rocdl.cvt.scalef32.pk.fp8.f16 (ROCDL::CvtScaleF32PkFp8F16Op) rocdl.cvt.scalef32.pk.fp8.f32 (ROCDL::CvtScaleF32PkFp8F32Op) rocdl.cvt.scalef32.pk32.bf16.bf6 (ROCDL::CvtScaleF32Pk32Bf16Bf6Op) rocdl.</description></item><item><title>'scf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SCFDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SCFDialect/</guid><description>The scf (structured control flow) dialect contains operations that represent control flow constructs such as if and for. Being structured means that the control flow has a structure unlike, for example, gotos or asserts. Unstructured control flow operations are located in the cf (control flow) dialect.
Originally, this dialect was developed as a common lowering stage for the affine and linalg dialects. Both convert to SCF loops instead of targeting branch-based CFGs directly.</description></item><item><title>'shape' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</guid><description>Description of operations &amp;amp; types within the Shape dialect as well as their usage.
Types and operations for shape dialect
This dialect contains operations for shape inference.
Note: Unless explicitly stated, all functions that return a shape and take shapes as input, return the invalid shape if one of its operands is an invalid shape. This avoids flagging multiple errors for one verification failure. The dialect itself does not specify how errors should be combined (there are multiple different options, from always choosing first operand, concatting etc.</description></item><item><title>'shard' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Shard/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Shard/</guid><description>The &amp;lsquo;shard&amp;rsquo; dialect defines a set of attributes, operations, and interfaces for working with tensor sharding and device communication.
It’s inspired by [GSPMD](General and Scalable Parallelization for ML Computation Graphs).
Originally, the dialect was called mesh, but it was renamed to better reflect what it actually does.
Collective Communication Operations Device Groups In-group Devices Purity and Execution Model Operations shard.all_gather (shard::AllGatherOp) shard.all_reduce (shard::AllReduceOp) shard.all_slice (shard::AllSliceOp) shard.all_to_all (shard::AllToAllOp) shard.broadcast (shard::BroadcastOp) shard.gather (shard::GatherOp) shard.</description></item><item><title>'smt' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SMT/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SMT/</guid><description>A dialect that models satisfiability modulo theories
Operations smt.and (mlir::smt::AndOp) smt.apply_func (mlir::smt::ApplyFuncOp) smt.array.broadcast (mlir::smt::ArrayBroadcastOp) smt.array.select (mlir::smt::ArraySelectOp) smt.array.store (mlir::smt::ArrayStoreOp) smt.assert (mlir::smt::AssertOp) smt.bv.add (mlir::smt::BVAddOp) smt.bv.and (mlir::smt::BVAndOp) smt.bv.ashr (mlir::smt::BVAShrOp) smt.bv.cmp (mlir::smt::BVCmpOp) smt.bv.concat (mlir::smt::ConcatOp) smt.bv.constant (mlir::smt::BVConstantOp) smt.bv.extract (mlir::smt::ExtractOp) smt.bv.lshr (mlir::smt::BVLShrOp) smt.bv.mul (mlir::smt::BVMulOp) smt.bv.neg (mlir::smt::BVNegOp) smt.bv.not (mlir::smt::BVNotOp) smt.bv.or (mlir::smt::BVOrOp) smt.bv.repeat (mlir::smt::RepeatOp) smt.bv.sdiv (mlir::smt::BVSDivOp) smt.bv.shl (mlir::smt::BVShlOp) smt.bv.smod (mlir::smt::BVSModOp) smt.bv.srem (mlir::smt::BVSRemOp) smt.bv.udiv (mlir::smt::BVUDivOp) smt.bv.urem (mlir::smt::BVURemOp) smt.bv.xor (mlir::smt::BVXOrOp) smt.bv2int (mlir::smt::BV2IntOp) smt.check (mlir::smt::CheckOp) smt.constant (mlir::smt::BoolConstantOp) smt.declare_fun (mlir::smt::DeclareFunOp) smt.distinct (mlir::smt::DistinctOp) smt.</description></item><item><title>'sparse_tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</guid><description>The SparseTensor dialect supports all the attributes, types, operations, and passes that are required to make sparse tensor types first class citizens within the MLIR compiler infrastructure. The dialect forms a bridge between high-level operations on sparse tensors types and lower-level operations on the actual sparse storage schemes consisting of positions, coordinates, and values. Lower-level support may consist of fully generated code or may be provided by means of a small sparse runtime support library.</description></item><item><title>'tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TensorOps/</guid><description>The tensor dialect is intended to hold core tensor creation and manipulation ops, which are not strongly associated with any particular other dialect or domain abstraction. The aim for ops in this dialect is that they make sense for any tensor element type. When this is not the case, the op is left to live in other dialects. Examples of element types that could be supported by the tensor dialect include:</description></item><item><title>'ub' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/UBOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/UBOps/</guid><description>Operations ub.poison (ub::PoisonOp) Attributes PoisonAttr Operations source
ub.poison (ub::PoisonOp) Poisoned constant operation.
Syntax:
operation ::= `ub.poison` attr-dict (`&amp;lt;` $value^ `&amp;gt;`)? `:` type($result) The poison operation materializes a compile-time poisoned constant value to indicate deferred undefined behavior. value attribute is needed to indicate an optional additional poison semantics (e.g. partially poisoned vectors), default value indicates results is fully poisoned.
Examples:
// Short form %0 = ub.poison : i32 // Long form %1 = ub.</description></item><item><title>'vcix' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/VCIXDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/VCIXDialect/</guid><description>The SiFive Vector Coprocessor Interface (VCIX) provides a flexible mechanism to extend application processors with custom coprocessors and variable-latency arithmetic units. The interface offers throughput comparable to that of standard RISC-V vector instructions. To accelerate performance, system designers may use VCIX as a low-latency, high-throughput interface to a coprocessor
https://www.sifive.com/document-file/sifive-vector-coprocessor-interface-vcix-software
Operations vcix.v.iv (vcix::BinaryImmOp) vcix.v.sv (vcix::BinaryOp) Operations source
vcix.v.iv (vcix::BinaryImmOp) Binary VCIX operation with an immediate second operand
Binary VCIX operation with an immediate second operand.</description></item><item><title>'vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Vector/</guid><description>Please post an RFC on the forum before adding any operation in this dialect.
Positioning in the Codegen Infrastructure Components of a Generic Retargetable Vector-Level Dialect Short Description of the Existing Infrastructure LLVM level Hardware Vector Ops Virtual Vector Ops Virtual Vector Rewrite Patterns Virtual Vector to Hardware Vector Lowering Rationale Hardware as vector Machines of Minimum Granularity Transformations Problems Avoided The Big Out-Of-Scope Piece: Automatic Vectorization Bikeshed Naming Discussion 0D Vectors LLVM Lowering Tradeoffs Alternatives For Lowering an n-D Vector Type to LLVM Constraints Inherited from LLVM (see LangRef) Nested Aggregate Flattened 1-D Vector Type Discussion Relationship to LLVM matrix type proposal.</description></item><item><title>'x86vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/X86Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/X86Vector/</guid><description>Operations x86vector.avx.bcst_to_f32.packed (x86vector::BcstToPackedF32Op) x86vector.avx.cvt.packed.even.indexed_to_f32 (x86vector::CvtPackedEvenIndexedToF32Op) x86vector.avx.cvt.packed.odd.indexed_to_f32 (x86vector::CvtPackedOddIndexedToF32Op) x86vector.avx.dot.i8 (x86vector::DotInt8Op) x86vector.avx.intr.dot (x86vector::DotOp) x86vector.avx.rsqrt (x86vector::RsqrtOp) x86vector.avx512.cvt.packed.f32_to_bf16 (x86vector::CvtPackedF32ToBF16Op) x86vector.avx512.dot (x86vector::DotBF16Op) x86vector.avx512.mask.compress (x86vector::MaskCompressOp) x86vector.avx512.mask.rndscale (x86vector::MaskRndScaleOp) x86vector.avx512.mask.scalef (x86vector::MaskScaleFOp) x86vector.avx512.vp2intersect (x86vector::Vp2IntersectOp) Operations source
x86vector.avx.bcst_to_f32.packed (x86vector::BcstToPackedF32Op) AVX: Broadcasts BF16/F16 into packed F32 Data.
Syntax:
operation ::= `x86vector.avx.bcst_to_f32.packed` $a attr-dict`:` type($a)`-&amp;gt;` type($dst) From the Intel Intrinsics Guide: Convert scalar BF16 or F16 (16-bit) floating-point element stored at memory locations starting at location __A to a single-precision (32-bit) floating-point, broadcast it to packed single-precision (32-bit) floating-point elements, and store the results in dst.</description></item><item><title>'xegpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/XeGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/XeGPU/</guid><description>The XeGPU dialect that models Intel GPU&amp;rsquo;s ISA
The XeGPU dialect closely models a subset of the Xe GPU&amp;rsquo;s ISA, providing an abstraction to support high-performance GEMM code generation. It serves as a bridge dialect in the MLIR gradual lowering process, working with MLIR memref and vector types, and complements the Arith, Math, Vector, and Memref dialects. XeGPU operations are introduced for special Xe instructions not modeled by the LLVM/SPIR-V dialect, such as DPAS and 2D block load and store.</description></item><item><title>'xevm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/XeVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/XeVMDialect/</guid><description>The XeVM dialect that extends LLVM dialect and models Intel GPU&amp;rsquo;s hardware features.
The XeVM dialect is extension to the LLVM dialect that models hardware features of Intel GPUs. The dialect is designed to work with the Xe architecture for Intel GPUs, supporting advanced operations like 2D block loads, stores, prefetch and matrix multiply-add (MMA) operations.
Operations xevm.blockload2d (xevm::BlockLoad2dOp) xevm.blockprefetch2d (xevm::BlockPrefetch2dOp) xevm.blockstore2d (xevm::BlockStore2dOp) xevm.memfence (xevm::MemfenceOp) xevm.mma (xevm::MMAOp) xevm.prefetch (xevm::PrefetchOp) Attributes AddrSpaceAttr LoadCacheControlAttr MMAShapeAttr MMATypesAttr MemScopeAttr StoreCacheControlAttr XeVMTargetAttr Enums AddrSpace ElemType LoadCacheControl MemScope StoreCacheControl Operations source</description></item><item><title>Action: Tracing and Debugging MLIR-based Compilers</title><link>https://mlir.llvm.org/docs/ActionTracing/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ActionTracing/</guid><description>Overview Wrapping a Transformation in an Action Intercepting Actions MLIR-provided Handlers Debug Counters ExecutionContext See also the slides and the recording from the MLIR Open Meeting where this feature was demoed.
Overview Action are means to encapsulate any transformation of any granularity in a way that can be intercepted by the framework for debugging or tracing purposes, including skipping a transformation programmatically (think about &amp;ldquo;compiler fuel&amp;rdquo; or &amp;ldquo;debug counters&amp;rdquo; in LLVM).</description></item><item><title>Bufferization</title><link>https://mlir.llvm.org/docs/Bufferization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Bufferization/</guid><description>Overview Deprecated Passes What is One-Shot Bufferize? Goals of Bufferization Destination-Passing Style Tensor / Buffer Boundary Using One-Shot Bufferize Memory Layouts Extending One-Shot Bufferize Debugging Buffer Copies Overview Bufferization in MLIR is the process of converting ops with tensor semantics to ops with memref semantics. There are multiple MLIR passes that are related to bufferization. These passes typically run as one of the last steps in a pass pipeline, right before lowering to memref ops to LLVM.</description></item><item><title>Builtin Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Builtin/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Builtin/</guid><description>The builtin dialect contains a core set of Attributes, Operations, and Types that have wide applicability across a very large number of domains and abstractions. Many of the components of this dialect are also instrumental in the implementation of the core IR. As such, this dialect is implicitly loaded in every MLIRContext, and available directly to all users of MLIR.
Given the far-reaching nature of this dialect and the fact that MLIR is extensible by design, any potential additions are heavily scrutinized.</description></item><item><title>Chapter 0: A Primer on “Structured” Linalg Operations</title><link>https://mlir.llvm.org/docs/Tutorials/transform/Ch0/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/transform/Ch0/</guid><description>Before starting the tutorial on the Transform dialect, let us take a brief look at the concept of Structured operations and its implementation in the Linalg dialect. Note that the Transform dialect does not require Structured operations and vice versa. The two co-evolved at the beginning of the Transform dialect, which makes the subset of transformations for Structured operations the most mature and most suitable for the tutorial. If you are already familiar with this concept, skip to Chapter 1.</description></item><item><title>Chapter 1: Combining Existing Transformations</title><link>https://mlir.llvm.org/docs/Tutorials/transform/Ch1/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/transform/Ch1/</guid><description>Introduction The Transform dialect allows one to precisely target transformations at specific operations in the IR and to chain them, that is to apply a transformation to operations produced by the previous transformation. To achieve this, transformations are expressed as other operations in the IR. We call these the IR containing these operations transform IR. And we call the IR that is being transformed payload IR.
Transform IR operations operate on values that may be associated with payload IR operations, values or attributes.</description></item><item><title>Chapter 1: Toy Language and AST</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-1/</guid><description>The Language The AST The Language This tutorial will be illustrated with a toy language that we’ll call “Toy” (naming is hard&amp;hellip;). Toy is a tensor-based language that allows you to define functions, perform some math computation, and print results.
Given that we want to keep things simple, the codegen will be limited to tensors of rank &amp;lt;= 2, and the only datatype in Toy is a 64-bit floating point type (aka ‘double’ in C parlance).</description></item><item><title>Chapter 2: Adding a Simple New Transformation Operation</title><link>https://mlir.llvm.org/docs/Tutorials/transform/Ch2/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/transform/Ch2/</guid><description>Setting Up to Add New Transformations Before defining a new transform operation, we need to choose where its implementation should be located. While MLIR encourages upstream contributions, it is not always possible or even desirable to modify the main Transform dialect, for example, if the transformation is specific to some out-of-tree dialect that is not itself available upstream.
The Transform dialect uses the dialect extension mechanism to allow additional operations to be injected without modifying the dialect itself.</description></item><item><title>Chapter 2: Emitting Basic MLIR</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/</guid><description>Introduction: Multi-Level Intermediate Representation Interfacing with MLIR Opaque API Defining a Toy Dialect Defining Toy Operations Op vs Operation: Using MLIR Operations Using the Operation Definition Specification (ODS) Framework Complete Toy Example Now that we&amp;rsquo;re familiar with our language and the AST, let&amp;rsquo;s see how MLIR can help to compile Toy.
Introduction: Multi-Level Intermediate Representation Other compilers, like LLVM (see the Kaleidoscope tutorial), offer a fixed set of predefined types and (usually low-level / RISC-like) instructions.</description></item><item><title>Chapter 3: High-level Language-Specific Analysis and Transformation</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-3/</guid><description>Optimize Transpose using C++ style pattern-match and rewrite Optimize Reshapes using DRR Creating a dialect that closely represents the semantics of an input language enables analyses, transformations and optimizations in MLIR that require high-level language information and are generally performed on the language AST. For example, clang has a fairly heavy mechanism for performing template instantiation in C++.
We divide compiler transformations into two categories: local and global. In this chapter, we focus on how to leverage the Toy Dialect and its high-level semantics to perform local pattern-match transformations that would be difficult in LLVM.</description></item><item><title>Chapter 3: More than Simple Transform Operations</title><link>https://mlir.llvm.org/docs/Tutorials/transform/Ch3/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/transform/Ch3/</guid><description>Type Constraints and ApplyEach Trait A transform operation that applies to each payload operation individually and requires it to be of a specific kind is a repeated pattern. One can use Transform dialect types to specify the preconditions of the type. Specifically, we can change the expected operand type from the wide TransformHandleTypeInterface to the more narrow Transform_ConcreteOp&amp;lt;&amp;quot;func.call&amp;quot;&amp;gt;. Furthermore, we use the TransformEachOpTrait trait to provide the skeleton implementation of the apply method that performs verification, iteration over payloads and result concatenation.</description></item><item><title>Chapter 4: Enabling Generic Transformation with Interfaces</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-4/</guid><description>Background: Grappling with an Extensible IR Shape Inference: Preparing for Code Generation Inlining Intraprocedural Shape Inference Background: Grappling with an Extensible IR Through dialects, MLIR allows for the representation of many different levels of abstraction; the Toy dialect that we have previously defined is one such example. Though these different dialects may represent different abstractions, there is often a set of common transformations and analyses that we would like to perform.</description></item><item><title>Chapter 4: Matching Payload with Transform Operations</title><link>https://mlir.llvm.org/docs/Tutorials/transform/Ch4/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/transform/Ch4/</guid><description>Check the continuously-tested version of MLIR files under mlir/test/Examples/transform/Ch4.
Up until now, we were applying transform dialect scripts under the assumption that specific payload operations are identified by the caller when the transform dialect interpreter is invoked. This may be seen as contrary to the idea of driving transformations from a dialect since the transformation targets must be identified through mechanisms external to the transform dialect interpreter, for example, when invoking the interpreter programmatically in C++ or through pass arguments as seen in previous chapters.</description></item><item><title>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-5/</guid><description>Conversion Target Conversion Patterns Partial Lowering Design Considerations With Partial Lowering Complete Toy Example Taking Advantage of Affine Optimization At this point, we are eager to generate actual code and see our Toy language take life. We will use LLVM to generate code, but just showing the LLVM builder interface here wouldn&amp;rsquo;t be very exciting. Instead, we will show how to perform progressive lowering through a mix of dialects coexisting in the same function.</description></item><item><title>Chapter 6: Lowering to LLVM and CodeGeneration</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-6/</guid><description>Lowering to LLVM Conversion Target Type Converter Conversion Patterns Full Lowering CodeGen: Getting Out of MLIR Emitting LLVM IR Setting up a JIT In the previous chapter, we introduced the dialect conversion framework and partially lowered many of the Toy operations to affine loop nests for optimization. In this chapter, we will finally lower to LLVM for code generation.
Lowering to LLVM For this lowering, we will again use the dialect conversion framework to perform the heavy lifting.</description></item><item><title>Chapter 7: Adding a Composite Type to Toy</title><link>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/Toy/Ch-7/</guid><description>Defining a struct in Toy Defining a struct in MLIR Defining the Type Class Exposing to ODS Parsing and Printing Operating on StructType In the previous chapter, we demonstrated an end-to-end compilation flow from our Toy front-end to LLVM IR. In this chapter, we will extend the Toy language to support a new composite struct type.
Defining a struct in Toy The first thing we need to define is the interface of this type in our toy source language.</description></item><item><title>Chapter H: Reproducing Halide Schedule</title><link>https://mlir.llvm.org/docs/Tutorials/transform/ChH/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/transform/ChH/</guid><description>This chapter demonstrates how a schedule from the Halide DSL can be implemented using Transform dialect for structured ops.
Note that the IR below is pseudo-code with types removed for brevity. It may also get out of sync with the current syntax. Always refer to the source code in mlir/examples/transform/ChH as the source of truth.
Channeled Convolution The Transform dialect provides a substrate for implementing “transformation directive” domain-specific languages (DSLs) in MLIR.</description></item><item><title>Constraints</title><link>https://mlir.llvm.org/docs/DefiningDialects/Constraints/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DefiningDialects/Constraints/</guid><description>Attribute / Type Constraints Attribute / Type Constraints When defining the arguments of an operation in TableGen, users can specify either plain attributes/types or use attribute/type constraints to levy additional requirements on the attribute value or operand type.
def My_Type1 : MyDialect_Type&amp;lt;&amp;#34;Type1&amp;#34;, &amp;#34;type1&amp;#34;&amp;gt; { ... } def My_Type2 : MyDialect_Type&amp;lt;&amp;#34;Type2&amp;#34;, &amp;#34;type2&amp;#34;&amp;gt; { ... } // Plain type let arguments = (ins MyType1:$val); // Type constraint let arguments = (ins AnyTypeOf&amp;lt;[MyType1, MyType2]&amp;gt;:$val); AnyTypeOf is an example for a type constraints.</description></item><item><title>Creating a Dialect</title><link>https://mlir.llvm.org/docs/Tutorials/CreatingADialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/CreatingADialect/</guid><description>CMake best practices TableGen Targets Library Targets CMake best practices Public dialects are typically separated into at least 3 directories:
mlir/include/mlir/Dialect/Foo (for public include files) mlir/lib/Dialect/Foo (for sources) mlir/lib/Dialect/Foo/IR (for operations) mlir/lib/Dialect/Foo/Transforms (for transforms) mlir/test/Dialect/Foo (for tests) Along with other public headers, the &amp;lsquo;include&amp;rsquo; directory contains a TableGen file in the ODS format, describing the operations in the dialect. This is used to generate operation declarations (FooOps.h.inc) and definitions (FooOps.</description></item><item><title>Customizing Assembly Behavior</title><link>https://mlir.llvm.org/docs/DefiningDialects/Assembly/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DefiningDialects/Assembly/</guid><description>Generating Aliases OpAsmDialectInterface OpAsmAttrInterface and OpAsmTypeInterface Suggesting SSA/Block Names Defining Default Dialect Generating Aliases AsmPrinter can generate aliases for frequently used types and attributes when not printing them in generic form. For example, !my_dialect.type&amp;lt;a=3,b=4,c=5,d=tuple,e=another_type&amp;gt; and #my_dialect.attr&amp;lt;a=3&amp;gt; can be aliased to !my_dialect_type and #my_dialect_attr.
There are mainly two ways to hook into the AsmPrinter. One is the attribute/type interface and the other is the dialect interface.
The attribute/type interface is the first hook to check.</description></item><item><title>Data Layout Modeling</title><link>https://mlir.llvm.org/docs/DataLayout/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DataLayout/</guid><description>Data layout information allows the compiler to answer questions related to how a value of a particular type is stored in memory. For example, the size of a value or its address alignment requirements. It enables, among others, the generation of various linear memory addressing schemes for containers of abstract types and deeper reasoning about vectors.
The data layout subsystem is designed to scale to MLIR&amp;rsquo;s open type and operation system.</description></item><item><title>Defining Dialect Attributes and Types</title><link>https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DefiningDialects/AttributesAndTypes/</guid><description>This document describes how to define dialect attributes and types.
LangRef Refresher Attributes Types Attributes and Types Adding a new Attribute or Type definition Class Name CMake Targets Documentation Mnemonic Parameters Traits Interfaces Builders Parsing and Printing Verification Storage Classes Mutable attributes and types Extra declarations Mnemonic Alias in Assembly Registering with the Dialect LangRef Refresher Before diving into how to define these constructs, below is a quick refresher from the MLIR LangRef.</description></item><item><title>Diagnostic Infrastructure</title><link>https://mlir.llvm.org/docs/Diagnostics/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Diagnostics/</guid><description>Source Locations Diagnostic Engine Constructing a Diagnostic Diagnostic Appending arguments Attaching notes Managing Metadata InFlight Diagnostic Diagnostic Configuration Options Print Operation On Diagnostic Print StackTrace On Diagnostic Common Diagnostic Handlers Scoped Diagnostic Handler SourceMgr Diagnostic Handler SourceMgr Diagnostic Verifier Handler Parallel Diagnostic Handler This document presents an introduction to using and interfacing with MLIR&amp;rsquo;s diagnostics infrastructure.
See MLIR specification for more information about MLIR, the structure of the IR, operations, etc.</description></item><item><title>Dialect Conversion</title><link>https://mlir.llvm.org/docs/DialectConversion/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DialectConversion/</guid><description>This document describes a framework in MLIR in which to perform operation conversions between, and within dialects. This framework allows for transforming illegal operations to those supported by a provided conversion target, via a set of pattern-based operation rewriting patterns.
The dialect conversion framework consists of the following components:
A Conversion Target A set of Rewrite Patterns A Type Converter (Optional) Modes of Conversion Conversion Target Recursive Legality Rewrite Pattern Specification Conversion Patterns Type Conversion Type Converter Region Signature Conversion Debugging Modes of Conversion When applying a conversion to a set of operations, there are several different conversion modes that may be selected from:</description></item><item><title>Generic DAG Rewriter Infrastructure Rationale</title><link>https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/RationaleGenericDAGRewriter/</guid><description>This document details the rationale behind a general DAG-to-DAG rewrite infrastructure for MLIR. For up-to-date documentation on the user facing API, please look at the main Pattern Rewriting document.
Introduction and Motivation The goal of a compiler IR is to represent code - at various levels of abstraction which pose different sets of tradeoffs in terms of representational capabilities and ease of transformation. However, the ability to represent code is not itself very useful - you also need to be able to implement those transformations.</description></item><item><title>Interfaces</title><link>https://mlir.llvm.org/docs/Interfaces/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Interfaces/</guid><description>MLIR is a generic and extensible framework, representing different dialects with their own attributes, operations, types, and so on. MLIR Dialects can express operations with a wide variety of semantics and different levels of abstraction. The downside to this is that MLIR transformations and analyses need to be able to account for the semantics of every operation, or be overly conservative. Without care, this can result in code with special-cases for each supported operation type.</description></item><item><title>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</title><link>https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/RationaleLinalgDialect/</guid><description>Introduction Positioning Inception Evolution Prior Art Lessons from ONNX Lessons from LIFT Lessons from XLA Lessons from Halide and TVM Lessons from Tensor Comprehensions Lessons from Polyhedral compilers Lessons from the Affine dialect Core Guiding Principles Transformations and Simplicity First Preservation of Information Composable and Declarative Transformations Suitability for Search and Machine Learning Extensibility and Future-Proofness Key Observations Algorithms + Data Structures = Programs The Dialect Need not be Closed Under Transformations Summary of Existing Alternatives a Picture Introduction Positioning This document describes the key design principles that led to the existing implementation of Linalg and aims at exposing the tradeoffs involved when building higher-level Intermediate Representations (IR) and Dialects to facilitate code generation.</description></item><item><title>Linalg OpDSL</title><link>https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Linalg/OpDSL/</guid><description>Warning: Linalg&amp;rsquo;s OpDSL is currently being deprecated, with its operations slowly being moved into TableGen&amp;rsquo;s ODS format. Please refer to the MLIR Restructuring discussion for more in-depth information.
Python based DSL for authoring Linalg op definitions and generating linalg.generic IR based on them for samples.
The Linalg OpDSL is a high level DSL for constructing structured op definitions in a way that can be exported to built-in, named structured ops via YAML-based definitions or used interactively to emit corresponding linalg.</description></item><item><title>LLVM IR Target</title><link>https://mlir.llvm.org/docs/TargetLLVMIR/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/TargetLLVMIR/</guid><description>This document describes the mechanisms of producing LLVM IR from MLIR. The overall flow is two-stage:
conversion of the IR to a set of dialects translatable to LLVM IR, for example LLVM Dialect or one of the hardware-specific dialects derived from LLVM IR intrinsics such as AMX, X86Vector or ArmNeon; translation of MLIR dialects to LLVM IR. This flow allows the non-trivial transformation to be performed within MLIR using MLIR APIs and makes the translation between MLIR and LLVM IR simple and potentially bidirectional.</description></item><item><title>MLIR : Language Server Protocol</title><link>https://mlir.llvm.org/docs/Tools/MLIRLSP/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tools/MLIRLSP/</guid><description>MLIR LSP Language Server : mlir-lsp-server Supporting custom dialects Features PDLL LSP Language Server : mlir-pdll-lsp-server Compilation Database Features TableGen LSP Language Server : tblgen-lsp-server Compilation Database Features Language Server Design Communication and Transport Language Server Protocol Language-Specific Server Editor Plugins Visual Studio Code This document describes the tools and utilities related to supporting LSP IDE language extensions for various MLIR-related languages. An LSP language extension is generally comprised of two components; a language client and a language server.</description></item><item><title>MLIR Bytecode Format</title><link>https://mlir.llvm.org/docs/BytecodeFormat/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/BytecodeFormat/</guid><description>This document describes the MLIR bytecode format and its encoding. This format is versioned and stable: we don&amp;rsquo;t plan to ever break compatibility, that is a dialect should be able to deserialize any older bytecode. Similarly, we support back-deployment so that an older version of the format can be targetted.
That said, it is important to realize that the promises of the bytecode format are made assuming immutable dialects: the format allows backward and forward compatibility, but only when nothing in a dialect changes (operations, types, attributes definitions).</description></item><item><title>MLIR C API</title><link>https://mlir.llvm.org/docs/CAPI/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/CAPI/</guid><description>Current status: Under development, API unstable, built by default.
Design Scope Object Model Naming Convention and Ownership Model Nullity Type Hierarchies Auxiliary Types Printing Common Patterns Indexed Components Iterable Components Extending the API Extensions for Dialect Attributes and Types Extensions for Interfaces Design Many languages can interoperate with C but have a harder time with C++ due to name mangling and memory model differences. Although the C API for MLIR can be used directly from C, it is primarily intended to be wrapped in higher-level language- or library-specific constructs.</description></item><item><title>MLIR Language Reference</title><link>https://mlir.llvm.org/docs/LangRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/LangRef/</guid><description>MLIR (Multi-Level IR) is a compiler intermediate representation with similarities to traditional three-address SSA representations (like LLVM IR or SIL), but which introduces notions from polyhedral loop optimization as first-class concepts. This hybrid design is optimized to represent, analyze, and transform high level dataflow graphs as well as target-specific code generated for high performance data parallel systems. Beyond its representational capabilities, its single continuous design provides a framework to lower from dataflow graphs to high-performance target-specific code.</description></item><item><title>MLIR Python Bindings</title><link>https://mlir.llvm.org/docs/Bindings/Python/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Bindings/Python/</guid><description>Current status: Under development and not enabled by default
Building Pre-requisites CMake variables Recommended development practices Design Use cases Composable modules Submodules Loader Use the C-API Ownership in the Core IR Optionality and argument ordering in the Core IR User-level API Context Management Inspecting IR Objects Creating IR Objects Style Properties vs get*() methods repr methods CamelCase vs snake_case Prefer pseudo-containers Provide one stop helpers for common things Testing Sample FileCheck test Integration with ODS Generating _{DIALECT_NAMESPACE}_ops_gen.</description></item><item><title>MLIR Rationale</title><link>https://mlir.llvm.org/docs/Rationale/Rationale/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/Rationale/</guid><description>This document is intended to capture some of the alternatives considered and open debates in the design of MLIR, along with the rationale for certain decisions we made. This is not intended to be a &amp;ldquo;finely groomed&amp;rdquo; document - we prefer the ability to dump in interesting tidbits without worrying too much about their consistency or readability.
Abstract Introduction and Motivation Design Decisions Loads and stores Symbols and types Block Arguments vs PHI nodes Index type usage and limitations Data layout of non-primitive types Integer signedness semantics Splitting floating point vs integer operations Specifying sign in integer comparison operations Specifying comparison kind as attribute Regions Dialect type extensions Tuple types Assembly forms Examples Non-affine control flow Non-affine loop bounds Reference 2D Convolution Design alternatives and extensions Polyhedral code representation alternatives: schedule lists vs schedules trees vs affine loop/if forms Affine Relations Regions Read/Write/May_Read/May_Write sets for External Functions Memref Extensions affine.</description></item><item><title>MLIR Reduce</title><link>https://mlir.llvm.org/docs/Tools/mlir-reduce/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tools/mlir-reduce/</guid><description>How to Use it Write the script for testing interestingness Available reduction strategies Operation elimination Rewrite patterns into simpler forms Reduce with built-in optimization passes Build a custom mlir-reduce Future works An MLIR input may trigger bugs after series of transformations. To root cause the problem or help verification after fixes, developers want to be able to reduce the size of a reproducer for a bug. This document describes mlir-reduce, which is similar to bugpoint, a tool that can reduce the size of the input needed to trigger the error.</description></item><item><title>MLIR Release Notes</title><link>https://mlir.llvm.org/docs/ReleaseNotes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ReleaseNotes/</guid><description>This document tries to provide some context about MLIR important changes in the context of LLVM releases. It is updated on a best effort basis.
At the moment the MLIR community does not qualify the LLVM release branch specifically, it is a snapshot of the MLIR development at the time of the release.
LLVM 20 LLVM 18 Properties: beyond attributes LLVM 17 Bytecode Properties: beyond attributes Action: Tracing and Debugging MLIR-based Compilers Transform Dialect Others LLVM 20 All the MLIR runners other than mlir-cpu-runner have been removed, as their functionality has been merged into it, and it has been renamed to mlir-runner.</description></item><item><title>mlir-rewrite</title><link>https://mlir.llvm.org/docs/Tools/mlir-rewrite/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tools/mlir-rewrite/</guid><description>Tool to simplify rewriting .mlir files. There are a couple of build in rewrites discussed below along with usage.
Note: This is still in very early stage. Its so early its less a tool than a growing collection of useful functions: to use its best to do what&amp;rsquo;s needed on a brance by just hacking it (dialects registered, rewrites etc) to say help ease a rename, upstream useful utility functions, point to ease others migrating, and then bin eventually.</description></item><item><title>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</title><link>https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/MLIRForGraphAlgorithms/</guid><description>The existing documentation about MLIR focuses on long term vision, how its pieces fit together, and the benefits of modular and composable infrastructure in the vast and distant future. While this viewpoint appeals to some, it causes concern for others who are more concerned about the &amp;ldquo;here and now&amp;rdquo; - why does it make sense to make a &amp;ldquo;revolutionary&amp;rdquo; change when any individual problem can be fixed in place?
This document explains that adoption of MLIR to solve graph based problems isn&amp;rsquo;t a revolutionary change: it is an incremental series of steps which build on each other, each of which delivers local value.</description></item><item><title>MLIR: The case for a simplified polyhedral form</title><link>https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/RationaleSimplifiedPolyhedralForm/</guid><description>MLIR embraces polyhedral compiler techniques for their many advantages representing and transforming dense numerical kernels, but it uses a form that differs significantly from other polyhedral frameworks.
Disclaimer / Warning
This document is a very early design proposal (which has since been accepted) that explored the tradeoffs of using this simplified form vs the traditional polyhedral schedule list form. At some point, this document could be dusted off and written as a proper academic paper, but until now, it is better to included it in this crafty form than not to.</description></item><item><title>ODS Documentation</title><link>https://mlir.llvm.org/docs/Dialects/OpenMPDialect/ODS/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenMPDialect/ODS/</guid><description>Operations omp.allocate_dir (omp::AllocateDirOp) omp.atomic.capture (omp::AtomicCaptureOp) omp.atomic.read (omp::AtomicReadOp) omp.atomic.update (omp::AtomicUpdateOp) omp.atomic.write (omp::AtomicWriteOp) omp.barrier (omp::BarrierOp) omp.cancel (omp::CancelOp) omp.cancellation_point (omp::CancellationPointOp) omp.canonical_loop (omp::CanonicalLoopOp) omp.critical (omp::CriticalOp) omp.critical.declare (omp::CriticalDeclareOp) omp.declare_mapper (omp::DeclareMapperOp) omp.declare_mapper.info (omp::DeclareMapperInfoOp) omp.declare_reduction (omp::DeclareReductionOp) omp.distribute (omp::DistributeOp) omp.flush (omp::FlushOp) omp.loop (omp::LoopOp) omp.loop_nest (omp::LoopNestOp) omp.map.bounds (omp::MapBoundsOp) omp.map.info (omp::MapInfoOp) omp.masked (omp::MaskedOp) omp.master (omp::MasterOp) omp.new_cli (omp::NewCliOp) omp.ordered (omp::OrderedOp) omp.ordered.region (omp::OrderedRegionOp) omp.parallel (omp::ParallelOp) omp.private (omp::PrivateClauseOp) omp.scan (omp::ScanOp) omp.section (omp::SectionOp) omp.sections (omp::SectionsOp) omp.simd (omp::SimdOp) omp.single (omp::SingleOp) omp.target (omp::TargetOp) omp.target_data (omp::TargetDataOp) omp.</description></item><item><title>Operation Canonicalization</title><link>https://mlir.llvm.org/docs/Canonicalization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Canonicalization/</guid><description>Canonicalization is an important part of compiler IR design: it makes it easier to implement reliable compiler transformations and to reason about what is better or worse in the code, and it forces interesting discussions about the goals of a particular level of IR. Dan Gohman wrote an article exploring these issues; it is worth reading if you&amp;rsquo;re not familiar with these concepts.
Most compilers have canonicalization passes, and sometimes they have many different ones (e.</description></item><item><title>Operation Definition Specification (ODS)</title><link>https://mlir.llvm.org/docs/DefiningDialects/Operations/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DefiningDialects/Operations/</guid><description>In addition to specializing the mlir::Op C++ template, MLIR also supports defining operations and data types in a table-driven manner. This is achieved via TableGen, which is both a generic language and its tooling to maintain records of domain-specific information. Facts regarding an operation are specified concisely into a TableGen record, which will be expanded into an equivalent mlir::Op C++ template specialization at compiler build time.
This manual explains in detail all the available mechanisms for defining operations in such a table-driven manner.</description></item><item><title>OpInterface definitions</title><link>https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/</guid><description> MatchOpInterface (MatchOpInterface) Methods:</description></item><item><title>Ownership-based Buffer Deallocation</title><link>https://mlir.llvm.org/docs/OwnershipBasedBufferDeallocation/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/OwnershipBasedBufferDeallocation/</guid><description>Function boundary ABI Inserting bufferization.dealloc operations Supported interfaces Limitations Example Buffer Deallocation Simplification Pass Lower Deallocations Pass Generic Lowering Specialized Lowerings One-Shot Bufferize does not deallocate any buffers that it allocates. After running One-Shot Bufferize, the resulting IR may have a number of memref.alloc ops, but no memref.dealloc ops. Buffer dellocation is delegated to the -ownership-based-buffer-deallocation pass.
On a high level, buffers are &amp;ldquo;owned&amp;rdquo; by a basic block. Ownership materializes as an i1 SSA value and can be thought of as &amp;ldquo;responsibility to deallocate&amp;rdquo;.</description></item><item><title>Pass Infrastructure</title><link>https://mlir.llvm.org/docs/PassManagement/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PassManagement/</guid><description>Operation Pass Op-Agnostic Operation Passes Filtered Operation Pass Operation Pass: Static Schedule Filtering Dependent Dialects Initialization Analysis Management Querying Analyses Preserving Analyses Pass Failure Pass Manager OpPassManager Dynamic Pass Pipelines Instance Specific Pass Options Pass Statistics Pass Registration Pass Pipeline Registration Textual Pass Pipeline Specification Declarative Pass Specification Tablegen Specification Pass Instrumentation Standard Instrumentations Crash and Failure Reproduction Local Reproducer Generation Passes represent the basic infrastructure for transformation and optimization.</description></item><item><title>Passes</title><link>https://mlir.llvm.org/docs/Passes/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Passes/</guid><description>This document describes the available MLIR passes and their contracts.
General Transformation Passes -canonicalize -composite-fixed-point-pass -control-flow-sink -cse -generate-runtime-verification -inline -loop-invariant-code-motion -loop-invariant-subset-hoisting -mem2reg -print-ir -print-op-stats -remove-dead-values -sccp -snapshot-op-locations -sroa -strip-debuginfo -symbol-dce -symbol-privatize -topological-sort -view-op-graph Bufferization Passes -buffer-deallocation-simplification -buffer-hoisting -buffer-loop-hoisting -buffer-results-to-out-params -bufferization-lower-deallocations -drop-equivalent-buffer-results -eliminate-empty-tensors -empty-tensor-to-alloc-tensor -one-shot-bufferize -optimize-allocation-liveness -ownership-based-buffer-deallocation -promote-buffers-to-stack Conversion Passes -arm-neon-2d-to-intr -convert-affine-for-to-gpu -convert-amdgpu-to-rocdl -convert-arith-to-amdgpu -convert-arith-to-arm-sme -convert-arith-to-emitc -convert-arith-to-llvm -convert-arith-to-spirv -convert-arm-sme-to-llvm -convert-arm-sme-to-scf -convert-async-to-llvm -convert-bufferization-to-memref -convert-cf-to-llvm -convert-cf-to-spirv -convert-complex-to-libm -convert-complex-to-llvm -convert-complex-to-rocdl-library-calls -convert-complex-to-spirv -convert-complex-to-standard -convert-func-to-emitc -convert-func-to-llvm -convert-func-to-spirv -convert-gpu-to-llvm-spv -convert-gpu-to-nvvm -convert-gpu-to-rocdl -convert-gpu-to-spirv -convert-index-to-llvm -convert-index-to-spirv -convert-linalg-to-std -convert-math-to-emitc -convert-math-to-funcs -convert-math-to-libm -convert-math-to-llvm -convert-math-to-rocdl -convert-math-to-spirv -convert-memref-to-emitc -convert-memref-to-spirv -convert-nvgpu-to-nvvm -convert-nvvm-to-llvm -convert-openacc-to-scf -convert-openmp-to-llvm -convert-parallel-loops-to-gpu -convert-pdl-to-pdl-interp -convert-scf-to-cf -convert-scf-to-emitc -convert-scf-to-openmp -convert-scf-to-spirv -convert-shape-constraints -convert-shape-to-std -convert-shard-to-mpi -convert-spirv-to-llvm -convert-tensor-to-linalg -convert-tensor-to-spirv -convert-to-emitc -convert-to-llvm -convert-ub-to-llvm -convert-ub-to-spirv -convert-vector-to-arm-sme -convert-vector-to-gpu -convert-vector-to-llvm -convert-vector-to-scf -convert-vector-to-spirv -convert-vector-to-xegpu -convert-xevm-to-llvm -finalize-memref-to-llvm -gpu-to-llvm -lift-cf-to-scf -lower-affine -lower-host-to-llvm -map-memref-spirv-storage-class -reconcile-unrealized-casts -set-llvm-module-datalayout -tosa-to-arith -tosa-to-linalg -tosa-to-linalg-named -tosa-to-mlprogram -tosa-to-scf -tosa-to-tensor &amp;lsquo;acc&amp;rsquo; Dialect Passes -openacc-legalize-data-values &amp;lsquo;affine&amp;rsquo; Dialect Passes -affine-data-copy-generate -affine-expand-index-ops -affine-expand-index-ops-as-affine -affine-loop-coalescing -affine-loop-fusion -affine-loop-invariant-code-motion -affine-loop-normalize -affine-loop-tile -affine-loop-unroll -affine-loop-unroll-jam -affine-parallelize -affine-pipeline-data-transfer -affine-raise-from-memref -affine-scalrep -affine-simplify-min-max -affine-simplify-structures -affine-super-vectorize &amp;lsquo;amdgpu&amp;rsquo; Dialect Passes -amdgpu-emulate-atomics -amdgpu-fold-memrefs-ops -amdgpu-maskedload-to-load -amdgpu-resolve-strided-metadata &amp;lsquo;arith&amp;rsquo; Dialect Passes -arith-emulate-unsupported-floats -arith-emulate-wide-int -arith-expand -arith-int-range-narrowing -arith-unsigned-when-equivalent -int-range-optimizations &amp;lsquo;arm_sme&amp;rsquo; Dialect Passes -arm-sme-outer-product-fusion -arm-sme-vector-legalization -enable-arm-streaming -test-arm-sme-tile-allocation &amp;lsquo;arm_sve&amp;rsquo; Dialect Passes -arm-sve-legalize-vector-storage &amp;lsquo;async&amp;rsquo; Dialect Passes -async-func-to-async-runtime -async-parallel-for -async-runtime-policy-based-ref-counting -async-runtime-ref-counting -async-runtime-ref-counting-opt -async-to-async-runtime &amp;rsquo;emitc&amp;rsquo; Dialect Passes -form-expressions -wrap-emitc-func-in-class &amp;lsquo;func&amp;rsquo; Dialect Passes -duplicate-function-elimination &amp;lsquo;gpu&amp;rsquo; Dialect Passes -gpu-async-region -gpu-decompose-memrefs -gpu-eliminate-barriers -gpu-kernel-outlining -gpu-launch-sink-index-computations -gpu-map-parallel-loops -gpu-module-to-binary -nvvm-attach-target -rocdl-attach-target -spirv-attach-target -xevm-attach-target &amp;rsquo;linalg&amp;rsquo; Dialect Passes -convert-elementwise-to-linalg -convert-linalg-to-affine-loops -convert-linalg-to-loops -convert-linalg-to-parallel-loops -linalg-block-pack-matmul -linalg-detensorize -linalg-fold-into-elementwise -linalg-fold-unit-extent-dims -linalg-fuse-elementwise-ops -linalg-generalize-named-ops -linalg-inline-scalar-operands -linalg-named-op-conversion -linalg-specialize-generic-ops &amp;rsquo;llvm&amp;rsquo; Dialect Passes -ensure-debug-info-scope-on-llvm-func -llvm-add-comdats -llvm-legalize-for-export -llvm-optimize-for-nvvm-target -llvm-request-c-wrappers &amp;lsquo;math&amp;rsquo; Dialect Passes -math-extend-to-supported-types -math-uplift-to-fma &amp;lsquo;memref&amp;rsquo; Dialect Passes -expand-realloc -expand-strided-metadata -flatten-memref -fold-memref-alias-ops -memref-emulate-wide-int -memref-expand -normalize-memrefs -reify-result-shapes -resolve-ranked-shaped-type-result-dims -resolve-shaped-type-result-dims &amp;lsquo;shard&amp;rsquo; Dialect Passes -shard-partition -sharding-propagation &amp;lsquo;ml_program&amp;rsquo; Dialect Passes -mlprogram-pipeline-globals &amp;rsquo;nvgpu&amp;rsquo; Dialect Passes -nvgpu-optimize-shared-memory &amp;lsquo;quant&amp;rsquo; Dialect Passes -lower-quant-ops -normalize-quant-types -strip-func-quant-types Reducer Passes -opt-reduction-pass -reduction-tree &amp;lsquo;scf&amp;rsquo; Dialect Passes -scf-for-loop-canonicalization -scf-for-loop-peeling -scf-for-loop-range-folding -scf-for-loop-specialization -scf-for-to-while -scf-forall-to-for -scf-forall-to-parallel -scf-if-condition-propagation -scf-parallel-loop-fusion -scf-parallel-loop-specialization -scf-parallel-loop-tiling -test-scf-parallel-loop-collapsing &amp;lsquo;shape&amp;rsquo; Dialect Passes -outline-shape-computation -remove-shape-constraints -shape-to-shape-lowering &amp;lsquo;sparse_tensor&amp;rsquo; Dialect Passes -lower-sparse-foreach-to-scf -lower-sparse-iteration-to-scf -lower-sparse-ops-to-foreach -pre-sparsification-rewrite -sparse-assembler -sparse-buffer-rewrite -sparse-gpu-codegen -sparse-reinterpret-map -sparse-space-collapse -sparse-storage-specifier-to-llvm -sparse-tensor-codegen -sparse-tensor-conversion -sparse-vectorization -sparsification -sparsification-and-bufferization -stage-sparse-ops &amp;lsquo;spv&amp;rsquo; Dialect Passes -decorate-spirv-composite-type-layout -spirv-canonicalize-gl -spirv-lower-abi-attrs -spirv-promote-to-replicated-constants -spirv-rewrite-inserts -spirv-unify-aliased-resource -spirv-update-vce -spirv-webgpu-prepare &amp;rsquo;tensor&amp;rsquo; Dialect Passes -fold-tensor-subset-ops &amp;rsquo;transform&amp;rsquo; Dialect Passes -transform-dialect-check-uses -transform-infer-effects -transform-interpreter -transform-preload-library &amp;lsquo;vector&amp;rsquo; Dialect Passes -lower-vector-mask -lower-vector-multi-reduction -lower-vector-to-from-elements-to-shuffle-tree TOSA Dialect Passes -tosa-convert-integer-type-to-signless -tosa-infer-shapes -tosa-layerwise-constant-fold -tosa-make-broadcastable -tosa-optional-decompositions -tosa-reduce-transposes -tosa-validate XeGPU Dialect Passes -xegpu-blocking -xegpu-fold-alias-ops -xegpu-propagate-layout -xegpu-subgroup-distribute -xegpu-wg-to-sg-distribute General Transformation Passes -canonicalize Canonicalize operations</description></item><item><title>Pattern Rewriting : Generic DAG-to-DAG Rewriting</title><link>https://mlir.llvm.org/docs/PatternRewriter/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PatternRewriter/</guid><description>Introduction Defining Patterns Benefit Root Operation Name (Optional) matchAndRewrite implementation Application Recursion Debug Names and Labels Initialization Construction Pattern Rewriter Pattern Application Common Pattern Drivers Dialect Conversion Driver Walk Pattern Rewrite Driver Greedy Pattern Rewrite Driver Debugging Pattern Filtering Common Pass Utilities This document details the design and API of the pattern rewriting infrastructure present in MLIR, a general DAG-to-DAG transformation framework. This framework is widely used throughout MLIR for canonicalization, conversion, and general transformation.</description></item><item><title>PDLL - PDL Language</title><link>https://mlir.llvm.org/docs/PDLL/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/PDLL/</guid><description>This document details the PDL Language (PDLL), a custom frontend language for writing pattern rewrites targeting MLIR.
Note: This document assumes a familiarity with MLIR concepts; more specifically the concepts detailed within the MLIR Pattern Rewriting and Operation Definition Specification (ODS) documentation.
Introduction Rationale Why build a new language instead of improving TableGen DRR? Why not build a DSL in &amp;ldquo;X&amp;rdquo;? Language Specification Includes Patterns Variables Operation Expression Attribute Expression Type Expression Tuples Constraints Rewriters Introduction Pattern matching is an extremely important component within MLIR, as it encompasses many different facets of the compiler.</description></item><item><title>Quantization</title><link>https://mlir.llvm.org/docs/Quantization/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Quantization/</guid><description>This document outlines the design of the MLIR quantization system. While the term &amp;ldquo;quantization&amp;rdquo; is highly overloaded, in this case, it refers to a fairly narrow scope of techniques in use to enable conversion of floating-point computations to corresponding and plausible variants expressed in integer math for inference, as has historically been supported by low-bit depth inference engines such as TFLite, various accelerator hardware, and many DSPs.
Much of this is inspired by the approach taken in this paper with many extensions and adaptations folded in.</description></item><item><title>Quickstart tutorial to adding MLIR graph rewrite</title><link>https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/QuickstartRewrites/</guid><description>This document will present a quickstart to adding graph rewrites. We shall start by defining an operation, showing multiple ways to define the rewrite using patterns, as well as defining the rewrite using a graph walker (note: using patterns and the rewrite engine is preferred, showing the walker is for demonstration purposes).
See MLIR specification for more information about MLIR, the structure of the IR, operations, etc. See Table-driven Operation Definition and Declarative Rewrite Rule for the detailed explanation of all available mechanisms for defining operations and rewrites in a table-driven manner.</description></item><item><title>Shape Inference</title><link>https://mlir.llvm.org/docs/ShapeInference/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/ShapeInference/</guid><description>Shape inference as discussed here is considered a specific instance of type inference for ShapedType. Type constraints are along (at least) three axis: 1) elemental type, 2) rank (including static or dynamic), 3) dimensions. While some operations have no compile time fixed shape (e.g., output shape is dictated by data) we could still have some knowledge of constraints/bounds in the system for that operation (e.g., the output of a tf.where is at most the size of the input data).</description></item><item><title>Side Effects &amp; Speculation</title><link>https://mlir.llvm.org/docs/Rationale/SideEffectsAndSpeculation/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/SideEffectsAndSpeculation/</guid><description>This document outlines how MLIR models side effects and how speculation works in MLIR.
This rationale only applies to operations used in CFG regions. Side effect modeling in graph regions is TBD.
Overview Categorization Modeling Examples SIMD compute operation Load like operation Overview Many MLIR operations don&amp;rsquo;t exhibit any behavior other than consuming and producing SSA values. These operations can be reordered with other operations as long as they obey SSA dominance requirements and can be eliminated or even introduced (e.</description></item><item><title>SPIR-V Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SPIR-V/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SPIR-V/</guid><description>This document describes the design of the SPIR-V dialect in MLIR. It lists various design choices we made for modeling different SPIR-V mechanisms, and their rationale.
This document also explains in a high-level manner how different components are organized and implemented in the code and gives steps to follow for extending them.
This document assumes familiarity with SPIR-V. SPIR-V is the Khronos Group’s binary intermediate language for representing graphics shaders and compute kernels.</description></item><item><title>SPIR-V Dialect to LLVM Dialect conversion manual</title><link>https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/SPIRVToLLVMDialectConversion/</guid><description>This manual describes the conversion from SPIR-V Dialect to LLVM Dialect. It assumes familiarity with both, and describes the design choices behind the modelling of SPIR-V concepts in LLVM Dialect. The conversion is an ongoing work, and is expected to grow as more features are implemented.
Conversion can be performed by invoking an appropriate conversion pass:
mlir-opt -convert-spirv-to-llvm &amp;lt;filename.mlir&amp;gt; This pass performs type and operation conversions for SPIR-V operations as described in this document.</description></item><item><title>Symbols and Symbol Tables</title><link>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/SymbolsAndSymbolTables/</guid><description>Symbol Defining or declaring a Symbol Symbol Table Referencing a Symbol Manipulating a Symbol Symbol Visibility With Regions, the multi-level aspect of MLIR is structural in the IR. A lot of infrastructure within the compiler is built around this nesting structure; including the processing of operations within the pass manager. One advantage of the MLIR design is that it is able to process operations in parallel, utilizing multiple threads. This is possible due to a property of the IR known as IsolatedFromAbove.</description></item><item><title>Table-driven Declarative Rewrite Rule (DRR)</title><link>https://mlir.llvm.org/docs/DeclarativeRewrites/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/DeclarativeRewrites/</guid><description>In addition to subclassing the mlir::RewritePattern C++ class, MLIR also supports defining rewrite rules in a declarative manner. Similar to Op Definition Specification (ODS), this is achieved via TableGen, which is a language to maintain records of domain-specific information. The rewrite rules are specified concisely in a TableGen record, which will be expanded into an equivalent mlir::RewritePattern subclass at compiler build time.
This manual explains in detail all of the available mechanisms for defining rewrite rules in such a declarative manner.</description></item><item><title>Tensor Operator Set Architecture (TOSA) Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TOSA/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TOSA/</guid><description>Rationale TOSA and Tensor Level Expressiveness Complete Minimal Numerical Precision TOSA Operator Rationale COND_IF and WHILE_LOOP Using TOSA In A Compiler Quantization Parameters in Ops vs Tensors Operation definitions tosa.abs (mlir::tosa::AbsOp) tosa.add (mlir::tosa::AddOp) tosa.apply_scale (mlir::tosa::ApplyScaleOp) tosa.argmax (mlir::tosa::ArgMaxOp) tosa.arithmetic_right_shift (mlir::tosa::ArithmeticRightShiftOp) tosa.avg_pool2d (mlir::tosa::AvgPool2dOp) tosa.bitwise_and (mlir::tosa::BitwiseAndOp) tosa.bitwise_not (mlir::tosa::BitwiseNotOp) tosa.bitwise_or (mlir::tosa::BitwiseOrOp) tosa.bitwise_xor (mlir::tosa::BitwiseXorOp) tosa.cast (mlir::tosa::CastOp) tosa.ceil (mlir::tosa::CeilOp) tosa.clamp (mlir::tosa::ClampOp) tosa.clz (mlir::tosa::ClzOp) tosa.concat (mlir::tosa::ConcatOp) tosa.const (mlir::tosa::ConstOp) tosa.const_shape (mlir::tosa::ConstShapeOp) tosa.conv2d (mlir::tosa::Conv2DOp) tosa.conv3d (mlir::tosa::Conv3DOp) tosa.cos (mlir::tosa::CosOp) tosa.</description></item><item><title>The `Broadcastable` Trait</title><link>https://mlir.llvm.org/docs/Traits/Broadcastable/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Traits/Broadcastable/</guid><description>Description Dimension inference Shape inference Verification Examples Description The Broadcastable trait enforces the following properties on an operation:
The operation has at least one input operand.
The operation has exactly one result.
All input operands and result are of type tensor or vector.
A shape inference mechanism is able to compute the result shape solely based on input operand shapes.
Input operands have broadcast-compatible shapes, according to the verification rules presented below.</description></item><item><title>Transform Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Transform/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Transform/</guid><description>Fine-grain transformation control dialect. See tutorial for more introductory information.
Overview Dialect Extension Mechanism Side Effects Execution Model Handle Invalidation Intended Use and Integrations Effects on the Infrastructure Type Definitions AffineMapParamType AnyOpType AnyParamType AnyValueType OperationType ParamType TypeParamType Core Operations transform.alternatives (transform::AlternativesOp) transform.annotate (transform::AnnotateOp) transform.apply_patterns.canonicalization (transform::ApplyCanonicalizationPatternsOp) transform.apply_cse (transform::ApplyCommonSubexpressionEliminationOp) transform.apply_conversion_patterns (transform::ApplyConversionPatternsOp) transform.apply_dce (transform::ApplyDeadCodeEliminationOp) transform.apply_licm (transform::ApplyLoopInvariantCodeMotionOp) transform.apply_patterns (transform::ApplyPatternsOp) transform.apply_registered_pass (transform::ApplyRegisteredPassOp) transform.apply_conversion_patterns.dialect_to_llvm (transform::ApplyToLLVMConversionPatternsOp) transform.cast (transform::CastOp) transform.collect_matching (transform::CollectMatchingOp) transform.foreach_match (transform::ForeachMatchOp) transform.foreach (transform::ForeachOp) transform.get_consumers_of_result (transform::GetConsumersOfResult) transform.get_defining_op (transform::GetDefiningOp) transform.</description></item><item><title>Understanding the IR Structure</title><link>https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/UnderstandingTheIRStructure/</guid><description>The MLIR Language Reference describes the High Level Structure, this document illustrates this structure through examples, and introduces at the same time the C++ APIs involved in manipulating it.
We will implement a pass that traverses any MLIR input and prints the entity inside the IR. A pass (or in general almost any piece of IR) is always rooted with an operation. Most of the time the top-level operation is a ModuleOp, the MLIR PassManager is actually limited to operation on a top-level ModuleOp.</description></item><item><title>Usage of 'const' in MLIR, for core IR types</title><link>https://mlir.llvm.org/docs/Rationale/UsageOfConst/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Rationale/UsageOfConst/</guid><description>aka, where&amp;rsquo;d const go?
The MLIR data structures that represent the IR itself (Instruction, Block, etc) form a graph-based data structure, and the compiler analyses and passes frequently walk this graph (e.g. traversing from defs to users). The early design of MLIR adopted the const model of LLVM, which is familiar and well understood (even though the LLVM implementation is flawed in many ways).
The design team since decided to change to a different model, which eschews const entirely for the core IR types: you should never see a const method on Operation, should never see the type const Value, and you shouldn&amp;rsquo;t feel bad about this.</description></item><item><title>Using `mlir-opt`</title><link>https://mlir.llvm.org/docs/Tutorials/MlirOpt/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/MlirOpt/</guid><description>mlir-opt is a command-line entry point for running passes and lowerings on MLIR code. This tutorial will explain how to use mlir-opt, show some examples of its usage, and mention some useful tips for working with it.
Prerequisites:
Building MLIR from source MLIR Language Reference mlir-opt basics Running a pass Running a pass with options Building a pass pipeline on the command line Useful CLI flags Further readering mlir-opt basics The mlir-opt tool loads a textual IR or bytecode into an in-memory structure, and optionally executes a sequence of passes before serializing back the IR (textual form by default).</description></item><item><title>Writing DataFlow Analyses in MLIR</title><link>https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Tutorials/DataFlowAnalysis/</guid><description>Writing dataflow analyses in MLIR, or well any compiler, can often seem quite daunting and/or complex. A dataflow analysis generally involves propagating information about the IR across various different types of control flow constructs, of which MLIR has many (Block-based branches, Region-based branches, CallGraph, etc), and it isn&amp;rsquo;t always clear how best to go about performing the propagation. To help writing these types of analyses in MLIR, this document details several utilities that simplify the process and make it a bit more approachable.</description></item></channel></rss>